{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 25000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004,
      "grad_norm": 0.7697810530662537,
      "learning_rate": 9e-07,
      "loss": 0.7331,
      "step": 10
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.6812847852706909,
      "learning_rate": 1.9e-06,
      "loss": 0.732,
      "step": 20
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.9064974188804626,
      "learning_rate": 2.9e-06,
      "loss": 0.7311,
      "step": 30
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.5379857420921326,
      "learning_rate": 3.9e-06,
      "loss": 0.7336,
      "step": 40
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7898451685905457,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 0.7371,
      "step": 50
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.7612894773483276,
      "learning_rate": 5.9e-06,
      "loss": 0.7373,
      "step": 60
    },
    {
      "epoch": 0.028,
      "grad_norm": 1.177695393562317,
      "learning_rate": 6.900000000000001e-06,
      "loss": 0.7328,
      "step": 70
    },
    {
      "epoch": 0.032,
      "grad_norm": 1.0202298164367676,
      "learning_rate": 7.9e-06,
      "loss": 0.7264,
      "step": 80
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.8124881982803345,
      "learning_rate": 8.9e-06,
      "loss": 0.7266,
      "step": 90
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6152690649032593,
      "learning_rate": 9.900000000000002e-06,
      "loss": 0.7312,
      "step": 100
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.7541699409484863,
      "learning_rate": 1.09e-05,
      "loss": 0.7307,
      "step": 110
    },
    {
      "epoch": 0.048,
      "grad_norm": 1.14076828956604,
      "learning_rate": 1.19e-05,
      "loss": 0.7219,
      "step": 120
    },
    {
      "epoch": 0.052,
      "grad_norm": 1.0257019996643066,
      "learning_rate": 1.29e-05,
      "loss": 0.7263,
      "step": 130
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.489273339509964,
      "learning_rate": 1.3900000000000002e-05,
      "loss": 0.721,
      "step": 140
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5663928389549255,
      "learning_rate": 1.49e-05,
      "loss": 0.7173,
      "step": 150
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.764143705368042,
      "learning_rate": 1.59e-05,
      "loss": 0.7109,
      "step": 160
    },
    {
      "epoch": 0.068,
      "grad_norm": 0.895918607711792,
      "learning_rate": 1.69e-05,
      "loss": 0.7096,
      "step": 170
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.7890273928642273,
      "learning_rate": 1.79e-05,
      "loss": 0.7104,
      "step": 180
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.6019591689109802,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 0.7022,
      "step": 190
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7503159046173096,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.7025,
      "step": 200
    },
    {
      "epoch": 0.084,
      "grad_norm": 0.5061823129653931,
      "learning_rate": 2.09e-05,
      "loss": 0.6976,
      "step": 210
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.7508589029312134,
      "learning_rate": 2.19e-05,
      "loss": 0.6938,
      "step": 220
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.8883190751075745,
      "learning_rate": 2.29e-05,
      "loss": 0.692,
      "step": 230
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.9832471013069153,
      "learning_rate": 2.39e-05,
      "loss": 0.6851,
      "step": 240
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7308040857315063,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 0.6806,
      "step": 250
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.8726274967193604,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 0.6764,
      "step": 260
    },
    {
      "epoch": 0.108,
      "grad_norm": 0.9063210487365723,
      "learning_rate": 2.6900000000000003e-05,
      "loss": 0.6673,
      "step": 270
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.7648795247077942,
      "learning_rate": 2.7900000000000004e-05,
      "loss": 0.6624,
      "step": 280
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.6220275163650513,
      "learning_rate": 2.8899999999999998e-05,
      "loss": 0.6588,
      "step": 290
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4374566674232483,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 0.6609,
      "step": 300
    },
    {
      "epoch": 0.124,
      "grad_norm": 0.7505306601524353,
      "learning_rate": 3.09e-05,
      "loss": 0.6508,
      "step": 310
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.8537880182266235,
      "learning_rate": 3.19e-05,
      "loss": 0.6422,
      "step": 320
    },
    {
      "epoch": 0.132,
      "grad_norm": 0.8739173412322998,
      "learning_rate": 3.29e-05,
      "loss": 0.6439,
      "step": 330
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.8737408518791199,
      "learning_rate": 3.3900000000000004e-05,
      "loss": 0.6353,
      "step": 340
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7512641549110413,
      "learning_rate": 3.49e-05,
      "loss": 0.6166,
      "step": 350
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.6419945955276489,
      "learning_rate": 3.59e-05,
      "loss": 0.6142,
      "step": 360
    },
    {
      "epoch": 0.148,
      "grad_norm": 1.0373624563217163,
      "learning_rate": 3.69e-05,
      "loss": 0.6181,
      "step": 370
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.5789099931716919,
      "learning_rate": 3.79e-05,
      "loss": 0.6078,
      "step": 380
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.40354108810424805,
      "learning_rate": 3.8900000000000004e-05,
      "loss": 0.5975,
      "step": 390
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0103334188461304,
      "learning_rate": 3.99e-05,
      "loss": 0.6068,
      "step": 400
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.5720890760421753,
      "learning_rate": 4.09e-05,
      "loss": 0.6093,
      "step": 410
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.8213599920272827,
      "learning_rate": 4.19e-05,
      "loss": 0.6054,
      "step": 420
    },
    {
      "epoch": 0.172,
      "grad_norm": 0.6895438432693481,
      "learning_rate": 4.29e-05,
      "loss": 0.5556,
      "step": 430
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.8878390192985535,
      "learning_rate": 4.39e-05,
      "loss": 0.5586,
      "step": 440
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.016960859298706,
      "learning_rate": 4.49e-05,
      "loss": 0.5676,
      "step": 450
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.697162926197052,
      "learning_rate": 4.5900000000000004e-05,
      "loss": 0.513,
      "step": 460
    },
    {
      "epoch": 0.188,
      "grad_norm": 0.5834737420082092,
      "learning_rate": 4.69e-05,
      "loss": 0.5251,
      "step": 470
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.4977843761444092,
      "learning_rate": 4.79e-05,
      "loss": 0.5415,
      "step": 480
    },
    {
      "epoch": 0.196,
      "grad_norm": 0.4714505076408386,
      "learning_rate": 4.89e-05,
      "loss": 0.5113,
      "step": 490
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9790632128715515,
      "learning_rate": 4.99e-05,
      "loss": 0.4946,
      "step": 500
    },
    {
      "epoch": 0.204,
      "grad_norm": 0.7298562526702881,
      "learning_rate": 4.998163265306123e-05,
      "loss": 0.4984,
      "step": 510
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.4274635910987854,
      "learning_rate": 4.996122448979592e-05,
      "loss": 0.4942,
      "step": 520
    },
    {
      "epoch": 0.212,
      "grad_norm": 0.40751174092292786,
      "learning_rate": 4.994081632653062e-05,
      "loss": 0.5219,
      "step": 530
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.47457078099250793,
      "learning_rate": 4.992040816326531e-05,
      "loss": 0.4667,
      "step": 540
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6494867205619812,
      "learning_rate": 4.99e-05,
      "loss": 0.5017,
      "step": 550
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.6666867136955261,
      "learning_rate": 4.98795918367347e-05,
      "loss": 0.4679,
      "step": 560
    },
    {
      "epoch": 0.228,
      "grad_norm": 0.8728222250938416,
      "learning_rate": 4.985918367346939e-05,
      "loss": 0.4627,
      "step": 570
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.5936099886894226,
      "learning_rate": 4.983877551020408e-05,
      "loss": 0.4917,
      "step": 580
    },
    {
      "epoch": 0.236,
      "grad_norm": 0.8328299522399902,
      "learning_rate": 4.981836734693878e-05,
      "loss": 0.5017,
      "step": 590
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4992597997188568,
      "learning_rate": 4.979795918367347e-05,
      "loss": 0.5103,
      "step": 600
    },
    {
      "epoch": 0.244,
      "grad_norm": 0.43190518021583557,
      "learning_rate": 4.977755102040816e-05,
      "loss": 0.5076,
      "step": 610
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.5831543207168579,
      "learning_rate": 4.9757142857142855e-05,
      "loss": 0.4117,
      "step": 620
    },
    {
      "epoch": 0.252,
      "grad_norm": 0.9921285510063171,
      "learning_rate": 4.973673469387755e-05,
      "loss": 0.4062,
      "step": 630
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.37721940875053406,
      "learning_rate": 4.9716326530612245e-05,
      "loss": 0.4743,
      "step": 640
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5588148236274719,
      "learning_rate": 4.9695918367346936e-05,
      "loss": 0.5086,
      "step": 650
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.6644742488861084,
      "learning_rate": 4.9675510204081634e-05,
      "loss": 0.4598,
      "step": 660
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.7403234839439392,
      "learning_rate": 4.965510204081633e-05,
      "loss": 0.4557,
      "step": 670
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.508813738822937,
      "learning_rate": 4.9634693877551024e-05,
      "loss": 0.4148,
      "step": 680
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.41641736030578613,
      "learning_rate": 4.9614285714285716e-05,
      "loss": 0.4226,
      "step": 690
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.47177237272262573,
      "learning_rate": 4.9593877551020414e-05,
      "loss": 0.4498,
      "step": 700
    },
    {
      "epoch": 0.284,
      "grad_norm": 0.4158409833908081,
      "learning_rate": 4.9573469387755106e-05,
      "loss": 0.4787,
      "step": 710
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.5033431053161621,
      "learning_rate": 4.95530612244898e-05,
      "loss": 0.4952,
      "step": 720
    },
    {
      "epoch": 0.292,
      "grad_norm": 0.658061683177948,
      "learning_rate": 4.9532653061224496e-05,
      "loss": 0.3894,
      "step": 730
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.5476710796356201,
      "learning_rate": 4.951224489795919e-05,
      "loss": 0.4778,
      "step": 740
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.9261690974235535,
      "learning_rate": 4.949183673469388e-05,
      "loss": 0.483,
      "step": 750
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.41573506593704224,
      "learning_rate": 4.947142857142858e-05,
      "loss": 0.4835,
      "step": 760
    },
    {
      "epoch": 0.308,
      "grad_norm": 0.4056008458137512,
      "learning_rate": 4.945102040816327e-05,
      "loss": 0.4233,
      "step": 770
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.5622342824935913,
      "learning_rate": 4.943061224489796e-05,
      "loss": 0.3849,
      "step": 780
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.49712955951690674,
      "learning_rate": 4.941020408163265e-05,
      "loss": 0.4533,
      "step": 790
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4068370461463928,
      "learning_rate": 4.938979591836735e-05,
      "loss": 0.507,
      "step": 800
    },
    {
      "epoch": 0.324,
      "grad_norm": 0.48114660382270813,
      "learning_rate": 4.936938775510204e-05,
      "loss": 0.4218,
      "step": 810
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.6382448673248291,
      "learning_rate": 4.9348979591836734e-05,
      "loss": 0.4319,
      "step": 820
    },
    {
      "epoch": 0.332,
      "grad_norm": 0.40320149064064026,
      "learning_rate": 4.932857142857143e-05,
      "loss": 0.4027,
      "step": 830
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.444858193397522,
      "learning_rate": 4.9308163265306124e-05,
      "loss": 0.4917,
      "step": 840
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.9591939449310303,
      "learning_rate": 4.9287755102040815e-05,
      "loss": 0.5035,
      "step": 850
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.3977522552013397,
      "learning_rate": 4.9267346938775514e-05,
      "loss": 0.4575,
      "step": 860
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.9478625655174255,
      "learning_rate": 4.9246938775510205e-05,
      "loss": 0.4666,
      "step": 870
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.5622704029083252,
      "learning_rate": 4.92265306122449e-05,
      "loss": 0.4593,
      "step": 880
    },
    {
      "epoch": 0.356,
      "grad_norm": 0.47932904958724976,
      "learning_rate": 4.9206122448979595e-05,
      "loss": 0.3943,
      "step": 890
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.41525954008102417,
      "learning_rate": 4.9185714285714293e-05,
      "loss": 0.4091,
      "step": 900
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.4480758011341095,
      "learning_rate": 4.9165306122448985e-05,
      "loss": 0.3994,
      "step": 910
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.421000212430954,
      "learning_rate": 4.914489795918368e-05,
      "loss": 0.4296,
      "step": 920
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.4085622727870941,
      "learning_rate": 4.912448979591837e-05,
      "loss": 0.4037,
      "step": 930
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.41222473978996277,
      "learning_rate": 4.9104081632653067e-05,
      "loss": 0.3738,
      "step": 940
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4584733247756958,
      "learning_rate": 4.908367346938776e-05,
      "loss": 0.3851,
      "step": 950
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.4137515425682068,
      "learning_rate": 4.906326530612245e-05,
      "loss": 0.4389,
      "step": 960
    },
    {
      "epoch": 0.388,
      "grad_norm": 0.5249487161636353,
      "learning_rate": 4.904285714285715e-05,
      "loss": 0.4064,
      "step": 970
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.46890488266944885,
      "learning_rate": 4.902244897959184e-05,
      "loss": 0.4028,
      "step": 980
    },
    {
      "epoch": 0.396,
      "grad_norm": 0.41262805461883545,
      "learning_rate": 4.900204081632653e-05,
      "loss": 0.4049,
      "step": 990
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6264034509658813,
      "learning_rate": 4.898163265306123e-05,
      "loss": 0.3653,
      "step": 1000
    },
    {
      "epoch": 0.404,
      "grad_norm": 0.4752362072467804,
      "learning_rate": 4.896122448979592e-05,
      "loss": 0.4656,
      "step": 1010
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.41449132561683655,
      "learning_rate": 4.894081632653061e-05,
      "loss": 0.3501,
      "step": 1020
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.6967061161994934,
      "learning_rate": 4.8920408163265304e-05,
      "loss": 0.4617,
      "step": 1030
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.6669502854347229,
      "learning_rate": 4.89e-05,
      "loss": 0.3778,
      "step": 1040
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5696307420730591,
      "learning_rate": 4.8879591836734694e-05,
      "loss": 0.4491,
      "step": 1050
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.41641971468925476,
      "learning_rate": 4.8859183673469386e-05,
      "loss": 0.3453,
      "step": 1060
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.47719672322273254,
      "learning_rate": 4.8838775510204084e-05,
      "loss": 0.3387,
      "step": 1070
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.5226959586143494,
      "learning_rate": 4.8818367346938776e-05,
      "loss": 0.3139,
      "step": 1080
    },
    {
      "epoch": 0.436,
      "grad_norm": 1.1345213651657104,
      "learning_rate": 4.879795918367347e-05,
      "loss": 0.4353,
      "step": 1090
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.43496885895729065,
      "learning_rate": 4.8777551020408166e-05,
      "loss": 0.3469,
      "step": 1100
    },
    {
      "epoch": 0.444,
      "grad_norm": 0.41997289657592773,
      "learning_rate": 4.875714285714286e-05,
      "loss": 0.3839,
      "step": 1110
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.8246904611587524,
      "learning_rate": 4.8736734693877556e-05,
      "loss": 0.3375,
      "step": 1120
    },
    {
      "epoch": 0.452,
      "grad_norm": 0.5797945857048035,
      "learning_rate": 4.871632653061225e-05,
      "loss": 0.451,
      "step": 1130
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.5737354159355164,
      "learning_rate": 4.8695918367346946e-05,
      "loss": 0.3856,
      "step": 1140
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6783115863800049,
      "learning_rate": 4.867551020408164e-05,
      "loss": 0.4216,
      "step": 1150
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.44437330961227417,
      "learning_rate": 4.865510204081633e-05,
      "loss": 0.3804,
      "step": 1160
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.46255940198898315,
      "learning_rate": 4.863469387755103e-05,
      "loss": 0.3878,
      "step": 1170
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.4414327144622803,
      "learning_rate": 4.861428571428572e-05,
      "loss": 0.4403,
      "step": 1180
    },
    {
      "epoch": 0.476,
      "grad_norm": 0.569471001625061,
      "learning_rate": 4.859387755102041e-05,
      "loss": 0.4037,
      "step": 1190
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6377344131469727,
      "learning_rate": 4.85734693877551e-05,
      "loss": 0.4095,
      "step": 1200
    },
    {
      "epoch": 0.484,
      "grad_norm": 0.6130297780036926,
      "learning_rate": 4.85530612244898e-05,
      "loss": 0.3456,
      "step": 1210
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.484546035528183,
      "learning_rate": 4.853265306122449e-05,
      "loss": 0.3968,
      "step": 1220
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.4734611511230469,
      "learning_rate": 4.8512244897959184e-05,
      "loss": 0.4104,
      "step": 1230
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.5228158235549927,
      "learning_rate": 4.849183673469388e-05,
      "loss": 0.3653,
      "step": 1240
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6019365787506104,
      "learning_rate": 4.8471428571428573e-05,
      "loss": 0.351,
      "step": 1250
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.40045154094696045,
      "learning_rate": 4.8451020408163265e-05,
      "loss": 0.3927,
      "step": 1260
    },
    {
      "epoch": 0.508,
      "grad_norm": 0.4467950761318207,
      "learning_rate": 4.8430612244897963e-05,
      "loss": 0.4129,
      "step": 1270
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.5398936867713928,
      "learning_rate": 4.8410204081632655e-05,
      "loss": 0.3425,
      "step": 1280
    },
    {
      "epoch": 0.516,
      "grad_norm": 0.6570366024971008,
      "learning_rate": 4.8389795918367347e-05,
      "loss": 0.3522,
      "step": 1290
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5175599455833435,
      "learning_rate": 4.836938775510204e-05,
      "loss": 0.3252,
      "step": 1300
    },
    {
      "epoch": 0.524,
      "grad_norm": 0.5468971729278564,
      "learning_rate": 4.8348979591836737e-05,
      "loss": 0.3687,
      "step": 1310
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.4935145378112793,
      "learning_rate": 4.832857142857143e-05,
      "loss": 0.3892,
      "step": 1320
    },
    {
      "epoch": 0.532,
      "grad_norm": 0.49485906958580017,
      "learning_rate": 4.830816326530612e-05,
      "loss": 0.3762,
      "step": 1330
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.47237464785575867,
      "learning_rate": 4.828775510204082e-05,
      "loss": 0.3844,
      "step": 1340
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.46487537026405334,
      "learning_rate": 4.8267346938775516e-05,
      "loss": 0.3629,
      "step": 1350
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.4510769546031952,
      "learning_rate": 4.824693877551021e-05,
      "loss": 0.3782,
      "step": 1360
    },
    {
      "epoch": 0.548,
      "grad_norm": 0.3746258020401001,
      "learning_rate": 4.82265306122449e-05,
      "loss": 0.3571,
      "step": 1370
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.678268551826477,
      "learning_rate": 4.82061224489796e-05,
      "loss": 0.353,
      "step": 1380
    },
    {
      "epoch": 0.556,
      "grad_norm": 0.44448786973953247,
      "learning_rate": 4.818571428571429e-05,
      "loss": 0.2795,
      "step": 1390
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4837326407432556,
      "learning_rate": 4.816530612244898e-05,
      "loss": 0.3251,
      "step": 1400
    },
    {
      "epoch": 0.564,
      "grad_norm": 0.49856895208358765,
      "learning_rate": 4.814489795918368e-05,
      "loss": 0.4101,
      "step": 1410
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.40160802006721497,
      "learning_rate": 4.812448979591837e-05,
      "loss": 0.3074,
      "step": 1420
    },
    {
      "epoch": 0.572,
      "grad_norm": 0.46017691493034363,
      "learning_rate": 4.810408163265306e-05,
      "loss": 0.3872,
      "step": 1430
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.5651145577430725,
      "learning_rate": 4.808367346938776e-05,
      "loss": 0.3713,
      "step": 1440
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.4395993947982788,
      "learning_rate": 4.806326530612245e-05,
      "loss": 0.3106,
      "step": 1450
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.5493476986885071,
      "learning_rate": 4.8042857142857144e-05,
      "loss": 0.3139,
      "step": 1460
    },
    {
      "epoch": 0.588,
      "grad_norm": 0.5596433281898499,
      "learning_rate": 4.8022448979591836e-05,
      "loss": 0.3604,
      "step": 1470
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.41749104857444763,
      "learning_rate": 4.8002040816326534e-05,
      "loss": 0.2977,
      "step": 1480
    },
    {
      "epoch": 0.596,
      "grad_norm": 0.5306190252304077,
      "learning_rate": 4.7981632653061226e-05,
      "loss": 0.3812,
      "step": 1490
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.45726442337036133,
      "learning_rate": 4.796122448979592e-05,
      "loss": 0.3255,
      "step": 1500
    },
    {
      "epoch": 0.604,
      "grad_norm": 0.5747855305671692,
      "learning_rate": 4.7940816326530616e-05,
      "loss": 0.296,
      "step": 1510
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.5603705644607544,
      "learning_rate": 4.792040816326531e-05,
      "loss": 0.3088,
      "step": 1520
    },
    {
      "epoch": 0.612,
      "grad_norm": 0.39830905199050903,
      "learning_rate": 4.79e-05,
      "loss": 0.3295,
      "step": 1530
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.41769731044769287,
      "learning_rate": 4.78795918367347e-05,
      "loss": 0.3097,
      "step": 1540
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5109930634498596,
      "learning_rate": 4.785918367346939e-05,
      "loss": 0.3499,
      "step": 1550
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.41328147053718567,
      "learning_rate": 4.783877551020408e-05,
      "loss": 0.3054,
      "step": 1560
    },
    {
      "epoch": 0.628,
      "grad_norm": 0.6946882605552673,
      "learning_rate": 4.781836734693878e-05,
      "loss": 0.3405,
      "step": 1570
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.40918150544166565,
      "learning_rate": 4.779795918367348e-05,
      "loss": 0.3568,
      "step": 1580
    },
    {
      "epoch": 0.636,
      "grad_norm": 0.5338321924209595,
      "learning_rate": 4.777755102040817e-05,
      "loss": 0.3629,
      "step": 1590
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4643367826938629,
      "learning_rate": 4.775714285714286e-05,
      "loss": 0.2592,
      "step": 1600
    },
    {
      "epoch": 0.644,
      "grad_norm": 0.6282195448875427,
      "learning_rate": 4.773673469387755e-05,
      "loss": 0.3628,
      "step": 1610
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.511138379573822,
      "learning_rate": 4.771632653061225e-05,
      "loss": 0.2811,
      "step": 1620
    },
    {
      "epoch": 0.652,
      "grad_norm": 0.6023508310317993,
      "learning_rate": 4.769591836734694e-05,
      "loss": 0.2777,
      "step": 1630
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.39568090438842773,
      "learning_rate": 4.767551020408163e-05,
      "loss": 0.2936,
      "step": 1640
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.49370622634887695,
      "learning_rate": 4.765510204081633e-05,
      "loss": 0.3221,
      "step": 1650
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.5173239707946777,
      "learning_rate": 4.763469387755102e-05,
      "loss": 0.2809,
      "step": 1660
    },
    {
      "epoch": 0.668,
      "grad_norm": 0.45864540338516235,
      "learning_rate": 4.7614285714285715e-05,
      "loss": 0.2528,
      "step": 1670
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.5333927273750305,
      "learning_rate": 4.759387755102041e-05,
      "loss": 0.3003,
      "step": 1680
    },
    {
      "epoch": 0.676,
      "grad_norm": 1.1689430475234985,
      "learning_rate": 4.7573469387755105e-05,
      "loss": 0.3305,
      "step": 1690
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.7406903505325317,
      "learning_rate": 4.7553061224489796e-05,
      "loss": 0.2931,
      "step": 1700
    },
    {
      "epoch": 0.684,
      "grad_norm": 0.5872862339019775,
      "learning_rate": 4.7532653061224495e-05,
      "loss": 0.267,
      "step": 1710
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.4019988477230072,
      "learning_rate": 4.7512244897959186e-05,
      "loss": 0.3349,
      "step": 1720
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.5818378329277039,
      "learning_rate": 4.749183673469388e-05,
      "loss": 0.2851,
      "step": 1730
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.4601708650588989,
      "learning_rate": 4.747142857142857e-05,
      "loss": 0.276,
      "step": 1740
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5309766530990601,
      "learning_rate": 4.745102040816327e-05,
      "loss": 0.244,
      "step": 1750
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.6802653074264526,
      "learning_rate": 4.743061224489796e-05,
      "loss": 0.2932,
      "step": 1760
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.505823016166687,
      "learning_rate": 4.741020408163265e-05,
      "loss": 0.2927,
      "step": 1770
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.7992659211158752,
      "learning_rate": 4.738979591836735e-05,
      "loss": 0.318,
      "step": 1780
    },
    {
      "epoch": 0.716,
      "grad_norm": 0.574295163154602,
      "learning_rate": 4.736938775510204e-05,
      "loss": 0.2579,
      "step": 1790
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.4638350009918213,
      "learning_rate": 4.734897959183674e-05,
      "loss": 0.2118,
      "step": 1800
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.6063691973686218,
      "learning_rate": 4.732857142857143e-05,
      "loss": 0.277,
      "step": 1810
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.5085068941116333,
      "learning_rate": 4.730816326530613e-05,
      "loss": 0.2735,
      "step": 1820
    },
    {
      "epoch": 0.732,
      "grad_norm": 0.6450293064117432,
      "learning_rate": 4.728775510204082e-05,
      "loss": 0.2971,
      "step": 1830
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.5562575459480286,
      "learning_rate": 4.726734693877551e-05,
      "loss": 0.3066,
      "step": 1840
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4626394808292389,
      "learning_rate": 4.724693877551021e-05,
      "loss": 0.2865,
      "step": 1850
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.5586384534835815,
      "learning_rate": 4.72265306122449e-05,
      "loss": 0.2776,
      "step": 1860
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.46690019965171814,
      "learning_rate": 4.7206122448979594e-05,
      "loss": 0.2592,
      "step": 1870
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.42737746238708496,
      "learning_rate": 4.7185714285714286e-05,
      "loss": 0.2586,
      "step": 1880
    },
    {
      "epoch": 0.756,
      "grad_norm": 0.5717331767082214,
      "learning_rate": 4.7165306122448984e-05,
      "loss": 0.2978,
      "step": 1890
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4991616904735565,
      "learning_rate": 4.7144897959183675e-05,
      "loss": 0.2426,
      "step": 1900
    },
    {
      "epoch": 0.764,
      "grad_norm": 0.5831864476203918,
      "learning_rate": 4.712448979591837e-05,
      "loss": 0.3563,
      "step": 1910
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.5957648754119873,
      "learning_rate": 4.7104081632653065e-05,
      "loss": 0.2429,
      "step": 1920
    },
    {
      "epoch": 0.772,
      "grad_norm": 0.7048337459564209,
      "learning_rate": 4.708367346938776e-05,
      "loss": 0.2779,
      "step": 1930
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.4072294235229492,
      "learning_rate": 4.706326530612245e-05,
      "loss": 0.2222,
      "step": 1940
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.4852302670478821,
      "learning_rate": 4.704285714285715e-05,
      "loss": 0.2071,
      "step": 1950
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.684874415397644,
      "learning_rate": 4.702244897959184e-05,
      "loss": 0.2232,
      "step": 1960
    },
    {
      "epoch": 0.788,
      "grad_norm": 0.4977792203426361,
      "learning_rate": 4.700204081632653e-05,
      "loss": 0.2434,
      "step": 1970
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.5768107175827026,
      "learning_rate": 4.698163265306122e-05,
      "loss": 0.2516,
      "step": 1980
    },
    {
      "epoch": 0.796,
      "grad_norm": 0.5198298692703247,
      "learning_rate": 4.696122448979592e-05,
      "loss": 0.2692,
      "step": 1990
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4947320818901062,
      "learning_rate": 4.694081632653061e-05,
      "loss": 0.2576,
      "step": 2000
    },
    {
      "epoch": 0.804,
      "grad_norm": 0.8069599270820618,
      "learning_rate": 4.69204081632653e-05,
      "loss": 0.2055,
      "step": 2010
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.7313035726547241,
      "learning_rate": 4.69e-05,
      "loss": 0.2373,
      "step": 2020
    },
    {
      "epoch": 0.812,
      "grad_norm": 0.7302405834197998,
      "learning_rate": 4.68795918367347e-05,
      "loss": 0.2455,
      "step": 2030
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.5136675238609314,
      "learning_rate": 4.685918367346939e-05,
      "loss": 0.2653,
      "step": 2040
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.090693712234497,
      "learning_rate": 4.683877551020408e-05,
      "loss": 0.2218,
      "step": 2050
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.5204006433486938,
      "learning_rate": 4.681836734693878e-05,
      "loss": 0.2237,
      "step": 2060
    },
    {
      "epoch": 0.828,
      "grad_norm": 0.5410826206207275,
      "learning_rate": 4.679795918367347e-05,
      "loss": 0.2073,
      "step": 2070
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.8459221720695496,
      "learning_rate": 4.6777551020408165e-05,
      "loss": 0.2278,
      "step": 2080
    },
    {
      "epoch": 0.836,
      "grad_norm": 1.047972321510315,
      "learning_rate": 4.675714285714286e-05,
      "loss": 0.3044,
      "step": 2090
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5688844919204712,
      "learning_rate": 4.6736734693877555e-05,
      "loss": 0.259,
      "step": 2100
    },
    {
      "epoch": 0.844,
      "grad_norm": 0.3198540508747101,
      "learning_rate": 4.6716326530612246e-05,
      "loss": 0.2053,
      "step": 2110
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.8005426526069641,
      "learning_rate": 4.6695918367346945e-05,
      "loss": 0.2357,
      "step": 2120
    },
    {
      "epoch": 0.852,
      "grad_norm": 0.44080692529678345,
      "learning_rate": 4.6675510204081636e-05,
      "loss": 0.272,
      "step": 2130
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.9955539703369141,
      "learning_rate": 4.665510204081633e-05,
      "loss": 0.2268,
      "step": 2140
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.9273502826690674,
      "learning_rate": 4.663469387755102e-05,
      "loss": 0.2236,
      "step": 2150
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.641830325126648,
      "learning_rate": 4.661428571428572e-05,
      "loss": 0.2435,
      "step": 2160
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.4910547435283661,
      "learning_rate": 4.659387755102041e-05,
      "loss": 0.2592,
      "step": 2170
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.6593384146690369,
      "learning_rate": 4.65734693877551e-05,
      "loss": 0.219,
      "step": 2180
    },
    {
      "epoch": 0.876,
      "grad_norm": 0.4986838102340698,
      "learning_rate": 4.65530612244898e-05,
      "loss": 0.2184,
      "step": 2190
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6279139518737793,
      "learning_rate": 4.653265306122449e-05,
      "loss": 0.2052,
      "step": 2200
    },
    {
      "epoch": 0.884,
      "grad_norm": 1.1542778015136719,
      "learning_rate": 4.651224489795918e-05,
      "loss": 0.2203,
      "step": 2210
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.48342186212539673,
      "learning_rate": 4.649183673469388e-05,
      "loss": 0.2181,
      "step": 2220
    },
    {
      "epoch": 0.892,
      "grad_norm": 0.6383405923843384,
      "learning_rate": 4.647142857142857e-05,
      "loss": 0.2556,
      "step": 2230
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.5586531758308411,
      "learning_rate": 4.6451020408163264e-05,
      "loss": 0.2672,
      "step": 2240
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3640231490135193,
      "learning_rate": 4.643061224489796e-05,
      "loss": 0.197,
      "step": 2250
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.4729352295398712,
      "learning_rate": 4.641020408163266e-05,
      "loss": 0.2405,
      "step": 2260
    },
    {
      "epoch": 0.908,
      "grad_norm": 0.6005011200904846,
      "learning_rate": 4.638979591836735e-05,
      "loss": 0.209,
      "step": 2270
    },
    {
      "epoch": 0.912,
      "grad_norm": 1.0480746030807495,
      "learning_rate": 4.6369387755102044e-05,
      "loss": 0.2469,
      "step": 2280
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.3975940942764282,
      "learning_rate": 4.6348979591836735e-05,
      "loss": 0.227,
      "step": 2290
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.4860129952430725,
      "learning_rate": 4.6328571428571434e-05,
      "loss": 0.1745,
      "step": 2300
    },
    {
      "epoch": 0.924,
      "grad_norm": 0.6715744137763977,
      "learning_rate": 4.6308163265306125e-05,
      "loss": 0.233,
      "step": 2310
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.7986295819282532,
      "learning_rate": 4.628775510204082e-05,
      "loss": 0.2037,
      "step": 2320
    },
    {
      "epoch": 0.932,
      "grad_norm": 0.8509233593940735,
      "learning_rate": 4.6267346938775515e-05,
      "loss": 0.2467,
      "step": 2330
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.7069099545478821,
      "learning_rate": 4.624693877551021e-05,
      "loss": 0.1942,
      "step": 2340
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.27642932534217834,
      "learning_rate": 4.62265306122449e-05,
      "loss": 0.2391,
      "step": 2350
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.47970467805862427,
      "learning_rate": 4.62061224489796e-05,
      "loss": 0.2753,
      "step": 2360
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.5537393093109131,
      "learning_rate": 4.618571428571429e-05,
      "loss": 0.1909,
      "step": 2370
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.630800724029541,
      "learning_rate": 4.616530612244898e-05,
      "loss": 0.2121,
      "step": 2380
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.5376859903335571,
      "learning_rate": 4.614489795918368e-05,
      "loss": 0.1791,
      "step": 2390
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.7400402426719666,
      "learning_rate": 4.612448979591837e-05,
      "loss": 0.1833,
      "step": 2400
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.49243101477622986,
      "learning_rate": 4.610408163265306e-05,
      "loss": 0.1948,
      "step": 2410
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.4631619155406952,
      "learning_rate": 4.608367346938775e-05,
      "loss": 0.1799,
      "step": 2420
    },
    {
      "epoch": 0.972,
      "grad_norm": 0.9317487478256226,
      "learning_rate": 4.606326530612245e-05,
      "loss": 0.2221,
      "step": 2430
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.5251697301864624,
      "learning_rate": 4.604285714285714e-05,
      "loss": 0.2106,
      "step": 2440
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5828481912612915,
      "learning_rate": 4.6022448979591835e-05,
      "loss": 0.193,
      "step": 2450
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.8403238654136658,
      "learning_rate": 4.600204081632653e-05,
      "loss": 0.2149,
      "step": 2460
    },
    {
      "epoch": 0.988,
      "grad_norm": 0.631033182144165,
      "learning_rate": 4.5981632653061224e-05,
      "loss": 0.2468,
      "step": 2470
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.550004780292511,
      "learning_rate": 4.596122448979592e-05,
      "loss": 0.1836,
      "step": 2480
    },
    {
      "epoch": 0.996,
      "grad_norm": 0.796711802482605,
      "learning_rate": 4.5940816326530614e-05,
      "loss": 0.2165,
      "step": 2490
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.8863765597343445,
      "learning_rate": 4.592040816326531e-05,
      "loss": 0.2363,
      "step": 2500
    },
    {
      "epoch": 1.004,
      "grad_norm": 0.5487090945243835,
      "learning_rate": 4.5900000000000004e-05,
      "loss": 0.1603,
      "step": 2510
    },
    {
      "epoch": 1.008,
      "grad_norm": 1.2156074047088623,
      "learning_rate": 4.5879591836734696e-05,
      "loss": 0.237,
      "step": 2520
    },
    {
      "epoch": 1.012,
      "grad_norm": 0.7795695066452026,
      "learning_rate": 4.5859183673469394e-05,
      "loss": 0.2509,
      "step": 2530
    },
    {
      "epoch": 1.016,
      "grad_norm": 0.741682767868042,
      "learning_rate": 4.5838775510204086e-05,
      "loss": 0.2125,
      "step": 2540
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.7509889602661133,
      "learning_rate": 4.581836734693878e-05,
      "loss": 0.2052,
      "step": 2550
    },
    {
      "epoch": 1.024,
      "grad_norm": 1.0464503765106201,
      "learning_rate": 4.579795918367347e-05,
      "loss": 0.2013,
      "step": 2560
    },
    {
      "epoch": 1.028,
      "grad_norm": 0.6271365284919739,
      "learning_rate": 4.577755102040817e-05,
      "loss": 0.158,
      "step": 2570
    },
    {
      "epoch": 1.032,
      "grad_norm": 0.832335889339447,
      "learning_rate": 4.575714285714286e-05,
      "loss": 0.2149,
      "step": 2580
    },
    {
      "epoch": 1.036,
      "grad_norm": 0.4363768398761749,
      "learning_rate": 4.573673469387755e-05,
      "loss": 0.1961,
      "step": 2590
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.716849684715271,
      "learning_rate": 4.571632653061225e-05,
      "loss": 0.1614,
      "step": 2600
    },
    {
      "epoch": 1.044,
      "grad_norm": 0.5967530608177185,
      "learning_rate": 4.569591836734694e-05,
      "loss": 0.1714,
      "step": 2610
    },
    {
      "epoch": 1.048,
      "grad_norm": 0.5195265412330627,
      "learning_rate": 4.567551020408163e-05,
      "loss": 0.1952,
      "step": 2620
    },
    {
      "epoch": 1.052,
      "grad_norm": 0.8666093945503235,
      "learning_rate": 4.565510204081633e-05,
      "loss": 0.2322,
      "step": 2630
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.49535825848579407,
      "learning_rate": 4.563469387755102e-05,
      "loss": 0.1699,
      "step": 2640
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.6114439964294434,
      "learning_rate": 4.5614285714285714e-05,
      "loss": 0.2057,
      "step": 2650
    },
    {
      "epoch": 1.064,
      "grad_norm": 0.48683905601501465,
      "learning_rate": 4.5593877551020405e-05,
      "loss": 0.2401,
      "step": 2660
    },
    {
      "epoch": 1.068,
      "grad_norm": 0.435312420129776,
      "learning_rate": 4.5573469387755104e-05,
      "loss": 0.1818,
      "step": 2670
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.5390604734420776,
      "learning_rate": 4.5553061224489795e-05,
      "loss": 0.1685,
      "step": 2680
    },
    {
      "epoch": 1.076,
      "grad_norm": 0.7401455640792847,
      "learning_rate": 4.553265306122449e-05,
      "loss": 0.1721,
      "step": 2690
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.5740934014320374,
      "learning_rate": 4.5512244897959185e-05,
      "loss": 0.2109,
      "step": 2700
    },
    {
      "epoch": 1.084,
      "grad_norm": 0.4788059890270233,
      "learning_rate": 4.5491836734693883e-05,
      "loss": 0.1631,
      "step": 2710
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.5749025940895081,
      "learning_rate": 4.5471428571428575e-05,
      "loss": 0.1658,
      "step": 2720
    },
    {
      "epoch": 1.092,
      "grad_norm": 1.0143202543258667,
      "learning_rate": 4.545102040816327e-05,
      "loss": 0.1783,
      "step": 2730
    },
    {
      "epoch": 1.096,
      "grad_norm": 0.9518183469772339,
      "learning_rate": 4.5430612244897965e-05,
      "loss": 0.1738,
      "step": 2740
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.8661364316940308,
      "learning_rate": 4.5410204081632657e-05,
      "loss": 0.2242,
      "step": 2750
    },
    {
      "epoch": 1.104,
      "grad_norm": 1.1881463527679443,
      "learning_rate": 4.538979591836735e-05,
      "loss": 0.2286,
      "step": 2760
    },
    {
      "epoch": 1.108,
      "grad_norm": 0.6333903670310974,
      "learning_rate": 4.5369387755102047e-05,
      "loss": 0.1913,
      "step": 2770
    },
    {
      "epoch": 1.112,
      "grad_norm": 0.4897889196872711,
      "learning_rate": 4.534897959183674e-05,
      "loss": 0.1574,
      "step": 2780
    },
    {
      "epoch": 1.116,
      "grad_norm": 0.6496104598045349,
      "learning_rate": 4.532857142857143e-05,
      "loss": 0.1592,
      "step": 2790
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.13943350315094,
      "learning_rate": 4.530816326530613e-05,
      "loss": 0.1909,
      "step": 2800
    },
    {
      "epoch": 1.124,
      "grad_norm": 0.8035538792610168,
      "learning_rate": 4.528775510204082e-05,
      "loss": 0.1667,
      "step": 2810
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 1.2701815366744995,
      "learning_rate": 4.526734693877551e-05,
      "loss": 0.208,
      "step": 2820
    },
    {
      "epoch": 1.1320000000000001,
      "grad_norm": 1.001304030418396,
      "learning_rate": 4.52469387755102e-05,
      "loss": 0.1668,
      "step": 2830
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.7274892330169678,
      "learning_rate": 4.52265306122449e-05,
      "loss": 0.1599,
      "step": 2840
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 0.6700906753540039,
      "learning_rate": 4.520612244897959e-05,
      "loss": 0.1942,
      "step": 2850
    },
    {
      "epoch": 1.144,
      "grad_norm": 0.6428379416465759,
      "learning_rate": 4.5185714285714284e-05,
      "loss": 0.1517,
      "step": 2860
    },
    {
      "epoch": 1.148,
      "grad_norm": 0.6563379168510437,
      "learning_rate": 4.516530612244898e-05,
      "loss": 0.1546,
      "step": 2870
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.9651193618774414,
      "learning_rate": 4.5144897959183674e-05,
      "loss": 0.2072,
      "step": 2880
    },
    {
      "epoch": 1.156,
      "grad_norm": 0.5813590884208679,
      "learning_rate": 4.5124489795918366e-05,
      "loss": 0.2183,
      "step": 2890
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.4866387844085693,
      "learning_rate": 4.5104081632653064e-05,
      "loss": 0.1843,
      "step": 2900
    },
    {
      "epoch": 1.164,
      "grad_norm": 0.5310546159744263,
      "learning_rate": 4.5083673469387756e-05,
      "loss": 0.1556,
      "step": 2910
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.952143669128418,
      "learning_rate": 4.506326530612245e-05,
      "loss": 0.1937,
      "step": 2920
    },
    {
      "epoch": 1.172,
      "grad_norm": 1.2350050210952759,
      "learning_rate": 4.5042857142857146e-05,
      "loss": 0.1683,
      "step": 2930
    },
    {
      "epoch": 1.176,
      "grad_norm": 0.5923644304275513,
      "learning_rate": 4.5022448979591844e-05,
      "loss": 0.1408,
      "step": 2940
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.5399428606033325,
      "learning_rate": 4.5002040816326536e-05,
      "loss": 0.1956,
      "step": 2950
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.8847969770431519,
      "learning_rate": 4.498163265306123e-05,
      "loss": 0.1859,
      "step": 2960
    },
    {
      "epoch": 1.188,
      "grad_norm": 0.8222836852073669,
      "learning_rate": 4.4961224489795926e-05,
      "loss": 0.2112,
      "step": 2970
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.7307872176170349,
      "learning_rate": 4.494081632653062e-05,
      "loss": 0.1431,
      "step": 2980
    },
    {
      "epoch": 1.196,
      "grad_norm": 0.8720045685768127,
      "learning_rate": 4.492040816326531e-05,
      "loss": 0.1901,
      "step": 2990
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.9566808342933655,
      "learning_rate": 4.49e-05,
      "loss": 0.1596,
      "step": 3000
    },
    {
      "epoch": 1.204,
      "grad_norm": 0.419816255569458,
      "learning_rate": 4.48795918367347e-05,
      "loss": 0.177,
      "step": 3010
    },
    {
      "epoch": 1.208,
      "grad_norm": 0.4046717882156372,
      "learning_rate": 4.485918367346939e-05,
      "loss": 0.129,
      "step": 3020
    },
    {
      "epoch": 1.212,
      "grad_norm": 0.5759591460227966,
      "learning_rate": 4.483877551020408e-05,
      "loss": 0.1466,
      "step": 3030
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.2860490679740906,
      "learning_rate": 4.481836734693878e-05,
      "loss": 0.1479,
      "step": 3040
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.7762587070465088,
      "learning_rate": 4.479795918367347e-05,
      "loss": 0.135,
      "step": 3050
    },
    {
      "epoch": 1.224,
      "grad_norm": 0.8158205151557922,
      "learning_rate": 4.4777551020408163e-05,
      "loss": 0.1661,
      "step": 3060
    },
    {
      "epoch": 1.228,
      "grad_norm": 0.961970329284668,
      "learning_rate": 4.475714285714286e-05,
      "loss": 0.1966,
      "step": 3070
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.8564358353614807,
      "learning_rate": 4.4736734693877553e-05,
      "loss": 0.157,
      "step": 3080
    },
    {
      "epoch": 1.236,
      "grad_norm": 0.3948069214820862,
      "learning_rate": 4.4716326530612245e-05,
      "loss": 0.1736,
      "step": 3090
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.3125212490558624,
      "learning_rate": 4.4695918367346937e-05,
      "loss": 0.1421,
      "step": 3100
    },
    {
      "epoch": 1.244,
      "grad_norm": 0.6561605334281921,
      "learning_rate": 4.4675510204081635e-05,
      "loss": 0.1624,
      "step": 3110
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.8036081194877625,
      "learning_rate": 4.4655102040816327e-05,
      "loss": 0.1417,
      "step": 3120
    },
    {
      "epoch": 1.252,
      "grad_norm": 0.3613887429237366,
      "learning_rate": 4.463469387755102e-05,
      "loss": 0.1596,
      "step": 3130
    },
    {
      "epoch": 1.256,
      "grad_norm": 0.9744250774383545,
      "learning_rate": 4.4614285714285716e-05,
      "loss": 0.1574,
      "step": 3140
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.5574161410331726,
      "learning_rate": 4.459387755102041e-05,
      "loss": 0.1398,
      "step": 3150
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.7147576212882996,
      "learning_rate": 4.4573469387755106e-05,
      "loss": 0.1648,
      "step": 3160
    },
    {
      "epoch": 1.268,
      "grad_norm": 0.504672110080719,
      "learning_rate": 4.45530612244898e-05,
      "loss": 0.149,
      "step": 3170
    },
    {
      "epoch": 1.272,
      "grad_norm": 0.5495333671569824,
      "learning_rate": 4.4532653061224496e-05,
      "loss": 0.1363,
      "step": 3180
    },
    {
      "epoch": 1.276,
      "grad_norm": 0.5424769520759583,
      "learning_rate": 4.451224489795919e-05,
      "loss": 0.1635,
      "step": 3190
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.779536247253418,
      "learning_rate": 4.449183673469388e-05,
      "loss": 0.1329,
      "step": 3200
    },
    {
      "epoch": 1.284,
      "grad_norm": 0.7299196720123291,
      "learning_rate": 4.447142857142858e-05,
      "loss": 0.1798,
      "step": 3210
    },
    {
      "epoch": 1.288,
      "grad_norm": 0.6573110818862915,
      "learning_rate": 4.445102040816327e-05,
      "loss": 0.1374,
      "step": 3220
    },
    {
      "epoch": 1.292,
      "grad_norm": 0.49613863229751587,
      "learning_rate": 4.443061224489796e-05,
      "loss": 0.1493,
      "step": 3230
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.1751486212015152,
      "learning_rate": 4.441020408163265e-05,
      "loss": 0.1299,
      "step": 3240
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.8615429401397705,
      "learning_rate": 4.438979591836735e-05,
      "loss": 0.1799,
      "step": 3250
    },
    {
      "epoch": 1.304,
      "grad_norm": 0.5009042620658875,
      "learning_rate": 4.436938775510204e-05,
      "loss": 0.1359,
      "step": 3260
    },
    {
      "epoch": 1.308,
      "grad_norm": 1.2867259979248047,
      "learning_rate": 4.4348979591836734e-05,
      "loss": 0.1915,
      "step": 3270
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.19988831877708435,
      "learning_rate": 4.432857142857143e-05,
      "loss": 0.1483,
      "step": 3280
    },
    {
      "epoch": 1.316,
      "grad_norm": 0.5913978219032288,
      "learning_rate": 4.4308163265306124e-05,
      "loss": 0.1684,
      "step": 3290
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.1690269708633423,
      "learning_rate": 4.4287755102040816e-05,
      "loss": 0.2041,
      "step": 3300
    },
    {
      "epoch": 1.324,
      "grad_norm": 1.0080136060714722,
      "learning_rate": 4.4267346938775514e-05,
      "loss": 0.2065,
      "step": 3310
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.5000267028808594,
      "learning_rate": 4.4246938775510206e-05,
      "loss": 0.1321,
      "step": 3320
    },
    {
      "epoch": 1.332,
      "grad_norm": 0.4773041307926178,
      "learning_rate": 4.42265306122449e-05,
      "loss": 0.1476,
      "step": 3330
    },
    {
      "epoch": 1.336,
      "grad_norm": 0.4258919656276703,
      "learning_rate": 4.4206122448979596e-05,
      "loss": 0.1092,
      "step": 3340
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.5678615570068359,
      "learning_rate": 4.418571428571429e-05,
      "loss": 0.1342,
      "step": 3350
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.7542991042137146,
      "learning_rate": 4.416530612244898e-05,
      "loss": 0.1848,
      "step": 3360
    },
    {
      "epoch": 1.3479999999999999,
      "grad_norm": 0.5343666076660156,
      "learning_rate": 4.414489795918367e-05,
      "loss": 0.1476,
      "step": 3370
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 0.8570231199264526,
      "learning_rate": 4.412448979591837e-05,
      "loss": 0.157,
      "step": 3380
    },
    {
      "epoch": 1.3559999999999999,
      "grad_norm": 0.25050973892211914,
      "learning_rate": 4.410408163265307e-05,
      "loss": 0.1314,
      "step": 3390
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.2769458293914795,
      "learning_rate": 4.408367346938776e-05,
      "loss": 0.1566,
      "step": 3400
    },
    {
      "epoch": 1.3639999999999999,
      "grad_norm": 0.8291923999786377,
      "learning_rate": 4.406326530612245e-05,
      "loss": 0.1471,
      "step": 3410
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 0.6281489133834839,
      "learning_rate": 4.404285714285715e-05,
      "loss": 0.1203,
      "step": 3420
    },
    {
      "epoch": 1.3719999999999999,
      "grad_norm": 0.5207359194755554,
      "learning_rate": 4.402244897959184e-05,
      "loss": 0.1245,
      "step": 3430
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.9283775687217712,
      "learning_rate": 4.400204081632653e-05,
      "loss": 0.128,
      "step": 3440
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.46007415652275085,
      "learning_rate": 4.398163265306123e-05,
      "loss": 0.1458,
      "step": 3450
    },
    {
      "epoch": 1.384,
      "grad_norm": 0.28678247332572937,
      "learning_rate": 4.396122448979592e-05,
      "loss": 0.1016,
      "step": 3460
    },
    {
      "epoch": 1.388,
      "grad_norm": 0.6182866096496582,
      "learning_rate": 4.394081632653061e-05,
      "loss": 0.1612,
      "step": 3470
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.3517351746559143,
      "learning_rate": 4.392040816326531e-05,
      "loss": 0.15,
      "step": 3480
    },
    {
      "epoch": 1.396,
      "grad_norm": 0.8821585178375244,
      "learning_rate": 4.39e-05,
      "loss": 0.1744,
      "step": 3490
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.39453601837158203,
      "learning_rate": 4.3879591836734695e-05,
      "loss": 0.1552,
      "step": 3500
    },
    {
      "epoch": 1.404,
      "grad_norm": 1.0455563068389893,
      "learning_rate": 4.3859183673469386e-05,
      "loss": 0.1353,
      "step": 3510
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.9557181596755981,
      "learning_rate": 4.3838775510204085e-05,
      "loss": 0.1597,
      "step": 3520
    },
    {
      "epoch": 1.412,
      "grad_norm": 0.8437669277191162,
      "learning_rate": 4.3818367346938776e-05,
      "loss": 0.1647,
      "step": 3530
    },
    {
      "epoch": 1.416,
      "grad_norm": 0.6722444295883179,
      "learning_rate": 4.379795918367347e-05,
      "loss": 0.1587,
      "step": 3540
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.2629862129688263,
      "learning_rate": 4.3777551020408166e-05,
      "loss": 0.1196,
      "step": 3550
    },
    {
      "epoch": 1.424,
      "grad_norm": 1.1695139408111572,
      "learning_rate": 4.375714285714286e-05,
      "loss": 0.1345,
      "step": 3560
    },
    {
      "epoch": 1.428,
      "grad_norm": 1.0644309520721436,
      "learning_rate": 4.373673469387755e-05,
      "loss": 0.1293,
      "step": 3570
    },
    {
      "epoch": 1.432,
      "grad_norm": 0.7221937775611877,
      "learning_rate": 4.371632653061225e-05,
      "loss": 0.1402,
      "step": 3580
    },
    {
      "epoch": 1.436,
      "grad_norm": 0.9440865516662598,
      "learning_rate": 4.369591836734694e-05,
      "loss": 0.103,
      "step": 3590
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.8124622702598572,
      "learning_rate": 4.367551020408163e-05,
      "loss": 0.1273,
      "step": 3600
    },
    {
      "epoch": 1.444,
      "grad_norm": 0.8231133818626404,
      "learning_rate": 4.365510204081633e-05,
      "loss": 0.131,
      "step": 3610
    },
    {
      "epoch": 1.448,
      "grad_norm": 0.7862504124641418,
      "learning_rate": 4.363469387755103e-05,
      "loss": 0.1327,
      "step": 3620
    },
    {
      "epoch": 1.452,
      "grad_norm": 1.0803295373916626,
      "learning_rate": 4.361428571428572e-05,
      "loss": 0.198,
      "step": 3630
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.40597864985466003,
      "learning_rate": 4.359387755102041e-05,
      "loss": 0.1241,
      "step": 3640
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.5002078413963318,
      "learning_rate": 4.357346938775511e-05,
      "loss": 0.1145,
      "step": 3650
    },
    {
      "epoch": 1.464,
      "grad_norm": 0.6972137689590454,
      "learning_rate": 4.35530612244898e-05,
      "loss": 0.1464,
      "step": 3660
    },
    {
      "epoch": 1.468,
      "grad_norm": 0.9874343872070312,
      "learning_rate": 4.353265306122449e-05,
      "loss": 0.1375,
      "step": 3670
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.7234496474266052,
      "learning_rate": 4.3512244897959184e-05,
      "loss": 0.1806,
      "step": 3680
    },
    {
      "epoch": 1.476,
      "grad_norm": 0.5957225561141968,
      "learning_rate": 4.349183673469388e-05,
      "loss": 0.1487,
      "step": 3690
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.7590116858482361,
      "learning_rate": 4.3471428571428574e-05,
      "loss": 0.1431,
      "step": 3700
    },
    {
      "epoch": 1.484,
      "grad_norm": 0.35339975357055664,
      "learning_rate": 4.3451020408163265e-05,
      "loss": 0.117,
      "step": 3710
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.5926899909973145,
      "learning_rate": 4.3430612244897964e-05,
      "loss": 0.1825,
      "step": 3720
    },
    {
      "epoch": 1.492,
      "grad_norm": 0.6695283055305481,
      "learning_rate": 4.3410204081632655e-05,
      "loss": 0.0891,
      "step": 3730
    },
    {
      "epoch": 1.496,
      "grad_norm": 0.7204468846321106,
      "learning_rate": 4.338979591836735e-05,
      "loss": 0.1106,
      "step": 3740
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.0032103061676025,
      "learning_rate": 4.3369387755102045e-05,
      "loss": 0.1061,
      "step": 3750
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.7823588848114014,
      "learning_rate": 4.334897959183674e-05,
      "loss": 0.1077,
      "step": 3760
    },
    {
      "epoch": 1.508,
      "grad_norm": 0.1648057997226715,
      "learning_rate": 4.332857142857143e-05,
      "loss": 0.1032,
      "step": 3770
    },
    {
      "epoch": 1.512,
      "grad_norm": 0.9174506664276123,
      "learning_rate": 4.330816326530612e-05,
      "loss": 0.1186,
      "step": 3780
    },
    {
      "epoch": 1.516,
      "grad_norm": 0.9149007201194763,
      "learning_rate": 4.328775510204082e-05,
      "loss": 0.1676,
      "step": 3790
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.4305257499217987,
      "learning_rate": 4.326734693877551e-05,
      "loss": 0.0894,
      "step": 3800
    },
    {
      "epoch": 1.524,
      "grad_norm": 0.6920815110206604,
      "learning_rate": 4.32469387755102e-05,
      "loss": 0.1358,
      "step": 3810
    },
    {
      "epoch": 1.528,
      "grad_norm": 1.0377036333084106,
      "learning_rate": 4.32265306122449e-05,
      "loss": 0.1426,
      "step": 3820
    },
    {
      "epoch": 1.532,
      "grad_norm": 0.653603732585907,
      "learning_rate": 4.320612244897959e-05,
      "loss": 0.119,
      "step": 3830
    },
    {
      "epoch": 1.536,
      "grad_norm": 1.0511980056762695,
      "learning_rate": 4.318571428571429e-05,
      "loss": 0.1524,
      "step": 3840
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.019919991493225,
      "learning_rate": 4.316530612244898e-05,
      "loss": 0.1233,
      "step": 3850
    },
    {
      "epoch": 1.544,
      "grad_norm": 0.7243791222572327,
      "learning_rate": 4.314489795918368e-05,
      "loss": 0.1183,
      "step": 3860
    },
    {
      "epoch": 1.548,
      "grad_norm": 0.7665486931800842,
      "learning_rate": 4.312448979591837e-05,
      "loss": 0.167,
      "step": 3870
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.8521060943603516,
      "learning_rate": 4.310408163265306e-05,
      "loss": 0.1624,
      "step": 3880
    },
    {
      "epoch": 1.556,
      "grad_norm": 0.8796730637550354,
      "learning_rate": 4.308367346938776e-05,
      "loss": 0.1403,
      "step": 3890
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.775701105594635,
      "learning_rate": 4.306326530612245e-05,
      "loss": 0.1392,
      "step": 3900
    },
    {
      "epoch": 1.564,
      "grad_norm": 0.7281259894371033,
      "learning_rate": 4.3042857142857145e-05,
      "loss": 0.1764,
      "step": 3910
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.6063981056213379,
      "learning_rate": 4.3022448979591836e-05,
      "loss": 0.1241,
      "step": 3920
    },
    {
      "epoch": 1.572,
      "grad_norm": 0.6297612190246582,
      "learning_rate": 4.3002040816326535e-05,
      "loss": 0.1417,
      "step": 3930
    },
    {
      "epoch": 1.576,
      "grad_norm": 0.6532738208770752,
      "learning_rate": 4.2981632653061226e-05,
      "loss": 0.1352,
      "step": 3940
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.7152881026268005,
      "learning_rate": 4.296122448979592e-05,
      "loss": 0.1098,
      "step": 3950
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.422711580991745,
      "learning_rate": 4.2940816326530616e-05,
      "loss": 0.1212,
      "step": 3960
    },
    {
      "epoch": 1.588,
      "grad_norm": 0.6885407567024231,
      "learning_rate": 4.292040816326531e-05,
      "loss": 0.1448,
      "step": 3970
    },
    {
      "epoch": 1.592,
      "grad_norm": 1.0499693155288696,
      "learning_rate": 4.29e-05,
      "loss": 0.0968,
      "step": 3980
    },
    {
      "epoch": 1.596,
      "grad_norm": 0.7878443002700806,
      "learning_rate": 4.28795918367347e-05,
      "loss": 0.1207,
      "step": 3990
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.1297557353973389,
      "learning_rate": 4.285918367346939e-05,
      "loss": 0.14,
      "step": 4000
    },
    {
      "epoch": 1.604,
      "grad_norm": 0.6445861458778381,
      "learning_rate": 4.283877551020408e-05,
      "loss": 0.1401,
      "step": 4010
    },
    {
      "epoch": 1.608,
      "grad_norm": 0.687770664691925,
      "learning_rate": 4.281836734693878e-05,
      "loss": 0.1328,
      "step": 4020
    },
    {
      "epoch": 1.612,
      "grad_norm": 0.7870615124702454,
      "learning_rate": 4.279795918367347e-05,
      "loss": 0.1181,
      "step": 4030
    },
    {
      "epoch": 1.616,
      "grad_norm": 1.0480694770812988,
      "learning_rate": 4.277755102040816e-05,
      "loss": 0.1629,
      "step": 4040
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.9025358557701111,
      "learning_rate": 4.2757142857142854e-05,
      "loss": 0.0947,
      "step": 4050
    },
    {
      "epoch": 1.624,
      "grad_norm": 0.7680396437644958,
      "learning_rate": 4.273673469387755e-05,
      "loss": 0.2189,
      "step": 4060
    },
    {
      "epoch": 1.6280000000000001,
      "grad_norm": 1.2419180870056152,
      "learning_rate": 4.271632653061225e-05,
      "loss": 0.1721,
      "step": 4070
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.5152934193611145,
      "learning_rate": 4.269591836734694e-05,
      "loss": 0.1267,
      "step": 4080
    },
    {
      "epoch": 1.6360000000000001,
      "grad_norm": 0.5981017351150513,
      "learning_rate": 4.2675510204081634e-05,
      "loss": 0.1147,
      "step": 4090
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.7724331021308899,
      "learning_rate": 4.265510204081633e-05,
      "loss": 0.1434,
      "step": 4100
    },
    {
      "epoch": 1.6440000000000001,
      "grad_norm": 0.8508053421974182,
      "learning_rate": 4.2634693877551024e-05,
      "loss": 0.1049,
      "step": 4110
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.8807116746902466,
      "learning_rate": 4.2614285714285715e-05,
      "loss": 0.1054,
      "step": 4120
    },
    {
      "epoch": 1.6520000000000001,
      "grad_norm": 0.41253772377967834,
      "learning_rate": 4.2593877551020414e-05,
      "loss": 0.0969,
      "step": 4130
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 0.4304836094379425,
      "learning_rate": 4.2573469387755105e-05,
      "loss": 0.1199,
      "step": 4140
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 1.0826832056045532,
      "learning_rate": 4.25530612244898e-05,
      "loss": 0.0919,
      "step": 4150
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 1.2546316385269165,
      "learning_rate": 4.2532653061224495e-05,
      "loss": 0.1572,
      "step": 4160
    },
    {
      "epoch": 1.6680000000000001,
      "grad_norm": 1.0726040601730347,
      "learning_rate": 4.251224489795919e-05,
      "loss": 0.1194,
      "step": 4170
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.7954222559928894,
      "learning_rate": 4.249183673469388e-05,
      "loss": 0.107,
      "step": 4180
    },
    {
      "epoch": 1.6760000000000002,
      "grad_norm": 0.8559194803237915,
      "learning_rate": 4.247142857142857e-05,
      "loss": 0.152,
      "step": 4190
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.825369656085968,
      "learning_rate": 4.245102040816327e-05,
      "loss": 0.1586,
      "step": 4200
    },
    {
      "epoch": 1.6840000000000002,
      "grad_norm": 0.6932575702667236,
      "learning_rate": 4.243061224489796e-05,
      "loss": 0.1348,
      "step": 4210
    },
    {
      "epoch": 1.688,
      "grad_norm": 0.6205533146858215,
      "learning_rate": 4.241020408163265e-05,
      "loss": 0.1142,
      "step": 4220
    },
    {
      "epoch": 1.692,
      "grad_norm": 1.599148154258728,
      "learning_rate": 4.238979591836735e-05,
      "loss": 0.1445,
      "step": 4230
    },
    {
      "epoch": 1.696,
      "grad_norm": 1.0348247289657593,
      "learning_rate": 4.236938775510204e-05,
      "loss": 0.1612,
      "step": 4240
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.8571152687072754,
      "learning_rate": 4.234897959183673e-05,
      "loss": 0.1275,
      "step": 4250
    },
    {
      "epoch": 1.704,
      "grad_norm": 0.6290044784545898,
      "learning_rate": 4.232857142857143e-05,
      "loss": 0.1042,
      "step": 4260
    },
    {
      "epoch": 1.708,
      "grad_norm": 0.826463520526886,
      "learning_rate": 4.230816326530612e-05,
      "loss": 0.1509,
      "step": 4270
    },
    {
      "epoch": 1.712,
      "grad_norm": 1.1105536222457886,
      "learning_rate": 4.2287755102040814e-05,
      "loss": 0.17,
      "step": 4280
    },
    {
      "epoch": 1.716,
      "grad_norm": 1.199321985244751,
      "learning_rate": 4.226734693877551e-05,
      "loss": 0.1535,
      "step": 4290
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.48365065455436707,
      "learning_rate": 4.224693877551021e-05,
      "loss": 0.1623,
      "step": 4300
    },
    {
      "epoch": 1.724,
      "grad_norm": 1.1879531145095825,
      "learning_rate": 4.22265306122449e-05,
      "loss": 0.1295,
      "step": 4310
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.3023352026939392,
      "learning_rate": 4.2206122448979594e-05,
      "loss": 0.1231,
      "step": 4320
    },
    {
      "epoch": 1.732,
      "grad_norm": 1.0488766431808472,
      "learning_rate": 4.218571428571429e-05,
      "loss": 0.1215,
      "step": 4330
    },
    {
      "epoch": 1.736,
      "grad_norm": 0.9969045519828796,
      "learning_rate": 4.2165306122448984e-05,
      "loss": 0.1358,
      "step": 4340
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.9522778987884521,
      "learning_rate": 4.2144897959183676e-05,
      "loss": 0.1161,
      "step": 4350
    },
    {
      "epoch": 1.744,
      "grad_norm": 1.4687702655792236,
      "learning_rate": 4.212448979591837e-05,
      "loss": 0.1112,
      "step": 4360
    },
    {
      "epoch": 1.748,
      "grad_norm": 0.5776559114456177,
      "learning_rate": 4.2104081632653066e-05,
      "loss": 0.124,
      "step": 4370
    },
    {
      "epoch": 1.752,
      "grad_norm": 1.1358665227890015,
      "learning_rate": 4.208367346938776e-05,
      "loss": 0.1481,
      "step": 4380
    },
    {
      "epoch": 1.756,
      "grad_norm": 0.4535524249076843,
      "learning_rate": 4.206326530612245e-05,
      "loss": 0.1591,
      "step": 4390
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.49366599321365356,
      "learning_rate": 4.204285714285715e-05,
      "loss": 0.1226,
      "step": 4400
    },
    {
      "epoch": 1.764,
      "grad_norm": 0.6342713832855225,
      "learning_rate": 4.202244897959184e-05,
      "loss": 0.0937,
      "step": 4410
    },
    {
      "epoch": 1.768,
      "grad_norm": 0.8377421498298645,
      "learning_rate": 4.200204081632653e-05,
      "loss": 0.0956,
      "step": 4420
    },
    {
      "epoch": 1.772,
      "grad_norm": 0.974619448184967,
      "learning_rate": 4.198163265306123e-05,
      "loss": 0.1123,
      "step": 4430
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.6775813102722168,
      "learning_rate": 4.196122448979592e-05,
      "loss": 0.1356,
      "step": 4440
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.061177372932434,
      "learning_rate": 4.194081632653061e-05,
      "loss": 0.1246,
      "step": 4450
    },
    {
      "epoch": 1.784,
      "grad_norm": 1.2221027612686157,
      "learning_rate": 4.1920408163265304e-05,
      "loss": 0.1314,
      "step": 4460
    },
    {
      "epoch": 1.788,
      "grad_norm": 1.2784229516983032,
      "learning_rate": 4.19e-05,
      "loss": 0.1412,
      "step": 4470
    },
    {
      "epoch": 1.792,
      "grad_norm": 1.7576227188110352,
      "learning_rate": 4.1879591836734694e-05,
      "loss": 0.1392,
      "step": 4480
    },
    {
      "epoch": 1.796,
      "grad_norm": 0.8542177081108093,
      "learning_rate": 4.1859183673469385e-05,
      "loss": 0.1362,
      "step": 4490
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.8311381936073303,
      "learning_rate": 4.1838775510204084e-05,
      "loss": 0.1127,
      "step": 4500
    },
    {
      "epoch": 1.804,
      "grad_norm": 0.9904112815856934,
      "learning_rate": 4.1818367346938775e-05,
      "loss": 0.128,
      "step": 4510
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.15198883414268494,
      "learning_rate": 4.1797959183673473e-05,
      "loss": 0.106,
      "step": 4520
    },
    {
      "epoch": 1.812,
      "grad_norm": 0.6793231964111328,
      "learning_rate": 4.1777551020408165e-05,
      "loss": 0.0889,
      "step": 4530
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 0.542214572429657,
      "learning_rate": 4.1757142857142863e-05,
      "loss": 0.137,
      "step": 4540
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 0.653413712978363,
      "learning_rate": 4.1736734693877555e-05,
      "loss": 0.1201,
      "step": 4550
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 1.089608907699585,
      "learning_rate": 4.1716326530612247e-05,
      "loss": 0.1434,
      "step": 4560
    },
    {
      "epoch": 1.8279999999999998,
      "grad_norm": 0.4249861240386963,
      "learning_rate": 4.1695918367346945e-05,
      "loss": 0.0882,
      "step": 4570
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 0.6777155995368958,
      "learning_rate": 4.1675510204081637e-05,
      "loss": 0.146,
      "step": 4580
    },
    {
      "epoch": 1.8359999999999999,
      "grad_norm": 0.6581858992576599,
      "learning_rate": 4.165510204081633e-05,
      "loss": 0.1311,
      "step": 4590
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 1.4366825819015503,
      "learning_rate": 4.1634693877551026e-05,
      "loss": 0.1303,
      "step": 4600
    },
    {
      "epoch": 1.8439999999999999,
      "grad_norm": 0.28082066774368286,
      "learning_rate": 4.161428571428572e-05,
      "loss": 0.1176,
      "step": 4610
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 0.3364940285682678,
      "learning_rate": 4.159387755102041e-05,
      "loss": 0.0676,
      "step": 4620
    },
    {
      "epoch": 1.8519999999999999,
      "grad_norm": 0.6605531573295593,
      "learning_rate": 4.15734693877551e-05,
      "loss": 0.1077,
      "step": 4630
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 1.2933002710342407,
      "learning_rate": 4.15530612244898e-05,
      "loss": 0.1429,
      "step": 4640
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 1.0293182134628296,
      "learning_rate": 4.153265306122449e-05,
      "loss": 0.1186,
      "step": 4650
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 0.39112555980682373,
      "learning_rate": 4.151224489795918e-05,
      "loss": 0.131,
      "step": 4660
    },
    {
      "epoch": 1.8679999999999999,
      "grad_norm": 0.6344195604324341,
      "learning_rate": 4.149183673469388e-05,
      "loss": 0.1017,
      "step": 4670
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.8751492500305176,
      "learning_rate": 4.147142857142857e-05,
      "loss": 0.1656,
      "step": 4680
    },
    {
      "epoch": 1.876,
      "grad_norm": 0.8829601407051086,
      "learning_rate": 4.1451020408163264e-05,
      "loss": 0.1237,
      "step": 4690
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.258910208940506,
      "learning_rate": 4.143061224489796e-05,
      "loss": 0.0709,
      "step": 4700
    },
    {
      "epoch": 1.884,
      "grad_norm": 1.0904593467712402,
      "learning_rate": 4.1410204081632654e-05,
      "loss": 0.1103,
      "step": 4710
    },
    {
      "epoch": 1.888,
      "grad_norm": 1.24696683883667,
      "learning_rate": 4.1389795918367346e-05,
      "loss": 0.1387,
      "step": 4720
    },
    {
      "epoch": 1.892,
      "grad_norm": 0.8957502841949463,
      "learning_rate": 4.136938775510204e-05,
      "loss": 0.1062,
      "step": 4730
    },
    {
      "epoch": 1.896,
      "grad_norm": 1.4759398698806763,
      "learning_rate": 4.1348979591836736e-05,
      "loss": 0.148,
      "step": 4740
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.305888831615448,
      "learning_rate": 4.1328571428571434e-05,
      "loss": 0.1095,
      "step": 4750
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.7560614347457886,
      "learning_rate": 4.1308163265306126e-05,
      "loss": 0.1243,
      "step": 4760
    },
    {
      "epoch": 1.908,
      "grad_norm": 1.1621639728546143,
      "learning_rate": 4.128775510204082e-05,
      "loss": 0.1214,
      "step": 4770
    },
    {
      "epoch": 1.912,
      "grad_norm": 0.42364799976348877,
      "learning_rate": 4.1267346938775516e-05,
      "loss": 0.1121,
      "step": 4780
    },
    {
      "epoch": 1.916,
      "grad_norm": 1.1115508079528809,
      "learning_rate": 4.124693877551021e-05,
      "loss": 0.1251,
      "step": 4790
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.9086545705795288,
      "learning_rate": 4.12265306122449e-05,
      "loss": 0.1259,
      "step": 4800
    },
    {
      "epoch": 1.924,
      "grad_norm": 0.9779207110404968,
      "learning_rate": 4.12061224489796e-05,
      "loss": 0.0971,
      "step": 4810
    },
    {
      "epoch": 1.928,
      "grad_norm": 0.7898931503295898,
      "learning_rate": 4.118571428571429e-05,
      "loss": 0.1389,
      "step": 4820
    },
    {
      "epoch": 1.932,
      "grad_norm": 0.3200424313545227,
      "learning_rate": 4.116530612244898e-05,
      "loss": 0.1164,
      "step": 4830
    },
    {
      "epoch": 1.936,
      "grad_norm": 1.0343104600906372,
      "learning_rate": 4.114489795918368e-05,
      "loss": 0.1356,
      "step": 4840
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.5151904225349426,
      "learning_rate": 4.112448979591837e-05,
      "loss": 0.108,
      "step": 4850
    },
    {
      "epoch": 1.944,
      "grad_norm": 0.72542405128479,
      "learning_rate": 4.110408163265306e-05,
      "loss": 0.1101,
      "step": 4860
    },
    {
      "epoch": 1.948,
      "grad_norm": 0.5008867979049683,
      "learning_rate": 4.1083673469387753e-05,
      "loss": 0.1336,
      "step": 4870
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.4390740692615509,
      "learning_rate": 4.106326530612245e-05,
      "loss": 0.1403,
      "step": 4880
    },
    {
      "epoch": 1.956,
      "grad_norm": 0.6992005705833435,
      "learning_rate": 4.1042857142857143e-05,
      "loss": 0.146,
      "step": 4890
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.9003922343254089,
      "learning_rate": 4.1022448979591835e-05,
      "loss": 0.0934,
      "step": 4900
    },
    {
      "epoch": 1.964,
      "grad_norm": 1.5267560482025146,
      "learning_rate": 4.100204081632653e-05,
      "loss": 0.0958,
      "step": 4910
    },
    {
      "epoch": 1.968,
      "grad_norm": 1.1183735132217407,
      "learning_rate": 4.0981632653061225e-05,
      "loss": 0.145,
      "step": 4920
    },
    {
      "epoch": 1.972,
      "grad_norm": 1.078264832496643,
      "learning_rate": 4.0961224489795917e-05,
      "loss": 0.1401,
      "step": 4930
    },
    {
      "epoch": 1.976,
      "grad_norm": 0.5080274939537048,
      "learning_rate": 4.0940816326530615e-05,
      "loss": 0.1139,
      "step": 4940
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.4269140064716339,
      "learning_rate": 4.0920408163265306e-05,
      "loss": 0.1484,
      "step": 4950
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.9946349859237671,
      "learning_rate": 4.09e-05,
      "loss": 0.157,
      "step": 4960
    },
    {
      "epoch": 1.988,
      "grad_norm": 0.5180814862251282,
      "learning_rate": 4.0879591836734696e-05,
      "loss": 0.1161,
      "step": 4970
    },
    {
      "epoch": 1.992,
      "grad_norm": 1.2932029962539673,
      "learning_rate": 4.0859183673469395e-05,
      "loss": 0.1508,
      "step": 4980
    },
    {
      "epoch": 1.996,
      "grad_norm": 1.1882041692733765,
      "learning_rate": 4.0838775510204086e-05,
      "loss": 0.0989,
      "step": 4990
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.5313844084739685,
      "learning_rate": 4.081836734693878e-05,
      "loss": 0.1269,
      "step": 5000
    },
    {
      "epoch": 2.004,
      "grad_norm": 0.3256315588951111,
      "learning_rate": 4.0797959183673476e-05,
      "loss": 0.0801,
      "step": 5010
    },
    {
      "epoch": 2.008,
      "grad_norm": 0.8326455354690552,
      "learning_rate": 4.077755102040817e-05,
      "loss": 0.1186,
      "step": 5020
    },
    {
      "epoch": 2.012,
      "grad_norm": 0.8231395483016968,
      "learning_rate": 4.075714285714286e-05,
      "loss": 0.1176,
      "step": 5030
    },
    {
      "epoch": 2.016,
      "grad_norm": 1.0464447736740112,
      "learning_rate": 4.073673469387755e-05,
      "loss": 0.142,
      "step": 5040
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.8932238221168518,
      "learning_rate": 4.071632653061225e-05,
      "loss": 0.1149,
      "step": 5050
    },
    {
      "epoch": 2.024,
      "grad_norm": 0.2593902349472046,
      "learning_rate": 4.069591836734694e-05,
      "loss": 0.1078,
      "step": 5060
    },
    {
      "epoch": 2.028,
      "grad_norm": 0.3467763066291809,
      "learning_rate": 4.067551020408163e-05,
      "loss": 0.1268,
      "step": 5070
    },
    {
      "epoch": 2.032,
      "grad_norm": 0.7464624047279358,
      "learning_rate": 4.065510204081633e-05,
      "loss": 0.1167,
      "step": 5080
    },
    {
      "epoch": 2.036,
      "grad_norm": 0.23358380794525146,
      "learning_rate": 4.063469387755102e-05,
      "loss": 0.1428,
      "step": 5090
    },
    {
      "epoch": 2.04,
      "grad_norm": 1.431191086769104,
      "learning_rate": 4.0614285714285714e-05,
      "loss": 0.1447,
      "step": 5100
    },
    {
      "epoch": 2.044,
      "grad_norm": 0.6020730137825012,
      "learning_rate": 4.059387755102041e-05,
      "loss": 0.1304,
      "step": 5110
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.6258113980293274,
      "learning_rate": 4.0573469387755104e-05,
      "loss": 0.0796,
      "step": 5120
    },
    {
      "epoch": 2.052,
      "grad_norm": 0.8621770739555359,
      "learning_rate": 4.0553061224489796e-05,
      "loss": 0.113,
      "step": 5130
    },
    {
      "epoch": 2.056,
      "grad_norm": 1.0150959491729736,
      "learning_rate": 4.053265306122449e-05,
      "loss": 0.1348,
      "step": 5140
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.792772114276886,
      "learning_rate": 4.0512244897959186e-05,
      "loss": 0.1608,
      "step": 5150
    },
    {
      "epoch": 2.064,
      "grad_norm": 0.9216389656066895,
      "learning_rate": 4.049183673469388e-05,
      "loss": 0.1142,
      "step": 5160
    },
    {
      "epoch": 2.068,
      "grad_norm": 1.0613982677459717,
      "learning_rate": 4.047142857142857e-05,
      "loss": 0.1084,
      "step": 5170
    },
    {
      "epoch": 2.072,
      "grad_norm": 0.7958241701126099,
      "learning_rate": 4.045102040816327e-05,
      "loss": 0.1335,
      "step": 5180
    },
    {
      "epoch": 2.076,
      "grad_norm": 1.2516520023345947,
      "learning_rate": 4.043061224489796e-05,
      "loss": 0.0905,
      "step": 5190
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.4266515374183655,
      "learning_rate": 4.041020408163266e-05,
      "loss": 0.1035,
      "step": 5200
    },
    {
      "epoch": 2.084,
      "grad_norm": 0.9410691261291504,
      "learning_rate": 4.038979591836735e-05,
      "loss": 0.1202,
      "step": 5210
    },
    {
      "epoch": 2.088,
      "grad_norm": 0.5112864375114441,
      "learning_rate": 4.036938775510205e-05,
      "loss": 0.0742,
      "step": 5220
    },
    {
      "epoch": 2.092,
      "grad_norm": 1.0976941585540771,
      "learning_rate": 4.034897959183674e-05,
      "loss": 0.1345,
      "step": 5230
    },
    {
      "epoch": 2.096,
      "grad_norm": 1.3920921087265015,
      "learning_rate": 4.032857142857143e-05,
      "loss": 0.0919,
      "step": 5240
    },
    {
      "epoch": 2.1,
      "grad_norm": 1.0094685554504395,
      "learning_rate": 4.030816326530613e-05,
      "loss": 0.1153,
      "step": 5250
    },
    {
      "epoch": 2.104,
      "grad_norm": 1.0665900707244873,
      "learning_rate": 4.028775510204082e-05,
      "loss": 0.0774,
      "step": 5260
    },
    {
      "epoch": 2.108,
      "grad_norm": 0.625679612159729,
      "learning_rate": 4.026734693877551e-05,
      "loss": 0.1336,
      "step": 5270
    },
    {
      "epoch": 2.112,
      "grad_norm": 1.4403715133666992,
      "learning_rate": 4.024693877551021e-05,
      "loss": 0.1627,
      "step": 5280
    },
    {
      "epoch": 2.116,
      "grad_norm": 0.6953492760658264,
      "learning_rate": 4.02265306122449e-05,
      "loss": 0.1309,
      "step": 5290
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.1926804631948471,
      "learning_rate": 4.020612244897959e-05,
      "loss": 0.087,
      "step": 5300
    },
    {
      "epoch": 2.124,
      "grad_norm": 0.6771782636642456,
      "learning_rate": 4.0185714285714285e-05,
      "loss": 0.1182,
      "step": 5310
    },
    {
      "epoch": 2.128,
      "grad_norm": 1.092373251914978,
      "learning_rate": 4.016530612244898e-05,
      "loss": 0.1342,
      "step": 5320
    },
    {
      "epoch": 2.132,
      "grad_norm": 0.6079437136650085,
      "learning_rate": 4.0144897959183675e-05,
      "loss": 0.1083,
      "step": 5330
    },
    {
      "epoch": 2.136,
      "grad_norm": 1.0997275114059448,
      "learning_rate": 4.0124489795918366e-05,
      "loss": 0.1037,
      "step": 5340
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.6154453754425049,
      "learning_rate": 4.0104081632653065e-05,
      "loss": 0.0951,
      "step": 5350
    },
    {
      "epoch": 2.144,
      "grad_norm": 0.6868354082107544,
      "learning_rate": 4.0083673469387756e-05,
      "loss": 0.0802,
      "step": 5360
    },
    {
      "epoch": 2.148,
      "grad_norm": 1.0785834789276123,
      "learning_rate": 4.006326530612245e-05,
      "loss": 0.1262,
      "step": 5370
    },
    {
      "epoch": 2.152,
      "grad_norm": 0.7050629258155823,
      "learning_rate": 4.0042857142857146e-05,
      "loss": 0.1244,
      "step": 5380
    },
    {
      "epoch": 2.156,
      "grad_norm": 0.5109451413154602,
      "learning_rate": 4.002244897959184e-05,
      "loss": 0.085,
      "step": 5390
    },
    {
      "epoch": 2.16,
      "grad_norm": 1.0084067583084106,
      "learning_rate": 4.000204081632653e-05,
      "loss": 0.1482,
      "step": 5400
    },
    {
      "epoch": 2.164,
      "grad_norm": 1.1618505716323853,
      "learning_rate": 3.998163265306122e-05,
      "loss": 0.1611,
      "step": 5410
    },
    {
      "epoch": 2.168,
      "grad_norm": 0.2919613718986511,
      "learning_rate": 3.996122448979592e-05,
      "loss": 0.0685,
      "step": 5420
    },
    {
      "epoch": 2.172,
      "grad_norm": 0.5227078795433044,
      "learning_rate": 3.994081632653062e-05,
      "loss": 0.0696,
      "step": 5430
    },
    {
      "epoch": 2.176,
      "grad_norm": 1.1297203302383423,
      "learning_rate": 3.992040816326531e-05,
      "loss": 0.1125,
      "step": 5440
    },
    {
      "epoch": 2.18,
      "grad_norm": 1.3721702098846436,
      "learning_rate": 3.99e-05,
      "loss": 0.1475,
      "step": 5450
    },
    {
      "epoch": 2.184,
      "grad_norm": 0.5165119171142578,
      "learning_rate": 3.98795918367347e-05,
      "loss": 0.1284,
      "step": 5460
    },
    {
      "epoch": 2.188,
      "grad_norm": 0.4019649624824524,
      "learning_rate": 3.985918367346939e-05,
      "loss": 0.0836,
      "step": 5470
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.27196434140205383,
      "learning_rate": 3.983877551020408e-05,
      "loss": 0.0747,
      "step": 5480
    },
    {
      "epoch": 2.196,
      "grad_norm": 1.1084485054016113,
      "learning_rate": 3.981836734693878e-05,
      "loss": 0.1222,
      "step": 5490
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.112529993057251,
      "learning_rate": 3.979795918367347e-05,
      "loss": 0.1373,
      "step": 5500
    },
    {
      "epoch": 2.204,
      "grad_norm": 1.2316054105758667,
      "learning_rate": 3.9777551020408164e-05,
      "loss": 0.0825,
      "step": 5510
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.7898724675178528,
      "learning_rate": 3.975714285714286e-05,
      "loss": 0.0984,
      "step": 5520
    },
    {
      "epoch": 2.212,
      "grad_norm": 0.8601699471473694,
      "learning_rate": 3.9736734693877554e-05,
      "loss": 0.1466,
      "step": 5530
    },
    {
      "epoch": 2.216,
      "grad_norm": 0.7619509696960449,
      "learning_rate": 3.9716326530612245e-05,
      "loss": 0.1937,
      "step": 5540
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.6245893239974976,
      "learning_rate": 3.969591836734694e-05,
      "loss": 0.1041,
      "step": 5550
    },
    {
      "epoch": 2.224,
      "grad_norm": 0.4254383444786072,
      "learning_rate": 3.9675510204081635e-05,
      "loss": 0.0879,
      "step": 5560
    },
    {
      "epoch": 2.228,
      "grad_norm": 0.8844025731086731,
      "learning_rate": 3.965510204081633e-05,
      "loss": 0.085,
      "step": 5570
    },
    {
      "epoch": 2.232,
      "grad_norm": 0.5487011671066284,
      "learning_rate": 3.963469387755102e-05,
      "loss": 0.0648,
      "step": 5580
    },
    {
      "epoch": 2.2359999999999998,
      "grad_norm": 1.1652905941009521,
      "learning_rate": 3.961428571428572e-05,
      "loss": 0.1177,
      "step": 5590
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.5791840553283691,
      "learning_rate": 3.959387755102041e-05,
      "loss": 0.1026,
      "step": 5600
    },
    {
      "epoch": 2.2439999999999998,
      "grad_norm": 0.5419225692749023,
      "learning_rate": 3.95734693877551e-05,
      "loss": 0.1119,
      "step": 5610
    },
    {
      "epoch": 2.248,
      "grad_norm": 0.3440704643726349,
      "learning_rate": 3.95530612244898e-05,
      "loss": 0.066,
      "step": 5620
    },
    {
      "epoch": 2.252,
      "grad_norm": 0.3632589876651764,
      "learning_rate": 3.953265306122449e-05,
      "loss": 0.1171,
      "step": 5630
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 0.3566359877586365,
      "learning_rate": 3.951224489795918e-05,
      "loss": 0.1249,
      "step": 5640
    },
    {
      "epoch": 2.26,
      "grad_norm": 1.129160761833191,
      "learning_rate": 3.949183673469388e-05,
      "loss": 0.1738,
      "step": 5650
    },
    {
      "epoch": 2.2640000000000002,
      "grad_norm": 0.9628431797027588,
      "learning_rate": 3.947142857142858e-05,
      "loss": 0.1087,
      "step": 5660
    },
    {
      "epoch": 2.268,
      "grad_norm": 0.9016406536102295,
      "learning_rate": 3.945102040816327e-05,
      "loss": 0.1005,
      "step": 5670
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 1.0062675476074219,
      "learning_rate": 3.943061224489796e-05,
      "loss": 0.1264,
      "step": 5680
    },
    {
      "epoch": 2.276,
      "grad_norm": 0.9257067441940308,
      "learning_rate": 3.941020408163266e-05,
      "loss": 0.1249,
      "step": 5690
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 1.574970006942749,
      "learning_rate": 3.938979591836735e-05,
      "loss": 0.1244,
      "step": 5700
    },
    {
      "epoch": 2.284,
      "grad_norm": 0.871432363986969,
      "learning_rate": 3.936938775510204e-05,
      "loss": 0.1338,
      "step": 5710
    },
    {
      "epoch": 2.288,
      "grad_norm": 0.6948128342628479,
      "learning_rate": 3.9348979591836735e-05,
      "loss": 0.1229,
      "step": 5720
    },
    {
      "epoch": 2.292,
      "grad_norm": 0.20771093666553497,
      "learning_rate": 3.932857142857143e-05,
      "loss": 0.1497,
      "step": 5730
    },
    {
      "epoch": 2.296,
      "grad_norm": 0.8856332302093506,
      "learning_rate": 3.9308163265306125e-05,
      "loss": 0.2212,
      "step": 5740
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.3516431450843811,
      "learning_rate": 3.9287755102040816e-05,
      "loss": 0.0884,
      "step": 5750
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.9888623952865601,
      "learning_rate": 3.9267346938775514e-05,
      "loss": 0.1194,
      "step": 5760
    },
    {
      "epoch": 2.308,
      "grad_norm": 0.8429744839668274,
      "learning_rate": 3.9246938775510206e-05,
      "loss": 0.104,
      "step": 5770
    },
    {
      "epoch": 2.312,
      "grad_norm": 0.8267683982849121,
      "learning_rate": 3.92265306122449e-05,
      "loss": 0.0853,
      "step": 5780
    },
    {
      "epoch": 2.316,
      "grad_norm": 0.26944857835769653,
      "learning_rate": 3.9206122448979596e-05,
      "loss": 0.071,
      "step": 5790
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.31409958004951477,
      "learning_rate": 3.918571428571429e-05,
      "loss": 0.1095,
      "step": 5800
    },
    {
      "epoch": 2.324,
      "grad_norm": 1.313391089439392,
      "learning_rate": 3.916530612244898e-05,
      "loss": 0.138,
      "step": 5810
    },
    {
      "epoch": 2.328,
      "grad_norm": 0.35515883564949036,
      "learning_rate": 3.914489795918367e-05,
      "loss": 0.0852,
      "step": 5820
    },
    {
      "epoch": 2.332,
      "grad_norm": 0.470897376537323,
      "learning_rate": 3.912448979591837e-05,
      "loss": 0.11,
      "step": 5830
    },
    {
      "epoch": 2.336,
      "grad_norm": 0.6108416318893433,
      "learning_rate": 3.910408163265306e-05,
      "loss": 0.1171,
      "step": 5840
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.8846965432167053,
      "learning_rate": 3.908367346938775e-05,
      "loss": 0.0975,
      "step": 5850
    },
    {
      "epoch": 2.344,
      "grad_norm": 0.19608400762081146,
      "learning_rate": 3.906326530612245e-05,
      "loss": 0.1316,
      "step": 5860
    },
    {
      "epoch": 2.348,
      "grad_norm": 1.3997869491577148,
      "learning_rate": 3.904285714285714e-05,
      "loss": 0.1219,
      "step": 5870
    },
    {
      "epoch": 2.352,
      "grad_norm": 0.9831692576408386,
      "learning_rate": 3.902244897959184e-05,
      "loss": 0.0995,
      "step": 5880
    },
    {
      "epoch": 2.356,
      "grad_norm": 0.7226189970970154,
      "learning_rate": 3.900204081632653e-05,
      "loss": 0.0806,
      "step": 5890
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.47886714339256287,
      "learning_rate": 3.898163265306123e-05,
      "loss": 0.1099,
      "step": 5900
    },
    {
      "epoch": 2.364,
      "grad_norm": 1.0548337697982788,
      "learning_rate": 3.896122448979592e-05,
      "loss": 0.0989,
      "step": 5910
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.9425394535064697,
      "learning_rate": 3.8940816326530614e-05,
      "loss": 0.0917,
      "step": 5920
    },
    {
      "epoch": 2.372,
      "grad_norm": 0.2627590596675873,
      "learning_rate": 3.892040816326531e-05,
      "loss": 0.0942,
      "step": 5930
    },
    {
      "epoch": 2.376,
      "grad_norm": 1.0530073642730713,
      "learning_rate": 3.8900000000000004e-05,
      "loss": 0.1262,
      "step": 5940
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.2722657322883606,
      "learning_rate": 3.8879591836734695e-05,
      "loss": 0.1264,
      "step": 5950
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.4559287130832672,
      "learning_rate": 3.8859183673469394e-05,
      "loss": 0.1097,
      "step": 5960
    },
    {
      "epoch": 2.388,
      "grad_norm": 0.6770692467689514,
      "learning_rate": 3.8838775510204085e-05,
      "loss": 0.1284,
      "step": 5970
    },
    {
      "epoch": 2.392,
      "grad_norm": 1.1014331579208374,
      "learning_rate": 3.881836734693878e-05,
      "loss": 0.0984,
      "step": 5980
    },
    {
      "epoch": 2.396,
      "grad_norm": 0.16928836703300476,
      "learning_rate": 3.879795918367347e-05,
      "loss": 0.1112,
      "step": 5990
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.634394645690918,
      "learning_rate": 3.877755102040817e-05,
      "loss": 0.131,
      "step": 6000
    },
    {
      "epoch": 2.404,
      "grad_norm": 0.700853705406189,
      "learning_rate": 3.875714285714286e-05,
      "loss": 0.0964,
      "step": 6010
    },
    {
      "epoch": 2.408,
      "grad_norm": 0.7379986643791199,
      "learning_rate": 3.873673469387755e-05,
      "loss": 0.1029,
      "step": 6020
    },
    {
      "epoch": 2.412,
      "grad_norm": 0.5539306998252869,
      "learning_rate": 3.871632653061225e-05,
      "loss": 0.0657,
      "step": 6030
    },
    {
      "epoch": 2.416,
      "grad_norm": 1.3795300722122192,
      "learning_rate": 3.869591836734694e-05,
      "loss": 0.1161,
      "step": 6040
    },
    {
      "epoch": 2.42,
      "grad_norm": 1.1388832330703735,
      "learning_rate": 3.867551020408163e-05,
      "loss": 0.0869,
      "step": 6050
    },
    {
      "epoch": 2.424,
      "grad_norm": 0.694307267665863,
      "learning_rate": 3.865510204081633e-05,
      "loss": 0.0813,
      "step": 6060
    },
    {
      "epoch": 2.428,
      "grad_norm": 0.8780298233032227,
      "learning_rate": 3.863469387755102e-05,
      "loss": 0.0642,
      "step": 6070
    },
    {
      "epoch": 2.432,
      "grad_norm": 1.1851940155029297,
      "learning_rate": 3.861428571428571e-05,
      "loss": 0.0873,
      "step": 6080
    },
    {
      "epoch": 2.436,
      "grad_norm": 0.3059636652469635,
      "learning_rate": 3.8593877551020405e-05,
      "loss": 0.1509,
      "step": 6090
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.7261601090431213,
      "learning_rate": 3.85734693877551e-05,
      "loss": 0.1026,
      "step": 6100
    },
    {
      "epoch": 2.444,
      "grad_norm": 0.9516509771347046,
      "learning_rate": 3.85530612244898e-05,
      "loss": 0.1183,
      "step": 6110
    },
    {
      "epoch": 2.448,
      "grad_norm": 0.46964141726493835,
      "learning_rate": 3.853265306122449e-05,
      "loss": 0.0889,
      "step": 6120
    },
    {
      "epoch": 2.452,
      "grad_norm": 1.0238375663757324,
      "learning_rate": 3.8512244897959184e-05,
      "loss": 0.112,
      "step": 6130
    },
    {
      "epoch": 2.456,
      "grad_norm": 1.2237757444381714,
      "learning_rate": 3.849183673469388e-05,
      "loss": 0.0876,
      "step": 6140
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.1896916925907135,
      "learning_rate": 3.8471428571428574e-05,
      "loss": 0.1372,
      "step": 6150
    },
    {
      "epoch": 2.464,
      "grad_norm": 0.7894453406333923,
      "learning_rate": 3.8451020408163266e-05,
      "loss": 0.0623,
      "step": 6160
    },
    {
      "epoch": 2.468,
      "grad_norm": 0.8797659873962402,
      "learning_rate": 3.8430612244897964e-05,
      "loss": 0.1289,
      "step": 6170
    },
    {
      "epoch": 2.472,
      "grad_norm": 0.2692916989326477,
      "learning_rate": 3.8410204081632656e-05,
      "loss": 0.1049,
      "step": 6180
    },
    {
      "epoch": 2.476,
      "grad_norm": 0.8738166689872742,
      "learning_rate": 3.838979591836735e-05,
      "loss": 0.0681,
      "step": 6190
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.21715083718299866,
      "learning_rate": 3.8369387755102046e-05,
      "loss": 0.1009,
      "step": 6200
    },
    {
      "epoch": 2.484,
      "grad_norm": 1.6812143325805664,
      "learning_rate": 3.834897959183674e-05,
      "loss": 0.107,
      "step": 6210
    },
    {
      "epoch": 2.488,
      "grad_norm": 1.0895960330963135,
      "learning_rate": 3.832857142857143e-05,
      "loss": 0.1217,
      "step": 6220
    },
    {
      "epoch": 2.492,
      "grad_norm": 0.5698420405387878,
      "learning_rate": 3.830816326530613e-05,
      "loss": 0.1093,
      "step": 6230
    },
    {
      "epoch": 2.496,
      "grad_norm": 1.0472183227539062,
      "learning_rate": 3.828775510204082e-05,
      "loss": 0.1368,
      "step": 6240
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.3384639620780945,
      "learning_rate": 3.826734693877551e-05,
      "loss": 0.0905,
      "step": 6250
    },
    {
      "epoch": 2.504,
      "grad_norm": 0.6715230941772461,
      "learning_rate": 3.82469387755102e-05,
      "loss": 0.1027,
      "step": 6260
    },
    {
      "epoch": 2.508,
      "grad_norm": 0.10777277499437332,
      "learning_rate": 3.82265306122449e-05,
      "loss": 0.1041,
      "step": 6270
    },
    {
      "epoch": 2.512,
      "grad_norm": 1.1595566272735596,
      "learning_rate": 3.820612244897959e-05,
      "loss": 0.0941,
      "step": 6280
    },
    {
      "epoch": 2.516,
      "grad_norm": 0.338288813829422,
      "learning_rate": 3.8185714285714284e-05,
      "loss": 0.0941,
      "step": 6290
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.8416520953178406,
      "learning_rate": 3.816530612244898e-05,
      "loss": 0.1183,
      "step": 6300
    },
    {
      "epoch": 2.524,
      "grad_norm": 0.47468435764312744,
      "learning_rate": 3.8144897959183674e-05,
      "loss": 0.1241,
      "step": 6310
    },
    {
      "epoch": 2.528,
      "grad_norm": 1.3245277404785156,
      "learning_rate": 3.8124489795918365e-05,
      "loss": 0.126,
      "step": 6320
    },
    {
      "epoch": 2.532,
      "grad_norm": 1.355132818222046,
      "learning_rate": 3.8104081632653063e-05,
      "loss": 0.1061,
      "step": 6330
    },
    {
      "epoch": 2.536,
      "grad_norm": 1.1699012517929077,
      "learning_rate": 3.808367346938776e-05,
      "loss": 0.1255,
      "step": 6340
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.7125569581985474,
      "learning_rate": 3.8063265306122453e-05,
      "loss": 0.1376,
      "step": 6350
    },
    {
      "epoch": 2.544,
      "grad_norm": 0.6167476773262024,
      "learning_rate": 3.8042857142857145e-05,
      "loss": 0.0919,
      "step": 6360
    },
    {
      "epoch": 2.548,
      "grad_norm": 0.6079023480415344,
      "learning_rate": 3.802244897959184e-05,
      "loss": 0.1149,
      "step": 6370
    },
    {
      "epoch": 2.552,
      "grad_norm": 0.9301245808601379,
      "learning_rate": 3.8002040816326535e-05,
      "loss": 0.1252,
      "step": 6380
    },
    {
      "epoch": 2.556,
      "grad_norm": 0.19560177624225616,
      "learning_rate": 3.7981632653061227e-05,
      "loss": 0.0929,
      "step": 6390
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.5015087723731995,
      "learning_rate": 3.796122448979592e-05,
      "loss": 0.1047,
      "step": 6400
    },
    {
      "epoch": 2.564,
      "grad_norm": 1.0339066982269287,
      "learning_rate": 3.7940816326530616e-05,
      "loss": 0.1169,
      "step": 6410
    },
    {
      "epoch": 2.568,
      "grad_norm": 1.1205103397369385,
      "learning_rate": 3.792040816326531e-05,
      "loss": 0.1526,
      "step": 6420
    },
    {
      "epoch": 2.572,
      "grad_norm": 0.3368460536003113,
      "learning_rate": 3.79e-05,
      "loss": 0.107,
      "step": 6430
    },
    {
      "epoch": 2.576,
      "grad_norm": 0.9996985197067261,
      "learning_rate": 3.78795918367347e-05,
      "loss": 0.1009,
      "step": 6440
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.807528018951416,
      "learning_rate": 3.785918367346939e-05,
      "loss": 0.0981,
      "step": 6450
    },
    {
      "epoch": 2.584,
      "grad_norm": 1.628237247467041,
      "learning_rate": 3.783877551020408e-05,
      "loss": 0.0646,
      "step": 6460
    },
    {
      "epoch": 2.588,
      "grad_norm": 1.201086401939392,
      "learning_rate": 3.781836734693878e-05,
      "loss": 0.0951,
      "step": 6470
    },
    {
      "epoch": 2.592,
      "grad_norm": 0.6063015460968018,
      "learning_rate": 3.779795918367347e-05,
      "loss": 0.0745,
      "step": 6480
    },
    {
      "epoch": 2.596,
      "grad_norm": 0.6498861312866211,
      "learning_rate": 3.777755102040816e-05,
      "loss": 0.1324,
      "step": 6490
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.9221120476722717,
      "learning_rate": 3.7757142857142854e-05,
      "loss": 0.0984,
      "step": 6500
    },
    {
      "epoch": 2.604,
      "grad_norm": 0.3126329481601715,
      "learning_rate": 3.773673469387755e-05,
      "loss": 0.1206,
      "step": 6510
    },
    {
      "epoch": 2.608,
      "grad_norm": 1.2832919359207153,
      "learning_rate": 3.7716326530612244e-05,
      "loss": 0.0761,
      "step": 6520
    },
    {
      "epoch": 2.612,
      "grad_norm": 0.43616974353790283,
      "learning_rate": 3.7695918367346936e-05,
      "loss": 0.092,
      "step": 6530
    },
    {
      "epoch": 2.616,
      "grad_norm": 0.8923965096473694,
      "learning_rate": 3.7675510204081634e-05,
      "loss": 0.1156,
      "step": 6540
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.19116634130477905,
      "learning_rate": 3.7655102040816326e-05,
      "loss": 0.1054,
      "step": 6550
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.6598361730575562,
      "learning_rate": 3.7634693877551024e-05,
      "loss": 0.1019,
      "step": 6560
    },
    {
      "epoch": 2.628,
      "grad_norm": 0.6146557331085205,
      "learning_rate": 3.7614285714285716e-05,
      "loss": 0.1351,
      "step": 6570
    },
    {
      "epoch": 2.632,
      "grad_norm": 0.8514676094055176,
      "learning_rate": 3.7593877551020414e-05,
      "loss": 0.1334,
      "step": 6580
    },
    {
      "epoch": 2.636,
      "grad_norm": 0.8403699398040771,
      "learning_rate": 3.7573469387755106e-05,
      "loss": 0.0965,
      "step": 6590
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.7384771704673767,
      "learning_rate": 3.75530612244898e-05,
      "loss": 0.0693,
      "step": 6600
    },
    {
      "epoch": 2.644,
      "grad_norm": 0.6753109693527222,
      "learning_rate": 3.7532653061224496e-05,
      "loss": 0.0893,
      "step": 6610
    },
    {
      "epoch": 2.648,
      "grad_norm": 0.34127068519592285,
      "learning_rate": 3.751224489795919e-05,
      "loss": 0.0771,
      "step": 6620
    },
    {
      "epoch": 2.652,
      "grad_norm": 1.0854601860046387,
      "learning_rate": 3.749183673469388e-05,
      "loss": 0.0872,
      "step": 6630
    },
    {
      "epoch": 2.656,
      "grad_norm": 1.3443970680236816,
      "learning_rate": 3.747142857142858e-05,
      "loss": 0.1746,
      "step": 6640
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.8977381587028503,
      "learning_rate": 3.745102040816327e-05,
      "loss": 0.0844,
      "step": 6650
    },
    {
      "epoch": 2.664,
      "grad_norm": 0.8883904218673706,
      "learning_rate": 3.743061224489796e-05,
      "loss": 0.0869,
      "step": 6660
    },
    {
      "epoch": 2.668,
      "grad_norm": 0.32253092527389526,
      "learning_rate": 3.741020408163265e-05,
      "loss": 0.0914,
      "step": 6670
    },
    {
      "epoch": 2.672,
      "grad_norm": 2.2560696601867676,
      "learning_rate": 3.738979591836735e-05,
      "loss": 0.1329,
      "step": 6680
    },
    {
      "epoch": 2.676,
      "grad_norm": 1.0311938524246216,
      "learning_rate": 3.736938775510204e-05,
      "loss": 0.1218,
      "step": 6690
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.4811459481716156,
      "learning_rate": 3.7348979591836733e-05,
      "loss": 0.0778,
      "step": 6700
    },
    {
      "epoch": 2.684,
      "grad_norm": 1.370164394378662,
      "learning_rate": 3.732857142857143e-05,
      "loss": 0.1131,
      "step": 6710
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 0.9451515674591064,
      "learning_rate": 3.730816326530612e-05,
      "loss": 0.117,
      "step": 6720
    },
    {
      "epoch": 2.692,
      "grad_norm": 0.5370224714279175,
      "learning_rate": 3.7287755102040815e-05,
      "loss": 0.082,
      "step": 6730
    },
    {
      "epoch": 2.6959999999999997,
      "grad_norm": 0.6163593530654907,
      "learning_rate": 3.726734693877551e-05,
      "loss": 0.0989,
      "step": 6740
    },
    {
      "epoch": 2.7,
      "grad_norm": 1.1925026178359985,
      "learning_rate": 3.7246938775510205e-05,
      "loss": 0.11,
      "step": 6750
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 0.1032075583934784,
      "learning_rate": 3.7226530612244896e-05,
      "loss": 0.1155,
      "step": 6760
    },
    {
      "epoch": 2.708,
      "grad_norm": 0.04466830566525459,
      "learning_rate": 3.720612244897959e-05,
      "loss": 0.1314,
      "step": 6770
    },
    {
      "epoch": 2.7119999999999997,
      "grad_norm": 0.551973819732666,
      "learning_rate": 3.7185714285714286e-05,
      "loss": 0.0799,
      "step": 6780
    },
    {
      "epoch": 2.716,
      "grad_norm": 0.4493045508861542,
      "learning_rate": 3.7165306122448985e-05,
      "loss": 0.1037,
      "step": 6790
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 1.4911742210388184,
      "learning_rate": 3.7144897959183676e-05,
      "loss": 0.1371,
      "step": 6800
    },
    {
      "epoch": 2.724,
      "grad_norm": 0.9009726047515869,
      "learning_rate": 3.712448979591837e-05,
      "loss": 0.1045,
      "step": 6810
    },
    {
      "epoch": 2.7279999999999998,
      "grad_norm": 0.9439386129379272,
      "learning_rate": 3.7104081632653066e-05,
      "loss": 0.1564,
      "step": 6820
    },
    {
      "epoch": 2.732,
      "grad_norm": 0.37454721331596375,
      "learning_rate": 3.708367346938776e-05,
      "loss": 0.0861,
      "step": 6830
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.5203161239624023,
      "learning_rate": 3.706326530612245e-05,
      "loss": 0.1049,
      "step": 6840
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.6309175491333008,
      "learning_rate": 3.704285714285715e-05,
      "loss": 0.1084,
      "step": 6850
    },
    {
      "epoch": 2.7439999999999998,
      "grad_norm": 0.7606952786445618,
      "learning_rate": 3.702244897959184e-05,
      "loss": 0.1625,
      "step": 6860
    },
    {
      "epoch": 2.748,
      "grad_norm": 0.3050583302974701,
      "learning_rate": 3.700204081632653e-05,
      "loss": 0.1045,
      "step": 6870
    },
    {
      "epoch": 2.752,
      "grad_norm": 0.8689749240875244,
      "learning_rate": 3.698163265306123e-05,
      "loss": 0.062,
      "step": 6880
    },
    {
      "epoch": 2.7560000000000002,
      "grad_norm": 0.31302374601364136,
      "learning_rate": 3.696122448979592e-05,
      "loss": 0.0899,
      "step": 6890
    },
    {
      "epoch": 2.76,
      "grad_norm": 1.3883814811706543,
      "learning_rate": 3.694081632653061e-05,
      "loss": 0.1442,
      "step": 6900
    },
    {
      "epoch": 2.7640000000000002,
      "grad_norm": 0.5771811008453369,
      "learning_rate": 3.692040816326531e-05,
      "loss": 0.109,
      "step": 6910
    },
    {
      "epoch": 2.768,
      "grad_norm": 0.6570715308189392,
      "learning_rate": 3.69e-05,
      "loss": 0.1384,
      "step": 6920
    },
    {
      "epoch": 2.7720000000000002,
      "grad_norm": 0.863745391368866,
      "learning_rate": 3.6879591836734694e-05,
      "loss": 0.0808,
      "step": 6930
    },
    {
      "epoch": 2.776,
      "grad_norm": 0.28069615364074707,
      "learning_rate": 3.6859183673469386e-05,
      "loss": 0.0638,
      "step": 6940
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 1.3254895210266113,
      "learning_rate": 3.6838775510204084e-05,
      "loss": 0.1198,
      "step": 6950
    },
    {
      "epoch": 2.784,
      "grad_norm": 1.0458464622497559,
      "learning_rate": 3.6818367346938776e-05,
      "loss": 0.0983,
      "step": 6960
    },
    {
      "epoch": 2.7880000000000003,
      "grad_norm": 0.9438714981079102,
      "learning_rate": 3.679795918367347e-05,
      "loss": 0.0951,
      "step": 6970
    },
    {
      "epoch": 2.792,
      "grad_norm": 1.0190622806549072,
      "learning_rate": 3.6777551020408166e-05,
      "loss": 0.1536,
      "step": 6980
    },
    {
      "epoch": 2.7960000000000003,
      "grad_norm": 0.17751869559288025,
      "learning_rate": 3.675714285714286e-05,
      "loss": 0.0813,
      "step": 6990
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.4317703247070312,
      "learning_rate": 3.673673469387755e-05,
      "loss": 0.1223,
      "step": 7000
    },
    {
      "epoch": 2.8040000000000003,
      "grad_norm": 1.339961290359497,
      "learning_rate": 3.671632653061225e-05,
      "loss": 0.1271,
      "step": 7010
    },
    {
      "epoch": 2.808,
      "grad_norm": 0.780597984790802,
      "learning_rate": 3.6695918367346945e-05,
      "loss": 0.0989,
      "step": 7020
    },
    {
      "epoch": 2.8120000000000003,
      "grad_norm": 0.5870117545127869,
      "learning_rate": 3.667551020408164e-05,
      "loss": 0.0706,
      "step": 7030
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.3952646255493164,
      "learning_rate": 3.665510204081633e-05,
      "loss": 0.0911,
      "step": 7040
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.40582457184791565,
      "learning_rate": 3.663469387755103e-05,
      "loss": 0.0981,
      "step": 7050
    },
    {
      "epoch": 2.824,
      "grad_norm": 0.3601856231689453,
      "learning_rate": 3.661428571428572e-05,
      "loss": 0.1053,
      "step": 7060
    },
    {
      "epoch": 2.828,
      "grad_norm": 0.16375035047531128,
      "learning_rate": 3.659387755102041e-05,
      "loss": 0.0801,
      "step": 7070
    },
    {
      "epoch": 2.832,
      "grad_norm": 1.1706464290618896,
      "learning_rate": 3.65734693877551e-05,
      "loss": 0.0983,
      "step": 7080
    },
    {
      "epoch": 2.836,
      "grad_norm": 0.2981586456298828,
      "learning_rate": 3.65530612244898e-05,
      "loss": 0.0827,
      "step": 7090
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.5104764699935913,
      "learning_rate": 3.653265306122449e-05,
      "loss": 0.0868,
      "step": 7100
    },
    {
      "epoch": 2.844,
      "grad_norm": 0.9863152503967285,
      "learning_rate": 3.651224489795918e-05,
      "loss": 0.1258,
      "step": 7110
    },
    {
      "epoch": 2.848,
      "grad_norm": 0.06651017814874649,
      "learning_rate": 3.649183673469388e-05,
      "loss": 0.1046,
      "step": 7120
    },
    {
      "epoch": 2.852,
      "grad_norm": 1.215112328529358,
      "learning_rate": 3.647142857142857e-05,
      "loss": 0.0991,
      "step": 7130
    },
    {
      "epoch": 2.856,
      "grad_norm": 0.07323283702135086,
      "learning_rate": 3.6451020408163265e-05,
      "loss": 0.0923,
      "step": 7140
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.6553344130516052,
      "learning_rate": 3.643061224489796e-05,
      "loss": 0.1143,
      "step": 7150
    },
    {
      "epoch": 2.864,
      "grad_norm": 0.16002923250198364,
      "learning_rate": 3.6410204081632655e-05,
      "loss": 0.1172,
      "step": 7160
    },
    {
      "epoch": 2.868,
      "grad_norm": 0.6280889511108398,
      "learning_rate": 3.6389795918367346e-05,
      "loss": 0.0747,
      "step": 7170
    },
    {
      "epoch": 2.872,
      "grad_norm": 0.655930757522583,
      "learning_rate": 3.636938775510204e-05,
      "loss": 0.1077,
      "step": 7180
    },
    {
      "epoch": 2.876,
      "grad_norm": 0.2081955522298813,
      "learning_rate": 3.6348979591836736e-05,
      "loss": 0.0939,
      "step": 7190
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.08031602203845978,
      "learning_rate": 3.632857142857143e-05,
      "loss": 0.1246,
      "step": 7200
    },
    {
      "epoch": 2.884,
      "grad_norm": 0.8683332800865173,
      "learning_rate": 3.630816326530612e-05,
      "loss": 0.097,
      "step": 7210
    },
    {
      "epoch": 2.888,
      "grad_norm": 0.9346135854721069,
      "learning_rate": 3.628775510204082e-05,
      "loss": 0.1173,
      "step": 7220
    },
    {
      "epoch": 2.892,
      "grad_norm": 1.1545326709747314,
      "learning_rate": 3.626734693877551e-05,
      "loss": 0.0852,
      "step": 7230
    },
    {
      "epoch": 2.896,
      "grad_norm": 0.9405556917190552,
      "learning_rate": 3.624693877551021e-05,
      "loss": 0.1037,
      "step": 7240
    },
    {
      "epoch": 2.9,
      "grad_norm": 1.3772201538085938,
      "learning_rate": 3.62265306122449e-05,
      "loss": 0.1428,
      "step": 7250
    },
    {
      "epoch": 2.904,
      "grad_norm": 0.24978160858154297,
      "learning_rate": 3.62061224489796e-05,
      "loss": 0.0963,
      "step": 7260
    },
    {
      "epoch": 2.908,
      "grad_norm": 1.1835323572158813,
      "learning_rate": 3.618571428571429e-05,
      "loss": 0.1122,
      "step": 7270
    },
    {
      "epoch": 2.912,
      "grad_norm": 1.3247709274291992,
      "learning_rate": 3.616530612244898e-05,
      "loss": 0.0842,
      "step": 7280
    },
    {
      "epoch": 2.916,
      "grad_norm": 0.2172781080007553,
      "learning_rate": 3.614489795918368e-05,
      "loss": 0.0902,
      "step": 7290
    },
    {
      "epoch": 2.92,
      "grad_norm": 1.1683518886566162,
      "learning_rate": 3.612448979591837e-05,
      "loss": 0.1216,
      "step": 7300
    },
    {
      "epoch": 2.924,
      "grad_norm": 0.9965038895606995,
      "learning_rate": 3.610408163265306e-05,
      "loss": 0.1093,
      "step": 7310
    },
    {
      "epoch": 2.928,
      "grad_norm": 0.03068588487803936,
      "learning_rate": 3.608367346938776e-05,
      "loss": 0.1091,
      "step": 7320
    },
    {
      "epoch": 2.932,
      "grad_norm": 0.30300813913345337,
      "learning_rate": 3.606326530612245e-05,
      "loss": 0.0787,
      "step": 7330
    },
    {
      "epoch": 2.936,
      "grad_norm": 0.1954745352268219,
      "learning_rate": 3.6042857142857144e-05,
      "loss": 0.117,
      "step": 7340
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.1823890507221222,
      "learning_rate": 3.6022448979591835e-05,
      "loss": 0.0314,
      "step": 7350
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.9805625081062317,
      "learning_rate": 3.6002040816326534e-05,
      "loss": 0.1436,
      "step": 7360
    },
    {
      "epoch": 2.948,
      "grad_norm": 0.8018060326576233,
      "learning_rate": 3.5981632653061225e-05,
      "loss": 0.0525,
      "step": 7370
    },
    {
      "epoch": 2.952,
      "grad_norm": 0.8876429200172424,
      "learning_rate": 3.596122448979592e-05,
      "loss": 0.0824,
      "step": 7380
    },
    {
      "epoch": 2.956,
      "grad_norm": 0.8991095423698425,
      "learning_rate": 3.5940816326530615e-05,
      "loss": 0.1259,
      "step": 7390
    },
    {
      "epoch": 2.96,
      "grad_norm": 1.0903007984161377,
      "learning_rate": 3.592040816326531e-05,
      "loss": 0.1338,
      "step": 7400
    },
    {
      "epoch": 2.964,
      "grad_norm": 0.26217591762542725,
      "learning_rate": 3.59e-05,
      "loss": 0.1006,
      "step": 7410
    },
    {
      "epoch": 2.968,
      "grad_norm": 1.097355604171753,
      "learning_rate": 3.58795918367347e-05,
      "loss": 0.156,
      "step": 7420
    },
    {
      "epoch": 2.972,
      "grad_norm": 0.4548388719558716,
      "learning_rate": 3.585918367346939e-05,
      "loss": 0.0932,
      "step": 7430
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.15713314712047577,
      "learning_rate": 3.583877551020408e-05,
      "loss": 0.0976,
      "step": 7440
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.5086670517921448,
      "learning_rate": 3.581836734693877e-05,
      "loss": 0.1078,
      "step": 7450
    },
    {
      "epoch": 2.984,
      "grad_norm": 2.329850435256958,
      "learning_rate": 3.579795918367347e-05,
      "loss": 0.0996,
      "step": 7460
    },
    {
      "epoch": 2.988,
      "grad_norm": 0.9394344091415405,
      "learning_rate": 3.577755102040817e-05,
      "loss": 0.0895,
      "step": 7470
    },
    {
      "epoch": 2.992,
      "grad_norm": 0.9515140056610107,
      "learning_rate": 3.575714285714286e-05,
      "loss": 0.0852,
      "step": 7480
    },
    {
      "epoch": 2.996,
      "grad_norm": 0.6323524713516235,
      "learning_rate": 3.573673469387756e-05,
      "loss": 0.0858,
      "step": 7490
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.3060672283172607,
      "learning_rate": 3.571632653061225e-05,
      "loss": 0.1353,
      "step": 7500
    },
    {
      "epoch": 3.004,
      "grad_norm": 0.2991143763065338,
      "learning_rate": 3.569591836734694e-05,
      "loss": 0.111,
      "step": 7510
    },
    {
      "epoch": 3.008,
      "grad_norm": 0.8371626734733582,
      "learning_rate": 3.567551020408163e-05,
      "loss": 0.114,
      "step": 7520
    },
    {
      "epoch": 3.012,
      "grad_norm": 0.36784300208091736,
      "learning_rate": 3.565510204081633e-05,
      "loss": 0.129,
      "step": 7530
    },
    {
      "epoch": 3.016,
      "grad_norm": 0.48794668912887573,
      "learning_rate": 3.563469387755102e-05,
      "loss": 0.0822,
      "step": 7540
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.7436416745185852,
      "learning_rate": 3.5614285714285715e-05,
      "loss": 0.1036,
      "step": 7550
    },
    {
      "epoch": 3.024,
      "grad_norm": 1.1777504682540894,
      "learning_rate": 3.559387755102041e-05,
      "loss": 0.084,
      "step": 7560
    },
    {
      "epoch": 3.028,
      "grad_norm": 0.686802864074707,
      "learning_rate": 3.5573469387755104e-05,
      "loss": 0.1237,
      "step": 7570
    },
    {
      "epoch": 3.032,
      "grad_norm": 1.248561978340149,
      "learning_rate": 3.5553061224489796e-05,
      "loss": 0.0914,
      "step": 7580
    },
    {
      "epoch": 3.036,
      "grad_norm": 0.6148331761360168,
      "learning_rate": 3.5532653061224494e-05,
      "loss": 0.0878,
      "step": 7590
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.9840417504310608,
      "learning_rate": 3.5512244897959186e-05,
      "loss": 0.0842,
      "step": 7600
    },
    {
      "epoch": 3.044,
      "grad_norm": 0.5134804248809814,
      "learning_rate": 3.549183673469388e-05,
      "loss": 0.127,
      "step": 7610
    },
    {
      "epoch": 3.048,
      "grad_norm": 0.22223781049251556,
      "learning_rate": 3.547142857142857e-05,
      "loss": 0.084,
      "step": 7620
    },
    {
      "epoch": 3.052,
      "grad_norm": 0.9913883805274963,
      "learning_rate": 3.545102040816327e-05,
      "loss": 0.0796,
      "step": 7630
    },
    {
      "epoch": 3.056,
      "grad_norm": 1.2057782411575317,
      "learning_rate": 3.543061224489796e-05,
      "loss": 0.0742,
      "step": 7640
    },
    {
      "epoch": 3.06,
      "grad_norm": 1.156940221786499,
      "learning_rate": 3.541020408163265e-05,
      "loss": 0.0691,
      "step": 7650
    },
    {
      "epoch": 3.064,
      "grad_norm": 0.7397598028182983,
      "learning_rate": 3.538979591836735e-05,
      "loss": 0.054,
      "step": 7660
    },
    {
      "epoch": 3.068,
      "grad_norm": 0.2551307678222656,
      "learning_rate": 3.536938775510204e-05,
      "loss": 0.1375,
      "step": 7670
    },
    {
      "epoch": 3.072,
      "grad_norm": 1.4653929471969604,
      "learning_rate": 3.534897959183673e-05,
      "loss": 0.12,
      "step": 7680
    },
    {
      "epoch": 3.076,
      "grad_norm": 0.7364618182182312,
      "learning_rate": 3.532857142857143e-05,
      "loss": 0.0889,
      "step": 7690
    },
    {
      "epoch": 3.08,
      "grad_norm": 1.055887222290039,
      "learning_rate": 3.530816326530613e-05,
      "loss": 0.1013,
      "step": 7700
    },
    {
      "epoch": 3.084,
      "grad_norm": 0.29298070073127747,
      "learning_rate": 3.528775510204082e-05,
      "loss": 0.0714,
      "step": 7710
    },
    {
      "epoch": 3.088,
      "grad_norm": 0.7484099864959717,
      "learning_rate": 3.526734693877551e-05,
      "loss": 0.116,
      "step": 7720
    },
    {
      "epoch": 3.092,
      "grad_norm": 0.8808135390281677,
      "learning_rate": 3.524693877551021e-05,
      "loss": 0.0722,
      "step": 7730
    },
    {
      "epoch": 3.096,
      "grad_norm": 1.5958900451660156,
      "learning_rate": 3.52265306122449e-05,
      "loss": 0.1263,
      "step": 7740
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.6928526759147644,
      "learning_rate": 3.5206122448979594e-05,
      "loss": 0.079,
      "step": 7750
    },
    {
      "epoch": 3.104,
      "grad_norm": 0.25908640027046204,
      "learning_rate": 3.5185714285714285e-05,
      "loss": 0.0833,
      "step": 7760
    },
    {
      "epoch": 3.108,
      "grad_norm": 1.0498377084732056,
      "learning_rate": 3.5165306122448984e-05,
      "loss": 0.093,
      "step": 7770
    },
    {
      "epoch": 3.112,
      "grad_norm": 0.7476193308830261,
      "learning_rate": 3.5144897959183675e-05,
      "loss": 0.1092,
      "step": 7780
    },
    {
      "epoch": 3.116,
      "grad_norm": 0.702069103717804,
      "learning_rate": 3.512448979591837e-05,
      "loss": 0.1358,
      "step": 7790
    },
    {
      "epoch": 3.12,
      "grad_norm": 2.0627684593200684,
      "learning_rate": 3.5104081632653065e-05,
      "loss": 0.1137,
      "step": 7800
    },
    {
      "epoch": 3.124,
      "grad_norm": 1.4426681995391846,
      "learning_rate": 3.508367346938776e-05,
      "loss": 0.1237,
      "step": 7810
    },
    {
      "epoch": 3.128,
      "grad_norm": 0.8925204277038574,
      "learning_rate": 3.506326530612245e-05,
      "loss": 0.0506,
      "step": 7820
    },
    {
      "epoch": 3.132,
      "grad_norm": 1.4172353744506836,
      "learning_rate": 3.504285714285715e-05,
      "loss": 0.1129,
      "step": 7830
    },
    {
      "epoch": 3.136,
      "grad_norm": 0.5689681172370911,
      "learning_rate": 3.502244897959184e-05,
      "loss": 0.0828,
      "step": 7840
    },
    {
      "epoch": 3.14,
      "grad_norm": 0.1500406712293625,
      "learning_rate": 3.500204081632653e-05,
      "loss": 0.092,
      "step": 7850
    },
    {
      "epoch": 3.144,
      "grad_norm": 0.6338847875595093,
      "learning_rate": 3.498163265306123e-05,
      "loss": 0.0843,
      "step": 7860
    },
    {
      "epoch": 3.148,
      "grad_norm": 0.28222736716270447,
      "learning_rate": 3.496122448979592e-05,
      "loss": 0.0748,
      "step": 7870
    },
    {
      "epoch": 3.152,
      "grad_norm": 1.2177860736846924,
      "learning_rate": 3.494081632653061e-05,
      "loss": 0.1435,
      "step": 7880
    },
    {
      "epoch": 3.156,
      "grad_norm": 0.6610565781593323,
      "learning_rate": 3.49204081632653e-05,
      "loss": 0.097,
      "step": 7890
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.17783966660499573,
      "learning_rate": 3.49e-05,
      "loss": 0.0693,
      "step": 7900
    },
    {
      "epoch": 3.164,
      "grad_norm": 0.6610011458396912,
      "learning_rate": 3.487959183673469e-05,
      "loss": 0.078,
      "step": 7910
    },
    {
      "epoch": 3.168,
      "grad_norm": 0.07642004638910294,
      "learning_rate": 3.485918367346939e-05,
      "loss": 0.1097,
      "step": 7920
    },
    {
      "epoch": 3.172,
      "grad_norm": 0.8573252558708191,
      "learning_rate": 3.483877551020408e-05,
      "loss": 0.125,
      "step": 7930
    },
    {
      "epoch": 3.176,
      "grad_norm": 1.7718619108200073,
      "learning_rate": 3.481836734693878e-05,
      "loss": 0.1291,
      "step": 7940
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.42051368951797485,
      "learning_rate": 3.479795918367347e-05,
      "loss": 0.0867,
      "step": 7950
    },
    {
      "epoch": 3.184,
      "grad_norm": 0.3392956256866455,
      "learning_rate": 3.4777551020408164e-05,
      "loss": 0.0544,
      "step": 7960
    },
    {
      "epoch": 3.188,
      "grad_norm": 0.7959629893302917,
      "learning_rate": 3.475714285714286e-05,
      "loss": 0.1305,
      "step": 7970
    },
    {
      "epoch": 3.192,
      "grad_norm": 0.9188898801803589,
      "learning_rate": 3.4736734693877554e-05,
      "loss": 0.1396,
      "step": 7980
    },
    {
      "epoch": 3.196,
      "grad_norm": 0.2655421793460846,
      "learning_rate": 3.4716326530612246e-05,
      "loss": 0.0633,
      "step": 7990
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.42124584317207336,
      "learning_rate": 3.4695918367346944e-05,
      "loss": 0.0666,
      "step": 8000
    },
    {
      "epoch": 3.204,
      "grad_norm": 1.3388410806655884,
      "learning_rate": 3.4675510204081636e-05,
      "loss": 0.0709,
      "step": 8010
    },
    {
      "epoch": 3.208,
      "grad_norm": 0.9156849980354309,
      "learning_rate": 3.465510204081633e-05,
      "loss": 0.1255,
      "step": 8020
    },
    {
      "epoch": 3.212,
      "grad_norm": 0.3406790792942047,
      "learning_rate": 3.463469387755102e-05,
      "loss": 0.0913,
      "step": 8030
    },
    {
      "epoch": 3.216,
      "grad_norm": 0.31482017040252686,
      "learning_rate": 3.461428571428572e-05,
      "loss": 0.0833,
      "step": 8040
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.5209554433822632,
      "learning_rate": 3.459387755102041e-05,
      "loss": 0.062,
      "step": 8050
    },
    {
      "epoch": 3.224,
      "grad_norm": 0.421078085899353,
      "learning_rate": 3.45734693877551e-05,
      "loss": 0.0584,
      "step": 8060
    },
    {
      "epoch": 3.228,
      "grad_norm": 0.9793078899383545,
      "learning_rate": 3.45530612244898e-05,
      "loss": 0.0688,
      "step": 8070
    },
    {
      "epoch": 3.232,
      "grad_norm": 0.12392246723175049,
      "learning_rate": 3.453265306122449e-05,
      "loss": 0.0502,
      "step": 8080
    },
    {
      "epoch": 3.2359999999999998,
      "grad_norm": 0.893113374710083,
      "learning_rate": 3.451224489795918e-05,
      "loss": 0.0823,
      "step": 8090
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.5987497568130493,
      "learning_rate": 3.449183673469388e-05,
      "loss": 0.0925,
      "step": 8100
    },
    {
      "epoch": 3.2439999999999998,
      "grad_norm": 0.9678307771682739,
      "learning_rate": 3.447142857142857e-05,
      "loss": 0.1112,
      "step": 8110
    },
    {
      "epoch": 3.248,
      "grad_norm": 0.10230905562639236,
      "learning_rate": 3.4451020408163264e-05,
      "loss": 0.1218,
      "step": 8120
    },
    {
      "epoch": 3.252,
      "grad_norm": 0.30077728629112244,
      "learning_rate": 3.4430612244897955e-05,
      "loss": 0.0778,
      "step": 8130
    },
    {
      "epoch": 3.2560000000000002,
      "grad_norm": 0.5205613374710083,
      "learning_rate": 3.4410204081632653e-05,
      "loss": 0.0509,
      "step": 8140
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.20870637893676758,
      "learning_rate": 3.438979591836735e-05,
      "loss": 0.1008,
      "step": 8150
    },
    {
      "epoch": 3.2640000000000002,
      "grad_norm": 0.22805853188037872,
      "learning_rate": 3.4369387755102043e-05,
      "loss": 0.1252,
      "step": 8160
    },
    {
      "epoch": 3.268,
      "grad_norm": 0.14372800290584564,
      "learning_rate": 3.434897959183674e-05,
      "loss": 0.0834,
      "step": 8170
    },
    {
      "epoch": 3.2720000000000002,
      "grad_norm": 0.8176012635231018,
      "learning_rate": 3.432857142857143e-05,
      "loss": 0.0756,
      "step": 8180
    },
    {
      "epoch": 3.276,
      "grad_norm": 0.1147446483373642,
      "learning_rate": 3.4308163265306125e-05,
      "loss": 0.0857,
      "step": 8190
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 0.8957242965698242,
      "learning_rate": 3.4287755102040817e-05,
      "loss": 0.1402,
      "step": 8200
    },
    {
      "epoch": 3.284,
      "grad_norm": 0.03543746471405029,
      "learning_rate": 3.4267346938775515e-05,
      "loss": 0.0376,
      "step": 8210
    },
    {
      "epoch": 3.288,
      "grad_norm": 0.9531128406524658,
      "learning_rate": 3.4246938775510206e-05,
      "loss": 0.0875,
      "step": 8220
    },
    {
      "epoch": 3.292,
      "grad_norm": 0.41069546341896057,
      "learning_rate": 3.42265306122449e-05,
      "loss": 0.0689,
      "step": 8230
    },
    {
      "epoch": 3.296,
      "grad_norm": 1.3441044092178345,
      "learning_rate": 3.4206122448979596e-05,
      "loss": 0.07,
      "step": 8240
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.4366792142391205,
      "learning_rate": 3.418571428571429e-05,
      "loss": 0.1007,
      "step": 8250
    },
    {
      "epoch": 3.304,
      "grad_norm": 0.1280737817287445,
      "learning_rate": 3.416530612244898e-05,
      "loss": 0.0859,
      "step": 8260
    },
    {
      "epoch": 3.308,
      "grad_norm": 0.2861780822277069,
      "learning_rate": 3.414489795918368e-05,
      "loss": 0.0726,
      "step": 8270
    },
    {
      "epoch": 3.312,
      "grad_norm": 1.2506763935089111,
      "learning_rate": 3.412448979591837e-05,
      "loss": 0.0514,
      "step": 8280
    },
    {
      "epoch": 3.316,
      "grad_norm": 0.44550031423568726,
      "learning_rate": 3.410408163265306e-05,
      "loss": 0.0813,
      "step": 8290
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.1611461490392685,
      "learning_rate": 3.408367346938775e-05,
      "loss": 0.0793,
      "step": 8300
    },
    {
      "epoch": 3.324,
      "grad_norm": 0.3829409182071686,
      "learning_rate": 3.406326530612245e-05,
      "loss": 0.0915,
      "step": 8310
    },
    {
      "epoch": 3.328,
      "grad_norm": 0.13611339032649994,
      "learning_rate": 3.404285714285714e-05,
      "loss": 0.077,
      "step": 8320
    },
    {
      "epoch": 3.332,
      "grad_norm": 1.1503541469573975,
      "learning_rate": 3.4022448979591834e-05,
      "loss": 0.1736,
      "step": 8330
    },
    {
      "epoch": 3.336,
      "grad_norm": 0.48515409231185913,
      "learning_rate": 3.400204081632653e-05,
      "loss": 0.0995,
      "step": 8340
    },
    {
      "epoch": 3.34,
      "grad_norm": 0.01930289715528488,
      "learning_rate": 3.3981632653061224e-05,
      "loss": 0.1036,
      "step": 8350
    },
    {
      "epoch": 3.344,
      "grad_norm": 1.0429766178131104,
      "learning_rate": 3.3961224489795916e-05,
      "loss": 0.1274,
      "step": 8360
    },
    {
      "epoch": 3.348,
      "grad_norm": 0.6919761300086975,
      "learning_rate": 3.3940816326530614e-05,
      "loss": 0.0589,
      "step": 8370
    },
    {
      "epoch": 3.352,
      "grad_norm": 1.187860131263733,
      "learning_rate": 3.392040816326531e-05,
      "loss": 0.1363,
      "step": 8380
    },
    {
      "epoch": 3.356,
      "grad_norm": 1.4822677373886108,
      "learning_rate": 3.3900000000000004e-05,
      "loss": 0.0872,
      "step": 8390
    },
    {
      "epoch": 3.36,
      "grad_norm": 1.031800389289856,
      "learning_rate": 3.3879591836734696e-05,
      "loss": 0.1033,
      "step": 8400
    },
    {
      "epoch": 3.364,
      "grad_norm": 1.0367448329925537,
      "learning_rate": 3.3859183673469394e-05,
      "loss": 0.1392,
      "step": 8410
    },
    {
      "epoch": 3.368,
      "grad_norm": 1.2908374071121216,
      "learning_rate": 3.3838775510204086e-05,
      "loss": 0.0611,
      "step": 8420
    },
    {
      "epoch": 3.372,
      "grad_norm": 0.7112705707550049,
      "learning_rate": 3.381836734693878e-05,
      "loss": 0.0657,
      "step": 8430
    },
    {
      "epoch": 3.376,
      "grad_norm": 1.0273805856704712,
      "learning_rate": 3.379795918367347e-05,
      "loss": 0.1035,
      "step": 8440
    },
    {
      "epoch": 3.38,
      "grad_norm": 1.0770217180252075,
      "learning_rate": 3.377755102040817e-05,
      "loss": 0.0794,
      "step": 8450
    },
    {
      "epoch": 3.384,
      "grad_norm": 0.33013617992401123,
      "learning_rate": 3.375714285714286e-05,
      "loss": 0.0772,
      "step": 8460
    },
    {
      "epoch": 3.388,
      "grad_norm": 1.104762315750122,
      "learning_rate": 3.373673469387755e-05,
      "loss": 0.1355,
      "step": 8470
    },
    {
      "epoch": 3.392,
      "grad_norm": 0.00896780751645565,
      "learning_rate": 3.371632653061225e-05,
      "loss": 0.0616,
      "step": 8480
    },
    {
      "epoch": 3.396,
      "grad_norm": 0.5805743932723999,
      "learning_rate": 3.369591836734694e-05,
      "loss": 0.104,
      "step": 8490
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.7986971735954285,
      "learning_rate": 3.367551020408163e-05,
      "loss": 0.0731,
      "step": 8500
    },
    {
      "epoch": 3.404,
      "grad_norm": 1.533193826675415,
      "learning_rate": 3.365510204081633e-05,
      "loss": 0.1164,
      "step": 8510
    },
    {
      "epoch": 3.408,
      "grad_norm": 1.1922659873962402,
      "learning_rate": 3.363469387755102e-05,
      "loss": 0.128,
      "step": 8520
    },
    {
      "epoch": 3.412,
      "grad_norm": 0.41441959142684937,
      "learning_rate": 3.361428571428571e-05,
      "loss": 0.1148,
      "step": 8530
    },
    {
      "epoch": 3.416,
      "grad_norm": 0.8314469456672668,
      "learning_rate": 3.359387755102041e-05,
      "loss": 0.1284,
      "step": 8540
    },
    {
      "epoch": 3.42,
      "grad_norm": 1.7428432703018188,
      "learning_rate": 3.35734693877551e-05,
      "loss": 0.1273,
      "step": 8550
    },
    {
      "epoch": 3.424,
      "grad_norm": 0.6640465259552002,
      "learning_rate": 3.3553061224489795e-05,
      "loss": 0.1034,
      "step": 8560
    },
    {
      "epoch": 3.428,
      "grad_norm": 1.9743942022323608,
      "learning_rate": 3.3532653061224486e-05,
      "loss": 0.0901,
      "step": 8570
    },
    {
      "epoch": 3.432,
      "grad_norm": 0.23782294988632202,
      "learning_rate": 3.3512244897959185e-05,
      "loss": 0.1079,
      "step": 8580
    },
    {
      "epoch": 3.436,
      "grad_norm": 0.5299702882766724,
      "learning_rate": 3.3491836734693876e-05,
      "loss": 0.1458,
      "step": 8590
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.8891941905021667,
      "learning_rate": 3.3471428571428575e-05,
      "loss": 0.0947,
      "step": 8600
    },
    {
      "epoch": 3.444,
      "grad_norm": 0.9215112328529358,
      "learning_rate": 3.3451020408163266e-05,
      "loss": 0.1061,
      "step": 8610
    },
    {
      "epoch": 3.448,
      "grad_norm": 0.6961548328399658,
      "learning_rate": 3.3430612244897965e-05,
      "loss": 0.0645,
      "step": 8620
    },
    {
      "epoch": 3.452,
      "grad_norm": 1.02730131149292,
      "learning_rate": 3.3410204081632656e-05,
      "loss": 0.1178,
      "step": 8630
    },
    {
      "epoch": 3.456,
      "grad_norm": 0.8345343470573425,
      "learning_rate": 3.338979591836735e-05,
      "loss": 0.0665,
      "step": 8640
    },
    {
      "epoch": 3.46,
      "grad_norm": 1.636262059211731,
      "learning_rate": 3.3369387755102046e-05,
      "loss": 0.0947,
      "step": 8650
    },
    {
      "epoch": 3.464,
      "grad_norm": 1.2541499137878418,
      "learning_rate": 3.334897959183674e-05,
      "loss": 0.1333,
      "step": 8660
    },
    {
      "epoch": 3.468,
      "grad_norm": 1.2026623487472534,
      "learning_rate": 3.332857142857143e-05,
      "loss": 0.1149,
      "step": 8670
    },
    {
      "epoch": 3.472,
      "grad_norm": 0.19804354012012482,
      "learning_rate": 3.330816326530613e-05,
      "loss": 0.0691,
      "step": 8680
    },
    {
      "epoch": 3.476,
      "grad_norm": 0.6948524117469788,
      "learning_rate": 3.328775510204082e-05,
      "loss": 0.139,
      "step": 8690
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.9867753982543945,
      "learning_rate": 3.326734693877551e-05,
      "loss": 0.1377,
      "step": 8700
    },
    {
      "epoch": 3.484,
      "grad_norm": 1.136572241783142,
      "learning_rate": 3.32469387755102e-05,
      "loss": 0.0828,
      "step": 8710
    },
    {
      "epoch": 3.488,
      "grad_norm": 1.4967548847198486,
      "learning_rate": 3.32265306122449e-05,
      "loss": 0.1232,
      "step": 8720
    },
    {
      "epoch": 3.492,
      "grad_norm": 0.6341081261634827,
      "learning_rate": 3.320612244897959e-05,
      "loss": 0.0982,
      "step": 8730
    },
    {
      "epoch": 3.496,
      "grad_norm": 0.9137505888938904,
      "learning_rate": 3.3185714285714284e-05,
      "loss": 0.0851,
      "step": 8740
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.1577223241329193,
      "learning_rate": 3.316530612244898e-05,
      "loss": 0.0949,
      "step": 8750
    },
    {
      "epoch": 3.504,
      "grad_norm": 0.42581796646118164,
      "learning_rate": 3.3144897959183674e-05,
      "loss": 0.0975,
      "step": 8760
    },
    {
      "epoch": 3.508,
      "grad_norm": 0.5793861746788025,
      "learning_rate": 3.3124489795918366e-05,
      "loss": 0.117,
      "step": 8770
    },
    {
      "epoch": 3.512,
      "grad_norm": 1.3346269130706787,
      "learning_rate": 3.3104081632653064e-05,
      "loss": 0.1042,
      "step": 8780
    },
    {
      "epoch": 3.516,
      "grad_norm": 0.6625227928161621,
      "learning_rate": 3.3083673469387756e-05,
      "loss": 0.0691,
      "step": 8790
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.7267107963562012,
      "learning_rate": 3.306326530612245e-05,
      "loss": 0.0747,
      "step": 8800
    },
    {
      "epoch": 3.524,
      "grad_norm": 0.07625424116849899,
      "learning_rate": 3.304285714285714e-05,
      "loss": 0.1079,
      "step": 8810
    },
    {
      "epoch": 3.528,
      "grad_norm": 0.2633592188358307,
      "learning_rate": 3.302244897959184e-05,
      "loss": 0.0513,
      "step": 8820
    },
    {
      "epoch": 3.532,
      "grad_norm": 1.4768496751785278,
      "learning_rate": 3.3002040816326535e-05,
      "loss": 0.1091,
      "step": 8830
    },
    {
      "epoch": 3.536,
      "grad_norm": 1.6505489349365234,
      "learning_rate": 3.298163265306123e-05,
      "loss": 0.1247,
      "step": 8840
    },
    {
      "epoch": 3.54,
      "grad_norm": 2.087794780731201,
      "learning_rate": 3.2961224489795925e-05,
      "loss": 0.1218,
      "step": 8850
    },
    {
      "epoch": 3.544,
      "grad_norm": 0.09490058571100235,
      "learning_rate": 3.294081632653062e-05,
      "loss": 0.1045,
      "step": 8860
    },
    {
      "epoch": 3.548,
      "grad_norm": 0.39101919531822205,
      "learning_rate": 3.292040816326531e-05,
      "loss": 0.0645,
      "step": 8870
    },
    {
      "epoch": 3.552,
      "grad_norm": 0.93271404504776,
      "learning_rate": 3.29e-05,
      "loss": 0.1088,
      "step": 8880
    },
    {
      "epoch": 3.556,
      "grad_norm": 1.1140015125274658,
      "learning_rate": 3.28795918367347e-05,
      "loss": 0.1171,
      "step": 8890
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.2859446704387665,
      "learning_rate": 3.285918367346939e-05,
      "loss": 0.065,
      "step": 8900
    },
    {
      "epoch": 3.564,
      "grad_norm": 0.4581426680088043,
      "learning_rate": 3.283877551020408e-05,
      "loss": 0.0639,
      "step": 8910
    },
    {
      "epoch": 3.568,
      "grad_norm": 1.5434298515319824,
      "learning_rate": 3.281836734693878e-05,
      "loss": 0.0896,
      "step": 8920
    },
    {
      "epoch": 3.572,
      "grad_norm": 0.9903477430343628,
      "learning_rate": 3.279795918367347e-05,
      "loss": 0.0767,
      "step": 8930
    },
    {
      "epoch": 3.576,
      "grad_norm": 1.237205982208252,
      "learning_rate": 3.277755102040816e-05,
      "loss": 0.0951,
      "step": 8940
    },
    {
      "epoch": 3.58,
      "grad_norm": 0.4663029611110687,
      "learning_rate": 3.275714285714286e-05,
      "loss": 0.0755,
      "step": 8950
    },
    {
      "epoch": 3.584,
      "grad_norm": 1.249204158782959,
      "learning_rate": 3.273673469387755e-05,
      "loss": 0.1102,
      "step": 8960
    },
    {
      "epoch": 3.588,
      "grad_norm": 1.4062130451202393,
      "learning_rate": 3.2716326530612245e-05,
      "loss": 0.1246,
      "step": 8970
    },
    {
      "epoch": 3.592,
      "grad_norm": 1.2835255861282349,
      "learning_rate": 3.2695918367346936e-05,
      "loss": 0.0608,
      "step": 8980
    },
    {
      "epoch": 3.596,
      "grad_norm": 0.47156646847724915,
      "learning_rate": 3.2675510204081635e-05,
      "loss": 0.1261,
      "step": 8990
    },
    {
      "epoch": 3.6,
      "grad_norm": 1.1950688362121582,
      "learning_rate": 3.2655102040816326e-05,
      "loss": 0.1318,
      "step": 9000
    },
    {
      "epoch": 3.604,
      "grad_norm": 0.9226110577583313,
      "learning_rate": 3.263469387755102e-05,
      "loss": 0.0925,
      "step": 9010
    },
    {
      "epoch": 3.608,
      "grad_norm": 0.6865926384925842,
      "learning_rate": 3.2614285714285716e-05,
      "loss": 0.0556,
      "step": 9020
    },
    {
      "epoch": 3.612,
      "grad_norm": 1.1600271463394165,
      "learning_rate": 3.259387755102041e-05,
      "loss": 0.0668,
      "step": 9030
    },
    {
      "epoch": 3.616,
      "grad_norm": 1.0829194784164429,
      "learning_rate": 3.25734693877551e-05,
      "loss": 0.0797,
      "step": 9040
    },
    {
      "epoch": 3.62,
      "grad_norm": 1.0083969831466675,
      "learning_rate": 3.25530612244898e-05,
      "loss": 0.0981,
      "step": 9050
    },
    {
      "epoch": 3.624,
      "grad_norm": 1.00813889503479,
      "learning_rate": 3.2532653061224496e-05,
      "loss": 0.1271,
      "step": 9060
    },
    {
      "epoch": 3.628,
      "grad_norm": 1.208091378211975,
      "learning_rate": 3.251224489795919e-05,
      "loss": 0.099,
      "step": 9070
    },
    {
      "epoch": 3.632,
      "grad_norm": 0.750999391078949,
      "learning_rate": 3.249183673469388e-05,
      "loss": 0.0461,
      "step": 9080
    },
    {
      "epoch": 3.636,
      "grad_norm": 1.6866905689239502,
      "learning_rate": 3.247142857142858e-05,
      "loss": 0.1064,
      "step": 9090
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.854691743850708,
      "learning_rate": 3.245102040816327e-05,
      "loss": 0.0506,
      "step": 9100
    },
    {
      "epoch": 3.644,
      "grad_norm": 0.20951777696609497,
      "learning_rate": 3.243061224489796e-05,
      "loss": 0.1177,
      "step": 9110
    },
    {
      "epoch": 3.648,
      "grad_norm": 0.9941877126693726,
      "learning_rate": 3.241020408163266e-05,
      "loss": 0.0936,
      "step": 9120
    },
    {
      "epoch": 3.652,
      "grad_norm": 0.8975988030433655,
      "learning_rate": 3.238979591836735e-05,
      "loss": 0.1164,
      "step": 9130
    },
    {
      "epoch": 3.656,
      "grad_norm": 0.4369342029094696,
      "learning_rate": 3.236938775510204e-05,
      "loss": 0.0786,
      "step": 9140
    },
    {
      "epoch": 3.66,
      "grad_norm": 0.3369053304195404,
      "learning_rate": 3.2348979591836734e-05,
      "loss": 0.0443,
      "step": 9150
    },
    {
      "epoch": 3.664,
      "grad_norm": 1.3879019021987915,
      "learning_rate": 3.232857142857143e-05,
      "loss": 0.0782,
      "step": 9160
    },
    {
      "epoch": 3.668,
      "grad_norm": 1.789404034614563,
      "learning_rate": 3.2308163265306124e-05,
      "loss": 0.089,
      "step": 9170
    },
    {
      "epoch": 3.672,
      "grad_norm": 0.9342732429504395,
      "learning_rate": 3.2287755102040815e-05,
      "loss": 0.0679,
      "step": 9180
    },
    {
      "epoch": 3.676,
      "grad_norm": 0.859305202960968,
      "learning_rate": 3.2267346938775514e-05,
      "loss": 0.0708,
      "step": 9190
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.7661983370780945,
      "learning_rate": 3.2246938775510205e-05,
      "loss": 0.0965,
      "step": 9200
    },
    {
      "epoch": 3.684,
      "grad_norm": 1.053135633468628,
      "learning_rate": 3.22265306122449e-05,
      "loss": 0.11,
      "step": 9210
    },
    {
      "epoch": 3.6879999999999997,
      "grad_norm": 0.45496463775634766,
      "learning_rate": 3.2206122448979595e-05,
      "loss": 0.0715,
      "step": 9220
    },
    {
      "epoch": 3.692,
      "grad_norm": 0.2592504620552063,
      "learning_rate": 3.218571428571429e-05,
      "loss": 0.0717,
      "step": 9230
    },
    {
      "epoch": 3.6959999999999997,
      "grad_norm": 0.6600731611251831,
      "learning_rate": 3.216530612244898e-05,
      "loss": 0.0797,
      "step": 9240
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.3441712558269501,
      "learning_rate": 3.214489795918367e-05,
      "loss": 0.0908,
      "step": 9250
    },
    {
      "epoch": 3.7039999999999997,
      "grad_norm": 0.6279475092887878,
      "learning_rate": 3.212448979591837e-05,
      "loss": 0.1091,
      "step": 9260
    },
    {
      "epoch": 3.708,
      "grad_norm": 1.1390749216079712,
      "learning_rate": 3.210408163265306e-05,
      "loss": 0.0906,
      "step": 9270
    },
    {
      "epoch": 3.7119999999999997,
      "grad_norm": 0.8790462613105774,
      "learning_rate": 3.208367346938775e-05,
      "loss": 0.1132,
      "step": 9280
    },
    {
      "epoch": 3.716,
      "grad_norm": 0.3389969766139984,
      "learning_rate": 3.206326530612245e-05,
      "loss": 0.0864,
      "step": 9290
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 0.09654984623193741,
      "learning_rate": 3.204285714285715e-05,
      "loss": 0.0629,
      "step": 9300
    },
    {
      "epoch": 3.724,
      "grad_norm": 0.44717636704444885,
      "learning_rate": 3.202244897959184e-05,
      "loss": 0.0961,
      "step": 9310
    },
    {
      "epoch": 3.7279999999999998,
      "grad_norm": 1.439119577407837,
      "learning_rate": 3.200204081632653e-05,
      "loss": 0.0913,
      "step": 9320
    },
    {
      "epoch": 3.732,
      "grad_norm": 0.7235950231552124,
      "learning_rate": 3.198163265306123e-05,
      "loss": 0.1059,
      "step": 9330
    },
    {
      "epoch": 3.7359999999999998,
      "grad_norm": 0.6047780513763428,
      "learning_rate": 3.196122448979592e-05,
      "loss": 0.0968,
      "step": 9340
    },
    {
      "epoch": 3.74,
      "grad_norm": 1.3746284246444702,
      "learning_rate": 3.194081632653061e-05,
      "loss": 0.1225,
      "step": 9350
    },
    {
      "epoch": 3.7439999999999998,
      "grad_norm": 0.5344308018684387,
      "learning_rate": 3.192040816326531e-05,
      "loss": 0.054,
      "step": 9360
    },
    {
      "epoch": 3.748,
      "grad_norm": 0.8440116047859192,
      "learning_rate": 3.19e-05,
      "loss": 0.0415,
      "step": 9370
    },
    {
      "epoch": 3.752,
      "grad_norm": 0.5227765440940857,
      "learning_rate": 3.1879591836734694e-05,
      "loss": 0.0738,
      "step": 9380
    },
    {
      "epoch": 3.7560000000000002,
      "grad_norm": 1.6951134204864502,
      "learning_rate": 3.1859183673469386e-05,
      "loss": 0.0948,
      "step": 9390
    },
    {
      "epoch": 3.76,
      "grad_norm": 1.1037158966064453,
      "learning_rate": 3.1838775510204084e-05,
      "loss": 0.1103,
      "step": 9400
    },
    {
      "epoch": 3.7640000000000002,
      "grad_norm": 1.5451550483703613,
      "learning_rate": 3.1818367346938776e-05,
      "loss": 0.0762,
      "step": 9410
    },
    {
      "epoch": 3.768,
      "grad_norm": 1.4093011617660522,
      "learning_rate": 3.179795918367347e-05,
      "loss": 0.0728,
      "step": 9420
    },
    {
      "epoch": 3.7720000000000002,
      "grad_norm": 0.7313290238380432,
      "learning_rate": 3.1777551020408166e-05,
      "loss": 0.1207,
      "step": 9430
    },
    {
      "epoch": 3.776,
      "grad_norm": 1.3878525495529175,
      "learning_rate": 3.175714285714286e-05,
      "loss": 0.1181,
      "step": 9440
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 0.3996167480945587,
      "learning_rate": 3.173673469387755e-05,
      "loss": 0.0926,
      "step": 9450
    },
    {
      "epoch": 3.784,
      "grad_norm": 0.02683575078845024,
      "learning_rate": 3.171632653061225e-05,
      "loss": 0.0867,
      "step": 9460
    },
    {
      "epoch": 3.7880000000000003,
      "grad_norm": 0.7543438673019409,
      "learning_rate": 3.169591836734694e-05,
      "loss": 0.0795,
      "step": 9470
    },
    {
      "epoch": 3.792,
      "grad_norm": 0.16287025809288025,
      "learning_rate": 3.167551020408163e-05,
      "loss": 0.0752,
      "step": 9480
    },
    {
      "epoch": 3.7960000000000003,
      "grad_norm": 0.9454212188720703,
      "learning_rate": 3.165510204081633e-05,
      "loss": 0.0827,
      "step": 9490
    },
    {
      "epoch": 3.8,
      "grad_norm": 1.0010788440704346,
      "learning_rate": 3.163469387755102e-05,
      "loss": 0.1244,
      "step": 9500
    },
    {
      "epoch": 3.8040000000000003,
      "grad_norm": 1.2260318994522095,
      "learning_rate": 3.161428571428572e-05,
      "loss": 0.0959,
      "step": 9510
    },
    {
      "epoch": 3.808,
      "grad_norm": 0.2543981075286865,
      "learning_rate": 3.159387755102041e-05,
      "loss": 0.0471,
      "step": 9520
    },
    {
      "epoch": 3.8120000000000003,
      "grad_norm": 1.3468685150146484,
      "learning_rate": 3.157346938775511e-05,
      "loss": 0.1215,
      "step": 9530
    },
    {
      "epoch": 3.816,
      "grad_norm": 0.737004280090332,
      "learning_rate": 3.15530612244898e-05,
      "loss": 0.1205,
      "step": 9540
    },
    {
      "epoch": 3.82,
      "grad_norm": 0.9793791174888611,
      "learning_rate": 3.153265306122449e-05,
      "loss": 0.0903,
      "step": 9550
    },
    {
      "epoch": 3.824,
      "grad_norm": 0.28730323910713196,
      "learning_rate": 3.1512244897959184e-05,
      "loss": 0.06,
      "step": 9560
    },
    {
      "epoch": 3.828,
      "grad_norm": 0.18447773158550262,
      "learning_rate": 3.149183673469388e-05,
      "loss": 0.0661,
      "step": 9570
    },
    {
      "epoch": 3.832,
      "grad_norm": 1.299879789352417,
      "learning_rate": 3.1471428571428574e-05,
      "loss": 0.0997,
      "step": 9580
    },
    {
      "epoch": 3.836,
      "grad_norm": 1.090701937675476,
      "learning_rate": 3.1451020408163265e-05,
      "loss": 0.1129,
      "step": 9590
    },
    {
      "epoch": 3.84,
      "grad_norm": 1.2266663312911987,
      "learning_rate": 3.1430612244897964e-05,
      "loss": 0.1471,
      "step": 9600
    },
    {
      "epoch": 3.844,
      "grad_norm": 1.2238211631774902,
      "learning_rate": 3.1410204081632655e-05,
      "loss": 0.0753,
      "step": 9610
    },
    {
      "epoch": 3.848,
      "grad_norm": 0.1704934537410736,
      "learning_rate": 3.138979591836735e-05,
      "loss": 0.0974,
      "step": 9620
    },
    {
      "epoch": 3.852,
      "grad_norm": 0.05693937465548515,
      "learning_rate": 3.1369387755102045e-05,
      "loss": 0.0858,
      "step": 9630
    },
    {
      "epoch": 3.856,
      "grad_norm": 0.7987735271453857,
      "learning_rate": 3.134897959183674e-05,
      "loss": 0.068,
      "step": 9640
    },
    {
      "epoch": 3.86,
      "grad_norm": 0.09593777358531952,
      "learning_rate": 3.132857142857143e-05,
      "loss": 0.0588,
      "step": 9650
    },
    {
      "epoch": 3.864,
      "grad_norm": 0.7452929019927979,
      "learning_rate": 3.130816326530612e-05,
      "loss": 0.0655,
      "step": 9660
    },
    {
      "epoch": 3.868,
      "grad_norm": 0.33180445432662964,
      "learning_rate": 3.128775510204082e-05,
      "loss": 0.0556,
      "step": 9670
    },
    {
      "epoch": 3.872,
      "grad_norm": 0.4015691876411438,
      "learning_rate": 3.126734693877551e-05,
      "loss": 0.1029,
      "step": 9680
    },
    {
      "epoch": 3.876,
      "grad_norm": 0.1873130202293396,
      "learning_rate": 3.12469387755102e-05,
      "loss": 0.1101,
      "step": 9690
    },
    {
      "epoch": 3.88,
      "grad_norm": 1.1248292922973633,
      "learning_rate": 3.12265306122449e-05,
      "loss": 0.0634,
      "step": 9700
    },
    {
      "epoch": 3.884,
      "grad_norm": 0.6671202182769775,
      "learning_rate": 3.120612244897959e-05,
      "loss": 0.0454,
      "step": 9710
    },
    {
      "epoch": 3.888,
      "grad_norm": 0.6752904653549194,
      "learning_rate": 3.118571428571428e-05,
      "loss": 0.0474,
      "step": 9720
    },
    {
      "epoch": 3.892,
      "grad_norm": 1.335464358329773,
      "learning_rate": 3.116530612244898e-05,
      "loss": 0.1042,
      "step": 9730
    },
    {
      "epoch": 3.896,
      "grad_norm": 0.7969493269920349,
      "learning_rate": 3.114489795918368e-05,
      "loss": 0.0549,
      "step": 9740
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.812524676322937,
      "learning_rate": 3.112448979591837e-05,
      "loss": 0.0763,
      "step": 9750
    },
    {
      "epoch": 3.904,
      "grad_norm": 0.4975253641605377,
      "learning_rate": 3.110408163265306e-05,
      "loss": 0.1307,
      "step": 9760
    },
    {
      "epoch": 3.908,
      "grad_norm": 0.5027107000350952,
      "learning_rate": 3.108367346938776e-05,
      "loss": 0.0897,
      "step": 9770
    },
    {
      "epoch": 3.912,
      "grad_norm": 1.2330130338668823,
      "learning_rate": 3.106326530612245e-05,
      "loss": 0.0613,
      "step": 9780
    },
    {
      "epoch": 3.916,
      "grad_norm": 0.6260605454444885,
      "learning_rate": 3.1042857142857144e-05,
      "loss": 0.0566,
      "step": 9790
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.6948937773704529,
      "learning_rate": 3.102244897959184e-05,
      "loss": 0.1063,
      "step": 9800
    },
    {
      "epoch": 3.924,
      "grad_norm": 0.3019374907016754,
      "learning_rate": 3.1002040816326534e-05,
      "loss": 0.0612,
      "step": 9810
    },
    {
      "epoch": 3.928,
      "grad_norm": 0.9457195401191711,
      "learning_rate": 3.0981632653061226e-05,
      "loss": 0.0722,
      "step": 9820
    },
    {
      "epoch": 3.932,
      "grad_norm": 0.36310356855392456,
      "learning_rate": 3.096122448979592e-05,
      "loss": 0.0821,
      "step": 9830
    },
    {
      "epoch": 3.936,
      "grad_norm": 0.9471089243888855,
      "learning_rate": 3.0940816326530616e-05,
      "loss": 0.0862,
      "step": 9840
    },
    {
      "epoch": 3.94,
      "grad_norm": 0.5132898688316345,
      "learning_rate": 3.092040816326531e-05,
      "loss": 0.0789,
      "step": 9850
    },
    {
      "epoch": 3.944,
      "grad_norm": 1.357499599456787,
      "learning_rate": 3.09e-05,
      "loss": 0.1073,
      "step": 9860
    },
    {
      "epoch": 3.948,
      "grad_norm": 1.653121829032898,
      "learning_rate": 3.08795918367347e-05,
      "loss": 0.0853,
      "step": 9870
    },
    {
      "epoch": 3.952,
      "grad_norm": 0.5788481831550598,
      "learning_rate": 3.085918367346939e-05,
      "loss": 0.0336,
      "step": 9880
    },
    {
      "epoch": 3.956,
      "grad_norm": 0.8606515526771545,
      "learning_rate": 3.083877551020408e-05,
      "loss": 0.0408,
      "step": 9890
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.03675973042845726,
      "learning_rate": 3.081836734693878e-05,
      "loss": 0.0626,
      "step": 9900
    },
    {
      "epoch": 3.964,
      "grad_norm": 0.4629869759082794,
      "learning_rate": 3.079795918367347e-05,
      "loss": 0.1206,
      "step": 9910
    },
    {
      "epoch": 3.968,
      "grad_norm": 0.26211267709732056,
      "learning_rate": 3.077755102040816e-05,
      "loss": 0.071,
      "step": 9920
    },
    {
      "epoch": 3.972,
      "grad_norm": 0.2356286495923996,
      "learning_rate": 3.0757142857142854e-05,
      "loss": 0.0731,
      "step": 9930
    },
    {
      "epoch": 3.976,
      "grad_norm": 0.9670105576515198,
      "learning_rate": 3.073673469387755e-05,
      "loss": 0.0897,
      "step": 9940
    },
    {
      "epoch": 3.98,
      "grad_norm": 0.7559313178062439,
      "learning_rate": 3.0716326530612244e-05,
      "loss": 0.0711,
      "step": 9950
    },
    {
      "epoch": 3.984,
      "grad_norm": 0.3348222076892853,
      "learning_rate": 3.0695918367346935e-05,
      "loss": 0.0456,
      "step": 9960
    },
    {
      "epoch": 3.988,
      "grad_norm": 0.5196929574012756,
      "learning_rate": 3.0675510204081633e-05,
      "loss": 0.1236,
      "step": 9970
    },
    {
      "epoch": 3.992,
      "grad_norm": 0.39057657122612,
      "learning_rate": 3.065510204081633e-05,
      "loss": 0.0603,
      "step": 9980
    },
    {
      "epoch": 3.996,
      "grad_norm": 1.0945180654525757,
      "learning_rate": 3.0634693877551023e-05,
      "loss": 0.0817,
      "step": 9990
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.1858188807964325,
      "learning_rate": 3.0614285714285715e-05,
      "loss": 0.1015,
      "step": 10000
    },
    {
      "epoch": 4.004,
      "grad_norm": 0.7248002886772156,
      "learning_rate": 3.059387755102041e-05,
      "loss": 0.0645,
      "step": 10010
    },
    {
      "epoch": 4.008,
      "grad_norm": 0.26694801449775696,
      "learning_rate": 3.0573469387755105e-05,
      "loss": 0.1045,
      "step": 10020
    },
    {
      "epoch": 4.012,
      "grad_norm": 0.8184037208557129,
      "learning_rate": 3.0553061224489796e-05,
      "loss": 0.1303,
      "step": 10030
    },
    {
      "epoch": 4.016,
      "grad_norm": 0.46361640095710754,
      "learning_rate": 3.0532653061224495e-05,
      "loss": 0.0433,
      "step": 10040
    },
    {
      "epoch": 4.02,
      "grad_norm": 1.162835955619812,
      "learning_rate": 3.0512244897959186e-05,
      "loss": 0.0803,
      "step": 10050
    },
    {
      "epoch": 4.024,
      "grad_norm": 1.5145190954208374,
      "learning_rate": 3.0491836734693878e-05,
      "loss": 0.1116,
      "step": 10060
    },
    {
      "epoch": 4.028,
      "grad_norm": 1.0168910026550293,
      "learning_rate": 3.0471428571428573e-05,
      "loss": 0.0593,
      "step": 10070
    },
    {
      "epoch": 4.032,
      "grad_norm": 1.2343043088912964,
      "learning_rate": 3.0451020408163268e-05,
      "loss": 0.0679,
      "step": 10080
    },
    {
      "epoch": 4.036,
      "grad_norm": 0.44926318526268005,
      "learning_rate": 3.043061224489796e-05,
      "loss": 0.0847,
      "step": 10090
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.6104540824890137,
      "learning_rate": 3.0410204081632655e-05,
      "loss": 0.0692,
      "step": 10100
    },
    {
      "epoch": 4.044,
      "grad_norm": 1.2023118734359741,
      "learning_rate": 3.0389795918367346e-05,
      "loss": 0.088,
      "step": 10110
    },
    {
      "epoch": 4.048,
      "grad_norm": 1.054508090019226,
      "learning_rate": 3.036938775510204e-05,
      "loss": 0.0895,
      "step": 10120
    },
    {
      "epoch": 4.052,
      "grad_norm": 1.2266690731048584,
      "learning_rate": 3.0348979591836736e-05,
      "loss": 0.1,
      "step": 10130
    },
    {
      "epoch": 4.056,
      "grad_norm": 0.3115402162075043,
      "learning_rate": 3.0328571428571428e-05,
      "loss": 0.1095,
      "step": 10140
    },
    {
      "epoch": 4.06,
      "grad_norm": 1.106844425201416,
      "learning_rate": 3.0308163265306123e-05,
      "loss": 0.0798,
      "step": 10150
    },
    {
      "epoch": 4.064,
      "grad_norm": 1.290340781211853,
      "learning_rate": 3.0287755102040814e-05,
      "loss": 0.1038,
      "step": 10160
    },
    {
      "epoch": 4.068,
      "grad_norm": 0.4468715786933899,
      "learning_rate": 3.026734693877551e-05,
      "loss": 0.0767,
      "step": 10170
    },
    {
      "epoch": 4.072,
      "grad_norm": 0.021092617884278297,
      "learning_rate": 3.0246938775510204e-05,
      "loss": 0.059,
      "step": 10180
    },
    {
      "epoch": 4.076,
      "grad_norm": 0.26185691356658936,
      "learning_rate": 3.0226530612244902e-05,
      "loss": 0.1301,
      "step": 10190
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.6356624364852905,
      "learning_rate": 3.0206122448979594e-05,
      "loss": 0.0935,
      "step": 10200
    },
    {
      "epoch": 4.084,
      "grad_norm": 1.9605120420455933,
      "learning_rate": 3.018571428571429e-05,
      "loss": 0.083,
      "step": 10210
    },
    {
      "epoch": 4.088,
      "grad_norm": 1.4572837352752686,
      "learning_rate": 3.0165306122448984e-05,
      "loss": 0.0632,
      "step": 10220
    },
    {
      "epoch": 4.092,
      "grad_norm": 1.9480774402618408,
      "learning_rate": 3.0144897959183676e-05,
      "loss": 0.0957,
      "step": 10230
    },
    {
      "epoch": 4.096,
      "grad_norm": 0.396984338760376,
      "learning_rate": 3.012448979591837e-05,
      "loss": 0.064,
      "step": 10240
    },
    {
      "epoch": 4.1,
      "grad_norm": 1.3464882373809814,
      "learning_rate": 3.0104081632653066e-05,
      "loss": 0.0923,
      "step": 10250
    },
    {
      "epoch": 4.104,
      "grad_norm": 1.370470643043518,
      "learning_rate": 3.0083673469387757e-05,
      "loss": 0.1084,
      "step": 10260
    },
    {
      "epoch": 4.108,
      "grad_norm": 1.335173487663269,
      "learning_rate": 3.0063265306122452e-05,
      "loss": 0.0918,
      "step": 10270
    },
    {
      "epoch": 4.112,
      "grad_norm": 1.2719032764434814,
      "learning_rate": 3.0042857142857144e-05,
      "loss": 0.0684,
      "step": 10280
    },
    {
      "epoch": 4.116,
      "grad_norm": 0.6331590414047241,
      "learning_rate": 3.002244897959184e-05,
      "loss": 0.0898,
      "step": 10290
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.2079463005065918,
      "learning_rate": 3.0002040816326534e-05,
      "loss": 0.1319,
      "step": 10300
    },
    {
      "epoch": 4.124,
      "grad_norm": 0.15398487448692322,
      "learning_rate": 2.9981632653061225e-05,
      "loss": 0.0778,
      "step": 10310
    },
    {
      "epoch": 4.128,
      "grad_norm": 0.6670708060264587,
      "learning_rate": 2.996122448979592e-05,
      "loss": 0.1236,
      "step": 10320
    },
    {
      "epoch": 4.132,
      "grad_norm": 0.8536337614059448,
      "learning_rate": 2.9940816326530612e-05,
      "loss": 0.1078,
      "step": 10330
    },
    {
      "epoch": 4.136,
      "grad_norm": 0.5074585676193237,
      "learning_rate": 2.9920408163265307e-05,
      "loss": 0.0574,
      "step": 10340
    },
    {
      "epoch": 4.14,
      "grad_norm": 0.3844391107559204,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 0.0412,
      "step": 10350
    },
    {
      "epoch": 4.144,
      "grad_norm": 0.4396857023239136,
      "learning_rate": 2.9879591836734693e-05,
      "loss": 0.0601,
      "step": 10360
    },
    {
      "epoch": 4.148,
      "grad_norm": 0.5549296140670776,
      "learning_rate": 2.9859183673469388e-05,
      "loss": 0.0755,
      "step": 10370
    },
    {
      "epoch": 4.152,
      "grad_norm": 1.1022642850875854,
      "learning_rate": 2.983877551020408e-05,
      "loss": 0.0613,
      "step": 10380
    },
    {
      "epoch": 4.156,
      "grad_norm": 1.3352824449539185,
      "learning_rate": 2.9818367346938775e-05,
      "loss": 0.0992,
      "step": 10390
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.9938352704048157,
      "learning_rate": 2.979795918367347e-05,
      "loss": 0.0809,
      "step": 10400
    },
    {
      "epoch": 4.164,
      "grad_norm": 0.6609174609184265,
      "learning_rate": 2.977755102040816e-05,
      "loss": 0.0802,
      "step": 10410
    },
    {
      "epoch": 4.168,
      "grad_norm": 1.1619552373886108,
      "learning_rate": 2.975714285714286e-05,
      "loss": 0.0741,
      "step": 10420
    },
    {
      "epoch": 4.172,
      "grad_norm": 1.2189675569534302,
      "learning_rate": 2.9736734693877555e-05,
      "loss": 0.0714,
      "step": 10430
    },
    {
      "epoch": 4.176,
      "grad_norm": 0.9445303082466125,
      "learning_rate": 2.971632653061225e-05,
      "loss": 0.0824,
      "step": 10440
    },
    {
      "epoch": 4.18,
      "grad_norm": 1.425801396369934,
      "learning_rate": 2.969591836734694e-05,
      "loss": 0.0559,
      "step": 10450
    },
    {
      "epoch": 4.184,
      "grad_norm": 0.18293915688991547,
      "learning_rate": 2.9675510204081636e-05,
      "loss": 0.0906,
      "step": 10460
    },
    {
      "epoch": 4.188,
      "grad_norm": 1.728444218635559,
      "learning_rate": 2.9655102040816328e-05,
      "loss": 0.0987,
      "step": 10470
    },
    {
      "epoch": 4.192,
      "grad_norm": 1.3691036701202393,
      "learning_rate": 2.9634693877551023e-05,
      "loss": 0.1059,
      "step": 10480
    },
    {
      "epoch": 4.196,
      "grad_norm": 0.2761857807636261,
      "learning_rate": 2.9614285714285718e-05,
      "loss": 0.0972,
      "step": 10490
    },
    {
      "epoch": 4.2,
      "grad_norm": 1.0228488445281982,
      "learning_rate": 2.959387755102041e-05,
      "loss": 0.0654,
      "step": 10500
    },
    {
      "epoch": 4.204,
      "grad_norm": 1.1988977193832397,
      "learning_rate": 2.9573469387755104e-05,
      "loss": 0.1197,
      "step": 10510
    },
    {
      "epoch": 4.208,
      "grad_norm": 0.21671290695667267,
      "learning_rate": 2.9553061224489796e-05,
      "loss": 0.0661,
      "step": 10520
    },
    {
      "epoch": 4.212,
      "grad_norm": 1.5666134357452393,
      "learning_rate": 2.953265306122449e-05,
      "loss": 0.0949,
      "step": 10530
    },
    {
      "epoch": 4.216,
      "grad_norm": 2.4074504375457764,
      "learning_rate": 2.9512244897959186e-05,
      "loss": 0.1088,
      "step": 10540
    },
    {
      "epoch": 4.22,
      "grad_norm": 0.4520672559738159,
      "learning_rate": 2.9491836734693877e-05,
      "loss": 0.0857,
      "step": 10550
    },
    {
      "epoch": 4.224,
      "grad_norm": 1.182527780532837,
      "learning_rate": 2.9471428571428572e-05,
      "loss": 0.0726,
      "step": 10560
    },
    {
      "epoch": 4.228,
      "grad_norm": 1.7115929126739502,
      "learning_rate": 2.9451020408163264e-05,
      "loss": 0.1399,
      "step": 10570
    },
    {
      "epoch": 4.232,
      "grad_norm": 0.6769790649414062,
      "learning_rate": 2.943061224489796e-05,
      "loss": 0.0706,
      "step": 10580
    },
    {
      "epoch": 4.236,
      "grad_norm": 0.6177055239677429,
      "learning_rate": 2.9410204081632654e-05,
      "loss": 0.0612,
      "step": 10590
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.620784342288971,
      "learning_rate": 2.9389795918367346e-05,
      "loss": 0.0705,
      "step": 10600
    },
    {
      "epoch": 4.244,
      "grad_norm": 0.8592617511749268,
      "learning_rate": 2.936938775510204e-05,
      "loss": 0.0736,
      "step": 10610
    },
    {
      "epoch": 4.248,
      "grad_norm": 0.7745420336723328,
      "learning_rate": 2.9348979591836735e-05,
      "loss": 0.061,
      "step": 10620
    },
    {
      "epoch": 4.252,
      "grad_norm": 1.1473264694213867,
      "learning_rate": 2.9328571428571427e-05,
      "loss": 0.0932,
      "step": 10630
    },
    {
      "epoch": 4.256,
      "grad_norm": 0.4804684817790985,
      "learning_rate": 2.9308163265306122e-05,
      "loss": 0.0881,
      "step": 10640
    },
    {
      "epoch": 4.26,
      "grad_norm": 0.8788352012634277,
      "learning_rate": 2.928775510204082e-05,
      "loss": 0.0505,
      "step": 10650
    },
    {
      "epoch": 4.264,
      "grad_norm": 0.7814933061599731,
      "learning_rate": 2.9267346938775515e-05,
      "loss": 0.0921,
      "step": 10660
    },
    {
      "epoch": 4.268,
      "grad_norm": 0.25738659501075745,
      "learning_rate": 2.9246938775510207e-05,
      "loss": 0.0637,
      "step": 10670
    },
    {
      "epoch": 4.272,
      "grad_norm": 0.6159392595291138,
      "learning_rate": 2.9226530612244902e-05,
      "loss": 0.0913,
      "step": 10680
    },
    {
      "epoch": 4.276,
      "grad_norm": 0.8827903270721436,
      "learning_rate": 2.9206122448979593e-05,
      "loss": 0.09,
      "step": 10690
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.4469039738178253,
      "learning_rate": 2.918571428571429e-05,
      "loss": 0.0983,
      "step": 10700
    },
    {
      "epoch": 4.284,
      "grad_norm": 0.8832043409347534,
      "learning_rate": 2.9165306122448983e-05,
      "loss": 0.0797,
      "step": 10710
    },
    {
      "epoch": 4.288,
      "grad_norm": 0.48761335015296936,
      "learning_rate": 2.9144897959183675e-05,
      "loss": 0.0961,
      "step": 10720
    },
    {
      "epoch": 4.292,
      "grad_norm": 0.8139605522155762,
      "learning_rate": 2.912448979591837e-05,
      "loss": 0.0617,
      "step": 10730
    },
    {
      "epoch": 4.296,
      "grad_norm": 0.8422667980194092,
      "learning_rate": 2.910408163265306e-05,
      "loss": 0.076,
      "step": 10740
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.46334683895111084,
      "learning_rate": 2.9083673469387757e-05,
      "loss": 0.0668,
      "step": 10750
    },
    {
      "epoch": 4.304,
      "grad_norm": 1.2859324216842651,
      "learning_rate": 2.906326530612245e-05,
      "loss": 0.0715,
      "step": 10760
    },
    {
      "epoch": 4.308,
      "grad_norm": 1.134245753288269,
      "learning_rate": 2.9042857142857143e-05,
      "loss": 0.0698,
      "step": 10770
    },
    {
      "epoch": 4.312,
      "grad_norm": 1.0090162754058838,
      "learning_rate": 2.9022448979591838e-05,
      "loss": 0.053,
      "step": 10780
    },
    {
      "epoch": 4.316,
      "grad_norm": 0.9351385831832886,
      "learning_rate": 2.900204081632653e-05,
      "loss": 0.0828,
      "step": 10790
    },
    {
      "epoch": 4.32,
      "grad_norm": 1.1074202060699463,
      "learning_rate": 2.8981632653061225e-05,
      "loss": 0.0931,
      "step": 10800
    },
    {
      "epoch": 4.324,
      "grad_norm": 0.21217840909957886,
      "learning_rate": 2.896122448979592e-05,
      "loss": 0.0984,
      "step": 10810
    },
    {
      "epoch": 4.328,
      "grad_norm": 0.9225795865058899,
      "learning_rate": 2.894081632653061e-05,
      "loss": 0.0796,
      "step": 10820
    },
    {
      "epoch": 4.332,
      "grad_norm": 0.648210883140564,
      "learning_rate": 2.8920408163265306e-05,
      "loss": 0.0687,
      "step": 10830
    },
    {
      "epoch": 4.336,
      "grad_norm": 0.74188232421875,
      "learning_rate": 2.8899999999999998e-05,
      "loss": 0.0896,
      "step": 10840
    },
    {
      "epoch": 4.34,
      "grad_norm": 1.3595166206359863,
      "learning_rate": 2.8879591836734693e-05,
      "loss": 0.0754,
      "step": 10850
    },
    {
      "epoch": 4.344,
      "grad_norm": 1.1045548915863037,
      "learning_rate": 2.8859183673469388e-05,
      "loss": 0.0935,
      "step": 10860
    },
    {
      "epoch": 4.348,
      "grad_norm": 1.6207993030548096,
      "learning_rate": 2.8838775510204086e-05,
      "loss": 0.0519,
      "step": 10870
    },
    {
      "epoch": 4.352,
      "grad_norm": 0.20307113230228424,
      "learning_rate": 2.881836734693878e-05,
      "loss": 0.0748,
      "step": 10880
    },
    {
      "epoch": 4.356,
      "grad_norm": 0.3299717605113983,
      "learning_rate": 2.8797959183673473e-05,
      "loss": 0.1078,
      "step": 10890
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.8125630617141724,
      "learning_rate": 2.8777551020408168e-05,
      "loss": 0.04,
      "step": 10900
    },
    {
      "epoch": 4.364,
      "grad_norm": 0.8992557525634766,
      "learning_rate": 2.875714285714286e-05,
      "loss": 0.0669,
      "step": 10910
    },
    {
      "epoch": 4.368,
      "grad_norm": 1.8277359008789062,
      "learning_rate": 2.8736734693877554e-05,
      "loss": 0.0839,
      "step": 10920
    },
    {
      "epoch": 4.372,
      "grad_norm": 0.346055805683136,
      "learning_rate": 2.871632653061225e-05,
      "loss": 0.0933,
      "step": 10930
    },
    {
      "epoch": 4.376,
      "grad_norm": 1.8543106317520142,
      "learning_rate": 2.869591836734694e-05,
      "loss": 0.0758,
      "step": 10940
    },
    {
      "epoch": 4.38,
      "grad_norm": 0.71882563829422,
      "learning_rate": 2.8675510204081636e-05,
      "loss": 0.0802,
      "step": 10950
    },
    {
      "epoch": 4.384,
      "grad_norm": 1.200972318649292,
      "learning_rate": 2.8655102040816327e-05,
      "loss": 0.0449,
      "step": 10960
    },
    {
      "epoch": 4.388,
      "grad_norm": 1.3256391286849976,
      "learning_rate": 2.8634693877551022e-05,
      "loss": 0.0825,
      "step": 10970
    },
    {
      "epoch": 4.392,
      "grad_norm": 1.5369457006454468,
      "learning_rate": 2.8614285714285717e-05,
      "loss": 0.0755,
      "step": 10980
    },
    {
      "epoch": 4.396,
      "grad_norm": 0.44545450806617737,
      "learning_rate": 2.859387755102041e-05,
      "loss": 0.0512,
      "step": 10990
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.44833213090896606,
      "learning_rate": 2.8573469387755104e-05,
      "loss": 0.0746,
      "step": 11000
    },
    {
      "epoch": 4.404,
      "grad_norm": 1.232093334197998,
      "learning_rate": 2.8553061224489795e-05,
      "loss": 0.0583,
      "step": 11010
    },
    {
      "epoch": 4.408,
      "grad_norm": 1.6474063396453857,
      "learning_rate": 2.853265306122449e-05,
      "loss": 0.0878,
      "step": 11020
    },
    {
      "epoch": 4.412,
      "grad_norm": 0.8362141251564026,
      "learning_rate": 2.8512244897959185e-05,
      "loss": 0.088,
      "step": 11030
    },
    {
      "epoch": 4.416,
      "grad_norm": 1.420750379562378,
      "learning_rate": 2.8491836734693877e-05,
      "loss": 0.0828,
      "step": 11040
    },
    {
      "epoch": 4.42,
      "grad_norm": 0.4838901162147522,
      "learning_rate": 2.8471428571428572e-05,
      "loss": 0.0963,
      "step": 11050
    },
    {
      "epoch": 4.424,
      "grad_norm": 0.9900944232940674,
      "learning_rate": 2.8451020408163263e-05,
      "loss": 0.0751,
      "step": 11060
    },
    {
      "epoch": 4.428,
      "grad_norm": 0.23298011720180511,
      "learning_rate": 2.843061224489796e-05,
      "loss": 0.0661,
      "step": 11070
    },
    {
      "epoch": 4.432,
      "grad_norm": 1.0079656839370728,
      "learning_rate": 2.8410204081632653e-05,
      "loss": 0.0963,
      "step": 11080
    },
    {
      "epoch": 4.436,
      "grad_norm": 0.5479084849357605,
      "learning_rate": 2.8389795918367345e-05,
      "loss": 0.085,
      "step": 11090
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.38386136293411255,
      "learning_rate": 2.8369387755102043e-05,
      "loss": 0.0639,
      "step": 11100
    },
    {
      "epoch": 4.444,
      "grad_norm": 1.9744809865951538,
      "learning_rate": 2.8348979591836738e-05,
      "loss": 0.169,
      "step": 11110
    },
    {
      "epoch": 4.448,
      "grad_norm": 0.41648727655410767,
      "learning_rate": 2.8328571428571433e-05,
      "loss": 0.067,
      "step": 11120
    },
    {
      "epoch": 4.452,
      "grad_norm": 0.6318320631980896,
      "learning_rate": 2.8308163265306125e-05,
      "loss": 0.0656,
      "step": 11130
    },
    {
      "epoch": 4.456,
      "grad_norm": 1.3214747905731201,
      "learning_rate": 2.828775510204082e-05,
      "loss": 0.0652,
      "step": 11140
    },
    {
      "epoch": 4.46,
      "grad_norm": 1.8899530172348022,
      "learning_rate": 2.826734693877551e-05,
      "loss": 0.1157,
      "step": 11150
    },
    {
      "epoch": 4.464,
      "grad_norm": 0.19076776504516602,
      "learning_rate": 2.8246938775510206e-05,
      "loss": 0.0986,
      "step": 11160
    },
    {
      "epoch": 4.468,
      "grad_norm": 0.595331609249115,
      "learning_rate": 2.82265306122449e-05,
      "loss": 0.0683,
      "step": 11170
    },
    {
      "epoch": 4.4719999999999995,
      "grad_norm": 1.5668548345565796,
      "learning_rate": 2.8206122448979593e-05,
      "loss": 0.092,
      "step": 11180
    },
    {
      "epoch": 4.476,
      "grad_norm": 0.1177874356508255,
      "learning_rate": 2.8185714285714288e-05,
      "loss": 0.0699,
      "step": 11190
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.8922727704048157,
      "learning_rate": 2.816530612244898e-05,
      "loss": 0.0934,
      "step": 11200
    },
    {
      "epoch": 4.484,
      "grad_norm": 0.6142949461936951,
      "learning_rate": 2.8144897959183674e-05,
      "loss": 0.0871,
      "step": 11210
    },
    {
      "epoch": 4.4879999999999995,
      "grad_norm": 0.8296774625778198,
      "learning_rate": 2.812448979591837e-05,
      "loss": 0.0698,
      "step": 11220
    },
    {
      "epoch": 4.492,
      "grad_norm": 0.2604500353336334,
      "learning_rate": 2.810408163265306e-05,
      "loss": 0.0984,
      "step": 11230
    },
    {
      "epoch": 4.496,
      "grad_norm": 0.09150781482458115,
      "learning_rate": 2.8083673469387756e-05,
      "loss": 0.0962,
      "step": 11240
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.28346240520477295,
      "learning_rate": 2.806326530612245e-05,
      "loss": 0.0499,
      "step": 11250
    },
    {
      "epoch": 4.504,
      "grad_norm": 0.44482484459877014,
      "learning_rate": 2.8042857142857143e-05,
      "loss": 0.1254,
      "step": 11260
    },
    {
      "epoch": 4.508,
      "grad_norm": 1.0934034585952759,
      "learning_rate": 2.8022448979591837e-05,
      "loss": 0.0753,
      "step": 11270
    },
    {
      "epoch": 4.5120000000000005,
      "grad_norm": 1.1942700147628784,
      "learning_rate": 2.800204081632653e-05,
      "loss": 0.1023,
      "step": 11280
    },
    {
      "epoch": 4.516,
      "grad_norm": 0.6006119251251221,
      "learning_rate": 2.7981632653061224e-05,
      "loss": 0.0532,
      "step": 11290
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.7363290190696716,
      "learning_rate": 2.796122448979592e-05,
      "loss": 0.0475,
      "step": 11300
    },
    {
      "epoch": 4.524,
      "grad_norm": 0.0547625906765461,
      "learning_rate": 2.794081632653061e-05,
      "loss": 0.0517,
      "step": 11310
    },
    {
      "epoch": 4.5280000000000005,
      "grad_norm": 0.41780519485473633,
      "learning_rate": 2.7920408163265306e-05,
      "loss": 0.0681,
      "step": 11320
    },
    {
      "epoch": 4.532,
      "grad_norm": 0.9740432500839233,
      "learning_rate": 2.7900000000000004e-05,
      "loss": 0.1032,
      "step": 11330
    },
    {
      "epoch": 4.536,
      "grad_norm": 0.650749921798706,
      "learning_rate": 2.78795918367347e-05,
      "loss": 0.0518,
      "step": 11340
    },
    {
      "epoch": 4.54,
      "grad_norm": 0.9378098249435425,
      "learning_rate": 2.785918367346939e-05,
      "loss": 0.1026,
      "step": 11350
    },
    {
      "epoch": 4.5440000000000005,
      "grad_norm": 1.9194990396499634,
      "learning_rate": 2.7838775510204085e-05,
      "loss": 0.0991,
      "step": 11360
    },
    {
      "epoch": 4.548,
      "grad_norm": 0.07555797696113586,
      "learning_rate": 2.7818367346938777e-05,
      "loss": 0.0755,
      "step": 11370
    },
    {
      "epoch": 4.552,
      "grad_norm": 0.040513843297958374,
      "learning_rate": 2.7797959183673472e-05,
      "loss": 0.0767,
      "step": 11380
    },
    {
      "epoch": 4.556,
      "grad_norm": 0.6926000118255615,
      "learning_rate": 2.7777551020408167e-05,
      "loss": 0.0918,
      "step": 11390
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 2.006291627883911,
      "learning_rate": 2.775714285714286e-05,
      "loss": 0.0853,
      "step": 11400
    },
    {
      "epoch": 4.564,
      "grad_norm": 0.028726616874337196,
      "learning_rate": 2.7736734693877554e-05,
      "loss": 0.0701,
      "step": 11410
    },
    {
      "epoch": 4.568,
      "grad_norm": 0.3288923501968384,
      "learning_rate": 2.7716326530612245e-05,
      "loss": 0.1252,
      "step": 11420
    },
    {
      "epoch": 4.572,
      "grad_norm": 1.2484318017959595,
      "learning_rate": 2.769591836734694e-05,
      "loss": 0.1218,
      "step": 11430
    },
    {
      "epoch": 4.576,
      "grad_norm": 0.17805476486682892,
      "learning_rate": 2.7675510204081635e-05,
      "loss": 0.0579,
      "step": 11440
    },
    {
      "epoch": 4.58,
      "grad_norm": 1.019976258277893,
      "learning_rate": 2.7655102040816327e-05,
      "loss": 0.0698,
      "step": 11450
    },
    {
      "epoch": 4.584,
      "grad_norm": 0.4780566394329071,
      "learning_rate": 2.763469387755102e-05,
      "loss": 0.1121,
      "step": 11460
    },
    {
      "epoch": 4.588,
      "grad_norm": 0.7051382064819336,
      "learning_rate": 2.7614285714285713e-05,
      "loss": 0.088,
      "step": 11470
    },
    {
      "epoch": 4.592,
      "grad_norm": 0.19621258974075317,
      "learning_rate": 2.7593877551020408e-05,
      "loss": 0.0795,
      "step": 11480
    },
    {
      "epoch": 4.596,
      "grad_norm": 0.9771621823310852,
      "learning_rate": 2.7573469387755103e-05,
      "loss": 0.067,
      "step": 11490
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.985279381275177,
      "learning_rate": 2.7553061224489795e-05,
      "loss": 0.0839,
      "step": 11500
    },
    {
      "epoch": 4.604,
      "grad_norm": 0.3785873353481293,
      "learning_rate": 2.753265306122449e-05,
      "loss": 0.0681,
      "step": 11510
    },
    {
      "epoch": 4.608,
      "grad_norm": 1.1148171424865723,
      "learning_rate": 2.751224489795918e-05,
      "loss": 0.0968,
      "step": 11520
    },
    {
      "epoch": 4.612,
      "grad_norm": 0.21181179583072662,
      "learning_rate": 2.7491836734693876e-05,
      "loss": 0.0974,
      "step": 11530
    },
    {
      "epoch": 4.616,
      "grad_norm": 0.563779354095459,
      "learning_rate": 2.747142857142857e-05,
      "loss": 0.0612,
      "step": 11540
    },
    {
      "epoch": 4.62,
      "grad_norm": 1.104238510131836,
      "learning_rate": 2.745102040816327e-05,
      "loss": 0.0872,
      "step": 11550
    },
    {
      "epoch": 4.624,
      "grad_norm": 0.8681454062461853,
      "learning_rate": 2.7430612244897965e-05,
      "loss": 0.0719,
      "step": 11560
    },
    {
      "epoch": 4.628,
      "grad_norm": 0.8084072470664978,
      "learning_rate": 2.7410204081632656e-05,
      "loss": 0.0694,
      "step": 11570
    },
    {
      "epoch": 4.632,
      "grad_norm": 0.7550397515296936,
      "learning_rate": 2.738979591836735e-05,
      "loss": 0.0581,
      "step": 11580
    },
    {
      "epoch": 4.636,
      "grad_norm": 0.048828598111867905,
      "learning_rate": 2.7369387755102043e-05,
      "loss": 0.1076,
      "step": 11590
    },
    {
      "epoch": 4.64,
      "grad_norm": 1.1362602710723877,
      "learning_rate": 2.7348979591836738e-05,
      "loss": 0.0828,
      "step": 11600
    },
    {
      "epoch": 4.644,
      "grad_norm": 0.41308239102363586,
      "learning_rate": 2.7328571428571433e-05,
      "loss": 0.0815,
      "step": 11610
    },
    {
      "epoch": 4.648,
      "grad_norm": 0.5456241965293884,
      "learning_rate": 2.7308163265306124e-05,
      "loss": 0.0548,
      "step": 11620
    },
    {
      "epoch": 4.652,
      "grad_norm": 1.389285922050476,
      "learning_rate": 2.728775510204082e-05,
      "loss": 0.0939,
      "step": 11630
    },
    {
      "epoch": 4.656,
      "grad_norm": 0.5468088388442993,
      "learning_rate": 2.726734693877551e-05,
      "loss": 0.085,
      "step": 11640
    },
    {
      "epoch": 4.66,
      "grad_norm": 0.702900230884552,
      "learning_rate": 2.7246938775510206e-05,
      "loss": 0.1033,
      "step": 11650
    },
    {
      "epoch": 4.664,
      "grad_norm": 0.5299795866012573,
      "learning_rate": 2.72265306122449e-05,
      "loss": 0.0672,
      "step": 11660
    },
    {
      "epoch": 4.668,
      "grad_norm": 1.3266940116882324,
      "learning_rate": 2.7206122448979592e-05,
      "loss": 0.0954,
      "step": 11670
    },
    {
      "epoch": 4.672,
      "grad_norm": 1.100536823272705,
      "learning_rate": 2.7185714285714287e-05,
      "loss": 0.087,
      "step": 11680
    },
    {
      "epoch": 4.676,
      "grad_norm": 0.369729608297348,
      "learning_rate": 2.716530612244898e-05,
      "loss": 0.0572,
      "step": 11690
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.6860167980194092,
      "learning_rate": 2.7144897959183674e-05,
      "loss": 0.09,
      "step": 11700
    },
    {
      "epoch": 4.684,
      "grad_norm": 0.7593515515327454,
      "learning_rate": 2.712448979591837e-05,
      "loss": 0.0666,
      "step": 11710
    },
    {
      "epoch": 4.688,
      "grad_norm": 1.1963036060333252,
      "learning_rate": 2.710408163265306e-05,
      "loss": 0.095,
      "step": 11720
    },
    {
      "epoch": 4.692,
      "grad_norm": 0.6618120670318604,
      "learning_rate": 2.7083673469387755e-05,
      "loss": 0.0731,
      "step": 11730
    },
    {
      "epoch": 4.696,
      "grad_norm": 1.655981183052063,
      "learning_rate": 2.7063265306122447e-05,
      "loss": 0.0777,
      "step": 11740
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.05826932191848755,
      "learning_rate": 2.7042857142857142e-05,
      "loss": 0.1013,
      "step": 11750
    },
    {
      "epoch": 4.704,
      "grad_norm": 0.645777702331543,
      "learning_rate": 2.7022448979591837e-05,
      "loss": 0.0611,
      "step": 11760
    },
    {
      "epoch": 4.708,
      "grad_norm": 0.3763398230075836,
      "learning_rate": 2.700204081632653e-05,
      "loss": 0.1126,
      "step": 11770
    },
    {
      "epoch": 4.712,
      "grad_norm": 0.6958228349685669,
      "learning_rate": 2.6981632653061227e-05,
      "loss": 0.0701,
      "step": 11780
    },
    {
      "epoch": 4.716,
      "grad_norm": 1.0456745624542236,
      "learning_rate": 2.6961224489795922e-05,
      "loss": 0.0611,
      "step": 11790
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.1258256435394287,
      "learning_rate": 2.6940816326530617e-05,
      "loss": 0.1146,
      "step": 11800
    },
    {
      "epoch": 4.724,
      "grad_norm": 0.21650798618793488,
      "learning_rate": 2.692040816326531e-05,
      "loss": 0.1146,
      "step": 11810
    },
    {
      "epoch": 4.728,
      "grad_norm": 0.9087498784065247,
      "learning_rate": 2.6900000000000003e-05,
      "loss": 0.0653,
      "step": 11820
    },
    {
      "epoch": 4.732,
      "grad_norm": 1.483880639076233,
      "learning_rate": 2.6879591836734695e-05,
      "loss": 0.0803,
      "step": 11830
    },
    {
      "epoch": 4.736,
      "grad_norm": 0.42240652441978455,
      "learning_rate": 2.685918367346939e-05,
      "loss": 0.06,
      "step": 11840
    },
    {
      "epoch": 4.74,
      "grad_norm": 0.5984033346176147,
      "learning_rate": 2.6838775510204085e-05,
      "loss": 0.09,
      "step": 11850
    },
    {
      "epoch": 4.744,
      "grad_norm": 1.4021532535552979,
      "learning_rate": 2.6818367346938776e-05,
      "loss": 0.0612,
      "step": 11860
    },
    {
      "epoch": 4.748,
      "grad_norm": 0.05445469170808792,
      "learning_rate": 2.679795918367347e-05,
      "loss": 0.0909,
      "step": 11870
    },
    {
      "epoch": 4.752,
      "grad_norm": 1.2299412488937378,
      "learning_rate": 2.6777551020408166e-05,
      "loss": 0.117,
      "step": 11880
    },
    {
      "epoch": 4.756,
      "grad_norm": 1.4248424768447876,
      "learning_rate": 2.6757142857142858e-05,
      "loss": 0.0907,
      "step": 11890
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.759462833404541,
      "learning_rate": 2.6736734693877553e-05,
      "loss": 0.1043,
      "step": 11900
    },
    {
      "epoch": 4.764,
      "grad_norm": 1.7601536512374878,
      "learning_rate": 2.6716326530612245e-05,
      "loss": 0.0913,
      "step": 11910
    },
    {
      "epoch": 4.768,
      "grad_norm": 0.7134551405906677,
      "learning_rate": 2.669591836734694e-05,
      "loss": 0.0427,
      "step": 11920
    },
    {
      "epoch": 4.772,
      "grad_norm": 0.17397131025791168,
      "learning_rate": 2.6675510204081634e-05,
      "loss": 0.0869,
      "step": 11930
    },
    {
      "epoch": 4.776,
      "grad_norm": 1.7596689462661743,
      "learning_rate": 2.6655102040816326e-05,
      "loss": 0.1263,
      "step": 11940
    },
    {
      "epoch": 4.78,
      "grad_norm": 0.10190337896347046,
      "learning_rate": 2.663469387755102e-05,
      "loss": 0.041,
      "step": 11950
    },
    {
      "epoch": 4.784,
      "grad_norm": 1.3124539852142334,
      "learning_rate": 2.6614285714285713e-05,
      "loss": 0.1289,
      "step": 11960
    },
    {
      "epoch": 4.788,
      "grad_norm": 0.3689451813697815,
      "learning_rate": 2.6593877551020408e-05,
      "loss": 0.1061,
      "step": 11970
    },
    {
      "epoch": 4.792,
      "grad_norm": 0.9346511960029602,
      "learning_rate": 2.6573469387755103e-05,
      "loss": 0.1077,
      "step": 11980
    },
    {
      "epoch": 4.796,
      "grad_norm": 1.057923674583435,
      "learning_rate": 2.6553061224489794e-05,
      "loss": 0.0449,
      "step": 11990
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.6896833777427673,
      "learning_rate": 2.653265306122449e-05,
      "loss": 0.0356,
      "step": 12000
    },
    {
      "epoch": 4.804,
      "grad_norm": 1.0254930257797241,
      "learning_rate": 2.6512244897959187e-05,
      "loss": 0.0825,
      "step": 12010
    },
    {
      "epoch": 4.808,
      "grad_norm": 0.3069210648536682,
      "learning_rate": 2.6491836734693882e-05,
      "loss": 0.0504,
      "step": 12020
    },
    {
      "epoch": 4.812,
      "grad_norm": 1.2867485284805298,
      "learning_rate": 2.6471428571428574e-05,
      "loss": 0.1207,
      "step": 12030
    },
    {
      "epoch": 4.816,
      "grad_norm": 0.9003486633300781,
      "learning_rate": 2.645102040816327e-05,
      "loss": 0.0496,
      "step": 12040
    },
    {
      "epoch": 4.82,
      "grad_norm": 0.02197042666375637,
      "learning_rate": 2.643061224489796e-05,
      "loss": 0.0805,
      "step": 12050
    },
    {
      "epoch": 4.824,
      "grad_norm": 0.5668536424636841,
      "learning_rate": 2.6410204081632656e-05,
      "loss": 0.0479,
      "step": 12060
    },
    {
      "epoch": 4.828,
      "grad_norm": 1.3223639726638794,
      "learning_rate": 2.638979591836735e-05,
      "loss": 0.0564,
      "step": 12070
    },
    {
      "epoch": 4.832,
      "grad_norm": 0.9486927390098572,
      "learning_rate": 2.6369387755102042e-05,
      "loss": 0.0596,
      "step": 12080
    },
    {
      "epoch": 4.836,
      "grad_norm": 0.026500705629587173,
      "learning_rate": 2.6348979591836737e-05,
      "loss": 0.0535,
      "step": 12090
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.6323457360267639,
      "learning_rate": 2.632857142857143e-05,
      "loss": 0.0604,
      "step": 12100
    },
    {
      "epoch": 4.844,
      "grad_norm": 0.4261210858821869,
      "learning_rate": 2.6308163265306124e-05,
      "loss": 0.0622,
      "step": 12110
    },
    {
      "epoch": 4.848,
      "grad_norm": 0.8335773944854736,
      "learning_rate": 2.628775510204082e-05,
      "loss": 0.1099,
      "step": 12120
    },
    {
      "epoch": 4.852,
      "grad_norm": 0.8427066206932068,
      "learning_rate": 2.626734693877551e-05,
      "loss": 0.0878,
      "step": 12130
    },
    {
      "epoch": 4.856,
      "grad_norm": 0.603495717048645,
      "learning_rate": 2.6246938775510205e-05,
      "loss": 0.095,
      "step": 12140
    },
    {
      "epoch": 4.86,
      "grad_norm": 0.9861535429954529,
      "learning_rate": 2.6226530612244897e-05,
      "loss": 0.0697,
      "step": 12150
    },
    {
      "epoch": 4.864,
      "grad_norm": 0.2955377399921417,
      "learning_rate": 2.6206122448979592e-05,
      "loss": 0.0763,
      "step": 12160
    },
    {
      "epoch": 4.868,
      "grad_norm": 0.28626778721809387,
      "learning_rate": 2.6185714285714287e-05,
      "loss": 0.0802,
      "step": 12170
    },
    {
      "epoch": 4.872,
      "grad_norm": 0.16565154492855072,
      "learning_rate": 2.6165306122448978e-05,
      "loss": 0.0641,
      "step": 12180
    },
    {
      "epoch": 4.876,
      "grad_norm": 0.7294909954071045,
      "learning_rate": 2.6144897959183673e-05,
      "loss": 0.068,
      "step": 12190
    },
    {
      "epoch": 4.88,
      "grad_norm": 1.093395471572876,
      "learning_rate": 2.6124489795918368e-05,
      "loss": 0.0842,
      "step": 12200
    },
    {
      "epoch": 4.884,
      "grad_norm": 0.027080142870545387,
      "learning_rate": 2.610408163265306e-05,
      "loss": 0.0617,
      "step": 12210
    },
    {
      "epoch": 4.888,
      "grad_norm": 0.8377162218093872,
      "learning_rate": 2.6083673469387755e-05,
      "loss": 0.0728,
      "step": 12220
    },
    {
      "epoch": 4.892,
      "grad_norm": 0.5680263042449951,
      "learning_rate": 2.6063265306122453e-05,
      "loss": 0.0923,
      "step": 12230
    },
    {
      "epoch": 4.896,
      "grad_norm": 1.46372389793396,
      "learning_rate": 2.6042857142857148e-05,
      "loss": 0.1087,
      "step": 12240
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.5306707620620728,
      "learning_rate": 2.602244897959184e-05,
      "loss": 0.1211,
      "step": 12250
    },
    {
      "epoch": 4.904,
      "grad_norm": 0.3147760331630707,
      "learning_rate": 2.6002040816326535e-05,
      "loss": 0.0807,
      "step": 12260
    },
    {
      "epoch": 4.908,
      "grad_norm": 1.5176714658737183,
      "learning_rate": 2.5981632653061226e-05,
      "loss": 0.0908,
      "step": 12270
    },
    {
      "epoch": 4.912,
      "grad_norm": 1.0678139925003052,
      "learning_rate": 2.596122448979592e-05,
      "loss": 0.1231,
      "step": 12280
    },
    {
      "epoch": 4.916,
      "grad_norm": 1.1269294023513794,
      "learning_rate": 2.5940816326530616e-05,
      "loss": 0.039,
      "step": 12290
    },
    {
      "epoch": 4.92,
      "grad_norm": 0.8726208209991455,
      "learning_rate": 2.5920408163265308e-05,
      "loss": 0.0729,
      "step": 12300
    },
    {
      "epoch": 4.924,
      "grad_norm": 0.5339171290397644,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 0.0858,
      "step": 12310
    },
    {
      "epoch": 4.928,
      "grad_norm": 1.1989939212799072,
      "learning_rate": 2.5879591836734694e-05,
      "loss": 0.0934,
      "step": 12320
    },
    {
      "epoch": 4.932,
      "grad_norm": 1.19804048538208,
      "learning_rate": 2.585918367346939e-05,
      "loss": 0.0505,
      "step": 12330
    },
    {
      "epoch": 4.936,
      "grad_norm": 2.6626839637756348,
      "learning_rate": 2.5838775510204084e-05,
      "loss": 0.0891,
      "step": 12340
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 0.966888964176178,
      "learning_rate": 2.5818367346938776e-05,
      "loss": 0.1242,
      "step": 12350
    },
    {
      "epoch": 4.944,
      "grad_norm": 1.5546948909759521,
      "learning_rate": 2.579795918367347e-05,
      "loss": 0.1254,
      "step": 12360
    },
    {
      "epoch": 4.948,
      "grad_norm": 0.10198922455310822,
      "learning_rate": 2.5777551020408162e-05,
      "loss": 0.0412,
      "step": 12370
    },
    {
      "epoch": 4.952,
      "grad_norm": 0.8961101770401001,
      "learning_rate": 2.5757142857142857e-05,
      "loss": 0.075,
      "step": 12380
    },
    {
      "epoch": 4.9559999999999995,
      "grad_norm": 0.03833508864045143,
      "learning_rate": 2.5736734693877552e-05,
      "loss": 0.0686,
      "step": 12390
    },
    {
      "epoch": 4.96,
      "grad_norm": 1.1095024347305298,
      "learning_rate": 2.5716326530612244e-05,
      "loss": 0.0945,
      "step": 12400
    },
    {
      "epoch": 4.964,
      "grad_norm": 0.32877442240715027,
      "learning_rate": 2.569591836734694e-05,
      "loss": 0.0633,
      "step": 12410
    },
    {
      "epoch": 4.968,
      "grad_norm": 1.3273366689682007,
      "learning_rate": 2.567551020408163e-05,
      "loss": 0.1422,
      "step": 12420
    },
    {
      "epoch": 4.9719999999999995,
      "grad_norm": 2.431541681289673,
      "learning_rate": 2.5655102040816325e-05,
      "loss": 0.1326,
      "step": 12430
    },
    {
      "epoch": 4.976,
      "grad_norm": 0.4969988465309143,
      "learning_rate": 2.563469387755102e-05,
      "loss": 0.0584,
      "step": 12440
    },
    {
      "epoch": 4.98,
      "grad_norm": 0.5913245677947998,
      "learning_rate": 2.5614285714285712e-05,
      "loss": 0.0341,
      "step": 12450
    },
    {
      "epoch": 4.984,
      "grad_norm": 1.6037614345550537,
      "learning_rate": 2.559387755102041e-05,
      "loss": 0.1082,
      "step": 12460
    },
    {
      "epoch": 4.9879999999999995,
      "grad_norm": 0.9405896663665771,
      "learning_rate": 2.5573469387755105e-05,
      "loss": 0.0829,
      "step": 12470
    },
    {
      "epoch": 4.992,
      "grad_norm": 0.27052852511405945,
      "learning_rate": 2.55530612244898e-05,
      "loss": 0.0835,
      "step": 12480
    },
    {
      "epoch": 4.996,
      "grad_norm": 2.5025863647460938,
      "learning_rate": 2.5532653061224492e-05,
      "loss": 0.0983,
      "step": 12490
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.8840848803520203,
      "learning_rate": 2.5512244897959187e-05,
      "loss": 0.0873,
      "step": 12500
    },
    {
      "epoch": 5.004,
      "grad_norm": 1.2188701629638672,
      "learning_rate": 2.5491836734693882e-05,
      "loss": 0.07,
      "step": 12510
    },
    {
      "epoch": 5.008,
      "grad_norm": 1.316097378730774,
      "learning_rate": 2.5471428571428573e-05,
      "loss": 0.0798,
      "step": 12520
    },
    {
      "epoch": 5.012,
      "grad_norm": 0.37865787744522095,
      "learning_rate": 2.545102040816327e-05,
      "loss": 0.0531,
      "step": 12530
    },
    {
      "epoch": 5.016,
      "grad_norm": 0.7643833756446838,
      "learning_rate": 2.543061224489796e-05,
      "loss": 0.0797,
      "step": 12540
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.859598696231842,
      "learning_rate": 2.5410204081632655e-05,
      "loss": 0.0683,
      "step": 12550
    },
    {
      "epoch": 5.024,
      "grad_norm": 1.3265981674194336,
      "learning_rate": 2.538979591836735e-05,
      "loss": 0.0986,
      "step": 12560
    },
    {
      "epoch": 5.028,
      "grad_norm": 0.045599862933158875,
      "learning_rate": 2.536938775510204e-05,
      "loss": 0.0804,
      "step": 12570
    },
    {
      "epoch": 5.032,
      "grad_norm": 0.8017162084579468,
      "learning_rate": 2.5348979591836736e-05,
      "loss": 0.0448,
      "step": 12580
    },
    {
      "epoch": 5.036,
      "grad_norm": 0.3185052275657654,
      "learning_rate": 2.5328571428571428e-05,
      "loss": 0.0538,
      "step": 12590
    },
    {
      "epoch": 5.04,
      "grad_norm": 0.33830732107162476,
      "learning_rate": 2.5308163265306123e-05,
      "loss": 0.0873,
      "step": 12600
    },
    {
      "epoch": 5.044,
      "grad_norm": 1.6156104803085327,
      "learning_rate": 2.5287755102040818e-05,
      "loss": 0.0944,
      "step": 12610
    },
    {
      "epoch": 5.048,
      "grad_norm": 1.4439938068389893,
      "learning_rate": 2.526734693877551e-05,
      "loss": 0.1413,
      "step": 12620
    },
    {
      "epoch": 5.052,
      "grad_norm": 0.9127569794654846,
      "learning_rate": 2.5246938775510205e-05,
      "loss": 0.1201,
      "step": 12630
    },
    {
      "epoch": 5.056,
      "grad_norm": 0.5798062086105347,
      "learning_rate": 2.5226530612244896e-05,
      "loss": 0.0509,
      "step": 12640
    },
    {
      "epoch": 5.06,
      "grad_norm": 1.5033818483352661,
      "learning_rate": 2.520612244897959e-05,
      "loss": 0.0716,
      "step": 12650
    },
    {
      "epoch": 5.064,
      "grad_norm": 0.1704075187444687,
      "learning_rate": 2.5185714285714286e-05,
      "loss": 0.0588,
      "step": 12660
    },
    {
      "epoch": 5.068,
      "grad_norm": 0.8732672929763794,
      "learning_rate": 2.5165306122448978e-05,
      "loss": 0.0905,
      "step": 12670
    },
    {
      "epoch": 5.072,
      "grad_norm": 1.1422460079193115,
      "learning_rate": 2.5144897959183673e-05,
      "loss": 0.07,
      "step": 12680
    },
    {
      "epoch": 5.076,
      "grad_norm": 0.4966922402381897,
      "learning_rate": 2.512448979591837e-05,
      "loss": 0.0746,
      "step": 12690
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.5519986152648926,
      "learning_rate": 2.5104081632653066e-05,
      "loss": 0.0436,
      "step": 12700
    },
    {
      "epoch": 5.084,
      "grad_norm": 1.0676201581954956,
      "learning_rate": 2.5083673469387758e-05,
      "loss": 0.0828,
      "step": 12710
    },
    {
      "epoch": 5.088,
      "grad_norm": 1.7705944776535034,
      "learning_rate": 2.5063265306122453e-05,
      "loss": 0.1263,
      "step": 12720
    },
    {
      "epoch": 5.092,
      "grad_norm": 1.4635895490646362,
      "learning_rate": 2.5042857142857144e-05,
      "loss": 0.0495,
      "step": 12730
    },
    {
      "epoch": 5.096,
      "grad_norm": 0.10445186495780945,
      "learning_rate": 2.502244897959184e-05,
      "loss": 0.0485,
      "step": 12740
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.5982151031494141,
      "learning_rate": 2.5002040816326534e-05,
      "loss": 0.0485,
      "step": 12750
    },
    {
      "epoch": 5.104,
      "grad_norm": 0.38890743255615234,
      "learning_rate": 2.4981632653061226e-05,
      "loss": 0.0605,
      "step": 12760
    },
    {
      "epoch": 5.108,
      "grad_norm": 0.8506534695625305,
      "learning_rate": 2.496122448979592e-05,
      "loss": 0.0631,
      "step": 12770
    },
    {
      "epoch": 5.112,
      "grad_norm": 0.35058656334877014,
      "learning_rate": 2.4940816326530612e-05,
      "loss": 0.0351,
      "step": 12780
    },
    {
      "epoch": 5.116,
      "grad_norm": 1.7926064729690552,
      "learning_rate": 2.4920408163265307e-05,
      "loss": 0.0703,
      "step": 12790
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.8767410516738892,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 0.1023,
      "step": 12800
    },
    {
      "epoch": 5.124,
      "grad_norm": 0.14057351648807526,
      "learning_rate": 2.4879591836734694e-05,
      "loss": 0.0541,
      "step": 12810
    },
    {
      "epoch": 5.128,
      "grad_norm": 0.5982944369316101,
      "learning_rate": 2.485918367346939e-05,
      "loss": 0.0708,
      "step": 12820
    },
    {
      "epoch": 5.132,
      "grad_norm": 0.7073796391487122,
      "learning_rate": 2.4838775510204084e-05,
      "loss": 0.0441,
      "step": 12830
    },
    {
      "epoch": 5.136,
      "grad_norm": 1.1200053691864014,
      "learning_rate": 2.4818367346938775e-05,
      "loss": 0.1266,
      "step": 12840
    },
    {
      "epoch": 5.14,
      "grad_norm": 0.5180574059486389,
      "learning_rate": 2.479795918367347e-05,
      "loss": 0.0553,
      "step": 12850
    },
    {
      "epoch": 5.144,
      "grad_norm": 0.7158071398735046,
      "learning_rate": 2.4777551020408165e-05,
      "loss": 0.111,
      "step": 12860
    },
    {
      "epoch": 5.148,
      "grad_norm": 0.7103878259658813,
      "learning_rate": 2.475714285714286e-05,
      "loss": 0.0449,
      "step": 12870
    },
    {
      "epoch": 5.152,
      "grad_norm": 0.42610371112823486,
      "learning_rate": 2.4736734693877552e-05,
      "loss": 0.0908,
      "step": 12880
    },
    {
      "epoch": 5.156,
      "grad_norm": 1.3563522100448608,
      "learning_rate": 2.4716326530612247e-05,
      "loss": 0.0513,
      "step": 12890
    },
    {
      "epoch": 5.16,
      "grad_norm": 0.14676935970783234,
      "learning_rate": 2.4695918367346942e-05,
      "loss": 0.0956,
      "step": 12900
    },
    {
      "epoch": 5.164,
      "grad_norm": 0.13056252896785736,
      "learning_rate": 2.4675510204081633e-05,
      "loss": 0.0465,
      "step": 12910
    },
    {
      "epoch": 5.168,
      "grad_norm": 1.3960105180740356,
      "learning_rate": 2.4655102040816328e-05,
      "loss": 0.0801,
      "step": 12920
    },
    {
      "epoch": 5.172,
      "grad_norm": 0.6782654523849487,
      "learning_rate": 2.463469387755102e-05,
      "loss": 0.0348,
      "step": 12930
    },
    {
      "epoch": 5.176,
      "grad_norm": 0.7088229656219482,
      "learning_rate": 2.4614285714285715e-05,
      "loss": 0.0502,
      "step": 12940
    },
    {
      "epoch": 5.18,
      "grad_norm": 0.7337384223937988,
      "learning_rate": 2.459387755102041e-05,
      "loss": 0.0803,
      "step": 12950
    },
    {
      "epoch": 5.184,
      "grad_norm": 2.0196316242218018,
      "learning_rate": 2.45734693877551e-05,
      "loss": 0.0984,
      "step": 12960
    },
    {
      "epoch": 5.188,
      "grad_norm": 1.650534987449646,
      "learning_rate": 2.45530612244898e-05,
      "loss": 0.0903,
      "step": 12970
    },
    {
      "epoch": 5.192,
      "grad_norm": 1.0698423385620117,
      "learning_rate": 2.453265306122449e-05,
      "loss": 0.0665,
      "step": 12980
    },
    {
      "epoch": 5.196,
      "grad_norm": 0.9103533625602722,
      "learning_rate": 2.4512244897959186e-05,
      "loss": 0.0917,
      "step": 12990
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.14456744492053986,
      "learning_rate": 2.4491836734693878e-05,
      "loss": 0.0309,
      "step": 13000
    },
    {
      "epoch": 5.204,
      "grad_norm": 1.177446722984314,
      "learning_rate": 2.4471428571428573e-05,
      "loss": 0.0839,
      "step": 13010
    },
    {
      "epoch": 5.208,
      "grad_norm": 1.720395565032959,
      "learning_rate": 2.4451020408163268e-05,
      "loss": 0.1037,
      "step": 13020
    },
    {
      "epoch": 5.212,
      "grad_norm": 0.8484231233596802,
      "learning_rate": 2.443061224489796e-05,
      "loss": 0.0913,
      "step": 13030
    },
    {
      "epoch": 5.216,
      "grad_norm": 0.48715561628341675,
      "learning_rate": 2.4410204081632654e-05,
      "loss": 0.0964,
      "step": 13040
    },
    {
      "epoch": 5.22,
      "grad_norm": 1.2812856435775757,
      "learning_rate": 2.4389795918367346e-05,
      "loss": 0.0854,
      "step": 13050
    },
    {
      "epoch": 5.224,
      "grad_norm": 0.9369724988937378,
      "learning_rate": 2.436938775510204e-05,
      "loss": 0.0686,
      "step": 13060
    },
    {
      "epoch": 5.228,
      "grad_norm": 0.8084055185317993,
      "learning_rate": 2.4348979591836736e-05,
      "loss": 0.0839,
      "step": 13070
    },
    {
      "epoch": 5.232,
      "grad_norm": 1.4612466096878052,
      "learning_rate": 2.432857142857143e-05,
      "loss": 0.0753,
      "step": 13080
    },
    {
      "epoch": 5.236,
      "grad_norm": 0.8196280598640442,
      "learning_rate": 2.4308163265306126e-05,
      "loss": 0.073,
      "step": 13090
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.6758369207382202,
      "learning_rate": 2.4287755102040817e-05,
      "loss": 0.0728,
      "step": 13100
    },
    {
      "epoch": 5.244,
      "grad_norm": 1.392268419265747,
      "learning_rate": 2.4267346938775512e-05,
      "loss": 0.0788,
      "step": 13110
    },
    {
      "epoch": 5.248,
      "grad_norm": 0.1540958285331726,
      "learning_rate": 2.4246938775510204e-05,
      "loss": 0.0962,
      "step": 13120
    },
    {
      "epoch": 5.252,
      "grad_norm": 0.5666881799697876,
      "learning_rate": 2.42265306122449e-05,
      "loss": 0.1091,
      "step": 13130
    },
    {
      "epoch": 5.256,
      "grad_norm": 1.2313311100006104,
      "learning_rate": 2.4206122448979594e-05,
      "loss": 0.0641,
      "step": 13140
    },
    {
      "epoch": 5.26,
      "grad_norm": 0.03577340394258499,
      "learning_rate": 2.4185714285714286e-05,
      "loss": 0.0953,
      "step": 13150
    },
    {
      "epoch": 5.264,
      "grad_norm": 0.8875718712806702,
      "learning_rate": 2.416530612244898e-05,
      "loss": 0.0897,
      "step": 13160
    },
    {
      "epoch": 5.268,
      "grad_norm": 1.1500518321990967,
      "learning_rate": 2.4144897959183675e-05,
      "loss": 0.0814,
      "step": 13170
    },
    {
      "epoch": 5.272,
      "grad_norm": 0.0405505895614624,
      "learning_rate": 2.4124489795918367e-05,
      "loss": 0.1075,
      "step": 13180
    },
    {
      "epoch": 5.276,
      "grad_norm": 1.4534757137298584,
      "learning_rate": 2.4104081632653062e-05,
      "loss": 0.0653,
      "step": 13190
    },
    {
      "epoch": 5.28,
      "grad_norm": 1.148922324180603,
      "learning_rate": 2.4083673469387757e-05,
      "loss": 0.0776,
      "step": 13200
    },
    {
      "epoch": 5.284,
      "grad_norm": 1.684704303741455,
      "learning_rate": 2.4063265306122452e-05,
      "loss": 0.0942,
      "step": 13210
    },
    {
      "epoch": 5.288,
      "grad_norm": 1.559739589691162,
      "learning_rate": 2.4042857142857144e-05,
      "loss": 0.0825,
      "step": 13220
    },
    {
      "epoch": 5.292,
      "grad_norm": 1.1421489715576172,
      "learning_rate": 2.402244897959184e-05,
      "loss": 0.1068,
      "step": 13230
    },
    {
      "epoch": 5.296,
      "grad_norm": 0.6023655533790588,
      "learning_rate": 2.4002040816326533e-05,
      "loss": 0.0414,
      "step": 13240
    },
    {
      "epoch": 5.3,
      "grad_norm": 1.069000482559204,
      "learning_rate": 2.3981632653061225e-05,
      "loss": 0.0689,
      "step": 13250
    },
    {
      "epoch": 5.304,
      "grad_norm": 1.1332625150680542,
      "learning_rate": 2.396122448979592e-05,
      "loss": 0.0477,
      "step": 13260
    },
    {
      "epoch": 5.308,
      "grad_norm": 0.5090751051902771,
      "learning_rate": 2.394081632653061e-05,
      "loss": 0.0813,
      "step": 13270
    },
    {
      "epoch": 5.312,
      "grad_norm": 0.6887373328208923,
      "learning_rate": 2.3920408163265307e-05,
      "loss": 0.0798,
      "step": 13280
    },
    {
      "epoch": 5.316,
      "grad_norm": 0.7541113495826721,
      "learning_rate": 2.39e-05,
      "loss": 0.0748,
      "step": 13290
    },
    {
      "epoch": 5.32,
      "grad_norm": 1.627463936805725,
      "learning_rate": 2.3879591836734693e-05,
      "loss": 0.0814,
      "step": 13300
    },
    {
      "epoch": 5.324,
      "grad_norm": 1.3394067287445068,
      "learning_rate": 2.385918367346939e-05,
      "loss": 0.0708,
      "step": 13310
    },
    {
      "epoch": 5.328,
      "grad_norm": 0.504148006439209,
      "learning_rate": 2.3838775510204083e-05,
      "loss": 0.0687,
      "step": 13320
    },
    {
      "epoch": 5.332,
      "grad_norm": 0.7084826827049255,
      "learning_rate": 2.3818367346938778e-05,
      "loss": 0.0908,
      "step": 13330
    },
    {
      "epoch": 5.336,
      "grad_norm": 0.7866883873939514,
      "learning_rate": 2.379795918367347e-05,
      "loss": 0.0634,
      "step": 13340
    },
    {
      "epoch": 5.34,
      "grad_norm": 1.3498698472976685,
      "learning_rate": 2.3777551020408165e-05,
      "loss": 0.066,
      "step": 13350
    },
    {
      "epoch": 5.344,
      "grad_norm": 2.2242915630340576,
      "learning_rate": 2.375714285714286e-05,
      "loss": 0.116,
      "step": 13360
    },
    {
      "epoch": 5.348,
      "grad_norm": 1.8457963466644287,
      "learning_rate": 2.373673469387755e-05,
      "loss": 0.075,
      "step": 13370
    },
    {
      "epoch": 5.352,
      "grad_norm": 0.19729836285114288,
      "learning_rate": 2.3716326530612246e-05,
      "loss": 0.0545,
      "step": 13380
    },
    {
      "epoch": 5.356,
      "grad_norm": 0.49220409989356995,
      "learning_rate": 2.3695918367346938e-05,
      "loss": 0.1489,
      "step": 13390
    },
    {
      "epoch": 5.36,
      "grad_norm": 0.5579656958580017,
      "learning_rate": 2.3675510204081633e-05,
      "loss": 0.0546,
      "step": 13400
    },
    {
      "epoch": 5.364,
      "grad_norm": 0.43558037281036377,
      "learning_rate": 2.3655102040816328e-05,
      "loss": 0.0901,
      "step": 13410
    },
    {
      "epoch": 5.368,
      "grad_norm": 0.5539060235023499,
      "learning_rate": 2.363469387755102e-05,
      "loss": 0.0947,
      "step": 13420
    },
    {
      "epoch": 5.372,
      "grad_norm": 1.5597525835037231,
      "learning_rate": 2.3614285714285718e-05,
      "loss": 0.1189,
      "step": 13430
    },
    {
      "epoch": 5.376,
      "grad_norm": 0.3138890564441681,
      "learning_rate": 2.359387755102041e-05,
      "loss": 0.0944,
      "step": 13440
    },
    {
      "epoch": 5.38,
      "grad_norm": 1.1396539211273193,
      "learning_rate": 2.3573469387755104e-05,
      "loss": 0.0661,
      "step": 13450
    },
    {
      "epoch": 5.384,
      "grad_norm": 0.5844570994377136,
      "learning_rate": 2.35530612244898e-05,
      "loss": 0.115,
      "step": 13460
    },
    {
      "epoch": 5.388,
      "grad_norm": 0.6828908920288086,
      "learning_rate": 2.353265306122449e-05,
      "loss": 0.0726,
      "step": 13470
    },
    {
      "epoch": 5.392,
      "grad_norm": 0.845674455165863,
      "learning_rate": 2.3512244897959186e-05,
      "loss": 0.0452,
      "step": 13480
    },
    {
      "epoch": 5.396,
      "grad_norm": 0.23065383732318878,
      "learning_rate": 2.3491836734693877e-05,
      "loss": 0.073,
      "step": 13490
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.21990250051021576,
      "learning_rate": 2.3471428571428572e-05,
      "loss": 0.1079,
      "step": 13500
    },
    {
      "epoch": 5.404,
      "grad_norm": 0.027948178350925446,
      "learning_rate": 2.3451020408163267e-05,
      "loss": 0.0854,
      "step": 13510
    },
    {
      "epoch": 5.408,
      "grad_norm": 1.386747121810913,
      "learning_rate": 2.343061224489796e-05,
      "loss": 0.068,
      "step": 13520
    },
    {
      "epoch": 5.412,
      "grad_norm": 1.225199818611145,
      "learning_rate": 2.3410204081632654e-05,
      "loss": 0.0881,
      "step": 13530
    },
    {
      "epoch": 5.416,
      "grad_norm": 0.5830211639404297,
      "learning_rate": 2.338979591836735e-05,
      "loss": 0.065,
      "step": 13540
    },
    {
      "epoch": 5.42,
      "grad_norm": 0.7577118277549744,
      "learning_rate": 2.3369387755102044e-05,
      "loss": 0.06,
      "step": 13550
    },
    {
      "epoch": 5.424,
      "grad_norm": 0.0780499130487442,
      "learning_rate": 2.3348979591836735e-05,
      "loss": 0.0654,
      "step": 13560
    },
    {
      "epoch": 5.428,
      "grad_norm": 1.824742078781128,
      "learning_rate": 2.332857142857143e-05,
      "loss": 0.052,
      "step": 13570
    },
    {
      "epoch": 5.432,
      "grad_norm": 1.583726167678833,
      "learning_rate": 2.3308163265306125e-05,
      "loss": 0.0653,
      "step": 13580
    },
    {
      "epoch": 5.436,
      "grad_norm": 0.848233163356781,
      "learning_rate": 2.3287755102040817e-05,
      "loss": 0.1017,
      "step": 13590
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.6282587647438049,
      "learning_rate": 2.3267346938775512e-05,
      "loss": 0.1144,
      "step": 13600
    },
    {
      "epoch": 5.444,
      "grad_norm": 0.9428195953369141,
      "learning_rate": 2.3246938775510203e-05,
      "loss": 0.0993,
      "step": 13610
    },
    {
      "epoch": 5.448,
      "grad_norm": 1.277175784111023,
      "learning_rate": 2.32265306122449e-05,
      "loss": 0.0571,
      "step": 13620
    },
    {
      "epoch": 5.452,
      "grad_norm": 1.393082618713379,
      "learning_rate": 2.3206122448979593e-05,
      "loss": 0.0882,
      "step": 13630
    },
    {
      "epoch": 5.456,
      "grad_norm": 0.3942825496196747,
      "learning_rate": 2.3185714285714285e-05,
      "loss": 0.0588,
      "step": 13640
    },
    {
      "epoch": 5.46,
      "grad_norm": 2.23673939704895,
      "learning_rate": 2.3165306122448983e-05,
      "loss": 0.0716,
      "step": 13650
    },
    {
      "epoch": 5.464,
      "grad_norm": 0.01363306399434805,
      "learning_rate": 2.3144897959183675e-05,
      "loss": 0.0762,
      "step": 13660
    },
    {
      "epoch": 5.468,
      "grad_norm": 0.4424305856227875,
      "learning_rate": 2.312448979591837e-05,
      "loss": 0.1144,
      "step": 13670
    },
    {
      "epoch": 5.4719999999999995,
      "grad_norm": 0.5841851234436035,
      "learning_rate": 2.310408163265306e-05,
      "loss": 0.0525,
      "step": 13680
    },
    {
      "epoch": 5.476,
      "grad_norm": 1.0629807710647583,
      "learning_rate": 2.3083673469387756e-05,
      "loss": 0.0958,
      "step": 13690
    },
    {
      "epoch": 5.48,
      "grad_norm": 1.0578577518463135,
      "learning_rate": 2.306326530612245e-05,
      "loss": 0.0514,
      "step": 13700
    },
    {
      "epoch": 5.484,
      "grad_norm": 0.1857578605413437,
      "learning_rate": 2.3042857142857143e-05,
      "loss": 0.0436,
      "step": 13710
    },
    {
      "epoch": 5.4879999999999995,
      "grad_norm": 0.7807029485702515,
      "learning_rate": 2.3022448979591838e-05,
      "loss": 0.0289,
      "step": 13720
    },
    {
      "epoch": 5.492,
      "grad_norm": 1.396764874458313,
      "learning_rate": 2.300204081632653e-05,
      "loss": 0.0856,
      "step": 13730
    },
    {
      "epoch": 5.496,
      "grad_norm": 0.9215884804725647,
      "learning_rate": 2.2981632653061224e-05,
      "loss": 0.0753,
      "step": 13740
    },
    {
      "epoch": 5.5,
      "grad_norm": 1.2858991622924805,
      "learning_rate": 2.296122448979592e-05,
      "loss": 0.1426,
      "step": 13750
    },
    {
      "epoch": 5.504,
      "grad_norm": 0.910280168056488,
      "learning_rate": 2.294081632653061e-05,
      "loss": 0.0556,
      "step": 13760
    },
    {
      "epoch": 5.508,
      "grad_norm": 0.7183061838150024,
      "learning_rate": 2.292040816326531e-05,
      "loss": 0.0755,
      "step": 13770
    },
    {
      "epoch": 5.5120000000000005,
      "grad_norm": 1.2633769512176514,
      "learning_rate": 2.29e-05,
      "loss": 0.0981,
      "step": 13780
    },
    {
      "epoch": 5.516,
      "grad_norm": 1.1922109127044678,
      "learning_rate": 2.2879591836734696e-05,
      "loss": 0.054,
      "step": 13790
    },
    {
      "epoch": 5.52,
      "grad_norm": 1.7440829277038574,
      "learning_rate": 2.285918367346939e-05,
      "loss": 0.0795,
      "step": 13800
    },
    {
      "epoch": 5.524,
      "grad_norm": 0.029153941199183464,
      "learning_rate": 2.2838775510204083e-05,
      "loss": 0.0494,
      "step": 13810
    },
    {
      "epoch": 5.5280000000000005,
      "grad_norm": 0.13454395532608032,
      "learning_rate": 2.2818367346938777e-05,
      "loss": 0.087,
      "step": 13820
    },
    {
      "epoch": 5.532,
      "grad_norm": 1.2097002267837524,
      "learning_rate": 2.279795918367347e-05,
      "loss": 0.0846,
      "step": 13830
    },
    {
      "epoch": 5.536,
      "grad_norm": 0.5650001168251038,
      "learning_rate": 2.2777551020408164e-05,
      "loss": 0.0542,
      "step": 13840
    },
    {
      "epoch": 5.54,
      "grad_norm": 0.1693972796201706,
      "learning_rate": 2.275714285714286e-05,
      "loss": 0.0641,
      "step": 13850
    },
    {
      "epoch": 5.5440000000000005,
      "grad_norm": 0.12166562676429749,
      "learning_rate": 2.273673469387755e-05,
      "loss": 0.055,
      "step": 13860
    },
    {
      "epoch": 5.548,
      "grad_norm": 0.6477595567703247,
      "learning_rate": 2.2716326530612246e-05,
      "loss": 0.0744,
      "step": 13870
    },
    {
      "epoch": 5.552,
      "grad_norm": 0.8325310349464417,
      "learning_rate": 2.269591836734694e-05,
      "loss": 0.047,
      "step": 13880
    },
    {
      "epoch": 5.556,
      "grad_norm": 1.1013777256011963,
      "learning_rate": 2.2675510204081636e-05,
      "loss": 0.0731,
      "step": 13890
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 1.6733345985412598,
      "learning_rate": 2.2655102040816327e-05,
      "loss": 0.0839,
      "step": 13900
    },
    {
      "epoch": 5.564,
      "grad_norm": 1.7460432052612305,
      "learning_rate": 2.2634693877551022e-05,
      "loss": 0.0616,
      "step": 13910
    },
    {
      "epoch": 5.568,
      "grad_norm": 0.4091512858867645,
      "learning_rate": 2.2614285714285717e-05,
      "loss": 0.0906,
      "step": 13920
    },
    {
      "epoch": 5.572,
      "grad_norm": 0.6491496562957764,
      "learning_rate": 2.259387755102041e-05,
      "loss": 0.0585,
      "step": 13930
    },
    {
      "epoch": 5.576,
      "grad_norm": 0.8484850525856018,
      "learning_rate": 2.2573469387755104e-05,
      "loss": 0.0699,
      "step": 13940
    },
    {
      "epoch": 5.58,
      "grad_norm": 0.1441420614719391,
      "learning_rate": 2.2553061224489795e-05,
      "loss": 0.0674,
      "step": 13950
    },
    {
      "epoch": 5.584,
      "grad_norm": 0.6110661625862122,
      "learning_rate": 2.253265306122449e-05,
      "loss": 0.0965,
      "step": 13960
    },
    {
      "epoch": 5.588,
      "grad_norm": 0.6907268762588501,
      "learning_rate": 2.2512244897959185e-05,
      "loss": 0.0616,
      "step": 13970
    },
    {
      "epoch": 5.592,
      "grad_norm": 0.14662609994411469,
      "learning_rate": 2.2491836734693877e-05,
      "loss": 0.0871,
      "step": 13980
    },
    {
      "epoch": 5.596,
      "grad_norm": 1.2493646144866943,
      "learning_rate": 2.2471428571428575e-05,
      "loss": 0.0758,
      "step": 13990
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.273093581199646,
      "learning_rate": 2.2451020408163267e-05,
      "loss": 0.1017,
      "step": 14000
    },
    {
      "epoch": 5.604,
      "grad_norm": 0.04343237355351448,
      "learning_rate": 2.243061224489796e-05,
      "loss": 0.0723,
      "step": 14010
    },
    {
      "epoch": 5.608,
      "grad_norm": 0.7935029864311218,
      "learning_rate": 2.2410204081632653e-05,
      "loss": 0.0763,
      "step": 14020
    },
    {
      "epoch": 5.612,
      "grad_norm": 0.946847677230835,
      "learning_rate": 2.2389795918367348e-05,
      "loss": 0.105,
      "step": 14030
    },
    {
      "epoch": 5.616,
      "grad_norm": 0.15923447906970978,
      "learning_rate": 2.2369387755102043e-05,
      "loss": 0.0632,
      "step": 14040
    },
    {
      "epoch": 5.62,
      "grad_norm": 1.0797961950302124,
      "learning_rate": 2.2348979591836735e-05,
      "loss": 0.0659,
      "step": 14050
    },
    {
      "epoch": 5.624,
      "grad_norm": 0.7445871233940125,
      "learning_rate": 2.232857142857143e-05,
      "loss": 0.1312,
      "step": 14060
    },
    {
      "epoch": 5.628,
      "grad_norm": 1.1400741338729858,
      "learning_rate": 2.230816326530612e-05,
      "loss": 0.0604,
      "step": 14070
    },
    {
      "epoch": 5.632,
      "grad_norm": 0.9599456191062927,
      "learning_rate": 2.2287755102040816e-05,
      "loss": 0.0667,
      "step": 14080
    },
    {
      "epoch": 5.636,
      "grad_norm": 0.26648852229118347,
      "learning_rate": 2.226734693877551e-05,
      "loss": 0.0491,
      "step": 14090
    },
    {
      "epoch": 5.64,
      "grad_norm": 1.9395325183868408,
      "learning_rate": 2.2246938775510203e-05,
      "loss": 0.0988,
      "step": 14100
    },
    {
      "epoch": 5.644,
      "grad_norm": 1.499887228012085,
      "learning_rate": 2.22265306122449e-05,
      "loss": 0.062,
      "step": 14110
    },
    {
      "epoch": 5.648,
      "grad_norm": 0.6217057108879089,
      "learning_rate": 2.2206122448979593e-05,
      "loss": 0.0521,
      "step": 14120
    },
    {
      "epoch": 5.652,
      "grad_norm": 0.8084392547607422,
      "learning_rate": 2.2185714285714288e-05,
      "loss": 0.0423,
      "step": 14130
    },
    {
      "epoch": 5.656,
      "grad_norm": 1.6897540092468262,
      "learning_rate": 2.2165306122448983e-05,
      "loss": 0.0722,
      "step": 14140
    },
    {
      "epoch": 5.66,
      "grad_norm": 1.5283745527267456,
      "learning_rate": 2.2144897959183674e-05,
      "loss": 0.0745,
      "step": 14150
    },
    {
      "epoch": 5.664,
      "grad_norm": 1.6778172254562378,
      "learning_rate": 2.212448979591837e-05,
      "loss": 0.1123,
      "step": 14160
    },
    {
      "epoch": 5.668,
      "grad_norm": 0.47278258204460144,
      "learning_rate": 2.210408163265306e-05,
      "loss": 0.0766,
      "step": 14170
    },
    {
      "epoch": 5.672,
      "grad_norm": 0.607611894607544,
      "learning_rate": 2.2083673469387756e-05,
      "loss": 0.0711,
      "step": 14180
    },
    {
      "epoch": 5.676,
      "grad_norm": 0.5756652355194092,
      "learning_rate": 2.206326530612245e-05,
      "loss": 0.0658,
      "step": 14190
    },
    {
      "epoch": 5.68,
      "grad_norm": 1.1076425313949585,
      "learning_rate": 2.2042857142857142e-05,
      "loss": 0.0738,
      "step": 14200
    },
    {
      "epoch": 5.684,
      "grad_norm": 1.1828553676605225,
      "learning_rate": 2.2022448979591837e-05,
      "loss": 0.0499,
      "step": 14210
    },
    {
      "epoch": 5.688,
      "grad_norm": 0.023918401449918747,
      "learning_rate": 2.2002040816326532e-05,
      "loss": 0.0747,
      "step": 14220
    },
    {
      "epoch": 5.692,
      "grad_norm": 1.0210262537002563,
      "learning_rate": 2.1981632653061227e-05,
      "loss": 0.0905,
      "step": 14230
    },
    {
      "epoch": 5.696,
      "grad_norm": 0.2271435409784317,
      "learning_rate": 2.196122448979592e-05,
      "loss": 0.0971,
      "step": 14240
    },
    {
      "epoch": 5.7,
      "grad_norm": 1.2527427673339844,
      "learning_rate": 2.1940816326530614e-05,
      "loss": 0.0934,
      "step": 14250
    },
    {
      "epoch": 5.704,
      "grad_norm": 0.5461322665214539,
      "learning_rate": 2.192040816326531e-05,
      "loss": 0.0577,
      "step": 14260
    },
    {
      "epoch": 5.708,
      "grad_norm": 0.41771742701530457,
      "learning_rate": 2.19e-05,
      "loss": 0.1049,
      "step": 14270
    },
    {
      "epoch": 5.712,
      "grad_norm": 0.4807196259498596,
      "learning_rate": 2.1879591836734695e-05,
      "loss": 0.0966,
      "step": 14280
    },
    {
      "epoch": 5.716,
      "grad_norm": 0.4544053077697754,
      "learning_rate": 2.1859183673469387e-05,
      "loss": 0.0884,
      "step": 14290
    },
    {
      "epoch": 5.72,
      "grad_norm": 1.0478557348251343,
      "learning_rate": 2.1838775510204082e-05,
      "loss": 0.0889,
      "step": 14300
    },
    {
      "epoch": 5.724,
      "grad_norm": 0.15373794734477997,
      "learning_rate": 2.1818367346938777e-05,
      "loss": 0.0532,
      "step": 14310
    },
    {
      "epoch": 5.728,
      "grad_norm": 0.14668406546115875,
      "learning_rate": 2.179795918367347e-05,
      "loss": 0.0597,
      "step": 14320
    },
    {
      "epoch": 5.732,
      "grad_norm": 0.5330999493598938,
      "learning_rate": 2.1777551020408167e-05,
      "loss": 0.0758,
      "step": 14330
    },
    {
      "epoch": 5.736,
      "grad_norm": 0.9071352481842041,
      "learning_rate": 2.175714285714286e-05,
      "loss": 0.1004,
      "step": 14340
    },
    {
      "epoch": 5.74,
      "grad_norm": 0.10532268136739731,
      "learning_rate": 2.1736734693877553e-05,
      "loss": 0.0816,
      "step": 14350
    },
    {
      "epoch": 5.744,
      "grad_norm": 1.0308327674865723,
      "learning_rate": 2.1716326530612245e-05,
      "loss": 0.1018,
      "step": 14360
    },
    {
      "epoch": 5.748,
      "grad_norm": 0.14553119242191315,
      "learning_rate": 2.169591836734694e-05,
      "loss": 0.0783,
      "step": 14370
    },
    {
      "epoch": 5.752,
      "grad_norm": 1.3207781314849854,
      "learning_rate": 2.1675510204081635e-05,
      "loss": 0.0786,
      "step": 14380
    },
    {
      "epoch": 5.756,
      "grad_norm": 0.20977169275283813,
      "learning_rate": 2.1655102040816326e-05,
      "loss": 0.0766,
      "step": 14390
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.6033576726913452,
      "learning_rate": 2.163469387755102e-05,
      "loss": 0.0951,
      "step": 14400
    },
    {
      "epoch": 5.764,
      "grad_norm": 0.27500680088996887,
      "learning_rate": 2.1614285714285713e-05,
      "loss": 0.07,
      "step": 14410
    },
    {
      "epoch": 5.768,
      "grad_norm": 0.6089083552360535,
      "learning_rate": 2.1593877551020408e-05,
      "loss": 0.0649,
      "step": 14420
    },
    {
      "epoch": 5.772,
      "grad_norm": 0.7544212937355042,
      "learning_rate": 2.1573469387755103e-05,
      "loss": 0.0777,
      "step": 14430
    },
    {
      "epoch": 5.776,
      "grad_norm": 0.21188472211360931,
      "learning_rate": 2.1553061224489795e-05,
      "loss": 0.09,
      "step": 14440
    },
    {
      "epoch": 5.78,
      "grad_norm": 1.8347241878509521,
      "learning_rate": 2.1532653061224493e-05,
      "loss": 0.0521,
      "step": 14450
    },
    {
      "epoch": 5.784,
      "grad_norm": 0.8797463178634644,
      "learning_rate": 2.1512244897959185e-05,
      "loss": 0.095,
      "step": 14460
    },
    {
      "epoch": 5.788,
      "grad_norm": 0.95091712474823,
      "learning_rate": 2.149183673469388e-05,
      "loss": 0.034,
      "step": 14470
    },
    {
      "epoch": 5.792,
      "grad_norm": 0.06434225291013718,
      "learning_rate": 2.1471428571428574e-05,
      "loss": 0.0796,
      "step": 14480
    },
    {
      "epoch": 5.796,
      "grad_norm": 0.29859548807144165,
      "learning_rate": 2.1451020408163266e-05,
      "loss": 0.078,
      "step": 14490
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.6455893516540527,
      "learning_rate": 2.143061224489796e-05,
      "loss": 0.0462,
      "step": 14500
    },
    {
      "epoch": 5.804,
      "grad_norm": 0.9109851121902466,
      "learning_rate": 2.1410204081632653e-05,
      "loss": 0.0694,
      "step": 14510
    },
    {
      "epoch": 5.808,
      "grad_norm": 0.11808023601770401,
      "learning_rate": 2.1389795918367348e-05,
      "loss": 0.0511,
      "step": 14520
    },
    {
      "epoch": 5.812,
      "grad_norm": 1.7744596004486084,
      "learning_rate": 2.1369387755102043e-05,
      "loss": 0.075,
      "step": 14530
    },
    {
      "epoch": 5.816,
      "grad_norm": 0.24745093286037445,
      "learning_rate": 2.1348979591836734e-05,
      "loss": 0.0703,
      "step": 14540
    },
    {
      "epoch": 5.82,
      "grad_norm": 1.2175109386444092,
      "learning_rate": 2.132857142857143e-05,
      "loss": 0.0929,
      "step": 14550
    },
    {
      "epoch": 5.824,
      "grad_norm": 0.27502596378326416,
      "learning_rate": 2.1308163265306124e-05,
      "loss": 0.0537,
      "step": 14560
    },
    {
      "epoch": 5.828,
      "grad_norm": 1.302462100982666,
      "learning_rate": 2.128775510204082e-05,
      "loss": 0.0756,
      "step": 14570
    },
    {
      "epoch": 5.832,
      "grad_norm": 0.02028404176235199,
      "learning_rate": 2.126734693877551e-05,
      "loss": 0.0361,
      "step": 14580
    },
    {
      "epoch": 5.836,
      "grad_norm": 0.0010817328002303839,
      "learning_rate": 2.1246938775510206e-05,
      "loss": 0.0492,
      "step": 14590
    },
    {
      "epoch": 5.84,
      "grad_norm": 1.4510043859481812,
      "learning_rate": 2.12265306122449e-05,
      "loss": 0.0869,
      "step": 14600
    },
    {
      "epoch": 5.844,
      "grad_norm": 1.2476651668548584,
      "learning_rate": 2.1206122448979592e-05,
      "loss": 0.0542,
      "step": 14610
    },
    {
      "epoch": 5.848,
      "grad_norm": 1.9672210216522217,
      "learning_rate": 2.1185714285714287e-05,
      "loss": 0.0919,
      "step": 14620
    },
    {
      "epoch": 5.852,
      "grad_norm": 0.009729395620524883,
      "learning_rate": 2.116530612244898e-05,
      "loss": 0.0662,
      "step": 14630
    },
    {
      "epoch": 5.856,
      "grad_norm": 0.013156597502529621,
      "learning_rate": 2.1144897959183674e-05,
      "loss": 0.0425,
      "step": 14640
    },
    {
      "epoch": 5.86,
      "grad_norm": 0.7151854038238525,
      "learning_rate": 2.112448979591837e-05,
      "loss": 0.0653,
      "step": 14650
    },
    {
      "epoch": 5.864,
      "grad_norm": 1.867971420288086,
      "learning_rate": 2.110408163265306e-05,
      "loss": 0.1221,
      "step": 14660
    },
    {
      "epoch": 5.868,
      "grad_norm": 0.3546193242073059,
      "learning_rate": 2.108367346938776e-05,
      "loss": 0.0436,
      "step": 14670
    },
    {
      "epoch": 5.872,
      "grad_norm": 1.8379325866699219,
      "learning_rate": 2.106326530612245e-05,
      "loss": 0.0641,
      "step": 14680
    },
    {
      "epoch": 5.876,
      "grad_norm": 0.6731255054473877,
      "learning_rate": 2.1042857142857145e-05,
      "loss": 0.0807,
      "step": 14690
    },
    {
      "epoch": 5.88,
      "grad_norm": 0.47516193985939026,
      "learning_rate": 2.1022448979591837e-05,
      "loss": 0.0576,
      "step": 14700
    },
    {
      "epoch": 5.884,
      "grad_norm": 0.5490984916687012,
      "learning_rate": 2.1002040816326532e-05,
      "loss": 0.1218,
      "step": 14710
    },
    {
      "epoch": 5.888,
      "grad_norm": 1.8688527345657349,
      "learning_rate": 2.0981632653061227e-05,
      "loss": 0.0581,
      "step": 14720
    },
    {
      "epoch": 5.892,
      "grad_norm": 0.5210027694702148,
      "learning_rate": 2.0961224489795918e-05,
      "loss": 0.052,
      "step": 14730
    },
    {
      "epoch": 5.896,
      "grad_norm": 0.6926536560058594,
      "learning_rate": 2.0940816326530613e-05,
      "loss": 0.0682,
      "step": 14740
    },
    {
      "epoch": 5.9,
      "grad_norm": 1.2187377214431763,
      "learning_rate": 2.0920408163265305e-05,
      "loss": 0.0768,
      "step": 14750
    },
    {
      "epoch": 5.904,
      "grad_norm": 1.3541430234909058,
      "learning_rate": 2.09e-05,
      "loss": 0.0724,
      "step": 14760
    },
    {
      "epoch": 5.908,
      "grad_norm": 1.8090885877609253,
      "learning_rate": 2.0879591836734695e-05,
      "loss": 0.1135,
      "step": 14770
    },
    {
      "epoch": 5.912,
      "grad_norm": 0.3386681079864502,
      "learning_rate": 2.0859183673469386e-05,
      "loss": 0.0659,
      "step": 14780
    },
    {
      "epoch": 5.916,
      "grad_norm": 0.9196505546569824,
      "learning_rate": 2.0838775510204085e-05,
      "loss": 0.0406,
      "step": 14790
    },
    {
      "epoch": 5.92,
      "grad_norm": 0.06024041771888733,
      "learning_rate": 2.0818367346938776e-05,
      "loss": 0.0828,
      "step": 14800
    },
    {
      "epoch": 5.924,
      "grad_norm": 1.459839940071106,
      "learning_rate": 2.079795918367347e-05,
      "loss": 0.1136,
      "step": 14810
    },
    {
      "epoch": 5.928,
      "grad_norm": 1.3262395858764648,
      "learning_rate": 2.0777551020408166e-05,
      "loss": 0.1022,
      "step": 14820
    },
    {
      "epoch": 5.932,
      "grad_norm": 0.8889086842536926,
      "learning_rate": 2.0757142857142858e-05,
      "loss": 0.0558,
      "step": 14830
    },
    {
      "epoch": 5.936,
      "grad_norm": 1.2499923706054688,
      "learning_rate": 2.0736734693877553e-05,
      "loss": 0.0559,
      "step": 14840
    },
    {
      "epoch": 5.9399999999999995,
      "grad_norm": 0.4566193222999573,
      "learning_rate": 2.0716326530612244e-05,
      "loss": 0.0683,
      "step": 14850
    },
    {
      "epoch": 5.944,
      "grad_norm": 0.877353847026825,
      "learning_rate": 2.069591836734694e-05,
      "loss": 0.0393,
      "step": 14860
    },
    {
      "epoch": 5.948,
      "grad_norm": 0.5905510187149048,
      "learning_rate": 2.0675510204081634e-05,
      "loss": 0.1006,
      "step": 14870
    },
    {
      "epoch": 5.952,
      "grad_norm": 0.8272134065628052,
      "learning_rate": 2.0655102040816326e-05,
      "loss": 0.0924,
      "step": 14880
    },
    {
      "epoch": 5.9559999999999995,
      "grad_norm": 0.6200165748596191,
      "learning_rate": 2.063469387755102e-05,
      "loss": 0.0502,
      "step": 14890
    },
    {
      "epoch": 5.96,
      "grad_norm": 1.4211022853851318,
      "learning_rate": 2.0614285714285716e-05,
      "loss": 0.0527,
      "step": 14900
    },
    {
      "epoch": 5.964,
      "grad_norm": 0.9802246689796448,
      "learning_rate": 2.059387755102041e-05,
      "loss": 0.0903,
      "step": 14910
    },
    {
      "epoch": 5.968,
      "grad_norm": 0.8468841910362244,
      "learning_rate": 2.0573469387755102e-05,
      "loss": 0.049,
      "step": 14920
    },
    {
      "epoch": 5.9719999999999995,
      "grad_norm": 0.9281829595565796,
      "learning_rate": 2.0553061224489797e-05,
      "loss": 0.0391,
      "step": 14930
    },
    {
      "epoch": 5.976,
      "grad_norm": 0.30634596943855286,
      "learning_rate": 2.0532653061224492e-05,
      "loss": 0.0609,
      "step": 14940
    },
    {
      "epoch": 5.98,
      "grad_norm": 0.21401984989643097,
      "learning_rate": 2.0512244897959184e-05,
      "loss": 0.0616,
      "step": 14950
    },
    {
      "epoch": 5.984,
      "grad_norm": 1.3223987817764282,
      "learning_rate": 2.049183673469388e-05,
      "loss": 0.1018,
      "step": 14960
    },
    {
      "epoch": 5.9879999999999995,
      "grad_norm": 1.6079012155532837,
      "learning_rate": 2.047142857142857e-05,
      "loss": 0.0855,
      "step": 14970
    },
    {
      "epoch": 5.992,
      "grad_norm": 1.0669939517974854,
      "learning_rate": 2.0451020408163265e-05,
      "loss": 0.0527,
      "step": 14980
    },
    {
      "epoch": 5.996,
      "grad_norm": 0.2504009008407593,
      "learning_rate": 2.043061224489796e-05,
      "loss": 0.0617,
      "step": 14990
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.7045755386352539,
      "learning_rate": 2.0410204081632652e-05,
      "loss": 0.0478,
      "step": 15000
    },
    {
      "epoch": 6.004,
      "grad_norm": 0.13260900974273682,
      "learning_rate": 2.038979591836735e-05,
      "loss": 0.0495,
      "step": 15010
    },
    {
      "epoch": 6.008,
      "grad_norm": 0.5422346591949463,
      "learning_rate": 2.0369387755102042e-05,
      "loss": 0.0978,
      "step": 15020
    },
    {
      "epoch": 6.012,
      "grad_norm": 0.7876365780830383,
      "learning_rate": 2.0348979591836737e-05,
      "loss": 0.0768,
      "step": 15030
    },
    {
      "epoch": 6.016,
      "grad_norm": 0.20011365413665771,
      "learning_rate": 2.032857142857143e-05,
      "loss": 0.0508,
      "step": 15040
    },
    {
      "epoch": 6.02,
      "grad_norm": 1.0121797323226929,
      "learning_rate": 2.0308163265306123e-05,
      "loss": 0.0626,
      "step": 15050
    },
    {
      "epoch": 6.024,
      "grad_norm": 0.6849403977394104,
      "learning_rate": 2.028775510204082e-05,
      "loss": 0.0616,
      "step": 15060
    },
    {
      "epoch": 6.028,
      "grad_norm": 0.4065665602684021,
      "learning_rate": 2.026734693877551e-05,
      "loss": 0.0724,
      "step": 15070
    },
    {
      "epoch": 6.032,
      "grad_norm": 0.20351587235927582,
      "learning_rate": 2.0246938775510205e-05,
      "loss": 0.0628,
      "step": 15080
    },
    {
      "epoch": 6.036,
      "grad_norm": 0.4009605348110199,
      "learning_rate": 2.02265306122449e-05,
      "loss": 0.1167,
      "step": 15090
    },
    {
      "epoch": 6.04,
      "grad_norm": 1.2558205127716064,
      "learning_rate": 2.020612244897959e-05,
      "loss": 0.0632,
      "step": 15100
    },
    {
      "epoch": 6.044,
      "grad_norm": 0.15500080585479736,
      "learning_rate": 2.0185714285714287e-05,
      "loss": 0.0569,
      "step": 15110
    },
    {
      "epoch": 6.048,
      "grad_norm": 0.48580652475357056,
      "learning_rate": 2.0165306122448978e-05,
      "loss": 0.0861,
      "step": 15120
    },
    {
      "epoch": 6.052,
      "grad_norm": 0.24734148383140564,
      "learning_rate": 2.0144897959183676e-05,
      "loss": 0.0434,
      "step": 15130
    },
    {
      "epoch": 6.056,
      "grad_norm": 0.5729501247406006,
      "learning_rate": 2.0124489795918368e-05,
      "loss": 0.0301,
      "step": 15140
    },
    {
      "epoch": 6.06,
      "grad_norm": 0.1252226084470749,
      "learning_rate": 2.0104081632653063e-05,
      "loss": 0.0917,
      "step": 15150
    },
    {
      "epoch": 6.064,
      "grad_norm": 0.6772736310958862,
      "learning_rate": 2.0083673469387758e-05,
      "loss": 0.0333,
      "step": 15160
    },
    {
      "epoch": 6.068,
      "grad_norm": 0.15541863441467285,
      "learning_rate": 2.006326530612245e-05,
      "loss": 0.0569,
      "step": 15170
    },
    {
      "epoch": 6.072,
      "grad_norm": 0.4494806230068207,
      "learning_rate": 2.0042857142857145e-05,
      "loss": 0.0804,
      "step": 15180
    },
    {
      "epoch": 6.076,
      "grad_norm": 0.37593719363212585,
      "learning_rate": 2.0022448979591836e-05,
      "loss": 0.0912,
      "step": 15190
    },
    {
      "epoch": 6.08,
      "grad_norm": 0.26122865080833435,
      "learning_rate": 2.000204081632653e-05,
      "loss": 0.0654,
      "step": 15200
    },
    {
      "epoch": 6.084,
      "grad_norm": 0.6962641477584839,
      "learning_rate": 1.9981632653061226e-05,
      "loss": 0.0579,
      "step": 15210
    },
    {
      "epoch": 6.088,
      "grad_norm": 0.6933239102363586,
      "learning_rate": 1.9961224489795918e-05,
      "loss": 0.0797,
      "step": 15220
    },
    {
      "epoch": 6.092,
      "grad_norm": 0.7093692421913147,
      "learning_rate": 1.9940816326530613e-05,
      "loss": 0.0757,
      "step": 15230
    },
    {
      "epoch": 6.096,
      "grad_norm": 0.9874966144561768,
      "learning_rate": 1.9920408163265308e-05,
      "loss": 0.0534,
      "step": 15240
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.2979360520839691,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.035,
      "step": 15250
    },
    {
      "epoch": 6.104,
      "grad_norm": 0.14714276790618896,
      "learning_rate": 1.9879591836734694e-05,
      "loss": 0.0446,
      "step": 15260
    },
    {
      "epoch": 6.108,
      "grad_norm": 0.4602350890636444,
      "learning_rate": 1.985918367346939e-05,
      "loss": 0.0684,
      "step": 15270
    },
    {
      "epoch": 6.112,
      "grad_norm": 1.3661264181137085,
      "learning_rate": 1.9838775510204084e-05,
      "loss": 0.0671,
      "step": 15280
    },
    {
      "epoch": 6.116,
      "grad_norm": 0.5349635481834412,
      "learning_rate": 1.9818367346938776e-05,
      "loss": 0.0351,
      "step": 15290
    },
    {
      "epoch": 6.12,
      "grad_norm": 0.8755946755409241,
      "learning_rate": 1.979795918367347e-05,
      "loss": 0.0429,
      "step": 15300
    },
    {
      "epoch": 6.124,
      "grad_norm": 0.9230324029922485,
      "learning_rate": 1.9777551020408162e-05,
      "loss": 0.0737,
      "step": 15310
    },
    {
      "epoch": 6.128,
      "grad_norm": 0.2199312448501587,
      "learning_rate": 1.9757142857142857e-05,
      "loss": 0.0429,
      "step": 15320
    },
    {
      "epoch": 6.132,
      "grad_norm": 1.0630676746368408,
      "learning_rate": 1.9736734693877552e-05,
      "loss": 0.0552,
      "step": 15330
    },
    {
      "epoch": 6.136,
      "grad_norm": 0.11876527965068817,
      "learning_rate": 1.9716326530612244e-05,
      "loss": 0.0316,
      "step": 15340
    },
    {
      "epoch": 6.14,
      "grad_norm": 0.09895895421504974,
      "learning_rate": 1.9695918367346942e-05,
      "loss": 0.0588,
      "step": 15350
    },
    {
      "epoch": 6.144,
      "grad_norm": 0.5465205311775208,
      "learning_rate": 1.9675510204081634e-05,
      "loss": 0.0613,
      "step": 15360
    },
    {
      "epoch": 6.148,
      "grad_norm": 0.6208755373954773,
      "learning_rate": 1.965510204081633e-05,
      "loss": 0.0652,
      "step": 15370
    },
    {
      "epoch": 6.152,
      "grad_norm": 1.8000189065933228,
      "learning_rate": 1.963469387755102e-05,
      "loss": 0.0885,
      "step": 15380
    },
    {
      "epoch": 6.156,
      "grad_norm": 0.29525867104530334,
      "learning_rate": 1.9614285714285715e-05,
      "loss": 0.0595,
      "step": 15390
    },
    {
      "epoch": 6.16,
      "grad_norm": 1.1276158094406128,
      "learning_rate": 1.959387755102041e-05,
      "loss": 0.0667,
      "step": 15400
    },
    {
      "epoch": 6.164,
      "grad_norm": 0.8552778363227844,
      "learning_rate": 1.9573469387755102e-05,
      "loss": 0.0423,
      "step": 15410
    },
    {
      "epoch": 6.168,
      "grad_norm": 1.897166132926941,
      "learning_rate": 1.9553061224489797e-05,
      "loss": 0.0826,
      "step": 15420
    },
    {
      "epoch": 6.172,
      "grad_norm": 1.507922887802124,
      "learning_rate": 1.9532653061224492e-05,
      "loss": 0.1112,
      "step": 15430
    },
    {
      "epoch": 6.176,
      "grad_norm": 1.024753212928772,
      "learning_rate": 1.9512244897959183e-05,
      "loss": 0.0561,
      "step": 15440
    },
    {
      "epoch": 6.18,
      "grad_norm": 0.1957084834575653,
      "learning_rate": 1.949183673469388e-05,
      "loss": 0.0689,
      "step": 15450
    },
    {
      "epoch": 6.184,
      "grad_norm": 0.6480629444122314,
      "learning_rate": 1.947142857142857e-05,
      "loss": 0.0579,
      "step": 15460
    },
    {
      "epoch": 6.188,
      "grad_norm": 0.2071504294872284,
      "learning_rate": 1.9451020408163268e-05,
      "loss": 0.03,
      "step": 15470
    },
    {
      "epoch": 6.192,
      "grad_norm": 0.25157272815704346,
      "learning_rate": 1.943061224489796e-05,
      "loss": 0.0894,
      "step": 15480
    },
    {
      "epoch": 6.196,
      "grad_norm": 0.8878388404846191,
      "learning_rate": 1.9410204081632655e-05,
      "loss": 0.0477,
      "step": 15490
    },
    {
      "epoch": 6.2,
      "grad_norm": 1.438260555267334,
      "learning_rate": 1.938979591836735e-05,
      "loss": 0.0474,
      "step": 15500
    },
    {
      "epoch": 6.204,
      "grad_norm": 1.5022838115692139,
      "learning_rate": 1.936938775510204e-05,
      "loss": 0.1065,
      "step": 15510
    },
    {
      "epoch": 6.208,
      "grad_norm": 0.8952526450157166,
      "learning_rate": 1.9348979591836736e-05,
      "loss": 0.0358,
      "step": 15520
    },
    {
      "epoch": 6.212,
      "grad_norm": 1.6878063678741455,
      "learning_rate": 1.9328571428571428e-05,
      "loss": 0.0756,
      "step": 15530
    },
    {
      "epoch": 6.216,
      "grad_norm": 0.6959004998207092,
      "learning_rate": 1.9308163265306123e-05,
      "loss": 0.0919,
      "step": 15540
    },
    {
      "epoch": 6.22,
      "grad_norm": 0.2278425097465515,
      "learning_rate": 1.9287755102040818e-05,
      "loss": 0.0442,
      "step": 15550
    },
    {
      "epoch": 6.224,
      "grad_norm": 1.3440181016921997,
      "learning_rate": 1.926734693877551e-05,
      "loss": 0.111,
      "step": 15560
    },
    {
      "epoch": 6.228,
      "grad_norm": 0.06586053222417831,
      "learning_rate": 1.9246938775510204e-05,
      "loss": 0.0776,
      "step": 15570
    },
    {
      "epoch": 6.232,
      "grad_norm": 1.1693447828292847,
      "learning_rate": 1.92265306122449e-05,
      "loss": 0.132,
      "step": 15580
    },
    {
      "epoch": 6.236,
      "grad_norm": 1.5028988122940063,
      "learning_rate": 1.9206122448979594e-05,
      "loss": 0.0552,
      "step": 15590
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.4603182375431061,
      "learning_rate": 1.9185714285714286e-05,
      "loss": 0.0439,
      "step": 15600
    },
    {
      "epoch": 6.244,
      "grad_norm": 1.107634425163269,
      "learning_rate": 1.916530612244898e-05,
      "loss": 0.071,
      "step": 15610
    },
    {
      "epoch": 6.248,
      "grad_norm": 1.451629877090454,
      "learning_rate": 1.9144897959183676e-05,
      "loss": 0.0639,
      "step": 15620
    },
    {
      "epoch": 6.252,
      "grad_norm": 0.6566123366355896,
      "learning_rate": 1.9124489795918367e-05,
      "loss": 0.095,
      "step": 15630
    },
    {
      "epoch": 6.256,
      "grad_norm": 0.9151973724365234,
      "learning_rate": 1.9104081632653062e-05,
      "loss": 0.0777,
      "step": 15640
    },
    {
      "epoch": 6.26,
      "grad_norm": 0.42811012268066406,
      "learning_rate": 1.9083673469387754e-05,
      "loss": 0.0343,
      "step": 15650
    },
    {
      "epoch": 6.264,
      "grad_norm": 1.1210588216781616,
      "learning_rate": 1.906326530612245e-05,
      "loss": 0.0663,
      "step": 15660
    },
    {
      "epoch": 6.268,
      "grad_norm": 0.17892977595329285,
      "learning_rate": 1.9042857142857144e-05,
      "loss": 0.0596,
      "step": 15670
    },
    {
      "epoch": 6.272,
      "grad_norm": 0.9621158838272095,
      "learning_rate": 1.9022448979591836e-05,
      "loss": 0.0716,
      "step": 15680
    },
    {
      "epoch": 6.276,
      "grad_norm": 1.135094404220581,
      "learning_rate": 1.9002040816326534e-05,
      "loss": 0.0602,
      "step": 15690
    },
    {
      "epoch": 6.28,
      "grad_norm": 0.5394893884658813,
      "learning_rate": 1.8981632653061226e-05,
      "loss": 0.0429,
      "step": 15700
    },
    {
      "epoch": 6.284,
      "grad_norm": 1.5880786180496216,
      "learning_rate": 1.896122448979592e-05,
      "loss": 0.0698,
      "step": 15710
    },
    {
      "epoch": 6.288,
      "grad_norm": 0.020441146567463875,
      "learning_rate": 1.8940816326530615e-05,
      "loss": 0.0201,
      "step": 15720
    },
    {
      "epoch": 6.292,
      "grad_norm": 0.8000156879425049,
      "learning_rate": 1.8920408163265307e-05,
      "loss": 0.0471,
      "step": 15730
    },
    {
      "epoch": 6.296,
      "grad_norm": 1.1692050695419312,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 0.0544,
      "step": 15740
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.13153618574142456,
      "learning_rate": 1.8879591836734694e-05,
      "loss": 0.0575,
      "step": 15750
    },
    {
      "epoch": 6.304,
      "grad_norm": 0.7559410333633423,
      "learning_rate": 1.885918367346939e-05,
      "loss": 0.0397,
      "step": 15760
    },
    {
      "epoch": 6.308,
      "grad_norm": 0.25717660784721375,
      "learning_rate": 1.8838775510204084e-05,
      "loss": 0.0401,
      "step": 15770
    },
    {
      "epoch": 6.312,
      "grad_norm": 0.24163997173309326,
      "learning_rate": 1.8818367346938775e-05,
      "loss": 0.0581,
      "step": 15780
    },
    {
      "epoch": 6.316,
      "grad_norm": 0.5005314946174622,
      "learning_rate": 1.879795918367347e-05,
      "loss": 0.0647,
      "step": 15790
    },
    {
      "epoch": 6.32,
      "grad_norm": 1.4893182516098022,
      "learning_rate": 1.877755102040816e-05,
      "loss": 0.0595,
      "step": 15800
    },
    {
      "epoch": 6.324,
      "grad_norm": 0.9159075021743774,
      "learning_rate": 1.875714285714286e-05,
      "loss": 0.0851,
      "step": 15810
    },
    {
      "epoch": 6.328,
      "grad_norm": 1.64412260055542,
      "learning_rate": 1.873673469387755e-05,
      "loss": 0.0803,
      "step": 15820
    },
    {
      "epoch": 6.332,
      "grad_norm": 0.8057374954223633,
      "learning_rate": 1.8716326530612247e-05,
      "loss": 0.0244,
      "step": 15830
    },
    {
      "epoch": 6.336,
      "grad_norm": 0.08420129120349884,
      "learning_rate": 1.869591836734694e-05,
      "loss": 0.1178,
      "step": 15840
    },
    {
      "epoch": 6.34,
      "grad_norm": 0.47229132056236267,
      "learning_rate": 1.8675510204081633e-05,
      "loss": 0.1259,
      "step": 15850
    },
    {
      "epoch": 6.344,
      "grad_norm": 0.40473854541778564,
      "learning_rate": 1.8655102040816328e-05,
      "loss": 0.0859,
      "step": 15860
    },
    {
      "epoch": 6.348,
      "grad_norm": 0.01456426177173853,
      "learning_rate": 1.863469387755102e-05,
      "loss": 0.0578,
      "step": 15870
    },
    {
      "epoch": 6.352,
      "grad_norm": 1.2262482643127441,
      "learning_rate": 1.8614285714285715e-05,
      "loss": 0.0543,
      "step": 15880
    },
    {
      "epoch": 6.356,
      "grad_norm": 0.6181187629699707,
      "learning_rate": 1.859387755102041e-05,
      "loss": 0.0795,
      "step": 15890
    },
    {
      "epoch": 6.36,
      "grad_norm": 0.02241590991616249,
      "learning_rate": 1.85734693877551e-05,
      "loss": 0.0623,
      "step": 15900
    },
    {
      "epoch": 6.364,
      "grad_norm": 1.4075207710266113,
      "learning_rate": 1.8553061224489796e-05,
      "loss": 0.053,
      "step": 15910
    },
    {
      "epoch": 6.368,
      "grad_norm": 0.6658626198768616,
      "learning_rate": 1.853265306122449e-05,
      "loss": 0.0796,
      "step": 15920
    },
    {
      "epoch": 6.372,
      "grad_norm": 1.188917636871338,
      "learning_rate": 1.8512244897959186e-05,
      "loss": 0.0691,
      "step": 15930
    },
    {
      "epoch": 6.376,
      "grad_norm": 0.6323738098144531,
      "learning_rate": 1.8491836734693878e-05,
      "loss": 0.0612,
      "step": 15940
    },
    {
      "epoch": 6.38,
      "grad_norm": 0.988167405128479,
      "learning_rate": 1.8471428571428573e-05,
      "loss": 0.0758,
      "step": 15950
    },
    {
      "epoch": 6.384,
      "grad_norm": 0.204126238822937,
      "learning_rate": 1.8451020408163268e-05,
      "loss": 0.0589,
      "step": 15960
    },
    {
      "epoch": 6.388,
      "grad_norm": 0.0901482030749321,
      "learning_rate": 1.843061224489796e-05,
      "loss": 0.0912,
      "step": 15970
    },
    {
      "epoch": 6.392,
      "grad_norm": 0.08717256039381027,
      "learning_rate": 1.8410204081632654e-05,
      "loss": 0.0623,
      "step": 15980
    },
    {
      "epoch": 6.396,
      "grad_norm": 0.2332516610622406,
      "learning_rate": 1.8389795918367346e-05,
      "loss": 0.0479,
      "step": 15990
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.2573528289794922,
      "learning_rate": 1.836938775510204e-05,
      "loss": 0.0624,
      "step": 16000
    },
    {
      "epoch": 6.404,
      "grad_norm": 0.9802103638648987,
      "learning_rate": 1.8348979591836736e-05,
      "loss": 0.0523,
      "step": 16010
    },
    {
      "epoch": 6.408,
      "grad_norm": 0.6147437691688538,
      "learning_rate": 1.8328571428571427e-05,
      "loss": 0.0659,
      "step": 16020
    },
    {
      "epoch": 6.412,
      "grad_norm": 1.247237205505371,
      "learning_rate": 1.8308163265306126e-05,
      "loss": 0.0573,
      "step": 16030
    },
    {
      "epoch": 6.416,
      "grad_norm": 0.4383505880832672,
      "learning_rate": 1.8287755102040817e-05,
      "loss": 0.057,
      "step": 16040
    },
    {
      "epoch": 6.42,
      "grad_norm": 0.8349671959877014,
      "learning_rate": 1.8267346938775512e-05,
      "loss": 0.0711,
      "step": 16050
    },
    {
      "epoch": 6.424,
      "grad_norm": 0.535896360874176,
      "learning_rate": 1.8246938775510207e-05,
      "loss": 0.08,
      "step": 16060
    },
    {
      "epoch": 6.428,
      "grad_norm": 0.5842028856277466,
      "learning_rate": 1.82265306122449e-05,
      "loss": 0.0848,
      "step": 16070
    },
    {
      "epoch": 6.432,
      "grad_norm": 1.4652239084243774,
      "learning_rate": 1.8206122448979594e-05,
      "loss": 0.0527,
      "step": 16080
    },
    {
      "epoch": 6.436,
      "grad_norm": 0.08084587752819061,
      "learning_rate": 1.8185714285714285e-05,
      "loss": 0.0407,
      "step": 16090
    },
    {
      "epoch": 6.44,
      "grad_norm": 1.0532691478729248,
      "learning_rate": 1.816530612244898e-05,
      "loss": 0.068,
      "step": 16100
    },
    {
      "epoch": 6.444,
      "grad_norm": 0.9532360434532166,
      "learning_rate": 1.8144897959183675e-05,
      "loss": 0.067,
      "step": 16110
    },
    {
      "epoch": 6.448,
      "grad_norm": 1.8994967937469482,
      "learning_rate": 1.8124489795918367e-05,
      "loss": 0.0735,
      "step": 16120
    },
    {
      "epoch": 6.452,
      "grad_norm": 0.37844571471214294,
      "learning_rate": 1.8104081632653062e-05,
      "loss": 0.096,
      "step": 16130
    },
    {
      "epoch": 6.456,
      "grad_norm": 0.2695729732513428,
      "learning_rate": 1.8083673469387753e-05,
      "loss": 0.0759,
      "step": 16140
    },
    {
      "epoch": 6.46,
      "grad_norm": 0.45140454173088074,
      "learning_rate": 1.8063265306122452e-05,
      "loss": 0.0696,
      "step": 16150
    },
    {
      "epoch": 6.464,
      "grad_norm": 0.14197349548339844,
      "learning_rate": 1.8042857142857143e-05,
      "loss": 0.0559,
      "step": 16160
    },
    {
      "epoch": 6.468,
      "grad_norm": 1.2095670700073242,
      "learning_rate": 1.802244897959184e-05,
      "loss": 0.0551,
      "step": 16170
    },
    {
      "epoch": 6.4719999999999995,
      "grad_norm": 0.659994900226593,
      "learning_rate": 1.8002040816326533e-05,
      "loss": 0.0526,
      "step": 16180
    },
    {
      "epoch": 6.476,
      "grad_norm": 1.4824994802474976,
      "learning_rate": 1.7981632653061225e-05,
      "loss": 0.0782,
      "step": 16190
    },
    {
      "epoch": 6.48,
      "grad_norm": 0.1429920792579651,
      "learning_rate": 1.796122448979592e-05,
      "loss": 0.0831,
      "step": 16200
    },
    {
      "epoch": 6.484,
      "grad_norm": 1.5940827131271362,
      "learning_rate": 1.794081632653061e-05,
      "loss": 0.0651,
      "step": 16210
    },
    {
      "epoch": 6.4879999999999995,
      "grad_norm": 1.2799413204193115,
      "learning_rate": 1.7920408163265306e-05,
      "loss": 0.0652,
      "step": 16220
    },
    {
      "epoch": 6.492,
      "grad_norm": 0.9284815192222595,
      "learning_rate": 1.79e-05,
      "loss": 0.0615,
      "step": 16230
    },
    {
      "epoch": 6.496,
      "grad_norm": 0.7211700081825256,
      "learning_rate": 1.7879591836734693e-05,
      "loss": 0.0597,
      "step": 16240
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.2214878797531128,
      "learning_rate": 1.7859183673469388e-05,
      "loss": 0.0606,
      "step": 16250
    },
    {
      "epoch": 6.504,
      "grad_norm": 1.4006547927856445,
      "learning_rate": 1.7838775510204083e-05,
      "loss": 0.0545,
      "step": 16260
    },
    {
      "epoch": 6.508,
      "grad_norm": 0.6920960545539856,
      "learning_rate": 1.7818367346938778e-05,
      "loss": 0.0442,
      "step": 16270
    },
    {
      "epoch": 6.5120000000000005,
      "grad_norm": 1.3955137729644775,
      "learning_rate": 1.779795918367347e-05,
      "loss": 0.077,
      "step": 16280
    },
    {
      "epoch": 6.516,
      "grad_norm": 0.18446335196495056,
      "learning_rate": 1.7777551020408164e-05,
      "loss": 0.0728,
      "step": 16290
    },
    {
      "epoch": 6.52,
      "grad_norm": 1.3459391593933105,
      "learning_rate": 1.775714285714286e-05,
      "loss": 0.0435,
      "step": 16300
    },
    {
      "epoch": 6.524,
      "grad_norm": 1.4351757764816284,
      "learning_rate": 1.773673469387755e-05,
      "loss": 0.1159,
      "step": 16310
    },
    {
      "epoch": 6.5280000000000005,
      "grad_norm": 0.17884033918380737,
      "learning_rate": 1.7716326530612246e-05,
      "loss": 0.0337,
      "step": 16320
    },
    {
      "epoch": 6.532,
      "grad_norm": 0.5030068755149841,
      "learning_rate": 1.7695918367346938e-05,
      "loss": 0.043,
      "step": 16330
    },
    {
      "epoch": 6.536,
      "grad_norm": 0.03388623893260956,
      "learning_rate": 1.7675510204081633e-05,
      "loss": 0.0822,
      "step": 16340
    },
    {
      "epoch": 6.54,
      "grad_norm": 1.6474756002426147,
      "learning_rate": 1.7655102040816328e-05,
      "loss": 0.1013,
      "step": 16350
    },
    {
      "epoch": 6.5440000000000005,
      "grad_norm": 1.8016518354415894,
      "learning_rate": 1.763469387755102e-05,
      "loss": 0.0686,
      "step": 16360
    },
    {
      "epoch": 6.548,
      "grad_norm": 0.39150145649909973,
      "learning_rate": 1.7614285714285717e-05,
      "loss": 0.0782,
      "step": 16370
    },
    {
      "epoch": 6.552,
      "grad_norm": 1.8307491540908813,
      "learning_rate": 1.759387755102041e-05,
      "loss": 0.0732,
      "step": 16380
    },
    {
      "epoch": 6.556,
      "grad_norm": 0.6292104721069336,
      "learning_rate": 1.7573469387755104e-05,
      "loss": 0.0529,
      "step": 16390
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 0.5549812912940979,
      "learning_rate": 1.75530612244898e-05,
      "loss": 0.0746,
      "step": 16400
    },
    {
      "epoch": 6.564,
      "grad_norm": 0.6723839044570923,
      "learning_rate": 1.753265306122449e-05,
      "loss": 0.0556,
      "step": 16410
    },
    {
      "epoch": 6.568,
      "grad_norm": 0.5859125852584839,
      "learning_rate": 1.7512244897959186e-05,
      "loss": 0.0514,
      "step": 16420
    },
    {
      "epoch": 6.572,
      "grad_norm": 1.1425014734268188,
      "learning_rate": 1.7491836734693877e-05,
      "loss": 0.052,
      "step": 16430
    },
    {
      "epoch": 6.576,
      "grad_norm": 0.5579436421394348,
      "learning_rate": 1.7471428571428572e-05,
      "loss": 0.0656,
      "step": 16440
    },
    {
      "epoch": 6.58,
      "grad_norm": 1.3156286478042603,
      "learning_rate": 1.7451020408163267e-05,
      "loss": 0.0738,
      "step": 16450
    },
    {
      "epoch": 6.584,
      "grad_norm": 0.11990508437156677,
      "learning_rate": 1.743061224489796e-05,
      "loss": 0.0534,
      "step": 16460
    },
    {
      "epoch": 6.588,
      "grad_norm": 0.5646544098854065,
      "learning_rate": 1.7410204081632654e-05,
      "loss": 0.0497,
      "step": 16470
    },
    {
      "epoch": 6.592,
      "grad_norm": 0.9653869867324829,
      "learning_rate": 1.7389795918367345e-05,
      "loss": 0.0753,
      "step": 16480
    },
    {
      "epoch": 6.596,
      "grad_norm": 0.7981047034263611,
      "learning_rate": 1.7369387755102044e-05,
      "loss": 0.1008,
      "step": 16490
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.12834660708904266,
      "learning_rate": 1.7348979591836735e-05,
      "loss": 0.0492,
      "step": 16500
    },
    {
      "epoch": 6.604,
      "grad_norm": 0.020932113751769066,
      "learning_rate": 1.732857142857143e-05,
      "loss": 0.0567,
      "step": 16510
    },
    {
      "epoch": 6.608,
      "grad_norm": 1.1238059997558594,
      "learning_rate": 1.7308163265306125e-05,
      "loss": 0.0897,
      "step": 16520
    },
    {
      "epoch": 6.612,
      "grad_norm": 1.6044360399246216,
      "learning_rate": 1.7287755102040817e-05,
      "loss": 0.1011,
      "step": 16530
    },
    {
      "epoch": 6.616,
      "grad_norm": 0.06328744441270828,
      "learning_rate": 1.726734693877551e-05,
      "loss": 0.0464,
      "step": 16540
    },
    {
      "epoch": 6.62,
      "grad_norm": 1.0336805582046509,
      "learning_rate": 1.7246938775510203e-05,
      "loss": 0.0529,
      "step": 16550
    },
    {
      "epoch": 6.624,
      "grad_norm": 2.020838975906372,
      "learning_rate": 1.7226530612244898e-05,
      "loss": 0.0795,
      "step": 16560
    },
    {
      "epoch": 6.628,
      "grad_norm": 0.22418276965618134,
      "learning_rate": 1.7206122448979593e-05,
      "loss": 0.043,
      "step": 16570
    },
    {
      "epoch": 6.632,
      "grad_norm": 1.1404087543487549,
      "learning_rate": 1.7185714285714285e-05,
      "loss": 0.0764,
      "step": 16580
    },
    {
      "epoch": 6.636,
      "grad_norm": 1.652441143989563,
      "learning_rate": 1.716530612244898e-05,
      "loss": 0.0834,
      "step": 16590
    },
    {
      "epoch": 6.64,
      "grad_norm": 0.8651134371757507,
      "learning_rate": 1.7144897959183675e-05,
      "loss": 0.0426,
      "step": 16600
    },
    {
      "epoch": 6.644,
      "grad_norm": 0.6536561846733093,
      "learning_rate": 1.712448979591837e-05,
      "loss": 0.0514,
      "step": 16610
    },
    {
      "epoch": 6.648,
      "grad_norm": 1.3291867971420288,
      "learning_rate": 1.710408163265306e-05,
      "loss": 0.0594,
      "step": 16620
    },
    {
      "epoch": 6.652,
      "grad_norm": 0.3719697892665863,
      "learning_rate": 1.7083673469387756e-05,
      "loss": 0.0609,
      "step": 16630
    },
    {
      "epoch": 6.656,
      "grad_norm": 0.739464282989502,
      "learning_rate": 1.706326530612245e-05,
      "loss": 0.0553,
      "step": 16640
    },
    {
      "epoch": 6.66,
      "grad_norm": 0.12773898243904114,
      "learning_rate": 1.7042857142857143e-05,
      "loss": 0.0551,
      "step": 16650
    },
    {
      "epoch": 6.664,
      "grad_norm": 0.7782471179962158,
      "learning_rate": 1.7022448979591838e-05,
      "loss": 0.0546,
      "step": 16660
    },
    {
      "epoch": 6.668,
      "grad_norm": 0.9093571305274963,
      "learning_rate": 1.700204081632653e-05,
      "loss": 0.075,
      "step": 16670
    },
    {
      "epoch": 6.672,
      "grad_norm": 1.841847538948059,
      "learning_rate": 1.6981632653061224e-05,
      "loss": 0.0895,
      "step": 16680
    },
    {
      "epoch": 6.676,
      "grad_norm": 0.3125546872615814,
      "learning_rate": 1.696122448979592e-05,
      "loss": 0.0636,
      "step": 16690
    },
    {
      "epoch": 6.68,
      "grad_norm": 0.8047571182250977,
      "learning_rate": 1.694081632653061e-05,
      "loss": 0.0932,
      "step": 16700
    },
    {
      "epoch": 6.684,
      "grad_norm": 1.0270639657974243,
      "learning_rate": 1.692040816326531e-05,
      "loss": 0.1211,
      "step": 16710
    },
    {
      "epoch": 6.688,
      "grad_norm": 1.4512113332748413,
      "learning_rate": 1.69e-05,
      "loss": 0.0701,
      "step": 16720
    },
    {
      "epoch": 6.692,
      "grad_norm": 0.7993916273117065,
      "learning_rate": 1.6879591836734696e-05,
      "loss": 0.1282,
      "step": 16730
    },
    {
      "epoch": 6.696,
      "grad_norm": 1.3497967720031738,
      "learning_rate": 1.685918367346939e-05,
      "loss": 0.0762,
      "step": 16740
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.3569726347923279,
      "learning_rate": 1.6838775510204082e-05,
      "loss": 0.057,
      "step": 16750
    },
    {
      "epoch": 6.704,
      "grad_norm": 0.32312074303627014,
      "learning_rate": 1.6818367346938777e-05,
      "loss": 0.0702,
      "step": 16760
    },
    {
      "epoch": 6.708,
      "grad_norm": 0.583351731300354,
      "learning_rate": 1.679795918367347e-05,
      "loss": 0.0695,
      "step": 16770
    },
    {
      "epoch": 6.712,
      "grad_norm": 0.8617318272590637,
      "learning_rate": 1.6777551020408164e-05,
      "loss": 0.0487,
      "step": 16780
    },
    {
      "epoch": 6.716,
      "grad_norm": 0.6731299161911011,
      "learning_rate": 1.675714285714286e-05,
      "loss": 0.0701,
      "step": 16790
    },
    {
      "epoch": 6.72,
      "grad_norm": 0.7652692198753357,
      "learning_rate": 1.673673469387755e-05,
      "loss": 0.0239,
      "step": 16800
    },
    {
      "epoch": 6.724,
      "grad_norm": 0.43599048256874084,
      "learning_rate": 1.6716326530612245e-05,
      "loss": 0.0547,
      "step": 16810
    },
    {
      "epoch": 6.728,
      "grad_norm": 1.1741288900375366,
      "learning_rate": 1.6695918367346937e-05,
      "loss": 0.0817,
      "step": 16820
    },
    {
      "epoch": 6.732,
      "grad_norm": 1.0481231212615967,
      "learning_rate": 1.6675510204081635e-05,
      "loss": 0.1144,
      "step": 16830
    },
    {
      "epoch": 6.736,
      "grad_norm": 0.7927948236465454,
      "learning_rate": 1.6655102040816327e-05,
      "loss": 0.0647,
      "step": 16840
    },
    {
      "epoch": 6.74,
      "grad_norm": 0.06813044846057892,
      "learning_rate": 1.6634693877551022e-05,
      "loss": 0.0642,
      "step": 16850
    },
    {
      "epoch": 6.744,
      "grad_norm": 0.4380418658256531,
      "learning_rate": 1.6614285714285717e-05,
      "loss": 0.0438,
      "step": 16860
    },
    {
      "epoch": 6.748,
      "grad_norm": 0.7328076958656311,
      "learning_rate": 1.659387755102041e-05,
      "loss": 0.0697,
      "step": 16870
    },
    {
      "epoch": 6.752,
      "grad_norm": 0.214008167386055,
      "learning_rate": 1.6573469387755103e-05,
      "loss": 0.0474,
      "step": 16880
    },
    {
      "epoch": 6.756,
      "grad_norm": 1.0871142148971558,
      "learning_rate": 1.6553061224489795e-05,
      "loss": 0.0711,
      "step": 16890
    },
    {
      "epoch": 6.76,
      "grad_norm": 0.6957976818084717,
      "learning_rate": 1.653265306122449e-05,
      "loss": 0.0657,
      "step": 16900
    },
    {
      "epoch": 6.764,
      "grad_norm": 1.2704153060913086,
      "learning_rate": 1.6512244897959185e-05,
      "loss": 0.0737,
      "step": 16910
    },
    {
      "epoch": 6.768,
      "grad_norm": 0.6092198491096497,
      "learning_rate": 1.6491836734693877e-05,
      "loss": 0.0713,
      "step": 16920
    },
    {
      "epoch": 6.772,
      "grad_norm": 1.228894829750061,
      "learning_rate": 1.647142857142857e-05,
      "loss": 0.0393,
      "step": 16930
    },
    {
      "epoch": 6.776,
      "grad_norm": 0.13121268153190613,
      "learning_rate": 1.6451020408163266e-05,
      "loss": 0.0736,
      "step": 16940
    },
    {
      "epoch": 6.78,
      "grad_norm": 0.42866718769073486,
      "learning_rate": 1.643061224489796e-05,
      "loss": 0.0659,
      "step": 16950
    },
    {
      "epoch": 6.784,
      "grad_norm": 0.9425621032714844,
      "learning_rate": 1.6410204081632653e-05,
      "loss": 0.0814,
      "step": 16960
    },
    {
      "epoch": 6.788,
      "grad_norm": 1.1109211444854736,
      "learning_rate": 1.6389795918367348e-05,
      "loss": 0.0675,
      "step": 16970
    },
    {
      "epoch": 6.792,
      "grad_norm": 0.7245254516601562,
      "learning_rate": 1.6369387755102043e-05,
      "loss": 0.0383,
      "step": 16980
    },
    {
      "epoch": 6.796,
      "grad_norm": 0.9965053200721741,
      "learning_rate": 1.6348979591836735e-05,
      "loss": 0.0513,
      "step": 16990
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.918124794960022,
      "learning_rate": 1.632857142857143e-05,
      "loss": 0.0636,
      "step": 17000
    },
    {
      "epoch": 6.804,
      "grad_norm": 3.0680973529815674,
      "learning_rate": 1.630816326530612e-05,
      "loss": 0.1402,
      "step": 17010
    },
    {
      "epoch": 6.808,
      "grad_norm": 1.1440248489379883,
      "learning_rate": 1.6287755102040816e-05,
      "loss": 0.0424,
      "step": 17020
    },
    {
      "epoch": 6.812,
      "grad_norm": 1.2636953592300415,
      "learning_rate": 1.626734693877551e-05,
      "loss": 0.0969,
      "step": 17030
    },
    {
      "epoch": 6.816,
      "grad_norm": 1.7592172622680664,
      "learning_rate": 1.6246938775510203e-05,
      "loss": 0.0887,
      "step": 17040
    },
    {
      "epoch": 6.82,
      "grad_norm": 0.16740188002586365,
      "learning_rate": 1.62265306122449e-05,
      "loss": 0.0508,
      "step": 17050
    },
    {
      "epoch": 6.824,
      "grad_norm": 1.0570502281188965,
      "learning_rate": 1.6206122448979593e-05,
      "loss": 0.0752,
      "step": 17060
    },
    {
      "epoch": 6.828,
      "grad_norm": 0.5239355564117432,
      "learning_rate": 1.6185714285714288e-05,
      "loss": 0.0727,
      "step": 17070
    },
    {
      "epoch": 6.832,
      "grad_norm": 0.043014366179704666,
      "learning_rate": 1.6165306122448983e-05,
      "loss": 0.0756,
      "step": 17080
    },
    {
      "epoch": 6.836,
      "grad_norm": 1.5055477619171143,
      "learning_rate": 1.6144897959183674e-05,
      "loss": 0.0605,
      "step": 17090
    },
    {
      "epoch": 6.84,
      "grad_norm": 0.03259306401014328,
      "learning_rate": 1.612448979591837e-05,
      "loss": 0.0444,
      "step": 17100
    },
    {
      "epoch": 6.844,
      "grad_norm": 0.3954300284385681,
      "learning_rate": 1.610408163265306e-05,
      "loss": 0.0454,
      "step": 17110
    },
    {
      "epoch": 6.848,
      "grad_norm": 0.6552781462669373,
      "learning_rate": 1.6083673469387756e-05,
      "loss": 0.0873,
      "step": 17120
    },
    {
      "epoch": 6.852,
      "grad_norm": 0.43415001034736633,
      "learning_rate": 1.606326530612245e-05,
      "loss": 0.0329,
      "step": 17130
    },
    {
      "epoch": 6.856,
      "grad_norm": 1.5788664817810059,
      "learning_rate": 1.6042857142857142e-05,
      "loss": 0.0902,
      "step": 17140
    },
    {
      "epoch": 6.86,
      "grad_norm": 0.09849990904331207,
      "learning_rate": 1.6022448979591837e-05,
      "loss": 0.0732,
      "step": 17150
    },
    {
      "epoch": 6.864,
      "grad_norm": 0.09906088560819626,
      "learning_rate": 1.600204081632653e-05,
      "loss": 0.0635,
      "step": 17160
    },
    {
      "epoch": 6.868,
      "grad_norm": 1.222561240196228,
      "learning_rate": 1.5981632653061227e-05,
      "loss": 0.0653,
      "step": 17170
    },
    {
      "epoch": 6.872,
      "grad_norm": 0.6713131070137024,
      "learning_rate": 1.596122448979592e-05,
      "loss": 0.0771,
      "step": 17180
    },
    {
      "epoch": 6.876,
      "grad_norm": 0.3674696683883667,
      "learning_rate": 1.5940816326530614e-05,
      "loss": 0.0468,
      "step": 17190
    },
    {
      "epoch": 6.88,
      "grad_norm": 0.23476751148700714,
      "learning_rate": 1.592040816326531e-05,
      "loss": 0.0742,
      "step": 17200
    },
    {
      "epoch": 6.884,
      "grad_norm": 0.4197300970554352,
      "learning_rate": 1.59e-05,
      "loss": 0.0506,
      "step": 17210
    },
    {
      "epoch": 6.888,
      "grad_norm": 0.2603250741958618,
      "learning_rate": 1.5879591836734695e-05,
      "loss": 0.055,
      "step": 17220
    },
    {
      "epoch": 6.892,
      "grad_norm": 0.9426602125167847,
      "learning_rate": 1.5859183673469387e-05,
      "loss": 0.0497,
      "step": 17230
    },
    {
      "epoch": 6.896,
      "grad_norm": 0.8067278265953064,
      "learning_rate": 1.5838775510204082e-05,
      "loss": 0.085,
      "step": 17240
    },
    {
      "epoch": 6.9,
      "grad_norm": 0.2755776345729828,
      "learning_rate": 1.5818367346938777e-05,
      "loss": 0.0635,
      "step": 17250
    },
    {
      "epoch": 6.904,
      "grad_norm": 1.2257331609725952,
      "learning_rate": 1.579795918367347e-05,
      "loss": 0.0496,
      "step": 17260
    },
    {
      "epoch": 6.908,
      "grad_norm": 1.2490265369415283,
      "learning_rate": 1.5777551020408163e-05,
      "loss": 0.0986,
      "step": 17270
    },
    {
      "epoch": 6.912,
      "grad_norm": 0.07876943796873093,
      "learning_rate": 1.5757142857142858e-05,
      "loss": 0.0952,
      "step": 17280
    },
    {
      "epoch": 6.916,
      "grad_norm": 0.17274323105812073,
      "learning_rate": 1.5736734693877553e-05,
      "loss": 0.0686,
      "step": 17290
    },
    {
      "epoch": 6.92,
      "grad_norm": 1.1680986881256104,
      "learning_rate": 1.5716326530612245e-05,
      "loss": 0.053,
      "step": 17300
    },
    {
      "epoch": 6.924,
      "grad_norm": 0.22414696216583252,
      "learning_rate": 1.569591836734694e-05,
      "loss": 0.03,
      "step": 17310
    },
    {
      "epoch": 6.928,
      "grad_norm": 0.20143285393714905,
      "learning_rate": 1.5675510204081635e-05,
      "loss": 0.066,
      "step": 17320
    },
    {
      "epoch": 6.932,
      "grad_norm": 1.1520785093307495,
      "learning_rate": 1.5655102040816326e-05,
      "loss": 0.0746,
      "step": 17330
    },
    {
      "epoch": 6.936,
      "grad_norm": 0.5958904027938843,
      "learning_rate": 1.563469387755102e-05,
      "loss": 0.049,
      "step": 17340
    },
    {
      "epoch": 6.9399999999999995,
      "grad_norm": 0.2769896984100342,
      "learning_rate": 1.5614285714285716e-05,
      "loss": 0.0811,
      "step": 17350
    },
    {
      "epoch": 6.944,
      "grad_norm": 0.04392850771546364,
      "learning_rate": 1.5593877551020408e-05,
      "loss": 0.0742,
      "step": 17360
    },
    {
      "epoch": 6.948,
      "grad_norm": 1.4873661994934082,
      "learning_rate": 1.5573469387755103e-05,
      "loss": 0.0798,
      "step": 17370
    },
    {
      "epoch": 6.952,
      "grad_norm": 0.6966013312339783,
      "learning_rate": 1.5553061224489794e-05,
      "loss": 0.0327,
      "step": 17380
    },
    {
      "epoch": 6.9559999999999995,
      "grad_norm": 0.1645909547805786,
      "learning_rate": 1.553265306122449e-05,
      "loss": 0.0611,
      "step": 17390
    },
    {
      "epoch": 6.96,
      "grad_norm": 1.3520509004592896,
      "learning_rate": 1.5512244897959184e-05,
      "loss": 0.0705,
      "step": 17400
    },
    {
      "epoch": 6.964,
      "grad_norm": 1.1571844816207886,
      "learning_rate": 1.549183673469388e-05,
      "loss": 0.0358,
      "step": 17410
    },
    {
      "epoch": 6.968,
      "grad_norm": 1.1169118881225586,
      "learning_rate": 1.5471428571428574e-05,
      "loss": 0.0333,
      "step": 17420
    },
    {
      "epoch": 6.9719999999999995,
      "grad_norm": 1.5010312795639038,
      "learning_rate": 1.5451020408163266e-05,
      "loss": 0.1209,
      "step": 17430
    },
    {
      "epoch": 6.976,
      "grad_norm": 1.5565272569656372,
      "learning_rate": 1.543061224489796e-05,
      "loss": 0.0608,
      "step": 17440
    },
    {
      "epoch": 6.98,
      "grad_norm": 1.0577261447906494,
      "learning_rate": 1.5410204081632652e-05,
      "loss": 0.055,
      "step": 17450
    },
    {
      "epoch": 6.984,
      "grad_norm": 0.7608022093772888,
      "learning_rate": 1.5389795918367347e-05,
      "loss": 0.0733,
      "step": 17460
    },
    {
      "epoch": 6.9879999999999995,
      "grad_norm": 1.4184556007385254,
      "learning_rate": 1.5369387755102042e-05,
      "loss": 0.0551,
      "step": 17470
    },
    {
      "epoch": 6.992,
      "grad_norm": 0.1399121880531311,
      "learning_rate": 1.5348979591836734e-05,
      "loss": 0.0634,
      "step": 17480
    },
    {
      "epoch": 6.996,
      "grad_norm": 0.5877676606178284,
      "learning_rate": 1.532857142857143e-05,
      "loss": 0.091,
      "step": 17490
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.9633328914642334,
      "learning_rate": 1.530816326530612e-05,
      "loss": 0.0835,
      "step": 17500
    },
    {
      "epoch": 7.004,
      "grad_norm": 0.4676494002342224,
      "learning_rate": 1.528775510204082e-05,
      "loss": 0.0678,
      "step": 17510
    },
    {
      "epoch": 7.008,
      "grad_norm": 1.777393102645874,
      "learning_rate": 1.526734693877551e-05,
      "loss": 0.0714,
      "step": 17520
    },
    {
      "epoch": 7.012,
      "grad_norm": 1.4952762126922607,
      "learning_rate": 1.5246938775510205e-05,
      "loss": 0.0948,
      "step": 17530
    },
    {
      "epoch": 7.016,
      "grad_norm": 0.3047919273376465,
      "learning_rate": 1.5226530612244899e-05,
      "loss": 0.024,
      "step": 17540
    },
    {
      "epoch": 7.02,
      "grad_norm": 1.3317331075668335,
      "learning_rate": 1.5206122448979592e-05,
      "loss": 0.0885,
      "step": 17550
    },
    {
      "epoch": 7.024,
      "grad_norm": 0.3890419602394104,
      "learning_rate": 1.5185714285714287e-05,
      "loss": 0.0646,
      "step": 17560
    },
    {
      "epoch": 7.028,
      "grad_norm": 1.2349668741226196,
      "learning_rate": 1.516530612244898e-05,
      "loss": 0.0604,
      "step": 17570
    },
    {
      "epoch": 7.032,
      "grad_norm": 0.11136548966169357,
      "learning_rate": 1.5144897959183674e-05,
      "loss": 0.0169,
      "step": 17580
    },
    {
      "epoch": 7.036,
      "grad_norm": 1.4639559984207153,
      "learning_rate": 1.5124489795918367e-05,
      "loss": 0.0977,
      "step": 17590
    },
    {
      "epoch": 7.04,
      "grad_norm": 1.0658643245697021,
      "learning_rate": 1.5104081632653062e-05,
      "loss": 0.0475,
      "step": 17600
    },
    {
      "epoch": 7.044,
      "grad_norm": 0.9310969114303589,
      "learning_rate": 1.5083673469387755e-05,
      "loss": 0.0535,
      "step": 17610
    },
    {
      "epoch": 7.048,
      "grad_norm": 1.0402023792266846,
      "learning_rate": 1.5063265306122452e-05,
      "loss": 0.0335,
      "step": 17620
    },
    {
      "epoch": 7.052,
      "grad_norm": 0.9602299332618713,
      "learning_rate": 1.5042857142857145e-05,
      "loss": 0.0677,
      "step": 17630
    },
    {
      "epoch": 7.056,
      "grad_norm": 1.286650538444519,
      "learning_rate": 1.5022448979591838e-05,
      "loss": 0.0509,
      "step": 17640
    },
    {
      "epoch": 7.06,
      "grad_norm": 0.2784566283226013,
      "learning_rate": 1.5002040816326532e-05,
      "loss": 0.0612,
      "step": 17650
    },
    {
      "epoch": 7.064,
      "grad_norm": 0.35675930976867676,
      "learning_rate": 1.4981632653061225e-05,
      "loss": 0.0798,
      "step": 17660
    },
    {
      "epoch": 7.068,
      "grad_norm": 0.6972737312316895,
      "learning_rate": 1.496122448979592e-05,
      "loss": 0.0917,
      "step": 17670
    },
    {
      "epoch": 7.072,
      "grad_norm": 0.8854712843894958,
      "learning_rate": 1.4940816326530613e-05,
      "loss": 0.0506,
      "step": 17680
    },
    {
      "epoch": 7.076,
      "grad_norm": 1.3621528148651123,
      "learning_rate": 1.4920408163265306e-05,
      "loss": 0.0448,
      "step": 17690
    },
    {
      "epoch": 7.08,
      "grad_norm": 1.2535133361816406,
      "learning_rate": 1.49e-05,
      "loss": 0.1135,
      "step": 17700
    },
    {
      "epoch": 7.084,
      "grad_norm": 0.7274724245071411,
      "learning_rate": 1.4879591836734693e-05,
      "loss": 0.0818,
      "step": 17710
    },
    {
      "epoch": 7.088,
      "grad_norm": 1.4138702154159546,
      "learning_rate": 1.4859183673469388e-05,
      "loss": 0.1001,
      "step": 17720
    },
    {
      "epoch": 7.092,
      "grad_norm": 1.294740080833435,
      "learning_rate": 1.4838775510204081e-05,
      "loss": 0.0721,
      "step": 17730
    },
    {
      "epoch": 7.096,
      "grad_norm": 1.0949684381484985,
      "learning_rate": 1.4818367346938778e-05,
      "loss": 0.0636,
      "step": 17740
    },
    {
      "epoch": 7.1,
      "grad_norm": 1.7161309719085693,
      "learning_rate": 1.4797959183673471e-05,
      "loss": 0.0554,
      "step": 17750
    },
    {
      "epoch": 7.104,
      "grad_norm": 1.4364612102508545,
      "learning_rate": 1.4777551020408164e-05,
      "loss": 0.0615,
      "step": 17760
    },
    {
      "epoch": 7.108,
      "grad_norm": 0.3518061935901642,
      "learning_rate": 1.4757142857142858e-05,
      "loss": 0.0373,
      "step": 17770
    },
    {
      "epoch": 7.112,
      "grad_norm": 1.313918113708496,
      "learning_rate": 1.4736734693877553e-05,
      "loss": 0.0593,
      "step": 17780
    },
    {
      "epoch": 7.116,
      "grad_norm": 0.14039409160614014,
      "learning_rate": 1.4716326530612246e-05,
      "loss": 0.0475,
      "step": 17790
    },
    {
      "epoch": 7.12,
      "grad_norm": 1.3001432418823242,
      "learning_rate": 1.469591836734694e-05,
      "loss": 0.0831,
      "step": 17800
    },
    {
      "epoch": 7.124,
      "grad_norm": 0.2486000657081604,
      "learning_rate": 1.4675510204081632e-05,
      "loss": 0.0581,
      "step": 17810
    },
    {
      "epoch": 7.128,
      "grad_norm": 0.6928421258926392,
      "learning_rate": 1.4655102040816326e-05,
      "loss": 0.0682,
      "step": 17820
    },
    {
      "epoch": 7.132,
      "grad_norm": 1.1779868602752686,
      "learning_rate": 1.463469387755102e-05,
      "loss": 0.0596,
      "step": 17830
    },
    {
      "epoch": 7.136,
      "grad_norm": 1.052781581878662,
      "learning_rate": 1.4614285714285714e-05,
      "loss": 0.0634,
      "step": 17840
    },
    {
      "epoch": 7.14,
      "grad_norm": 1.3918557167053223,
      "learning_rate": 1.459387755102041e-05,
      "loss": 0.0774,
      "step": 17850
    },
    {
      "epoch": 7.144,
      "grad_norm": 1.7437478303909302,
      "learning_rate": 1.4573469387755104e-05,
      "loss": 0.0657,
      "step": 17860
    },
    {
      "epoch": 7.148,
      "grad_norm": 0.4965519607067108,
      "learning_rate": 1.4553061224489797e-05,
      "loss": 0.0747,
      "step": 17870
    },
    {
      "epoch": 7.152,
      "grad_norm": 1.2460579872131348,
      "learning_rate": 1.453265306122449e-05,
      "loss": 0.0498,
      "step": 17880
    },
    {
      "epoch": 7.156,
      "grad_norm": 0.5090842843055725,
      "learning_rate": 1.4512244897959185e-05,
      "loss": 0.038,
      "step": 17890
    },
    {
      "epoch": 7.16,
      "grad_norm": 0.623444676399231,
      "learning_rate": 1.4491836734693879e-05,
      "loss": 0.0526,
      "step": 17900
    },
    {
      "epoch": 7.164,
      "grad_norm": 1.315294861793518,
      "learning_rate": 1.4471428571428572e-05,
      "loss": 0.0775,
      "step": 17910
    },
    {
      "epoch": 7.168,
      "grad_norm": 0.275238037109375,
      "learning_rate": 1.4451020408163265e-05,
      "loss": 0.0721,
      "step": 17920
    },
    {
      "epoch": 7.172,
      "grad_norm": 0.1205020323395729,
      "learning_rate": 1.4430612244897959e-05,
      "loss": 0.0332,
      "step": 17930
    },
    {
      "epoch": 7.176,
      "grad_norm": 0.7423611283302307,
      "learning_rate": 1.4410204081632654e-05,
      "loss": 0.1032,
      "step": 17940
    },
    {
      "epoch": 7.18,
      "grad_norm": 0.761969804763794,
      "learning_rate": 1.4389795918367347e-05,
      "loss": 0.0864,
      "step": 17950
    },
    {
      "epoch": 7.184,
      "grad_norm": 1.5851513147354126,
      "learning_rate": 1.4369387755102044e-05,
      "loss": 0.0662,
      "step": 17960
    },
    {
      "epoch": 7.188,
      "grad_norm": 0.019506119191646576,
      "learning_rate": 1.4348979591836737e-05,
      "loss": 0.06,
      "step": 17970
    },
    {
      "epoch": 7.192,
      "grad_norm": 1.4975932836532593,
      "learning_rate": 1.432857142857143e-05,
      "loss": 0.0661,
      "step": 17980
    },
    {
      "epoch": 7.196,
      "grad_norm": 1.2162429094314575,
      "learning_rate": 1.4308163265306123e-05,
      "loss": 0.0469,
      "step": 17990
    },
    {
      "epoch": 7.2,
      "grad_norm": 1.033007264137268,
      "learning_rate": 1.4287755102040817e-05,
      "loss": 0.0571,
      "step": 18000
    },
    {
      "epoch": 7.204,
      "grad_norm": 1.1894804239273071,
      "learning_rate": 1.4267346938775512e-05,
      "loss": 0.0982,
      "step": 18010
    },
    {
      "epoch": 7.208,
      "grad_norm": 0.10088969022035599,
      "learning_rate": 1.4246938775510205e-05,
      "loss": 0.0372,
      "step": 18020
    },
    {
      "epoch": 7.212,
      "grad_norm": 0.22740232944488525,
      "learning_rate": 1.4226530612244898e-05,
      "loss": 0.0424,
      "step": 18030
    },
    {
      "epoch": 7.216,
      "grad_norm": 0.2354719340801239,
      "learning_rate": 1.4206122448979591e-05,
      "loss": 0.092,
      "step": 18040
    },
    {
      "epoch": 7.22,
      "grad_norm": 1.4996603727340698,
      "learning_rate": 1.4185714285714285e-05,
      "loss": 0.0484,
      "step": 18050
    },
    {
      "epoch": 7.224,
      "grad_norm": 0.17031776905059814,
      "learning_rate": 1.416530612244898e-05,
      "loss": 0.0536,
      "step": 18060
    },
    {
      "epoch": 7.228,
      "grad_norm": 0.7203126549720764,
      "learning_rate": 1.4144897959183673e-05,
      "loss": 0.0456,
      "step": 18070
    },
    {
      "epoch": 7.232,
      "grad_norm": 0.13085342943668365,
      "learning_rate": 1.412448979591837e-05,
      "loss": 0.0459,
      "step": 18080
    },
    {
      "epoch": 7.236,
      "grad_norm": 1.4697457551956177,
      "learning_rate": 1.4104081632653063e-05,
      "loss": 0.07,
      "step": 18090
    },
    {
      "epoch": 7.24,
      "grad_norm": 0.8038829565048218,
      "learning_rate": 1.4083673469387756e-05,
      "loss": 0.0332,
      "step": 18100
    },
    {
      "epoch": 7.244,
      "grad_norm": 0.741145133972168,
      "learning_rate": 1.406326530612245e-05,
      "loss": 0.0473,
      "step": 18110
    },
    {
      "epoch": 7.248,
      "grad_norm": 0.526116669178009,
      "learning_rate": 1.4042857142857144e-05,
      "loss": 0.0723,
      "step": 18120
    },
    {
      "epoch": 7.252,
      "grad_norm": 0.7317844033241272,
      "learning_rate": 1.4022448979591838e-05,
      "loss": 0.0257,
      "step": 18130
    },
    {
      "epoch": 7.256,
      "grad_norm": 0.05845574662089348,
      "learning_rate": 1.4002040816326531e-05,
      "loss": 0.0461,
      "step": 18140
    },
    {
      "epoch": 7.26,
      "grad_norm": 1.634779691696167,
      "learning_rate": 1.3981632653061224e-05,
      "loss": 0.0539,
      "step": 18150
    },
    {
      "epoch": 7.264,
      "grad_norm": 0.20416134595870972,
      "learning_rate": 1.3961224489795918e-05,
      "loss": 0.0887,
      "step": 18160
    },
    {
      "epoch": 7.268,
      "grad_norm": 1.0702742338180542,
      "learning_rate": 1.3940816326530612e-05,
      "loss": 0.0472,
      "step": 18170
    },
    {
      "epoch": 7.272,
      "grad_norm": 0.3970247805118561,
      "learning_rate": 1.3920408163265306e-05,
      "loss": 0.0288,
      "step": 18180
    },
    {
      "epoch": 7.276,
      "grad_norm": 0.06292081624269485,
      "learning_rate": 1.3900000000000002e-05,
      "loss": 0.0673,
      "step": 18190
    },
    {
      "epoch": 7.28,
      "grad_norm": 1.0039609670639038,
      "learning_rate": 1.3879591836734696e-05,
      "loss": 0.0644,
      "step": 18200
    },
    {
      "epoch": 7.284,
      "grad_norm": 0.6748102307319641,
      "learning_rate": 1.3859183673469389e-05,
      "loss": 0.096,
      "step": 18210
    },
    {
      "epoch": 7.288,
      "grad_norm": 0.21277816593647003,
      "learning_rate": 1.3838775510204082e-05,
      "loss": 0.056,
      "step": 18220
    },
    {
      "epoch": 7.292,
      "grad_norm": 0.8764687180519104,
      "learning_rate": 1.3818367346938777e-05,
      "loss": 0.0675,
      "step": 18230
    },
    {
      "epoch": 7.296,
      "grad_norm": 0.31255921721458435,
      "learning_rate": 1.379795918367347e-05,
      "loss": 0.0752,
      "step": 18240
    },
    {
      "epoch": 7.3,
      "grad_norm": 0.19414061307907104,
      "learning_rate": 1.3777551020408164e-05,
      "loss": 0.0752,
      "step": 18250
    },
    {
      "epoch": 7.304,
      "grad_norm": 0.523429811000824,
      "learning_rate": 1.3757142857142857e-05,
      "loss": 0.052,
      "step": 18260
    },
    {
      "epoch": 7.308,
      "grad_norm": 0.33234038949012756,
      "learning_rate": 1.373673469387755e-05,
      "loss": 0.0355,
      "step": 18270
    },
    {
      "epoch": 7.312,
      "grad_norm": 1.3856992721557617,
      "learning_rate": 1.3716326530612245e-05,
      "loss": 0.0743,
      "step": 18280
    },
    {
      "epoch": 7.316,
      "grad_norm": 0.2655254006385803,
      "learning_rate": 1.3695918367346939e-05,
      "loss": 0.0657,
      "step": 18290
    },
    {
      "epoch": 7.32,
      "grad_norm": 1.0899510383605957,
      "learning_rate": 1.3675510204081635e-05,
      "loss": 0.0741,
      "step": 18300
    },
    {
      "epoch": 7.324,
      "grad_norm": 1.9872486591339111,
      "learning_rate": 1.3655102040816329e-05,
      "loss": 0.059,
      "step": 18310
    },
    {
      "epoch": 7.328,
      "grad_norm": 0.9143995046615601,
      "learning_rate": 1.3634693877551022e-05,
      "loss": 0.0828,
      "step": 18320
    },
    {
      "epoch": 7.332,
      "grad_norm": 0.4274846315383911,
      "learning_rate": 1.3614285714285715e-05,
      "loss": 0.1114,
      "step": 18330
    },
    {
      "epoch": 7.336,
      "grad_norm": 0.7116711735725403,
      "learning_rate": 1.3593877551020408e-05,
      "loss": 0.0394,
      "step": 18340
    },
    {
      "epoch": 7.34,
      "grad_norm": 0.981097400188446,
      "learning_rate": 1.3573469387755103e-05,
      "loss": 0.0672,
      "step": 18350
    },
    {
      "epoch": 7.344,
      "grad_norm": 0.040615614503622055,
      "learning_rate": 1.3553061224489797e-05,
      "loss": 0.0795,
      "step": 18360
    },
    {
      "epoch": 7.348,
      "grad_norm": 1.3569289445877075,
      "learning_rate": 1.353265306122449e-05,
      "loss": 0.0748,
      "step": 18370
    },
    {
      "epoch": 7.352,
      "grad_norm": 1.5384186506271362,
      "learning_rate": 1.3512244897959183e-05,
      "loss": 0.0778,
      "step": 18380
    },
    {
      "epoch": 7.356,
      "grad_norm": 1.0911593437194824,
      "learning_rate": 1.3491836734693878e-05,
      "loss": 0.0481,
      "step": 18390
    },
    {
      "epoch": 7.36,
      "grad_norm": 1.2205159664154053,
      "learning_rate": 1.3471428571428571e-05,
      "loss": 0.0508,
      "step": 18400
    },
    {
      "epoch": 7.364,
      "grad_norm": 1.250490427017212,
      "learning_rate": 1.3451020408163265e-05,
      "loss": 0.0743,
      "step": 18410
    },
    {
      "epoch": 7.368,
      "grad_norm": 0.48764467239379883,
      "learning_rate": 1.3430612244897961e-05,
      "loss": 0.0377,
      "step": 18420
    },
    {
      "epoch": 7.372,
      "grad_norm": 0.5186643600463867,
      "learning_rate": 1.3410204081632655e-05,
      "loss": 0.0714,
      "step": 18430
    },
    {
      "epoch": 7.376,
      "grad_norm": 0.814430296421051,
      "learning_rate": 1.3389795918367348e-05,
      "loss": 0.0561,
      "step": 18440
    },
    {
      "epoch": 7.38,
      "grad_norm": 0.3322609066963196,
      "learning_rate": 1.3369387755102041e-05,
      "loss": 0.0472,
      "step": 18450
    },
    {
      "epoch": 7.384,
      "grad_norm": 0.5868624448776245,
      "learning_rate": 1.3348979591836736e-05,
      "loss": 0.0979,
      "step": 18460
    },
    {
      "epoch": 7.388,
      "grad_norm": 0.223223477602005,
      "learning_rate": 1.332857142857143e-05,
      "loss": 0.063,
      "step": 18470
    },
    {
      "epoch": 7.392,
      "grad_norm": 0.08724229782819748,
      "learning_rate": 1.3308163265306123e-05,
      "loss": 0.069,
      "step": 18480
    },
    {
      "epoch": 7.396,
      "grad_norm": 1.3656891584396362,
      "learning_rate": 1.3287755102040816e-05,
      "loss": 0.0513,
      "step": 18490
    },
    {
      "epoch": 7.4,
      "grad_norm": 1.1155980825424194,
      "learning_rate": 1.326734693877551e-05,
      "loss": 0.0683,
      "step": 18500
    },
    {
      "epoch": 7.404,
      "grad_norm": 0.0026714459527283907,
      "learning_rate": 1.3246938775510204e-05,
      "loss": 0.0362,
      "step": 18510
    },
    {
      "epoch": 7.408,
      "grad_norm": 1.3718781471252441,
      "learning_rate": 1.3226530612244898e-05,
      "loss": 0.0754,
      "step": 18520
    },
    {
      "epoch": 7.412,
      "grad_norm": 0.7205114960670471,
      "learning_rate": 1.3206122448979594e-05,
      "loss": 0.0214,
      "step": 18530
    },
    {
      "epoch": 7.416,
      "grad_norm": 0.324916809797287,
      "learning_rate": 1.3185714285714287e-05,
      "loss": 0.0385,
      "step": 18540
    },
    {
      "epoch": 7.42,
      "grad_norm": 0.27504023909568787,
      "learning_rate": 1.316530612244898e-05,
      "loss": 0.0481,
      "step": 18550
    },
    {
      "epoch": 7.424,
      "grad_norm": 0.21572095155715942,
      "learning_rate": 1.3144897959183674e-05,
      "loss": 0.032,
      "step": 18560
    },
    {
      "epoch": 7.428,
      "grad_norm": 1.9590455293655396,
      "learning_rate": 1.3124489795918369e-05,
      "loss": 0.0814,
      "step": 18570
    },
    {
      "epoch": 7.432,
      "grad_norm": 0.7469592690467834,
      "learning_rate": 1.3104081632653062e-05,
      "loss": 0.0586,
      "step": 18580
    },
    {
      "epoch": 7.436,
      "grad_norm": 0.21751165390014648,
      "learning_rate": 1.3083673469387756e-05,
      "loss": 0.0513,
      "step": 18590
    },
    {
      "epoch": 7.44,
      "grad_norm": 0.05549129098653793,
      "learning_rate": 1.3063265306122449e-05,
      "loss": 0.0558,
      "step": 18600
    },
    {
      "epoch": 7.444,
      "grad_norm": 1.033440351486206,
      "learning_rate": 1.3042857142857142e-05,
      "loss": 0.0695,
      "step": 18610
    },
    {
      "epoch": 7.448,
      "grad_norm": 0.9467715620994568,
      "learning_rate": 1.3022448979591837e-05,
      "loss": 0.0918,
      "step": 18620
    },
    {
      "epoch": 7.452,
      "grad_norm": 0.5173123478889465,
      "learning_rate": 1.300204081632653e-05,
      "loss": 0.0447,
      "step": 18630
    },
    {
      "epoch": 7.456,
      "grad_norm": 1.0376460552215576,
      "learning_rate": 1.2981632653061227e-05,
      "loss": 0.0615,
      "step": 18640
    },
    {
      "epoch": 7.46,
      "grad_norm": 1.0834276676177979,
      "learning_rate": 1.296122448979592e-05,
      "loss": 0.0743,
      "step": 18650
    },
    {
      "epoch": 7.464,
      "grad_norm": 2.0614850521087646,
      "learning_rate": 1.2940816326530614e-05,
      "loss": 0.0907,
      "step": 18660
    },
    {
      "epoch": 7.468,
      "grad_norm": 0.6298859119415283,
      "learning_rate": 1.2920408163265307e-05,
      "loss": 0.0397,
      "step": 18670
    },
    {
      "epoch": 7.4719999999999995,
      "grad_norm": 1.6764615774154663,
      "learning_rate": 1.29e-05,
      "loss": 0.0958,
      "step": 18680
    },
    {
      "epoch": 7.476,
      "grad_norm": 0.5914362668991089,
      "learning_rate": 1.2879591836734695e-05,
      "loss": 0.0558,
      "step": 18690
    },
    {
      "epoch": 7.48,
      "grad_norm": 0.07567747682332993,
      "learning_rate": 1.2859183673469388e-05,
      "loss": 0.1227,
      "step": 18700
    },
    {
      "epoch": 7.484,
      "grad_norm": 0.03827189654111862,
      "learning_rate": 1.2838775510204082e-05,
      "loss": 0.0291,
      "step": 18710
    },
    {
      "epoch": 7.4879999999999995,
      "grad_norm": 0.29295653104782104,
      "learning_rate": 1.2818367346938775e-05,
      "loss": 0.0472,
      "step": 18720
    },
    {
      "epoch": 7.492,
      "grad_norm": 0.6019138693809509,
      "learning_rate": 1.279795918367347e-05,
      "loss": 0.0811,
      "step": 18730
    },
    {
      "epoch": 7.496,
      "grad_norm": 0.6060718297958374,
      "learning_rate": 1.2777551020408163e-05,
      "loss": 0.0632,
      "step": 18740
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.2338676452636719,
      "learning_rate": 1.2757142857142856e-05,
      "loss": 0.0488,
      "step": 18750
    },
    {
      "epoch": 7.504,
      "grad_norm": 0.21100564301013947,
      "learning_rate": 1.2736734693877553e-05,
      "loss": 0.035,
      "step": 18760
    },
    {
      "epoch": 7.508,
      "grad_norm": 0.3028124272823334,
      "learning_rate": 1.2716326530612246e-05,
      "loss": 0.0429,
      "step": 18770
    },
    {
      "epoch": 7.5120000000000005,
      "grad_norm": 1.0376111268997192,
      "learning_rate": 1.269591836734694e-05,
      "loss": 0.0622,
      "step": 18780
    },
    {
      "epoch": 7.516,
      "grad_norm": 1.2063370943069458,
      "learning_rate": 1.2675510204081633e-05,
      "loss": 0.0332,
      "step": 18790
    },
    {
      "epoch": 7.52,
      "grad_norm": 0.298632949590683,
      "learning_rate": 1.2655102040816328e-05,
      "loss": 0.0782,
      "step": 18800
    },
    {
      "epoch": 7.524,
      "grad_norm": 1.1236683130264282,
      "learning_rate": 1.2634693877551021e-05,
      "loss": 0.0508,
      "step": 18810
    },
    {
      "epoch": 7.5280000000000005,
      "grad_norm": 1.406370997428894,
      "learning_rate": 1.2614285714285715e-05,
      "loss": 0.0523,
      "step": 18820
    },
    {
      "epoch": 7.532,
      "grad_norm": 1.5181514024734497,
      "learning_rate": 1.2593877551020408e-05,
      "loss": 0.0491,
      "step": 18830
    },
    {
      "epoch": 7.536,
      "grad_norm": 0.9476471543312073,
      "learning_rate": 1.2573469387755101e-05,
      "loss": 0.0729,
      "step": 18840
    },
    {
      "epoch": 7.54,
      "grad_norm": 0.5434909462928772,
      "learning_rate": 1.2553061224489796e-05,
      "loss": 0.0502,
      "step": 18850
    },
    {
      "epoch": 7.5440000000000005,
      "grad_norm": 1.3772220611572266,
      "learning_rate": 1.253265306122449e-05,
      "loss": 0.0562,
      "step": 18860
    },
    {
      "epoch": 7.548,
      "grad_norm": 1.5195791721343994,
      "learning_rate": 1.2512244897959186e-05,
      "loss": 0.0608,
      "step": 18870
    },
    {
      "epoch": 7.552,
      "grad_norm": 1.579425573348999,
      "learning_rate": 1.2491836734693878e-05,
      "loss": 0.0804,
      "step": 18880
    },
    {
      "epoch": 7.556,
      "grad_norm": 0.11473346501588821,
      "learning_rate": 1.2471428571428571e-05,
      "loss": 0.0771,
      "step": 18890
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 1.5409575700759888,
      "learning_rate": 1.2451020408163266e-05,
      "loss": 0.0635,
      "step": 18900
    },
    {
      "epoch": 7.564,
      "grad_norm": 0.9603279829025269,
      "learning_rate": 1.243061224489796e-05,
      "loss": 0.0371,
      "step": 18910
    },
    {
      "epoch": 7.568,
      "grad_norm": 0.05798763409256935,
      "learning_rate": 1.2410204081632654e-05,
      "loss": 0.0816,
      "step": 18920
    },
    {
      "epoch": 7.572,
      "grad_norm": 0.2922214865684509,
      "learning_rate": 1.2389795918367347e-05,
      "loss": 0.0614,
      "step": 18930
    },
    {
      "epoch": 7.576,
      "grad_norm": 0.8229970932006836,
      "learning_rate": 1.236938775510204e-05,
      "loss": 0.0746,
      "step": 18940
    },
    {
      "epoch": 7.58,
      "grad_norm": 0.4133686423301697,
      "learning_rate": 1.2348979591836736e-05,
      "loss": 0.0454,
      "step": 18950
    },
    {
      "epoch": 7.584,
      "grad_norm": 1.1507084369659424,
      "learning_rate": 1.2328571428571429e-05,
      "loss": 0.0701,
      "step": 18960
    },
    {
      "epoch": 7.588,
      "grad_norm": 0.231657013297081,
      "learning_rate": 1.2308163265306124e-05,
      "loss": 0.0868,
      "step": 18970
    },
    {
      "epoch": 7.592,
      "grad_norm": 0.526607871055603,
      "learning_rate": 1.2287755102040817e-05,
      "loss": 0.0767,
      "step": 18980
    },
    {
      "epoch": 7.596,
      "grad_norm": 0.41186031699180603,
      "learning_rate": 1.226734693877551e-05,
      "loss": 0.0503,
      "step": 18990
    },
    {
      "epoch": 7.6,
      "grad_norm": 1.0269660949707031,
      "learning_rate": 1.2246938775510204e-05,
      "loss": 0.0525,
      "step": 19000
    },
    {
      "epoch": 7.604,
      "grad_norm": 0.2823726534843445,
      "learning_rate": 1.2226530612244899e-05,
      "loss": 0.0755,
      "step": 19010
    },
    {
      "epoch": 7.608,
      "grad_norm": 0.19424594938755035,
      "learning_rate": 1.2206122448979594e-05,
      "loss": 0.0597,
      "step": 19020
    },
    {
      "epoch": 7.612,
      "grad_norm": 0.9073119163513184,
      "learning_rate": 1.2185714285714287e-05,
      "loss": 0.0618,
      "step": 19030
    },
    {
      "epoch": 7.616,
      "grad_norm": 2.0410521030426025,
      "learning_rate": 1.216530612244898e-05,
      "loss": 0.0828,
      "step": 19040
    },
    {
      "epoch": 7.62,
      "grad_norm": 1.5833228826522827,
      "learning_rate": 1.2144897959183673e-05,
      "loss": 0.0902,
      "step": 19050
    },
    {
      "epoch": 7.624,
      "grad_norm": 1.4535369873046875,
      "learning_rate": 1.2124489795918367e-05,
      "loss": 0.053,
      "step": 19060
    },
    {
      "epoch": 7.628,
      "grad_norm": 0.6363374590873718,
      "learning_rate": 1.2104081632653062e-05,
      "loss": 0.0597,
      "step": 19070
    },
    {
      "epoch": 7.632,
      "grad_norm": 0.5499403476715088,
      "learning_rate": 1.2083673469387757e-05,
      "loss": 0.0725,
      "step": 19080
    },
    {
      "epoch": 7.636,
      "grad_norm": 1.283223032951355,
      "learning_rate": 1.206326530612245e-05,
      "loss": 0.0855,
      "step": 19090
    },
    {
      "epoch": 7.64,
      "grad_norm": 0.3939335346221924,
      "learning_rate": 1.2042857142857143e-05,
      "loss": 0.0417,
      "step": 19100
    },
    {
      "epoch": 7.644,
      "grad_norm": 1.2543694972991943,
      "learning_rate": 1.2022448979591837e-05,
      "loss": 0.0716,
      "step": 19110
    },
    {
      "epoch": 7.648,
      "grad_norm": 0.4712625741958618,
      "learning_rate": 1.2002040816326531e-05,
      "loss": 0.1199,
      "step": 19120
    },
    {
      "epoch": 7.652,
      "grad_norm": 1.311444640159607,
      "learning_rate": 1.1981632653061225e-05,
      "loss": 0.0704,
      "step": 19130
    },
    {
      "epoch": 7.656,
      "grad_norm": 1.023992896080017,
      "learning_rate": 1.196122448979592e-05,
      "loss": 0.0402,
      "step": 19140
    },
    {
      "epoch": 7.66,
      "grad_norm": 0.9742768406867981,
      "learning_rate": 1.1940816326530613e-05,
      "loss": 0.0929,
      "step": 19150
    },
    {
      "epoch": 7.664,
      "grad_norm": 0.2945248484611511,
      "learning_rate": 1.1920408163265306e-05,
      "loss": 0.0247,
      "step": 19160
    },
    {
      "epoch": 7.668,
      "grad_norm": 0.9830597043037415,
      "learning_rate": 1.19e-05,
      "loss": 0.0598,
      "step": 19170
    },
    {
      "epoch": 7.672,
      "grad_norm": 0.7501512169837952,
      "learning_rate": 1.1879591836734695e-05,
      "loss": 0.0766,
      "step": 19180
    },
    {
      "epoch": 7.676,
      "grad_norm": 0.7407836318016052,
      "learning_rate": 1.185918367346939e-05,
      "loss": 0.1083,
      "step": 19190
    },
    {
      "epoch": 7.68,
      "grad_norm": 1.4041996002197266,
      "learning_rate": 1.1838775510204083e-05,
      "loss": 0.0842,
      "step": 19200
    },
    {
      "epoch": 7.684,
      "grad_norm": 0.2622050642967224,
      "learning_rate": 1.1818367346938776e-05,
      "loss": 0.0563,
      "step": 19210
    },
    {
      "epoch": 7.688,
      "grad_norm": 1.1096636056900024,
      "learning_rate": 1.179795918367347e-05,
      "loss": 0.0704,
      "step": 19220
    },
    {
      "epoch": 7.692,
      "grad_norm": 1.3104802370071411,
      "learning_rate": 1.1777551020408163e-05,
      "loss": 0.0865,
      "step": 19230
    },
    {
      "epoch": 7.696,
      "grad_norm": 0.0789942666888237,
      "learning_rate": 1.1757142857142858e-05,
      "loss": 0.0687,
      "step": 19240
    },
    {
      "epoch": 7.7,
      "grad_norm": 0.03900064527988434,
      "learning_rate": 1.1736734693877553e-05,
      "loss": 0.046,
      "step": 19250
    },
    {
      "epoch": 7.704,
      "grad_norm": 0.45974475145339966,
      "learning_rate": 1.1716326530612246e-05,
      "loss": 0.0403,
      "step": 19260
    },
    {
      "epoch": 7.708,
      "grad_norm": 0.6140151619911194,
      "learning_rate": 1.1695918367346939e-05,
      "loss": 0.0458,
      "step": 19270
    },
    {
      "epoch": 7.712,
      "grad_norm": 1.1693741083145142,
      "learning_rate": 1.1675510204081632e-05,
      "loss": 0.0817,
      "step": 19280
    },
    {
      "epoch": 7.716,
      "grad_norm": 0.9166029691696167,
      "learning_rate": 1.1655102040816326e-05,
      "loss": 0.0568,
      "step": 19290
    },
    {
      "epoch": 7.72,
      "grad_norm": 1.0894428491592407,
      "learning_rate": 1.163469387755102e-05,
      "loss": 0.0889,
      "step": 19300
    },
    {
      "epoch": 7.724,
      "grad_norm": 0.6474668383598328,
      "learning_rate": 1.1614285714285716e-05,
      "loss": 0.0408,
      "step": 19310
    },
    {
      "epoch": 7.728,
      "grad_norm": 1.2143112421035767,
      "learning_rate": 1.1593877551020409e-05,
      "loss": 0.0448,
      "step": 19320
    },
    {
      "epoch": 7.732,
      "grad_norm": 1.1076545715332031,
      "learning_rate": 1.1573469387755102e-05,
      "loss": 0.0409,
      "step": 19330
    },
    {
      "epoch": 7.736,
      "grad_norm": 0.7753165364265442,
      "learning_rate": 1.1553061224489795e-05,
      "loss": 0.0409,
      "step": 19340
    },
    {
      "epoch": 7.74,
      "grad_norm": 1.041056752204895,
      "learning_rate": 1.153265306122449e-05,
      "loss": 0.0555,
      "step": 19350
    },
    {
      "epoch": 7.744,
      "grad_norm": 1.044294834136963,
      "learning_rate": 1.1512244897959185e-05,
      "loss": 0.0655,
      "step": 19360
    },
    {
      "epoch": 7.748,
      "grad_norm": 0.3147766590118408,
      "learning_rate": 1.1491836734693879e-05,
      "loss": 0.1102,
      "step": 19370
    },
    {
      "epoch": 7.752,
      "grad_norm": 1.461625337600708,
      "learning_rate": 1.1471428571428572e-05,
      "loss": 0.0362,
      "step": 19380
    },
    {
      "epoch": 7.756,
      "grad_norm": 0.9258280992507935,
      "learning_rate": 1.1451020408163265e-05,
      "loss": 0.0641,
      "step": 19390
    },
    {
      "epoch": 7.76,
      "grad_norm": 1.6765433549880981,
      "learning_rate": 1.1430612244897959e-05,
      "loss": 0.0939,
      "step": 19400
    },
    {
      "epoch": 7.764,
      "grad_norm": 1.5523133277893066,
      "learning_rate": 1.1410204081632653e-05,
      "loss": 0.0593,
      "step": 19410
    },
    {
      "epoch": 7.768,
      "grad_norm": 0.5010026693344116,
      "learning_rate": 1.1389795918367348e-05,
      "loss": 0.0268,
      "step": 19420
    },
    {
      "epoch": 7.772,
      "grad_norm": 0.6074976325035095,
      "learning_rate": 1.1369387755102042e-05,
      "loss": 0.0545,
      "step": 19430
    },
    {
      "epoch": 7.776,
      "grad_norm": 0.3245229423046112,
      "learning_rate": 1.1348979591836735e-05,
      "loss": 0.0448,
      "step": 19440
    },
    {
      "epoch": 7.78,
      "grad_norm": 0.3912254273891449,
      "learning_rate": 1.1328571428571428e-05,
      "loss": 0.0813,
      "step": 19450
    },
    {
      "epoch": 7.784,
      "grad_norm": 0.8540425896644592,
      "learning_rate": 1.1308163265306122e-05,
      "loss": 0.0606,
      "step": 19460
    },
    {
      "epoch": 7.788,
      "grad_norm": 0.20577847957611084,
      "learning_rate": 1.1287755102040817e-05,
      "loss": 0.0538,
      "step": 19470
    },
    {
      "epoch": 7.792,
      "grad_norm": 0.18542100489139557,
      "learning_rate": 1.1267346938775512e-05,
      "loss": 0.061,
      "step": 19480
    },
    {
      "epoch": 7.796,
      "grad_norm": 0.45368215441703796,
      "learning_rate": 1.1246938775510205e-05,
      "loss": 0.0359,
      "step": 19490
    },
    {
      "epoch": 7.8,
      "grad_norm": 1.261658787727356,
      "learning_rate": 1.1226530612244898e-05,
      "loss": 0.0422,
      "step": 19500
    },
    {
      "epoch": 7.804,
      "grad_norm": 1.242201328277588,
      "learning_rate": 1.1206122448979591e-05,
      "loss": 0.045,
      "step": 19510
    },
    {
      "epoch": 7.808,
      "grad_norm": 0.7036309838294983,
      "learning_rate": 1.1185714285714286e-05,
      "loss": 0.0911,
      "step": 19520
    },
    {
      "epoch": 7.812,
      "grad_norm": 0.13851475715637207,
      "learning_rate": 1.1165306122448981e-05,
      "loss": 0.0577,
      "step": 19530
    },
    {
      "epoch": 7.816,
      "grad_norm": 0.13514237105846405,
      "learning_rate": 1.1144897959183675e-05,
      "loss": 0.0335,
      "step": 19540
    },
    {
      "epoch": 7.82,
      "grad_norm": 0.8467788696289062,
      "learning_rate": 1.1124489795918368e-05,
      "loss": 0.0731,
      "step": 19550
    },
    {
      "epoch": 7.824,
      "grad_norm": 0.06430631875991821,
      "learning_rate": 1.1104081632653061e-05,
      "loss": 0.0348,
      "step": 19560
    },
    {
      "epoch": 7.828,
      "grad_norm": 0.3496972918510437,
      "learning_rate": 1.1083673469387754e-05,
      "loss": 0.0343,
      "step": 19570
    },
    {
      "epoch": 7.832,
      "grad_norm": 0.5652735233306885,
      "learning_rate": 1.106326530612245e-05,
      "loss": 0.0763,
      "step": 19580
    },
    {
      "epoch": 7.836,
      "grad_norm": 0.18967588245868683,
      "learning_rate": 1.1042857142857144e-05,
      "loss": 0.029,
      "step": 19590
    },
    {
      "epoch": 7.84,
      "grad_norm": 0.19955386221408844,
      "learning_rate": 1.1022448979591838e-05,
      "loss": 0.0816,
      "step": 19600
    },
    {
      "epoch": 7.844,
      "grad_norm": 0.8891515135765076,
      "learning_rate": 1.1002040816326531e-05,
      "loss": 0.0721,
      "step": 19610
    },
    {
      "epoch": 7.848,
      "grad_norm": 0.11286190897226334,
      "learning_rate": 1.0981632653061224e-05,
      "loss": 0.057,
      "step": 19620
    },
    {
      "epoch": 7.852,
      "grad_norm": 0.1826784610748291,
      "learning_rate": 1.0961224489795917e-05,
      "loss": 0.0409,
      "step": 19630
    },
    {
      "epoch": 7.856,
      "grad_norm": 0.38188332319259644,
      "learning_rate": 1.0940816326530612e-05,
      "loss": 0.0334,
      "step": 19640
    },
    {
      "epoch": 7.86,
      "grad_norm": 1.761231780052185,
      "learning_rate": 1.0920408163265307e-05,
      "loss": 0.076,
      "step": 19650
    },
    {
      "epoch": 7.864,
      "grad_norm": 2.384335517883301,
      "learning_rate": 1.09e-05,
      "loss": 0.1122,
      "step": 19660
    },
    {
      "epoch": 7.868,
      "grad_norm": 1.5997086763381958,
      "learning_rate": 1.0879591836734694e-05,
      "loss": 0.0745,
      "step": 19670
    },
    {
      "epoch": 7.872,
      "grad_norm": 2.057718276977539,
      "learning_rate": 1.0859183673469387e-05,
      "loss": 0.0688,
      "step": 19680
    },
    {
      "epoch": 7.876,
      "grad_norm": 0.5154147744178772,
      "learning_rate": 1.0838775510204082e-05,
      "loss": 0.0266,
      "step": 19690
    },
    {
      "epoch": 7.88,
      "grad_norm": 1.2357743978500366,
      "learning_rate": 1.0818367346938777e-05,
      "loss": 0.0771,
      "step": 19700
    },
    {
      "epoch": 7.884,
      "grad_norm": 0.07696957141160965,
      "learning_rate": 1.079795918367347e-05,
      "loss": 0.0763,
      "step": 19710
    },
    {
      "epoch": 7.888,
      "grad_norm": 0.8936722874641418,
      "learning_rate": 1.0777551020408164e-05,
      "loss": 0.0998,
      "step": 19720
    },
    {
      "epoch": 7.892,
      "grad_norm": 1.488614797592163,
      "learning_rate": 1.0757142857142857e-05,
      "loss": 0.0814,
      "step": 19730
    },
    {
      "epoch": 7.896,
      "grad_norm": 1.159820556640625,
      "learning_rate": 1.073673469387755e-05,
      "loss": 0.0841,
      "step": 19740
    },
    {
      "epoch": 7.9,
      "grad_norm": 1.8194125890731812,
      "learning_rate": 1.0716326530612245e-05,
      "loss": 0.0629,
      "step": 19750
    },
    {
      "epoch": 7.904,
      "grad_norm": 0.14145775139331818,
      "learning_rate": 1.069591836734694e-05,
      "loss": 0.0461,
      "step": 19760
    },
    {
      "epoch": 7.908,
      "grad_norm": 0.9291896820068359,
      "learning_rate": 1.0675510204081634e-05,
      "loss": 0.0434,
      "step": 19770
    },
    {
      "epoch": 7.912,
      "grad_norm": 0.2528593838214874,
      "learning_rate": 1.0655102040816327e-05,
      "loss": 0.1059,
      "step": 19780
    },
    {
      "epoch": 7.916,
      "grad_norm": 0.17696960270404816,
      "learning_rate": 1.063469387755102e-05,
      "loss": 0.0376,
      "step": 19790
    },
    {
      "epoch": 7.92,
      "grad_norm": 0.9805833697319031,
      "learning_rate": 1.0614285714285713e-05,
      "loss": 0.0454,
      "step": 19800
    },
    {
      "epoch": 7.924,
      "grad_norm": 0.2916257083415985,
      "learning_rate": 1.0593877551020408e-05,
      "loss": 0.0563,
      "step": 19810
    },
    {
      "epoch": 7.928,
      "grad_norm": 0.49155718088150024,
      "learning_rate": 1.0573469387755103e-05,
      "loss": 0.1239,
      "step": 19820
    },
    {
      "epoch": 7.932,
      "grad_norm": 1.9372891187667847,
      "learning_rate": 1.0553061224489797e-05,
      "loss": 0.0653,
      "step": 19830
    },
    {
      "epoch": 7.936,
      "grad_norm": 0.6210033893585205,
      "learning_rate": 1.053265306122449e-05,
      "loss": 0.0632,
      "step": 19840
    },
    {
      "epoch": 7.9399999999999995,
      "grad_norm": 0.6807532906532288,
      "learning_rate": 1.0512244897959183e-05,
      "loss": 0.0545,
      "step": 19850
    },
    {
      "epoch": 7.944,
      "grad_norm": 0.194626584649086,
      "learning_rate": 1.0491836734693878e-05,
      "loss": 0.0793,
      "step": 19860
    },
    {
      "epoch": 7.948,
      "grad_norm": 1.0116060972213745,
      "learning_rate": 1.0471428571428573e-05,
      "loss": 0.0784,
      "step": 19870
    },
    {
      "epoch": 7.952,
      "grad_norm": 1.6533095836639404,
      "learning_rate": 1.0451020408163266e-05,
      "loss": 0.0719,
      "step": 19880
    },
    {
      "epoch": 7.9559999999999995,
      "grad_norm": 0.6420762538909912,
      "learning_rate": 1.043061224489796e-05,
      "loss": 0.0637,
      "step": 19890
    },
    {
      "epoch": 7.96,
      "grad_norm": 0.08644137531518936,
      "learning_rate": 1.0410204081632653e-05,
      "loss": 0.0518,
      "step": 19900
    },
    {
      "epoch": 7.964,
      "grad_norm": 0.5781614780426025,
      "learning_rate": 1.0389795918367346e-05,
      "loss": 0.0731,
      "step": 19910
    },
    {
      "epoch": 7.968,
      "grad_norm": 1.616013765335083,
      "learning_rate": 1.0369387755102041e-05,
      "loss": 0.044,
      "step": 19920
    },
    {
      "epoch": 7.9719999999999995,
      "grad_norm": 0.14430752396583557,
      "learning_rate": 1.0348979591836736e-05,
      "loss": 0.041,
      "step": 19930
    },
    {
      "epoch": 7.976,
      "grad_norm": 0.04645627364516258,
      "learning_rate": 1.032857142857143e-05,
      "loss": 0.062,
      "step": 19940
    },
    {
      "epoch": 7.98,
      "grad_norm": 0.25047439336776733,
      "learning_rate": 1.0308163265306123e-05,
      "loss": 0.0586,
      "step": 19950
    },
    {
      "epoch": 7.984,
      "grad_norm": 0.1874603033065796,
      "learning_rate": 1.0287755102040816e-05,
      "loss": 0.0524,
      "step": 19960
    },
    {
      "epoch": 7.9879999999999995,
      "grad_norm": 0.4114021360874176,
      "learning_rate": 1.026734693877551e-05,
      "loss": 0.044,
      "step": 19970
    },
    {
      "epoch": 7.992,
      "grad_norm": 0.6438743472099304,
      "learning_rate": 1.0246938775510204e-05,
      "loss": 0.0565,
      "step": 19980
    },
    {
      "epoch": 7.996,
      "grad_norm": 0.12096365541219711,
      "learning_rate": 1.02265306122449e-05,
      "loss": 0.0709,
      "step": 19990
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.0031416416168213,
      "learning_rate": 1.0206122448979592e-05,
      "loss": 0.076,
      "step": 20000
    },
    {
      "epoch": 8.004,
      "grad_norm": 0.5901467800140381,
      "learning_rate": 1.0185714285714286e-05,
      "loss": 0.048,
      "step": 20010
    },
    {
      "epoch": 8.008,
      "grad_norm": 1.820924997329712,
      "learning_rate": 1.0165306122448979e-05,
      "loss": 0.0691,
      "step": 20020
    },
    {
      "epoch": 8.012,
      "grad_norm": 0.03303225338459015,
      "learning_rate": 1.0144897959183674e-05,
      "loss": 0.1182,
      "step": 20030
    },
    {
      "epoch": 8.016,
      "grad_norm": 0.20767465233802795,
      "learning_rate": 1.0124489795918369e-05,
      "loss": 0.0629,
      "step": 20040
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.46861982345581055,
      "learning_rate": 1.0104081632653062e-05,
      "loss": 0.0545,
      "step": 20050
    },
    {
      "epoch": 8.024,
      "grad_norm": 1.233295202255249,
      "learning_rate": 1.0083673469387755e-05,
      "loss": 0.0719,
      "step": 20060
    },
    {
      "epoch": 8.028,
      "grad_norm": 0.2519978880882263,
      "learning_rate": 1.0063265306122449e-05,
      "loss": 0.0518,
      "step": 20070
    },
    {
      "epoch": 8.032,
      "grad_norm": 1.6754006147384644,
      "learning_rate": 1.0042857142857142e-05,
      "loss": 0.084,
      "step": 20080
    },
    {
      "epoch": 8.036,
      "grad_norm": 0.3207131028175354,
      "learning_rate": 1.0022448979591837e-05,
      "loss": 0.0335,
      "step": 20090
    },
    {
      "epoch": 8.04,
      "grad_norm": 1.612077236175537,
      "learning_rate": 1.0002040816326532e-05,
      "loss": 0.0957,
      "step": 20100
    },
    {
      "epoch": 8.044,
      "grad_norm": 1.098413109779358,
      "learning_rate": 9.981632653061225e-06,
      "loss": 0.0593,
      "step": 20110
    },
    {
      "epoch": 8.048,
      "grad_norm": 1.0238233804702759,
      "learning_rate": 9.961224489795919e-06,
      "loss": 0.07,
      "step": 20120
    },
    {
      "epoch": 8.052,
      "grad_norm": 1.0519659519195557,
      "learning_rate": 9.940816326530612e-06,
      "loss": 0.07,
      "step": 20130
    },
    {
      "epoch": 8.056,
      "grad_norm": 1.218648076057434,
      "learning_rate": 9.920408163265305e-06,
      "loss": 0.0341,
      "step": 20140
    },
    {
      "epoch": 8.06,
      "grad_norm": 0.5429235696792603,
      "learning_rate": 9.900000000000002e-06,
      "loss": 0.0872,
      "step": 20150
    },
    {
      "epoch": 8.064,
      "grad_norm": 1.276976227760315,
      "learning_rate": 9.879591836734695e-06,
      "loss": 0.065,
      "step": 20160
    },
    {
      "epoch": 8.068,
      "grad_norm": 1.404952883720398,
      "learning_rate": 9.859183673469388e-06,
      "loss": 0.0427,
      "step": 20170
    },
    {
      "epoch": 8.072,
      "grad_norm": 0.2693381905555725,
      "learning_rate": 9.838775510204082e-06,
      "loss": 0.0595,
      "step": 20180
    },
    {
      "epoch": 8.076,
      "grad_norm": 1.8537899255752563,
      "learning_rate": 9.818367346938775e-06,
      "loss": 0.0549,
      "step": 20190
    },
    {
      "epoch": 8.08,
      "grad_norm": 0.5295649170875549,
      "learning_rate": 9.79795918367347e-06,
      "loss": 0.0403,
      "step": 20200
    },
    {
      "epoch": 8.084,
      "grad_norm": 1.1967657804489136,
      "learning_rate": 9.777551020408165e-06,
      "loss": 0.0558,
      "step": 20210
    },
    {
      "epoch": 8.088,
      "grad_norm": 1.0557399988174438,
      "learning_rate": 9.757142857142858e-06,
      "loss": 0.0593,
      "step": 20220
    },
    {
      "epoch": 8.092,
      "grad_norm": 1.346042513847351,
      "learning_rate": 9.736734693877551e-06,
      "loss": 0.0414,
      "step": 20230
    },
    {
      "epoch": 8.096,
      "grad_norm": 0.7135373950004578,
      "learning_rate": 9.716326530612245e-06,
      "loss": 0.0615,
      "step": 20240
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.34199875593185425,
      "learning_rate": 9.695918367346938e-06,
      "loss": 0.0533,
      "step": 20250
    },
    {
      "epoch": 8.104,
      "grad_norm": 1.0689826011657715,
      "learning_rate": 9.675510204081633e-06,
      "loss": 0.1161,
      "step": 20260
    },
    {
      "epoch": 8.108,
      "grad_norm": 0.17435725033283234,
      "learning_rate": 9.655102040816328e-06,
      "loss": 0.0562,
      "step": 20270
    },
    {
      "epoch": 8.112,
      "grad_norm": 0.5720546245574951,
      "learning_rate": 9.634693877551021e-06,
      "loss": 0.0506,
      "step": 20280
    },
    {
      "epoch": 8.116,
      "grad_norm": 0.3384912610054016,
      "learning_rate": 9.614285714285714e-06,
      "loss": 0.0709,
      "step": 20290
    },
    {
      "epoch": 8.12,
      "grad_norm": 0.8911347985267639,
      "learning_rate": 9.593877551020408e-06,
      "loss": 0.0854,
      "step": 20300
    },
    {
      "epoch": 8.124,
      "grad_norm": 0.4718106985092163,
      "learning_rate": 9.573469387755101e-06,
      "loss": 0.0411,
      "step": 20310
    },
    {
      "epoch": 8.128,
      "grad_norm": 0.5102283954620361,
      "learning_rate": 9.553061224489798e-06,
      "loss": 0.0659,
      "step": 20320
    },
    {
      "epoch": 8.132,
      "grad_norm": 1.3424992561340332,
      "learning_rate": 9.532653061224491e-06,
      "loss": 0.0602,
      "step": 20330
    },
    {
      "epoch": 8.136,
      "grad_norm": 0.013763898983597755,
      "learning_rate": 9.512244897959184e-06,
      "loss": 0.0683,
      "step": 20340
    },
    {
      "epoch": 8.14,
      "grad_norm": 0.5043348073959351,
      "learning_rate": 9.491836734693877e-06,
      "loss": 0.0289,
      "step": 20350
    },
    {
      "epoch": 8.144,
      "grad_norm": 1.1700717210769653,
      "learning_rate": 9.47142857142857e-06,
      "loss": 0.1055,
      "step": 20360
    },
    {
      "epoch": 8.148,
      "grad_norm": 0.33269819617271423,
      "learning_rate": 9.451020408163266e-06,
      "loss": 0.0637,
      "step": 20370
    },
    {
      "epoch": 8.152,
      "grad_norm": 0.08365264534950256,
      "learning_rate": 9.43061224489796e-06,
      "loss": 0.0388,
      "step": 20380
    },
    {
      "epoch": 8.156,
      "grad_norm": 0.009747214615345001,
      "learning_rate": 9.410204081632654e-06,
      "loss": 0.042,
      "step": 20390
    },
    {
      "epoch": 8.16,
      "grad_norm": 1.134003758430481,
      "learning_rate": 9.389795918367347e-06,
      "loss": 0.0386,
      "step": 20400
    },
    {
      "epoch": 8.164,
      "grad_norm": 0.21477010846138,
      "learning_rate": 9.36938775510204e-06,
      "loss": 0.0652,
      "step": 20410
    },
    {
      "epoch": 8.168,
      "grad_norm": 0.4259743094444275,
      "learning_rate": 9.348979591836734e-06,
      "loss": 0.0415,
      "step": 20420
    },
    {
      "epoch": 8.172,
      "grad_norm": 0.4703303575515747,
      "learning_rate": 9.328571428571429e-06,
      "loss": 0.0435,
      "step": 20430
    },
    {
      "epoch": 8.176,
      "grad_norm": 2.262064218521118,
      "learning_rate": 9.308163265306124e-06,
      "loss": 0.0807,
      "step": 20440
    },
    {
      "epoch": 8.18,
      "grad_norm": 0.9533348679542542,
      "learning_rate": 9.287755102040817e-06,
      "loss": 0.0385,
      "step": 20450
    },
    {
      "epoch": 8.184,
      "grad_norm": 1.127063274383545,
      "learning_rate": 9.26734693877551e-06,
      "loss": 0.0591,
      "step": 20460
    },
    {
      "epoch": 8.188,
      "grad_norm": 0.7911510467529297,
      "learning_rate": 9.246938775510204e-06,
      "loss": 0.0949,
      "step": 20470
    },
    {
      "epoch": 8.192,
      "grad_norm": 1.022821307182312,
      "learning_rate": 9.226530612244899e-06,
      "loss": 0.0745,
      "step": 20480
    },
    {
      "epoch": 8.196,
      "grad_norm": 0.4927687346935272,
      "learning_rate": 9.206122448979594e-06,
      "loss": 0.0394,
      "step": 20490
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.40907835960388184,
      "learning_rate": 9.185714285714287e-06,
      "loss": 0.0582,
      "step": 20500
    },
    {
      "epoch": 8.204,
      "grad_norm": 0.3676616847515106,
      "learning_rate": 9.16530612244898e-06,
      "loss": 0.0724,
      "step": 20510
    },
    {
      "epoch": 8.208,
      "grad_norm": 0.899603009223938,
      "learning_rate": 9.144897959183673e-06,
      "loss": 0.0695,
      "step": 20520
    },
    {
      "epoch": 8.212,
      "grad_norm": 1.405135154724121,
      "learning_rate": 9.124489795918367e-06,
      "loss": 0.0638,
      "step": 20530
    },
    {
      "epoch": 8.216,
      "grad_norm": 1.4257036447525024,
      "learning_rate": 9.104081632653062e-06,
      "loss": 0.0877,
      "step": 20540
    },
    {
      "epoch": 8.22,
      "grad_norm": 0.908964216709137,
      "learning_rate": 9.083673469387757e-06,
      "loss": 0.0557,
      "step": 20550
    },
    {
      "epoch": 8.224,
      "grad_norm": 1.07976233959198,
      "learning_rate": 9.06326530612245e-06,
      "loss": 0.064,
      "step": 20560
    },
    {
      "epoch": 8.228,
      "grad_norm": 1.079768180847168,
      "learning_rate": 9.042857142857143e-06,
      "loss": 0.0459,
      "step": 20570
    },
    {
      "epoch": 8.232,
      "grad_norm": 1.5562151670455933,
      "learning_rate": 9.022448979591836e-06,
      "loss": 0.0683,
      "step": 20580
    },
    {
      "epoch": 8.236,
      "grad_norm": 0.0759863629937172,
      "learning_rate": 9.00204081632653e-06,
      "loss": 0.0408,
      "step": 20590
    },
    {
      "epoch": 8.24,
      "grad_norm": 0.6690840721130371,
      "learning_rate": 8.981632653061225e-06,
      "loss": 0.0659,
      "step": 20600
    },
    {
      "epoch": 8.244,
      "grad_norm": 1.4813923835754395,
      "learning_rate": 8.96122448979592e-06,
      "loss": 0.0933,
      "step": 20610
    },
    {
      "epoch": 8.248,
      "grad_norm": 2.1361355781555176,
      "learning_rate": 8.940816326530613e-06,
      "loss": 0.0837,
      "step": 20620
    },
    {
      "epoch": 8.252,
      "grad_norm": 1.236028790473938,
      "learning_rate": 8.920408163265306e-06,
      "loss": 0.0719,
      "step": 20630
    },
    {
      "epoch": 8.256,
      "grad_norm": 1.3234267234802246,
      "learning_rate": 8.9e-06,
      "loss": 0.069,
      "step": 20640
    },
    {
      "epoch": 8.26,
      "grad_norm": 0.06148185580968857,
      "learning_rate": 8.879591836734694e-06,
      "loss": 0.067,
      "step": 20650
    },
    {
      "epoch": 8.264,
      "grad_norm": 0.6344675421714783,
      "learning_rate": 8.85918367346939e-06,
      "loss": 0.0442,
      "step": 20660
    },
    {
      "epoch": 8.268,
      "grad_norm": 1.3777073621749878,
      "learning_rate": 8.838775510204083e-06,
      "loss": 0.0786,
      "step": 20670
    },
    {
      "epoch": 8.272,
      "grad_norm": 1.0119402408599854,
      "learning_rate": 8.818367346938776e-06,
      "loss": 0.0485,
      "step": 20680
    },
    {
      "epoch": 8.276,
      "grad_norm": 0.48319971561431885,
      "learning_rate": 8.79795918367347e-06,
      "loss": 0.0253,
      "step": 20690
    },
    {
      "epoch": 8.28,
      "grad_norm": 0.32044631242752075,
      "learning_rate": 8.777551020408163e-06,
      "loss": 0.1004,
      "step": 20700
    },
    {
      "epoch": 8.284,
      "grad_norm": 0.8619548082351685,
      "learning_rate": 8.757142857142858e-06,
      "loss": 0.0927,
      "step": 20710
    },
    {
      "epoch": 8.288,
      "grad_norm": 0.1442522257566452,
      "learning_rate": 8.736734693877552e-06,
      "loss": 0.0767,
      "step": 20720
    },
    {
      "epoch": 8.292,
      "grad_norm": 1.1354488134384155,
      "learning_rate": 8.716326530612246e-06,
      "loss": 0.062,
      "step": 20730
    },
    {
      "epoch": 8.296,
      "grad_norm": 0.6808655261993408,
      "learning_rate": 8.695918367346939e-06,
      "loss": 0.0559,
      "step": 20740
    },
    {
      "epoch": 8.3,
      "grad_norm": 0.9352748990058899,
      "learning_rate": 8.675510204081632e-06,
      "loss": 0.0433,
      "step": 20750
    },
    {
      "epoch": 8.304,
      "grad_norm": 0.5296128392219543,
      "learning_rate": 8.655102040816326e-06,
      "loss": 0.046,
      "step": 20760
    },
    {
      "epoch": 8.308,
      "grad_norm": 1.3185391426086426,
      "learning_rate": 8.63469387755102e-06,
      "loss": 0.0268,
      "step": 20770
    },
    {
      "epoch": 8.312,
      "grad_norm": 0.9316660165786743,
      "learning_rate": 8.614285714285716e-06,
      "loss": 0.0407,
      "step": 20780
    },
    {
      "epoch": 8.316,
      "grad_norm": 1.6872166395187378,
      "learning_rate": 8.593877551020409e-06,
      "loss": 0.0837,
      "step": 20790
    },
    {
      "epoch": 8.32,
      "grad_norm": 1.2446341514587402,
      "learning_rate": 8.573469387755102e-06,
      "loss": 0.0743,
      "step": 20800
    },
    {
      "epoch": 8.324,
      "grad_norm": 0.965210497379303,
      "learning_rate": 8.553061224489795e-06,
      "loss": 0.0862,
      "step": 20810
    },
    {
      "epoch": 8.328,
      "grad_norm": 0.36537837982177734,
      "learning_rate": 8.53265306122449e-06,
      "loss": 0.0363,
      "step": 20820
    },
    {
      "epoch": 8.332,
      "grad_norm": 0.5132481455802917,
      "learning_rate": 8.512244897959185e-06,
      "loss": 0.0383,
      "step": 20830
    },
    {
      "epoch": 8.336,
      "grad_norm": 0.06605292856693268,
      "learning_rate": 8.491836734693879e-06,
      "loss": 0.0441,
      "step": 20840
    },
    {
      "epoch": 8.34,
      "grad_norm": 1.3161931037902832,
      "learning_rate": 8.471428571428572e-06,
      "loss": 0.0574,
      "step": 20850
    },
    {
      "epoch": 8.344,
      "grad_norm": 1.3148928880691528,
      "learning_rate": 8.451020408163265e-06,
      "loss": 0.0504,
      "step": 20860
    },
    {
      "epoch": 8.348,
      "grad_norm": 1.2492046356201172,
      "learning_rate": 8.430612244897958e-06,
      "loss": 0.0472,
      "step": 20870
    },
    {
      "epoch": 8.352,
      "grad_norm": 0.9640190005302429,
      "learning_rate": 8.410204081632653e-06,
      "loss": 0.0848,
      "step": 20880
    },
    {
      "epoch": 8.356,
      "grad_norm": 1.2952722311019897,
      "learning_rate": 8.389795918367348e-06,
      "loss": 0.0571,
      "step": 20890
    },
    {
      "epoch": 8.36,
      "grad_norm": 1.6006159782409668,
      "learning_rate": 8.369387755102042e-06,
      "loss": 0.0716,
      "step": 20900
    },
    {
      "epoch": 8.364,
      "grad_norm": 0.117616206407547,
      "learning_rate": 8.348979591836735e-06,
      "loss": 0.0506,
      "step": 20910
    },
    {
      "epoch": 8.368,
      "grad_norm": 1.096873164176941,
      "learning_rate": 8.328571428571428e-06,
      "loss": 0.0377,
      "step": 20920
    },
    {
      "epoch": 8.372,
      "grad_norm": 1.0446078777313232,
      "learning_rate": 8.308163265306121e-06,
      "loss": 0.059,
      "step": 20930
    },
    {
      "epoch": 8.376,
      "grad_norm": 1.3642921447753906,
      "learning_rate": 8.287755102040816e-06,
      "loss": 0.0466,
      "step": 20940
    },
    {
      "epoch": 8.38,
      "grad_norm": 0.6488432288169861,
      "learning_rate": 8.267346938775511e-06,
      "loss": 0.0632,
      "step": 20950
    },
    {
      "epoch": 8.384,
      "grad_norm": 0.8097265958786011,
      "learning_rate": 8.246938775510205e-06,
      "loss": 0.0486,
      "step": 20960
    },
    {
      "epoch": 8.388,
      "grad_norm": 1.0632520914077759,
      "learning_rate": 8.226530612244898e-06,
      "loss": 0.0771,
      "step": 20970
    },
    {
      "epoch": 8.392,
      "grad_norm": 0.24121159315109253,
      "learning_rate": 8.206122448979591e-06,
      "loss": 0.0545,
      "step": 20980
    },
    {
      "epoch": 8.396,
      "grad_norm": 0.8479042649269104,
      "learning_rate": 8.185714285714286e-06,
      "loss": 0.0593,
      "step": 20990
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.5874834656715393,
      "learning_rate": 8.165306122448981e-06,
      "loss": 0.0349,
      "step": 21000
    },
    {
      "epoch": 8.404,
      "grad_norm": 0.42076370120048523,
      "learning_rate": 8.144897959183674e-06,
      "loss": 0.0748,
      "step": 21010
    },
    {
      "epoch": 8.408,
      "grad_norm": 0.9394983649253845,
      "learning_rate": 8.124489795918368e-06,
      "loss": 0.0631,
      "step": 21020
    },
    {
      "epoch": 8.412,
      "grad_norm": 0.9502449631690979,
      "learning_rate": 8.104081632653061e-06,
      "loss": 0.077,
      "step": 21030
    },
    {
      "epoch": 8.416,
      "grad_norm": 0.08129574358463287,
      "learning_rate": 8.083673469387754e-06,
      "loss": 0.0571,
      "step": 21040
    },
    {
      "epoch": 8.42,
      "grad_norm": 0.2377379983663559,
      "learning_rate": 8.06326530612245e-06,
      "loss": 0.0417,
      "step": 21050
    },
    {
      "epoch": 8.424,
      "grad_norm": 0.991127610206604,
      "learning_rate": 8.042857142857144e-06,
      "loss": 0.0389,
      "step": 21060
    },
    {
      "epoch": 8.428,
      "grad_norm": 1.5451085567474365,
      "learning_rate": 8.022448979591838e-06,
      "loss": 0.1159,
      "step": 21070
    },
    {
      "epoch": 8.432,
      "grad_norm": 0.4491705298423767,
      "learning_rate": 8.00204081632653e-06,
      "loss": 0.0262,
      "step": 21080
    },
    {
      "epoch": 8.436,
      "grad_norm": 0.37781184911727905,
      "learning_rate": 7.981632653061224e-06,
      "loss": 0.055,
      "step": 21090
    },
    {
      "epoch": 8.44,
      "grad_norm": 0.6521828174591064,
      "learning_rate": 7.961224489795917e-06,
      "loss": 0.0965,
      "step": 21100
    },
    {
      "epoch": 8.444,
      "grad_norm": 1.1455459594726562,
      "learning_rate": 7.940816326530612e-06,
      "loss": 0.0539,
      "step": 21110
    },
    {
      "epoch": 8.448,
      "grad_norm": 0.16835874319076538,
      "learning_rate": 7.920408163265307e-06,
      "loss": 0.0726,
      "step": 21120
    },
    {
      "epoch": 8.452,
      "grad_norm": 0.46472957730293274,
      "learning_rate": 7.9e-06,
      "loss": 0.0776,
      "step": 21130
    },
    {
      "epoch": 8.456,
      "grad_norm": 1.0303363800048828,
      "learning_rate": 7.879591836734694e-06,
      "loss": 0.0852,
      "step": 21140
    },
    {
      "epoch": 8.46,
      "grad_norm": 1.1826403141021729,
      "learning_rate": 7.859183673469387e-06,
      "loss": 0.0577,
      "step": 21150
    },
    {
      "epoch": 8.464,
      "grad_norm": 0.10013877600431442,
      "learning_rate": 7.838775510204082e-06,
      "loss": 0.0789,
      "step": 21160
    },
    {
      "epoch": 8.468,
      "grad_norm": 0.9523593187332153,
      "learning_rate": 7.818367346938777e-06,
      "loss": 0.0804,
      "step": 21170
    },
    {
      "epoch": 8.472,
      "grad_norm": 0.1711786836385727,
      "learning_rate": 7.79795918367347e-06,
      "loss": 0.0324,
      "step": 21180
    },
    {
      "epoch": 8.475999999999999,
      "grad_norm": 0.3981999456882477,
      "learning_rate": 7.777551020408164e-06,
      "loss": 0.0818,
      "step": 21190
    },
    {
      "epoch": 8.48,
      "grad_norm": 2.268476963043213,
      "learning_rate": 7.757142857142857e-06,
      "loss": 0.0811,
      "step": 21200
    },
    {
      "epoch": 8.484,
      "grad_norm": 1.0398597717285156,
      "learning_rate": 7.73673469387755e-06,
      "loss": 0.0681,
      "step": 21210
    },
    {
      "epoch": 8.488,
      "grad_norm": 0.1029260903596878,
      "learning_rate": 7.716326530612245e-06,
      "loss": 0.0585,
      "step": 21220
    },
    {
      "epoch": 8.492,
      "grad_norm": 0.29506394267082214,
      "learning_rate": 7.69591836734694e-06,
      "loss": 0.0448,
      "step": 21230
    },
    {
      "epoch": 8.496,
      "grad_norm": 0.6336995363235474,
      "learning_rate": 7.675510204081633e-06,
      "loss": 0.0685,
      "step": 21240
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.7140724658966064,
      "learning_rate": 7.655102040816327e-06,
      "loss": 0.1219,
      "step": 21250
    },
    {
      "epoch": 8.504,
      "grad_norm": 0.5291928052902222,
      "learning_rate": 7.63469387755102e-06,
      "loss": 0.0496,
      "step": 21260
    },
    {
      "epoch": 8.508,
      "grad_norm": 2.5560240745544434,
      "learning_rate": 7.614285714285714e-06,
      "loss": 0.1287,
      "step": 21270
    },
    {
      "epoch": 8.512,
      "grad_norm": 0.27626046538352966,
      "learning_rate": 7.593877551020409e-06,
      "loss": 0.0699,
      "step": 21280
    },
    {
      "epoch": 8.516,
      "grad_norm": 0.13094095885753632,
      "learning_rate": 7.573469387755102e-06,
      "loss": 0.0415,
      "step": 21290
    },
    {
      "epoch": 8.52,
      "grad_norm": 1.5902655124664307,
      "learning_rate": 7.5530612244897965e-06,
      "loss": 0.0755,
      "step": 21300
    },
    {
      "epoch": 8.524000000000001,
      "grad_norm": 0.9997512102127075,
      "learning_rate": 7.53265306122449e-06,
      "loss": 0.042,
      "step": 21310
    },
    {
      "epoch": 8.528,
      "grad_norm": 2.0638175010681152,
      "learning_rate": 7.512244897959184e-06,
      "loss": 0.0487,
      "step": 21320
    },
    {
      "epoch": 8.532,
      "grad_norm": 1.0896198749542236,
      "learning_rate": 7.491836734693877e-06,
      "loss": 0.0497,
      "step": 21330
    },
    {
      "epoch": 8.536,
      "grad_norm": 0.4663861393928528,
      "learning_rate": 7.471428571428572e-06,
      "loss": 0.0385,
      "step": 21340
    },
    {
      "epoch": 8.54,
      "grad_norm": 0.8310793042182922,
      "learning_rate": 7.451020408163266e-06,
      "loss": 0.0605,
      "step": 21350
    },
    {
      "epoch": 8.544,
      "grad_norm": 0.8187574744224548,
      "learning_rate": 7.4306122448979595e-06,
      "loss": 0.0413,
      "step": 21360
    },
    {
      "epoch": 8.548,
      "grad_norm": 0.19173263013362885,
      "learning_rate": 7.410204081632653e-06,
      "loss": 0.0199,
      "step": 21370
    },
    {
      "epoch": 8.552,
      "grad_norm": 2.35388445854187,
      "learning_rate": 7.389795918367347e-06,
      "loss": 0.0856,
      "step": 21380
    },
    {
      "epoch": 8.556000000000001,
      "grad_norm": 1.3815797567367554,
      "learning_rate": 7.369387755102042e-06,
      "loss": 0.0682,
      "step": 21390
    },
    {
      "epoch": 8.56,
      "grad_norm": 0.026889026165008545,
      "learning_rate": 7.348979591836735e-06,
      "loss": 0.0228,
      "step": 21400
    },
    {
      "epoch": 8.564,
      "grad_norm": 0.7647515535354614,
      "learning_rate": 7.328571428571429e-06,
      "loss": 0.0562,
      "step": 21410
    },
    {
      "epoch": 8.568,
      "grad_norm": 2.1108803749084473,
      "learning_rate": 7.308163265306123e-06,
      "loss": 0.1098,
      "step": 21420
    },
    {
      "epoch": 8.572,
      "grad_norm": 0.2786640524864197,
      "learning_rate": 7.287755102040817e-06,
      "loss": 0.0499,
      "step": 21430
    },
    {
      "epoch": 8.576,
      "grad_norm": 1.6565625667572021,
      "learning_rate": 7.26734693877551e-06,
      "loss": 0.0683,
      "step": 21440
    },
    {
      "epoch": 8.58,
      "grad_norm": 0.8438428640365601,
      "learning_rate": 7.246938775510205e-06,
      "loss": 0.0437,
      "step": 21450
    },
    {
      "epoch": 8.584,
      "grad_norm": 0.9622299075126648,
      "learning_rate": 7.226530612244898e-06,
      "loss": 0.0356,
      "step": 21460
    },
    {
      "epoch": 8.588,
      "grad_norm": 0.1727714091539383,
      "learning_rate": 7.206122448979592e-06,
      "loss": 0.0458,
      "step": 21470
    },
    {
      "epoch": 8.592,
      "grad_norm": 0.4497841000556946,
      "learning_rate": 7.185714285714286e-06,
      "loss": 0.0372,
      "step": 21480
    },
    {
      "epoch": 8.596,
      "grad_norm": 1.0522829294204712,
      "learning_rate": 7.16530612244898e-06,
      "loss": 0.0661,
      "step": 21490
    },
    {
      "epoch": 8.6,
      "grad_norm": 1.2017254829406738,
      "learning_rate": 7.144897959183673e-06,
      "loss": 0.0725,
      "step": 21500
    },
    {
      "epoch": 8.604,
      "grad_norm": 1.3732776641845703,
      "learning_rate": 7.124489795918368e-06,
      "loss": 0.0538,
      "step": 21510
    },
    {
      "epoch": 8.608,
      "grad_norm": 0.8857055902481079,
      "learning_rate": 7.104081632653062e-06,
      "loss": 0.0371,
      "step": 21520
    },
    {
      "epoch": 8.612,
      "grad_norm": 0.581195592880249,
      "learning_rate": 7.083673469387755e-06,
      "loss": 0.0394,
      "step": 21530
    },
    {
      "epoch": 8.616,
      "grad_norm": 1.1041275262832642,
      "learning_rate": 7.063265306122449e-06,
      "loss": 0.055,
      "step": 21540
    },
    {
      "epoch": 8.62,
      "grad_norm": 0.6861816048622131,
      "learning_rate": 7.042857142857143e-06,
      "loss": 0.0394,
      "step": 21550
    },
    {
      "epoch": 8.624,
      "grad_norm": 1.5508824586868286,
      "learning_rate": 7.022448979591838e-06,
      "loss": 0.1315,
      "step": 21560
    },
    {
      "epoch": 8.628,
      "grad_norm": 1.3470802307128906,
      "learning_rate": 7.002040816326531e-06,
      "loss": 0.0813,
      "step": 21570
    },
    {
      "epoch": 8.632,
      "grad_norm": 0.17261789739131927,
      "learning_rate": 6.981632653061225e-06,
      "loss": 0.0627,
      "step": 21580
    },
    {
      "epoch": 8.636,
      "grad_norm": 1.2606520652770996,
      "learning_rate": 6.9612244897959185e-06,
      "loss": 0.0554,
      "step": 21590
    },
    {
      "epoch": 8.64,
      "grad_norm": 0.16370302438735962,
      "learning_rate": 6.940816326530613e-06,
      "loss": 0.0512,
      "step": 21600
    },
    {
      "epoch": 8.644,
      "grad_norm": 0.5171160697937012,
      "learning_rate": 6.920408163265306e-06,
      "loss": 0.084,
      "step": 21610
    },
    {
      "epoch": 8.648,
      "grad_norm": 0.7943912148475647,
      "learning_rate": 6.900000000000001e-06,
      "loss": 0.0355,
      "step": 21620
    },
    {
      "epoch": 8.652,
      "grad_norm": 1.1547067165374756,
      "learning_rate": 6.879591836734694e-06,
      "loss": 0.0762,
      "step": 21630
    },
    {
      "epoch": 8.656,
      "grad_norm": 0.13485075533390045,
      "learning_rate": 6.859183673469388e-06,
      "loss": 0.0742,
      "step": 21640
    },
    {
      "epoch": 8.66,
      "grad_norm": 0.49224454164505005,
      "learning_rate": 6.8387755102040815e-06,
      "loss": 0.0632,
      "step": 21650
    },
    {
      "epoch": 8.664,
      "grad_norm": 0.8239928483963013,
      "learning_rate": 6.818367346938776e-06,
      "loss": 0.0266,
      "step": 21660
    },
    {
      "epoch": 8.668,
      "grad_norm": 0.5214343667030334,
      "learning_rate": 6.797959183673469e-06,
      "loss": 0.0888,
      "step": 21670
    },
    {
      "epoch": 8.672,
      "grad_norm": 0.9141854047775269,
      "learning_rate": 6.777551020408164e-06,
      "loss": 0.0762,
      "step": 21680
    },
    {
      "epoch": 8.676,
      "grad_norm": 0.6303664445877075,
      "learning_rate": 6.757142857142858e-06,
      "loss": 0.082,
      "step": 21690
    },
    {
      "epoch": 8.68,
      "grad_norm": 0.5326265096664429,
      "learning_rate": 6.736734693877551e-06,
      "loss": 0.0347,
      "step": 21700
    },
    {
      "epoch": 8.684,
      "grad_norm": 0.05865684896707535,
      "learning_rate": 6.716326530612245e-06,
      "loss": 0.0322,
      "step": 21710
    },
    {
      "epoch": 8.688,
      "grad_norm": 0.16803193092346191,
      "learning_rate": 6.695918367346939e-06,
      "loss": 0.0394,
      "step": 21720
    },
    {
      "epoch": 8.692,
      "grad_norm": 0.39496034383773804,
      "learning_rate": 6.675510204081634e-06,
      "loss": 0.1015,
      "step": 21730
    },
    {
      "epoch": 8.696,
      "grad_norm": 0.7220191359519958,
      "learning_rate": 6.655102040816327e-06,
      "loss": 0.0654,
      "step": 21740
    },
    {
      "epoch": 8.7,
      "grad_norm": 1.109406590461731,
      "learning_rate": 6.634693877551021e-06,
      "loss": 0.0418,
      "step": 21750
    },
    {
      "epoch": 8.704,
      "grad_norm": 0.6610082387924194,
      "learning_rate": 6.614285714285714e-06,
      "loss": 0.0709,
      "step": 21760
    },
    {
      "epoch": 8.708,
      "grad_norm": 0.42524388432502747,
      "learning_rate": 6.5938775510204085e-06,
      "loss": 0.1006,
      "step": 21770
    },
    {
      "epoch": 8.712,
      "grad_norm": 1.2064763307571411,
      "learning_rate": 6.573469387755102e-06,
      "loss": 0.0999,
      "step": 21780
    },
    {
      "epoch": 8.716,
      "grad_norm": 1.138913631439209,
      "learning_rate": 6.553061224489797e-06,
      "loss": 0.0964,
      "step": 21790
    },
    {
      "epoch": 8.72,
      "grad_norm": 0.5144635438919067,
      "learning_rate": 6.532653061224491e-06,
      "loss": 0.0587,
      "step": 21800
    },
    {
      "epoch": 8.724,
      "grad_norm": 0.7157074809074402,
      "learning_rate": 6.512244897959184e-06,
      "loss": 0.0583,
      "step": 21810
    },
    {
      "epoch": 8.728,
      "grad_norm": 0.5316373705863953,
      "learning_rate": 6.491836734693877e-06,
      "loss": 0.0751,
      "step": 21820
    },
    {
      "epoch": 8.732,
      "grad_norm": 0.7327598333358765,
      "learning_rate": 6.4714285714285715e-06,
      "loss": 0.0677,
      "step": 21830
    },
    {
      "epoch": 8.736,
      "grad_norm": 0.9116663932800293,
      "learning_rate": 6.451020408163265e-06,
      "loss": 0.0886,
      "step": 21840
    },
    {
      "epoch": 8.74,
      "grad_norm": 0.6821489334106445,
      "learning_rate": 6.43061224489796e-06,
      "loss": 0.0625,
      "step": 21850
    },
    {
      "epoch": 8.744,
      "grad_norm": 2.1857383251190186,
      "learning_rate": 6.410204081632654e-06,
      "loss": 0.0825,
      "step": 21860
    },
    {
      "epoch": 8.748,
      "grad_norm": 0.17567241191864014,
      "learning_rate": 6.389795918367347e-06,
      "loss": 0.0287,
      "step": 21870
    },
    {
      "epoch": 8.752,
      "grad_norm": 1.8014332056045532,
      "learning_rate": 6.3693877551020405e-06,
      "loss": 0.0342,
      "step": 21880
    },
    {
      "epoch": 8.756,
      "grad_norm": 0.3941052556037903,
      "learning_rate": 6.348979591836735e-06,
      "loss": 0.0278,
      "step": 21890
    },
    {
      "epoch": 8.76,
      "grad_norm": 0.05874639376997948,
      "learning_rate": 6.3285714285714296e-06,
      "loss": 0.0435,
      "step": 21900
    },
    {
      "epoch": 8.764,
      "grad_norm": 0.8892983198165894,
      "learning_rate": 6.308163265306123e-06,
      "loss": 0.052,
      "step": 21910
    },
    {
      "epoch": 8.768,
      "grad_norm": 0.01060410588979721,
      "learning_rate": 6.287755102040817e-06,
      "loss": 0.0691,
      "step": 21920
    },
    {
      "epoch": 8.772,
      "grad_norm": 0.1763831526041031,
      "learning_rate": 6.26734693877551e-06,
      "loss": 0.0496,
      "step": 21930
    },
    {
      "epoch": 8.776,
      "grad_norm": 1.3355841636657715,
      "learning_rate": 6.246938775510204e-06,
      "loss": 0.1,
      "step": 21940
    },
    {
      "epoch": 8.78,
      "grad_norm": 0.542424738407135,
      "learning_rate": 6.2265306122448985e-06,
      "loss": 0.0603,
      "step": 21950
    },
    {
      "epoch": 8.784,
      "grad_norm": 0.23891720175743103,
      "learning_rate": 6.206122448979592e-06,
      "loss": 0.0328,
      "step": 21960
    },
    {
      "epoch": 8.788,
      "grad_norm": 1.2538622617721558,
      "learning_rate": 6.185714285714287e-06,
      "loss": 0.0467,
      "step": 21970
    },
    {
      "epoch": 8.792,
      "grad_norm": 0.1618814617395401,
      "learning_rate": 6.16530612244898e-06,
      "loss": 0.032,
      "step": 21980
    },
    {
      "epoch": 8.796,
      "grad_norm": 0.5622094869613647,
      "learning_rate": 6.144897959183673e-06,
      "loss": 0.0479,
      "step": 21990
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.4220842719078064,
      "learning_rate": 6.124489795918368e-06,
      "loss": 0.0756,
      "step": 22000
    },
    {
      "epoch": 8.804,
      "grad_norm": 1.2540048360824585,
      "learning_rate": 6.1040816326530616e-06,
      "loss": 0.0409,
      "step": 22010
    },
    {
      "epoch": 8.808,
      "grad_norm": 1.0539265871047974,
      "learning_rate": 6.083673469387755e-06,
      "loss": 0.0686,
      "step": 22020
    },
    {
      "epoch": 8.812,
      "grad_norm": 0.29953065514564514,
      "learning_rate": 6.06326530612245e-06,
      "loss": 0.071,
      "step": 22030
    },
    {
      "epoch": 8.816,
      "grad_norm": 1.0109639167785645,
      "learning_rate": 6.042857142857143e-06,
      "loss": 0.0333,
      "step": 22040
    },
    {
      "epoch": 8.82,
      "grad_norm": 0.4142221212387085,
      "learning_rate": 6.022448979591837e-06,
      "loss": 0.0574,
      "step": 22050
    },
    {
      "epoch": 8.824,
      "grad_norm": 2.940659523010254,
      "learning_rate": 6.002040816326531e-06,
      "loss": 0.0975,
      "step": 22060
    },
    {
      "epoch": 8.828,
      "grad_norm": 0.5777759552001953,
      "learning_rate": 5.981632653061225e-06,
      "loss": 0.0671,
      "step": 22070
    },
    {
      "epoch": 8.832,
      "grad_norm": 1.331104040145874,
      "learning_rate": 5.961224489795919e-06,
      "loss": 0.08,
      "step": 22080
    },
    {
      "epoch": 8.836,
      "grad_norm": 0.5046334266662598,
      "learning_rate": 5.940816326530613e-06,
      "loss": 0.0459,
      "step": 22090
    },
    {
      "epoch": 8.84,
      "grad_norm": 1.7264460325241089,
      "learning_rate": 5.920408163265306e-06,
      "loss": 0.0651,
      "step": 22100
    },
    {
      "epoch": 8.844,
      "grad_norm": 0.27652549743652344,
      "learning_rate": 5.9e-06,
      "loss": 0.0298,
      "step": 22110
    },
    {
      "epoch": 8.848,
      "grad_norm": 0.7919347882270813,
      "learning_rate": 5.879591836734694e-06,
      "loss": 0.0714,
      "step": 22120
    },
    {
      "epoch": 8.852,
      "grad_norm": 0.9350985884666443,
      "learning_rate": 5.859183673469388e-06,
      "loss": 0.0484,
      "step": 22130
    },
    {
      "epoch": 8.856,
      "grad_norm": 0.12772326171398163,
      "learning_rate": 5.838775510204083e-06,
      "loss": 0.0571,
      "step": 22140
    },
    {
      "epoch": 8.86,
      "grad_norm": 1.4404751062393188,
      "learning_rate": 5.818367346938776e-06,
      "loss": 0.0529,
      "step": 22150
    },
    {
      "epoch": 8.864,
      "grad_norm": 1.001227855682373,
      "learning_rate": 5.797959183673469e-06,
      "loss": 0.0645,
      "step": 22160
    },
    {
      "epoch": 8.868,
      "grad_norm": 0.7559996247291565,
      "learning_rate": 5.777551020408164e-06,
      "loss": 0.0526,
      "step": 22170
    },
    {
      "epoch": 8.872,
      "grad_norm": 1.0265531539916992,
      "learning_rate": 5.7571428571428574e-06,
      "loss": 0.0772,
      "step": 22180
    },
    {
      "epoch": 8.876,
      "grad_norm": 1.2508537769317627,
      "learning_rate": 5.736734693877551e-06,
      "loss": 0.0723,
      "step": 22190
    },
    {
      "epoch": 8.88,
      "grad_norm": 0.9326562881469727,
      "learning_rate": 5.716326530612246e-06,
      "loss": 0.0776,
      "step": 22200
    },
    {
      "epoch": 8.884,
      "grad_norm": 0.33699315786361694,
      "learning_rate": 5.695918367346939e-06,
      "loss": 0.0563,
      "step": 22210
    },
    {
      "epoch": 8.888,
      "grad_norm": 0.07631292194128036,
      "learning_rate": 5.675510204081633e-06,
      "loss": 0.0564,
      "step": 22220
    },
    {
      "epoch": 8.892,
      "grad_norm": 0.3372080624103546,
      "learning_rate": 5.655102040816327e-06,
      "loss": 0.0556,
      "step": 22230
    },
    {
      "epoch": 8.896,
      "grad_norm": 1.5353652238845825,
      "learning_rate": 5.6346938775510205e-06,
      "loss": 0.0774,
      "step": 22240
    },
    {
      "epoch": 8.9,
      "grad_norm": 1.2504804134368896,
      "learning_rate": 5.614285714285715e-06,
      "loss": 0.0887,
      "step": 22250
    },
    {
      "epoch": 8.904,
      "grad_norm": 0.29867392778396606,
      "learning_rate": 5.593877551020409e-06,
      "loss": 0.0399,
      "step": 22260
    },
    {
      "epoch": 8.908,
      "grad_norm": 0.05480222776532173,
      "learning_rate": 5.573469387755102e-06,
      "loss": 0.0819,
      "step": 22270
    },
    {
      "epoch": 8.912,
      "grad_norm": 0.7228659987449646,
      "learning_rate": 5.553061224489796e-06,
      "loss": 0.0633,
      "step": 22280
    },
    {
      "epoch": 8.916,
      "grad_norm": 0.24851329624652863,
      "learning_rate": 5.53265306122449e-06,
      "loss": 0.0526,
      "step": 22290
    },
    {
      "epoch": 8.92,
      "grad_norm": 0.052403565496206284,
      "learning_rate": 5.5122448979591836e-06,
      "loss": 0.049,
      "step": 22300
    },
    {
      "epoch": 8.924,
      "grad_norm": 0.021206360310316086,
      "learning_rate": 5.4918367346938785e-06,
      "loss": 0.051,
      "step": 22310
    },
    {
      "epoch": 8.928,
      "grad_norm": 0.1661582738161087,
      "learning_rate": 5.471428571428572e-06,
      "loss": 0.0488,
      "step": 22320
    },
    {
      "epoch": 8.932,
      "grad_norm": 0.22364217042922974,
      "learning_rate": 5.451020408163265e-06,
      "loss": 0.0655,
      "step": 22330
    },
    {
      "epoch": 8.936,
      "grad_norm": 0.25052160024642944,
      "learning_rate": 5.43061224489796e-06,
      "loss": 0.0699,
      "step": 22340
    },
    {
      "epoch": 8.94,
      "grad_norm": 0.4040091335773468,
      "learning_rate": 5.410204081632653e-06,
      "loss": 0.0265,
      "step": 22350
    },
    {
      "epoch": 8.943999999999999,
      "grad_norm": 0.46630266308784485,
      "learning_rate": 5.389795918367347e-06,
      "loss": 0.0462,
      "step": 22360
    },
    {
      "epoch": 8.948,
      "grad_norm": 0.3944891393184662,
      "learning_rate": 5.369387755102042e-06,
      "loss": 0.029,
      "step": 22370
    },
    {
      "epoch": 8.952,
      "grad_norm": 1.139592170715332,
      "learning_rate": 5.348979591836735e-06,
      "loss": 0.0918,
      "step": 22380
    },
    {
      "epoch": 8.956,
      "grad_norm": 1.217045545578003,
      "learning_rate": 5.328571428571429e-06,
      "loss": 0.0416,
      "step": 22390
    },
    {
      "epoch": 8.96,
      "grad_norm": 0.2185676544904709,
      "learning_rate": 5.308163265306123e-06,
      "loss": 0.073,
      "step": 22400
    },
    {
      "epoch": 8.964,
      "grad_norm": 0.8158991932868958,
      "learning_rate": 5.287755102040816e-06,
      "loss": 0.07,
      "step": 22410
    },
    {
      "epoch": 8.968,
      "grad_norm": 1.5700174570083618,
      "learning_rate": 5.2673469387755105e-06,
      "loss": 0.0717,
      "step": 22420
    },
    {
      "epoch": 8.972,
      "grad_norm": 0.6768568158149719,
      "learning_rate": 5.246938775510205e-06,
      "loss": 0.0552,
      "step": 22430
    },
    {
      "epoch": 8.975999999999999,
      "grad_norm": 1.2646855115890503,
      "learning_rate": 5.226530612244898e-06,
      "loss": 0.0505,
      "step": 22440
    },
    {
      "epoch": 8.98,
      "grad_norm": 1.1272732019424438,
      "learning_rate": 5.206122448979592e-06,
      "loss": 0.0764,
      "step": 22450
    },
    {
      "epoch": 8.984,
      "grad_norm": 1.648564338684082,
      "learning_rate": 5.185714285714286e-06,
      "loss": 0.0607,
      "step": 22460
    },
    {
      "epoch": 8.988,
      "grad_norm": 1.0245342254638672,
      "learning_rate": 5.1653061224489794e-06,
      "loss": 0.0805,
      "step": 22470
    },
    {
      "epoch": 8.992,
      "grad_norm": 0.9912453889846802,
      "learning_rate": 5.1448979591836736e-06,
      "loss": 0.0454,
      "step": 22480
    },
    {
      "epoch": 8.996,
      "grad_norm": 0.5200166702270508,
      "learning_rate": 5.124489795918368e-06,
      "loss": 0.0611,
      "step": 22490
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.5324453115463257,
      "learning_rate": 5.104081632653061e-06,
      "loss": 0.0499,
      "step": 22500
    },
    {
      "epoch": 9.004,
      "grad_norm": 0.2713208496570587,
      "learning_rate": 5.083673469387756e-06,
      "loss": 0.0779,
      "step": 22510
    },
    {
      "epoch": 9.008,
      "grad_norm": 0.8973396420478821,
      "learning_rate": 5.063265306122449e-06,
      "loss": 0.027,
      "step": 22520
    },
    {
      "epoch": 9.012,
      "grad_norm": 1.226372241973877,
      "learning_rate": 5.042857142857143e-06,
      "loss": 0.054,
      "step": 22530
    },
    {
      "epoch": 9.016,
      "grad_norm": 0.6342881917953491,
      "learning_rate": 5.0224489795918375e-06,
      "loss": 0.0626,
      "step": 22540
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.5466746687889099,
      "learning_rate": 5.002040816326531e-06,
      "loss": 0.0689,
      "step": 22550
    },
    {
      "epoch": 9.024,
      "grad_norm": 0.9370414018630981,
      "learning_rate": 4.981632653061225e-06,
      "loss": 0.0466,
      "step": 22560
    },
    {
      "epoch": 9.028,
      "grad_norm": 0.27276867628097534,
      "learning_rate": 4.961224489795919e-06,
      "loss": 0.0732,
      "step": 22570
    },
    {
      "epoch": 9.032,
      "grad_norm": 0.883052408695221,
      "learning_rate": 4.940816326530612e-06,
      "loss": 0.018,
      "step": 22580
    },
    {
      "epoch": 9.036,
      "grad_norm": 1.6437097787857056,
      "learning_rate": 4.920408163265306e-06,
      "loss": 0.0646,
      "step": 22590
    },
    {
      "epoch": 9.04,
      "grad_norm": 1.093284010887146,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 0.0483,
      "step": 22600
    },
    {
      "epoch": 9.044,
      "grad_norm": 0.06548968702554703,
      "learning_rate": 4.879591836734694e-06,
      "loss": 0.0511,
      "step": 22610
    },
    {
      "epoch": 9.048,
      "grad_norm": 0.4696071147918701,
      "learning_rate": 4.859183673469388e-06,
      "loss": 0.0313,
      "step": 22620
    },
    {
      "epoch": 9.052,
      "grad_norm": 0.1462869495153427,
      "learning_rate": 4.838775510204082e-06,
      "loss": 0.0489,
      "step": 22630
    },
    {
      "epoch": 9.056,
      "grad_norm": 0.7618330121040344,
      "learning_rate": 4.818367346938775e-06,
      "loss": 0.0224,
      "step": 22640
    },
    {
      "epoch": 9.06,
      "grad_norm": 0.7009792327880859,
      "learning_rate": 4.7979591836734694e-06,
      "loss": 0.0849,
      "step": 22650
    },
    {
      "epoch": 9.064,
      "grad_norm": 0.9768059849739075,
      "learning_rate": 4.7775510204081636e-06,
      "loss": 0.0802,
      "step": 22660
    },
    {
      "epoch": 9.068,
      "grad_norm": 0.09736836701631546,
      "learning_rate": 4.757142857142857e-06,
      "loss": 0.0612,
      "step": 22670
    },
    {
      "epoch": 9.072,
      "grad_norm": 1.3087384700775146,
      "learning_rate": 4.736734693877552e-06,
      "loss": 0.0618,
      "step": 22680
    },
    {
      "epoch": 9.076,
      "grad_norm": 0.1874455362558365,
      "learning_rate": 4.716326530612245e-06,
      "loss": 0.072,
      "step": 22690
    },
    {
      "epoch": 9.08,
      "grad_norm": 1.3482446670532227,
      "learning_rate": 4.695918367346939e-06,
      "loss": 0.055,
      "step": 22700
    },
    {
      "epoch": 9.084,
      "grad_norm": 0.005113059189170599,
      "learning_rate": 4.675510204081633e-06,
      "loss": 0.0626,
      "step": 22710
    },
    {
      "epoch": 9.088,
      "grad_norm": 1.887796401977539,
      "learning_rate": 4.655102040816327e-06,
      "loss": 0.0579,
      "step": 22720
    },
    {
      "epoch": 9.092,
      "grad_norm": 0.5130645632743835,
      "learning_rate": 4.634693877551021e-06,
      "loss": 0.0488,
      "step": 22730
    },
    {
      "epoch": 9.096,
      "grad_norm": 1.1061453819274902,
      "learning_rate": 4.614285714285715e-06,
      "loss": 0.0558,
      "step": 22740
    },
    {
      "epoch": 9.1,
      "grad_norm": 0.47140470147132874,
      "learning_rate": 4.593877551020408e-06,
      "loss": 0.0395,
      "step": 22750
    },
    {
      "epoch": 9.104,
      "grad_norm": 0.6307046413421631,
      "learning_rate": 4.573469387755102e-06,
      "loss": 0.0698,
      "step": 22760
    },
    {
      "epoch": 9.108,
      "grad_norm": 0.08617875725030899,
      "learning_rate": 4.553061224489796e-06,
      "loss": 0.0247,
      "step": 22770
    },
    {
      "epoch": 9.112,
      "grad_norm": 1.3452584743499756,
      "learning_rate": 4.53265306122449e-06,
      "loss": 0.0669,
      "step": 22780
    },
    {
      "epoch": 9.116,
      "grad_norm": 0.1661945879459381,
      "learning_rate": 4.512244897959184e-06,
      "loss": 0.0369,
      "step": 22790
    },
    {
      "epoch": 9.12,
      "grad_norm": 0.36598333716392517,
      "learning_rate": 4.491836734693878e-06,
      "loss": 0.0381,
      "step": 22800
    },
    {
      "epoch": 9.124,
      "grad_norm": 1.4713561534881592,
      "learning_rate": 4.471428571428571e-06,
      "loss": 0.0509,
      "step": 22810
    },
    {
      "epoch": 9.128,
      "grad_norm": 0.6676710247993469,
      "learning_rate": 4.451020408163265e-06,
      "loss": 0.0565,
      "step": 22820
    },
    {
      "epoch": 9.132,
      "grad_norm": 1.2620302438735962,
      "learning_rate": 4.4306122448979595e-06,
      "loss": 0.0445,
      "step": 22830
    },
    {
      "epoch": 9.136,
      "grad_norm": 1.1701123714447021,
      "learning_rate": 4.410204081632653e-06,
      "loss": 0.049,
      "step": 22840
    },
    {
      "epoch": 9.14,
      "grad_norm": 1.528818964958191,
      "learning_rate": 4.389795918367348e-06,
      "loss": 0.0616,
      "step": 22850
    },
    {
      "epoch": 9.144,
      "grad_norm": 1.1408601999282837,
      "learning_rate": 4.369387755102041e-06,
      "loss": 0.0386,
      "step": 22860
    },
    {
      "epoch": 9.148,
      "grad_norm": 0.44291800260543823,
      "learning_rate": 4.348979591836735e-06,
      "loss": 0.0554,
      "step": 22870
    },
    {
      "epoch": 9.152,
      "grad_norm": 1.0096702575683594,
      "learning_rate": 4.328571428571429e-06,
      "loss": 0.0931,
      "step": 22880
    },
    {
      "epoch": 9.156,
      "grad_norm": 0.16527630388736725,
      "learning_rate": 4.3081632653061225e-06,
      "loss": 0.0296,
      "step": 22890
    },
    {
      "epoch": 9.16,
      "grad_norm": 1.2352583408355713,
      "learning_rate": 4.287755102040817e-06,
      "loss": 0.0402,
      "step": 22900
    },
    {
      "epoch": 9.164,
      "grad_norm": 0.5085968375205994,
      "learning_rate": 4.267346938775511e-06,
      "loss": 0.0651,
      "step": 22910
    },
    {
      "epoch": 9.168,
      "grad_norm": 0.9006853699684143,
      "learning_rate": 4.246938775510204e-06,
      "loss": 0.082,
      "step": 22920
    },
    {
      "epoch": 9.172,
      "grad_norm": 0.9849440455436707,
      "learning_rate": 4.226530612244898e-06,
      "loss": 0.0739,
      "step": 22930
    },
    {
      "epoch": 9.176,
      "grad_norm": 0.46819785237312317,
      "learning_rate": 4.206122448979592e-06,
      "loss": 0.0618,
      "step": 22940
    },
    {
      "epoch": 9.18,
      "grad_norm": 1.2736022472381592,
      "learning_rate": 4.1857142857142856e-06,
      "loss": 0.0722,
      "step": 22950
    },
    {
      "epoch": 9.184,
      "grad_norm": 1.668333888053894,
      "learning_rate": 4.16530612244898e-06,
      "loss": 0.0659,
      "step": 22960
    },
    {
      "epoch": 9.188,
      "grad_norm": 0.9864785075187683,
      "learning_rate": 4.144897959183674e-06,
      "loss": 0.0568,
      "step": 22970
    },
    {
      "epoch": 9.192,
      "grad_norm": 0.404057115316391,
      "learning_rate": 4.124489795918367e-06,
      "loss": 0.0424,
      "step": 22980
    },
    {
      "epoch": 9.196,
      "grad_norm": 2.138291358947754,
      "learning_rate": 4.104081632653061e-06,
      "loss": 0.0513,
      "step": 22990
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.214101642370224,
      "learning_rate": 4.083673469387755e-06,
      "loss": 0.0313,
      "step": 23000
    },
    {
      "epoch": 9.204,
      "grad_norm": 0.8658479452133179,
      "learning_rate": 4.063265306122449e-06,
      "loss": 0.0576,
      "step": 23010
    },
    {
      "epoch": 9.208,
      "grad_norm": 0.20737798511981964,
      "learning_rate": 4.042857142857144e-06,
      "loss": 0.0571,
      "step": 23020
    },
    {
      "epoch": 9.212,
      "grad_norm": 0.4621712267398834,
      "learning_rate": 4.022448979591837e-06,
      "loss": 0.0392,
      "step": 23030
    },
    {
      "epoch": 9.216,
      "grad_norm": 1.0095964670181274,
      "learning_rate": 4.002040816326531e-06,
      "loss": 0.0614,
      "step": 23040
    },
    {
      "epoch": 9.22,
      "grad_norm": 0.02179221250116825,
      "learning_rate": 3.981632653061225e-06,
      "loss": 0.034,
      "step": 23050
    },
    {
      "epoch": 9.224,
      "grad_norm": 0.8337184190750122,
      "learning_rate": 3.961224489795918e-06,
      "loss": 0.0661,
      "step": 23060
    },
    {
      "epoch": 9.228,
      "grad_norm": 1.5901216268539429,
      "learning_rate": 3.9408163265306125e-06,
      "loss": 0.0559,
      "step": 23070
    },
    {
      "epoch": 9.232,
      "grad_norm": 1.3199392557144165,
      "learning_rate": 3.920408163265307e-06,
      "loss": 0.0622,
      "step": 23080
    },
    {
      "epoch": 9.236,
      "grad_norm": 1.1090421676635742,
      "learning_rate": 3.9e-06,
      "loss": 0.0564,
      "step": 23090
    },
    {
      "epoch": 9.24,
      "grad_norm": 1.475001335144043,
      "learning_rate": 3.879591836734694e-06,
      "loss": 0.0514,
      "step": 23100
    },
    {
      "epoch": 9.244,
      "grad_norm": 0.7565126419067383,
      "learning_rate": 3.859183673469388e-06,
      "loss": 0.0793,
      "step": 23110
    },
    {
      "epoch": 9.248,
      "grad_norm": 0.7880014181137085,
      "learning_rate": 3.8387755102040815e-06,
      "loss": 0.046,
      "step": 23120
    },
    {
      "epoch": 9.252,
      "grad_norm": 0.17382007837295532,
      "learning_rate": 3.818367346938776e-06,
      "loss": 0.107,
      "step": 23130
    },
    {
      "epoch": 9.256,
      "grad_norm": 1.0757256746292114,
      "learning_rate": 3.7979591836734697e-06,
      "loss": 0.0385,
      "step": 23140
    },
    {
      "epoch": 9.26,
      "grad_norm": 0.11891672015190125,
      "learning_rate": 3.7775510204081634e-06,
      "loss": 0.0306,
      "step": 23150
    },
    {
      "epoch": 9.264,
      "grad_norm": 1.1024596691131592,
      "learning_rate": 3.757142857142857e-06,
      "loss": 0.0547,
      "step": 23160
    },
    {
      "epoch": 9.268,
      "grad_norm": 1.2045363187789917,
      "learning_rate": 3.7367346938775512e-06,
      "loss": 0.0523,
      "step": 23170
    },
    {
      "epoch": 9.272,
      "grad_norm": 0.832956850528717,
      "learning_rate": 3.716326530612245e-06,
      "loss": 0.0697,
      "step": 23180
    },
    {
      "epoch": 9.276,
      "grad_norm": 0.4622827470302582,
      "learning_rate": 3.6959183673469395e-06,
      "loss": 0.0471,
      "step": 23190
    },
    {
      "epoch": 9.28,
      "grad_norm": 0.3827860355377197,
      "learning_rate": 3.6755102040816328e-06,
      "loss": 0.0444,
      "step": 23200
    },
    {
      "epoch": 9.284,
      "grad_norm": 0.5204343199729919,
      "learning_rate": 3.6551020408163265e-06,
      "loss": 0.0436,
      "step": 23210
    },
    {
      "epoch": 9.288,
      "grad_norm": 0.11360428482294083,
      "learning_rate": 3.634693877551021e-06,
      "loss": 0.1025,
      "step": 23220
    },
    {
      "epoch": 9.292,
      "grad_norm": 0.11689949035644531,
      "learning_rate": 3.6142857142857143e-06,
      "loss": 0.0519,
      "step": 23230
    },
    {
      "epoch": 9.296,
      "grad_norm": 1.4730122089385986,
      "learning_rate": 3.593877551020408e-06,
      "loss": 0.0539,
      "step": 23240
    },
    {
      "epoch": 9.3,
      "grad_norm": 0.01583225652575493,
      "learning_rate": 3.5734693877551025e-06,
      "loss": 0.0402,
      "step": 23250
    },
    {
      "epoch": 9.304,
      "grad_norm": 0.305428147315979,
      "learning_rate": 3.5530612244897962e-06,
      "loss": 0.0284,
      "step": 23260
    },
    {
      "epoch": 9.308,
      "grad_norm": 0.5291092991828918,
      "learning_rate": 3.5326530612244895e-06,
      "loss": 0.0189,
      "step": 23270
    },
    {
      "epoch": 9.312,
      "grad_norm": 0.34601178765296936,
      "learning_rate": 3.512244897959184e-06,
      "loss": 0.0351,
      "step": 23280
    },
    {
      "epoch": 9.316,
      "grad_norm": 0.9673150181770325,
      "learning_rate": 3.4918367346938778e-06,
      "loss": 0.0416,
      "step": 23290
    },
    {
      "epoch": 9.32,
      "grad_norm": 1.73916757106781,
      "learning_rate": 3.4714285714285715e-06,
      "loss": 0.0508,
      "step": 23300
    },
    {
      "epoch": 9.324,
      "grad_norm": 0.2375902384519577,
      "learning_rate": 3.4510204081632656e-06,
      "loss": 0.0331,
      "step": 23310
    },
    {
      "epoch": 9.328,
      "grad_norm": 0.8834676146507263,
      "learning_rate": 3.4306122448979593e-06,
      "loss": 0.0738,
      "step": 23320
    },
    {
      "epoch": 9.332,
      "grad_norm": 0.8033340573310852,
      "learning_rate": 3.410204081632653e-06,
      "loss": 0.0598,
      "step": 23330
    },
    {
      "epoch": 9.336,
      "grad_norm": 0.23427945375442505,
      "learning_rate": 3.389795918367347e-06,
      "loss": 0.0656,
      "step": 23340
    },
    {
      "epoch": 9.34,
      "grad_norm": 0.314693421125412,
      "learning_rate": 3.369387755102041e-06,
      "loss": 0.0881,
      "step": 23350
    },
    {
      "epoch": 9.344,
      "grad_norm": 0.13252103328704834,
      "learning_rate": 3.3489795918367354e-06,
      "loss": 0.056,
      "step": 23360
    },
    {
      "epoch": 9.348,
      "grad_norm": 0.4171220064163208,
      "learning_rate": 3.3285714285714286e-06,
      "loss": 0.0359,
      "step": 23370
    },
    {
      "epoch": 9.352,
      "grad_norm": 2.224212408065796,
      "learning_rate": 3.3081632653061223e-06,
      "loss": 0.1141,
      "step": 23380
    },
    {
      "epoch": 9.356,
      "grad_norm": 0.021235661581158638,
      "learning_rate": 3.287755102040817e-06,
      "loss": 0.0551,
      "step": 23390
    },
    {
      "epoch": 9.36,
      "grad_norm": 1.0664877891540527,
      "learning_rate": 3.2673469387755106e-06,
      "loss": 0.0546,
      "step": 23400
    },
    {
      "epoch": 9.364,
      "grad_norm": 0.497671514749527,
      "learning_rate": 3.246938775510204e-06,
      "loss": 0.0554,
      "step": 23410
    },
    {
      "epoch": 9.368,
      "grad_norm": 0.6766025424003601,
      "learning_rate": 3.2265306122448984e-06,
      "loss": 0.0713,
      "step": 23420
    },
    {
      "epoch": 9.372,
      "grad_norm": 1.25644052028656,
      "learning_rate": 3.206122448979592e-06,
      "loss": 0.0863,
      "step": 23430
    },
    {
      "epoch": 9.376,
      "grad_norm": 0.8678618669509888,
      "learning_rate": 3.185714285714286e-06,
      "loss": 0.0573,
      "step": 23440
    },
    {
      "epoch": 9.38,
      "grad_norm": 0.4001503586769104,
      "learning_rate": 3.16530612244898e-06,
      "loss": 0.0936,
      "step": 23450
    },
    {
      "epoch": 9.384,
      "grad_norm": 0.7092105150222778,
      "learning_rate": 3.1448979591836737e-06,
      "loss": 0.0219,
      "step": 23460
    },
    {
      "epoch": 9.388,
      "grad_norm": 0.8953125476837158,
      "learning_rate": 3.1244897959183674e-06,
      "loss": 0.0472,
      "step": 23470
    },
    {
      "epoch": 9.392,
      "grad_norm": 1.8014789819717407,
      "learning_rate": 3.1040816326530615e-06,
      "loss": 0.075,
      "step": 23480
    },
    {
      "epoch": 9.396,
      "grad_norm": 1.7311850786209106,
      "learning_rate": 3.083673469387755e-06,
      "loss": 0.0633,
      "step": 23490
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.31770437955856323,
      "learning_rate": 3.0632653061224493e-06,
      "loss": 0.0435,
      "step": 23500
    },
    {
      "epoch": 9.404,
      "grad_norm": 1.1733142137527466,
      "learning_rate": 3.042857142857143e-06,
      "loss": 0.0503,
      "step": 23510
    },
    {
      "epoch": 9.408,
      "grad_norm": 1.6186164617538452,
      "learning_rate": 3.0224489795918367e-06,
      "loss": 0.0454,
      "step": 23520
    },
    {
      "epoch": 9.412,
      "grad_norm": 0.24112039804458618,
      "learning_rate": 3.002040816326531e-06,
      "loss": 0.0691,
      "step": 23530
    },
    {
      "epoch": 9.416,
      "grad_norm": 1.0465794801712036,
      "learning_rate": 2.9816326530612245e-06,
      "loss": 0.047,
      "step": 23540
    },
    {
      "epoch": 9.42,
      "grad_norm": 0.311402291059494,
      "learning_rate": 2.9612244897959182e-06,
      "loss": 0.0413,
      "step": 23550
    },
    {
      "epoch": 9.424,
      "grad_norm": 0.11593114584684372,
      "learning_rate": 2.9408163265306124e-06,
      "loss": 0.0467,
      "step": 23560
    },
    {
      "epoch": 9.428,
      "grad_norm": 1.16788649559021,
      "learning_rate": 2.9204081632653065e-06,
      "loss": 0.0621,
      "step": 23570
    },
    {
      "epoch": 9.432,
      "grad_norm": 0.6133482456207275,
      "learning_rate": 2.9e-06,
      "loss": 0.09,
      "step": 23580
    },
    {
      "epoch": 9.436,
      "grad_norm": 1.915054202079773,
      "learning_rate": 2.879591836734694e-06,
      "loss": 0.1089,
      "step": 23590
    },
    {
      "epoch": 9.44,
      "grad_norm": 1.6881487369537354,
      "learning_rate": 2.859183673469388e-06,
      "loss": 0.0815,
      "step": 23600
    },
    {
      "epoch": 9.444,
      "grad_norm": 0.3186533451080322,
      "learning_rate": 2.8387755102040817e-06,
      "loss": 0.0392,
      "step": 23610
    },
    {
      "epoch": 9.448,
      "grad_norm": 0.13884389400482178,
      "learning_rate": 2.8183673469387754e-06,
      "loss": 0.0533,
      "step": 23620
    },
    {
      "epoch": 9.452,
      "grad_norm": 0.1966952681541443,
      "learning_rate": 2.7979591836734695e-06,
      "loss": 0.0389,
      "step": 23630
    },
    {
      "epoch": 9.456,
      "grad_norm": 0.11761423200368881,
      "learning_rate": 2.7775510204081637e-06,
      "loss": 0.0461,
      "step": 23640
    },
    {
      "epoch": 9.46,
      "grad_norm": 1.1550931930541992,
      "learning_rate": 2.7571428571428574e-06,
      "loss": 0.0722,
      "step": 23650
    },
    {
      "epoch": 9.464,
      "grad_norm": 0.21959099173545837,
      "learning_rate": 2.736734693877551e-06,
      "loss": 0.0739,
      "step": 23660
    },
    {
      "epoch": 9.468,
      "grad_norm": 1.0734394788742065,
      "learning_rate": 2.716326530612245e-06,
      "loss": 0.0527,
      "step": 23670
    },
    {
      "epoch": 9.472,
      "grad_norm": 1.288485050201416,
      "learning_rate": 2.695918367346939e-06,
      "loss": 0.073,
      "step": 23680
    },
    {
      "epoch": 9.475999999999999,
      "grad_norm": 0.7578178644180298,
      "learning_rate": 2.6755102040816326e-06,
      "loss": 0.0538,
      "step": 23690
    },
    {
      "epoch": 9.48,
      "grad_norm": 0.02740979939699173,
      "learning_rate": 2.6551020408163267e-06,
      "loss": 0.0306,
      "step": 23700
    },
    {
      "epoch": 9.484,
      "grad_norm": 0.08831162750720978,
      "learning_rate": 2.6346938775510204e-06,
      "loss": 0.0595,
      "step": 23710
    },
    {
      "epoch": 9.488,
      "grad_norm": 0.7214728593826294,
      "learning_rate": 2.614285714285714e-06,
      "loss": 0.0536,
      "step": 23720
    },
    {
      "epoch": 9.492,
      "grad_norm": 1.3577018976211548,
      "learning_rate": 2.5938775510204082e-06,
      "loss": 0.1096,
      "step": 23730
    },
    {
      "epoch": 9.496,
      "grad_norm": 1.366845726966858,
      "learning_rate": 2.5734693877551024e-06,
      "loss": 0.1094,
      "step": 23740
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.24680541455745697,
      "learning_rate": 2.553061224489796e-06,
      "loss": 0.0553,
      "step": 23750
    },
    {
      "epoch": 9.504,
      "grad_norm": 0.1610066145658493,
      "learning_rate": 2.5326530612244898e-06,
      "loss": 0.043,
      "step": 23760
    },
    {
      "epoch": 9.508,
      "grad_norm": 0.19863975048065186,
      "learning_rate": 2.512244897959184e-06,
      "loss": 0.0666,
      "step": 23770
    },
    {
      "epoch": 9.512,
      "grad_norm": 0.8736908435821533,
      "learning_rate": 2.4918367346938776e-06,
      "loss": 0.0438,
      "step": 23780
    },
    {
      "epoch": 9.516,
      "grad_norm": 0.12991566956043243,
      "learning_rate": 2.4714285714285713e-06,
      "loss": 0.0563,
      "step": 23790
    },
    {
      "epoch": 9.52,
      "grad_norm": 2.3829758167266846,
      "learning_rate": 2.4510204081632654e-06,
      "loss": 0.0999,
      "step": 23800
    },
    {
      "epoch": 9.524000000000001,
      "grad_norm": 0.9150004386901855,
      "learning_rate": 2.4306122448979596e-06,
      "loss": 0.0445,
      "step": 23810
    },
    {
      "epoch": 9.528,
      "grad_norm": 0.15128453075885773,
      "learning_rate": 2.4102040816326533e-06,
      "loss": 0.0294,
      "step": 23820
    },
    {
      "epoch": 9.532,
      "grad_norm": 1.3778220415115356,
      "learning_rate": 2.389795918367347e-06,
      "loss": 0.0862,
      "step": 23830
    },
    {
      "epoch": 9.536,
      "grad_norm": 0.08246253430843353,
      "learning_rate": 2.369387755102041e-06,
      "loss": 0.0383,
      "step": 23840
    },
    {
      "epoch": 9.54,
      "grad_norm": 1.4992555379867554,
      "learning_rate": 2.3489795918367348e-06,
      "loss": 0.0378,
      "step": 23850
    },
    {
      "epoch": 9.544,
      "grad_norm": 1.540603756904602,
      "learning_rate": 2.3285714285714285e-06,
      "loss": 0.0908,
      "step": 23860
    },
    {
      "epoch": 9.548,
      "grad_norm": 0.6524764895439148,
      "learning_rate": 2.3081632653061226e-06,
      "loss": 0.06,
      "step": 23870
    },
    {
      "epoch": 9.552,
      "grad_norm": 1.485969066619873,
      "learning_rate": 2.2877551020408167e-06,
      "loss": 0.0493,
      "step": 23880
    },
    {
      "epoch": 9.556000000000001,
      "grad_norm": 0.5639276504516602,
      "learning_rate": 2.26734693877551e-06,
      "loss": 0.0399,
      "step": 23890
    },
    {
      "epoch": 9.56,
      "grad_norm": 0.949671745300293,
      "learning_rate": 2.246938775510204e-06,
      "loss": 0.0308,
      "step": 23900
    },
    {
      "epoch": 9.564,
      "grad_norm": 1.7394670248031616,
      "learning_rate": 2.2265306122448983e-06,
      "loss": 0.0511,
      "step": 23910
    },
    {
      "epoch": 9.568,
      "grad_norm": 0.536202073097229,
      "learning_rate": 2.206122448979592e-06,
      "loss": 0.0486,
      "step": 23920
    },
    {
      "epoch": 9.572,
      "grad_norm": 0.07920452207326889,
      "learning_rate": 2.1857142857142857e-06,
      "loss": 0.0402,
      "step": 23930
    },
    {
      "epoch": 9.576,
      "grad_norm": 0.12403420358896255,
      "learning_rate": 2.1653061224489798e-06,
      "loss": 0.0396,
      "step": 23940
    },
    {
      "epoch": 9.58,
      "grad_norm": 0.6896355152130127,
      "learning_rate": 2.1448979591836735e-06,
      "loss": 0.0619,
      "step": 23950
    },
    {
      "epoch": 9.584,
      "grad_norm": 0.31047454476356506,
      "learning_rate": 2.124489795918367e-06,
      "loss": 0.0638,
      "step": 23960
    },
    {
      "epoch": 9.588,
      "grad_norm": 0.45136532187461853,
      "learning_rate": 2.1040816326530613e-06,
      "loss": 0.1096,
      "step": 23970
    },
    {
      "epoch": 9.592,
      "grad_norm": 0.8384220600128174,
      "learning_rate": 2.0836734693877554e-06,
      "loss": 0.0561,
      "step": 23980
    },
    {
      "epoch": 9.596,
      "grad_norm": 1.335038661956787,
      "learning_rate": 2.0632653061224487e-06,
      "loss": 0.0483,
      "step": 23990
    },
    {
      "epoch": 9.6,
      "grad_norm": 1.1354504823684692,
      "learning_rate": 2.042857142857143e-06,
      "loss": 0.081,
      "step": 24000
    },
    {
      "epoch": 9.604,
      "grad_norm": 1.4060423374176025,
      "learning_rate": 2.022448979591837e-06,
      "loss": 0.0492,
      "step": 24010
    },
    {
      "epoch": 9.608,
      "grad_norm": 0.4502640664577484,
      "learning_rate": 2.0020408163265307e-06,
      "loss": 0.0642,
      "step": 24020
    },
    {
      "epoch": 9.612,
      "grad_norm": 1.1551944017410278,
      "learning_rate": 1.9816326530612244e-06,
      "loss": 0.049,
      "step": 24030
    },
    {
      "epoch": 9.616,
      "grad_norm": 1.464016318321228,
      "learning_rate": 1.9612244897959185e-06,
      "loss": 0.0624,
      "step": 24040
    },
    {
      "epoch": 9.62,
      "grad_norm": 2.1279287338256836,
      "learning_rate": 1.9408163265306126e-06,
      "loss": 0.072,
      "step": 24050
    },
    {
      "epoch": 9.624,
      "grad_norm": 0.983695924282074,
      "learning_rate": 1.920408163265306e-06,
      "loss": 0.038,
      "step": 24060
    },
    {
      "epoch": 9.628,
      "grad_norm": 1.3907074928283691,
      "learning_rate": 1.9e-06,
      "loss": 0.064,
      "step": 24070
    },
    {
      "epoch": 9.632,
      "grad_norm": 1.5399647951126099,
      "learning_rate": 1.879591836734694e-06,
      "loss": 0.039,
      "step": 24080
    },
    {
      "epoch": 9.636,
      "grad_norm": 0.6000096201896667,
      "learning_rate": 1.859183673469388e-06,
      "loss": 0.0605,
      "step": 24090
    },
    {
      "epoch": 9.64,
      "grad_norm": 0.5623230934143066,
      "learning_rate": 1.8387755102040815e-06,
      "loss": 0.1284,
      "step": 24100
    },
    {
      "epoch": 9.644,
      "grad_norm": 0.8386109471321106,
      "learning_rate": 1.8183673469387757e-06,
      "loss": 0.06,
      "step": 24110
    },
    {
      "epoch": 9.648,
      "grad_norm": 1.4347493648529053,
      "learning_rate": 1.7979591836734696e-06,
      "loss": 0.0683,
      "step": 24120
    },
    {
      "epoch": 9.652,
      "grad_norm": 1.0647609233856201,
      "learning_rate": 1.7775510204081633e-06,
      "loss": 0.0705,
      "step": 24130
    },
    {
      "epoch": 9.656,
      "grad_norm": 1.0243836641311646,
      "learning_rate": 1.7571428571428572e-06,
      "loss": 0.0484,
      "step": 24140
    },
    {
      "epoch": 9.66,
      "grad_norm": 1.0032751560211182,
      "learning_rate": 1.7367346938775511e-06,
      "loss": 0.0769,
      "step": 24150
    },
    {
      "epoch": 9.664,
      "grad_norm": 0.2129565328359604,
      "learning_rate": 1.7163265306122448e-06,
      "loss": 0.0411,
      "step": 24160
    },
    {
      "epoch": 9.668,
      "grad_norm": 1.608567714691162,
      "learning_rate": 1.6959183673469387e-06,
      "loss": 0.0752,
      "step": 24170
    },
    {
      "epoch": 9.672,
      "grad_norm": 0.11126574128866196,
      "learning_rate": 1.6755102040816329e-06,
      "loss": 0.0465,
      "step": 24180
    },
    {
      "epoch": 9.676,
      "grad_norm": 0.06106802448630333,
      "learning_rate": 1.6551020408163268e-06,
      "loss": 0.062,
      "step": 24190
    },
    {
      "epoch": 9.68,
      "grad_norm": 0.3810074031352997,
      "learning_rate": 1.6346938775510205e-06,
      "loss": 0.0755,
      "step": 24200
    },
    {
      "epoch": 9.684,
      "grad_norm": 0.8935461044311523,
      "learning_rate": 1.6142857142857144e-06,
      "loss": 0.1133,
      "step": 24210
    },
    {
      "epoch": 9.688,
      "grad_norm": 1.457793951034546,
      "learning_rate": 1.5938775510204083e-06,
      "loss": 0.0468,
      "step": 24220
    },
    {
      "epoch": 9.692,
      "grad_norm": 0.254343181848526,
      "learning_rate": 1.573469387755102e-06,
      "loss": 0.0557,
      "step": 24230
    },
    {
      "epoch": 9.696,
      "grad_norm": 0.33495211601257324,
      "learning_rate": 1.553061224489796e-06,
      "loss": 0.0447,
      "step": 24240
    },
    {
      "epoch": 9.7,
      "grad_norm": 0.40229296684265137,
      "learning_rate": 1.53265306122449e-06,
      "loss": 0.0424,
      "step": 24250
    },
    {
      "epoch": 9.704,
      "grad_norm": 0.5609128475189209,
      "learning_rate": 1.5122448979591837e-06,
      "loss": 0.0477,
      "step": 24260
    },
    {
      "epoch": 9.708,
      "grad_norm": 1.4650758504867554,
      "learning_rate": 1.4918367346938774e-06,
      "loss": 0.0432,
      "step": 24270
    },
    {
      "epoch": 9.712,
      "grad_norm": 0.28862255811691284,
      "learning_rate": 1.4714285714285716e-06,
      "loss": 0.0541,
      "step": 24280
    },
    {
      "epoch": 9.716,
      "grad_norm": 1.520565152168274,
      "learning_rate": 1.4510204081632653e-06,
      "loss": 0.0481,
      "step": 24290
    },
    {
      "epoch": 9.72,
      "grad_norm": 0.08952673524618149,
      "learning_rate": 1.4306122448979594e-06,
      "loss": 0.0441,
      "step": 24300
    },
    {
      "epoch": 9.724,
      "grad_norm": 1.324737548828125,
      "learning_rate": 1.410204081632653e-06,
      "loss": 0.0532,
      "step": 24310
    },
    {
      "epoch": 9.728,
      "grad_norm": 1.4353430271148682,
      "learning_rate": 1.389795918367347e-06,
      "loss": 0.1095,
      "step": 24320
    },
    {
      "epoch": 9.732,
      "grad_norm": 0.6118010878562927,
      "learning_rate": 1.369387755102041e-06,
      "loss": 0.0372,
      "step": 24330
    },
    {
      "epoch": 9.736,
      "grad_norm": 0.2557682394981384,
      "learning_rate": 1.3489795918367346e-06,
      "loss": 0.0299,
      "step": 24340
    },
    {
      "epoch": 9.74,
      "grad_norm": 0.4888875484466553,
      "learning_rate": 1.3285714285714287e-06,
      "loss": 0.0517,
      "step": 24350
    },
    {
      "epoch": 9.744,
      "grad_norm": 0.2930053174495697,
      "learning_rate": 1.3081632653061224e-06,
      "loss": 0.0404,
      "step": 24360
    },
    {
      "epoch": 9.748,
      "grad_norm": 1.1038103103637695,
      "learning_rate": 1.2877551020408166e-06,
      "loss": 0.0545,
      "step": 24370
    },
    {
      "epoch": 9.752,
      "grad_norm": 0.6487769484519958,
      "learning_rate": 1.2673469387755103e-06,
      "loss": 0.0714,
      "step": 24380
    },
    {
      "epoch": 9.756,
      "grad_norm": 0.6688640117645264,
      "learning_rate": 1.246938775510204e-06,
      "loss": 0.0727,
      "step": 24390
    },
    {
      "epoch": 9.76,
      "grad_norm": 0.17187215387821198,
      "learning_rate": 1.226530612244898e-06,
      "loss": 0.0559,
      "step": 24400
    },
    {
      "epoch": 9.764,
      "grad_norm": 1.6960110664367676,
      "learning_rate": 1.2061224489795918e-06,
      "loss": 0.0547,
      "step": 24410
    },
    {
      "epoch": 9.768,
      "grad_norm": 1.2704380750656128,
      "learning_rate": 1.185714285714286e-06,
      "loss": 0.0489,
      "step": 24420
    },
    {
      "epoch": 9.772,
      "grad_norm": 0.9353586435317993,
      "learning_rate": 1.1653061224489796e-06,
      "loss": 0.0518,
      "step": 24430
    },
    {
      "epoch": 9.776,
      "grad_norm": 1.320724368095398,
      "learning_rate": 1.1448979591836735e-06,
      "loss": 0.0831,
      "step": 24440
    },
    {
      "epoch": 9.78,
      "grad_norm": 0.6083497405052185,
      "learning_rate": 1.1244897959183674e-06,
      "loss": 0.0829,
      "step": 24450
    },
    {
      "epoch": 9.784,
      "grad_norm": 1.9477829933166504,
      "learning_rate": 1.1040816326530611e-06,
      "loss": 0.0491,
      "step": 24460
    },
    {
      "epoch": 9.788,
      "grad_norm": 0.9265921115875244,
      "learning_rate": 1.0836734693877553e-06,
      "loss": 0.0733,
      "step": 24470
    },
    {
      "epoch": 9.792,
      "grad_norm": 0.04657470062375069,
      "learning_rate": 1.063265306122449e-06,
      "loss": 0.0893,
      "step": 24480
    },
    {
      "epoch": 9.796,
      "grad_norm": 0.7697755098342896,
      "learning_rate": 1.0428571428571429e-06,
      "loss": 0.0247,
      "step": 24490
    },
    {
      "epoch": 9.8,
      "grad_norm": 1.5888453722000122,
      "learning_rate": 1.0224489795918368e-06,
      "loss": 0.0534,
      "step": 24500
    },
    {
      "epoch": 9.804,
      "grad_norm": 0.13210126757621765,
      "learning_rate": 1.0020408163265305e-06,
      "loss": 0.0632,
      "step": 24510
    },
    {
      "epoch": 9.808,
      "grad_norm": 0.7089018821716309,
      "learning_rate": 9.816326530612246e-07,
      "loss": 0.0719,
      "step": 24520
    },
    {
      "epoch": 9.812,
      "grad_norm": 0.7388591170310974,
      "learning_rate": 9.612244897959183e-07,
      "loss": 0.0864,
      "step": 24530
    },
    {
      "epoch": 9.816,
      "grad_norm": 0.15310625731945038,
      "learning_rate": 9.408163265306123e-07,
      "loss": 0.0412,
      "step": 24540
    },
    {
      "epoch": 9.82,
      "grad_norm": 0.9023667573928833,
      "learning_rate": 9.204081632653062e-07,
      "loss": 0.0497,
      "step": 24550
    },
    {
      "epoch": 9.824,
      "grad_norm": 0.669176459312439,
      "learning_rate": 9e-07,
      "loss": 0.1458,
      "step": 24560
    },
    {
      "epoch": 9.828,
      "grad_norm": 0.8760576844215393,
      "learning_rate": 8.79591836734694e-07,
      "loss": 0.0615,
      "step": 24570
    },
    {
      "epoch": 9.832,
      "grad_norm": 0.45228081941604614,
      "learning_rate": 8.591836734693878e-07,
      "loss": 0.0565,
      "step": 24580
    },
    {
      "epoch": 9.836,
      "grad_norm": 1.0983870029449463,
      "learning_rate": 8.387755102040817e-07,
      "loss": 0.0591,
      "step": 24590
    },
    {
      "epoch": 9.84,
      "grad_norm": 0.5693173408508301,
      "learning_rate": 8.183673469387755e-07,
      "loss": 0.0737,
      "step": 24600
    },
    {
      "epoch": 9.844,
      "grad_norm": 0.8937259912490845,
      "learning_rate": 7.979591836734693e-07,
      "loss": 0.0343,
      "step": 24610
    },
    {
      "epoch": 9.848,
      "grad_norm": 0.32293465733528137,
      "learning_rate": 7.775510204081633e-07,
      "loss": 0.0508,
      "step": 24620
    },
    {
      "epoch": 9.852,
      "grad_norm": 0.8313837647438049,
      "learning_rate": 7.571428571428572e-07,
      "loss": 0.0468,
      "step": 24630
    },
    {
      "epoch": 9.856,
      "grad_norm": 0.7201724648475647,
      "learning_rate": 7.36734693877551e-07,
      "loss": 0.0554,
      "step": 24640
    },
    {
      "epoch": 9.86,
      "grad_norm": 0.13808800280094147,
      "learning_rate": 7.16326530612245e-07,
      "loss": 0.0364,
      "step": 24650
    },
    {
      "epoch": 9.864,
      "grad_norm": 0.3948347568511963,
      "learning_rate": 6.959183673469388e-07,
      "loss": 0.0464,
      "step": 24660
    },
    {
      "epoch": 9.868,
      "grad_norm": 0.35861527919769287,
      "learning_rate": 6.755102040816327e-07,
      "loss": 0.0575,
      "step": 24670
    },
    {
      "epoch": 9.872,
      "grad_norm": 0.6441318988800049,
      "learning_rate": 6.551020408163266e-07,
      "loss": 0.0764,
      "step": 24680
    },
    {
      "epoch": 9.876,
      "grad_norm": 1.3719265460968018,
      "learning_rate": 6.346938775510204e-07,
      "loss": 0.0495,
      "step": 24690
    },
    {
      "epoch": 9.88,
      "grad_norm": 0.5347196459770203,
      "learning_rate": 6.142857142857143e-07,
      "loss": 0.0444,
      "step": 24700
    },
    {
      "epoch": 9.884,
      "grad_norm": 0.6573810577392578,
      "learning_rate": 5.938775510204082e-07,
      "loss": 0.0633,
      "step": 24710
    },
    {
      "epoch": 9.888,
      "grad_norm": 0.38550713658332825,
      "learning_rate": 5.73469387755102e-07,
      "loss": 0.0432,
      "step": 24720
    },
    {
      "epoch": 9.892,
      "grad_norm": 1.662105679512024,
      "learning_rate": 5.53061224489796e-07,
      "loss": 0.0373,
      "step": 24730
    },
    {
      "epoch": 9.896,
      "grad_norm": 0.014640969224274158,
      "learning_rate": 5.326530612244899e-07,
      "loss": 0.0291,
      "step": 24740
    },
    {
      "epoch": 9.9,
      "grad_norm": 1.1290758848190308,
      "learning_rate": 5.122448979591837e-07,
      "loss": 0.0832,
      "step": 24750
    },
    {
      "epoch": 9.904,
      "grad_norm": 0.25892725586891174,
      "learning_rate": 4.918367346938776e-07,
      "loss": 0.0658,
      "step": 24760
    },
    {
      "epoch": 9.908,
      "grad_norm": 2.3202626705169678,
      "learning_rate": 4.7142857142857145e-07,
      "loss": 0.0455,
      "step": 24770
    },
    {
      "epoch": 9.912,
      "grad_norm": 1.2151007652282715,
      "learning_rate": 4.5102040816326536e-07,
      "loss": 0.0817,
      "step": 24780
    },
    {
      "epoch": 9.916,
      "grad_norm": 0.17795224487781525,
      "learning_rate": 4.306122448979592e-07,
      "loss": 0.0294,
      "step": 24790
    },
    {
      "epoch": 9.92,
      "grad_norm": 0.8862199187278748,
      "learning_rate": 4.10204081632653e-07,
      "loss": 0.0924,
      "step": 24800
    },
    {
      "epoch": 9.924,
      "grad_norm": 1.5950977802276611,
      "learning_rate": 3.89795918367347e-07,
      "loss": 0.0785,
      "step": 24810
    },
    {
      "epoch": 9.928,
      "grad_norm": 0.11337333917617798,
      "learning_rate": 3.693877551020408e-07,
      "loss": 0.064,
      "step": 24820
    },
    {
      "epoch": 9.932,
      "grad_norm": 0.5910760164260864,
      "learning_rate": 3.489795918367347e-07,
      "loss": 0.062,
      "step": 24830
    },
    {
      "epoch": 9.936,
      "grad_norm": 1.1112916469573975,
      "learning_rate": 3.285714285714286e-07,
      "loss": 0.0416,
      "step": 24840
    },
    {
      "epoch": 9.94,
      "grad_norm": 0.671332061290741,
      "learning_rate": 3.0816326530612243e-07,
      "loss": 0.0538,
      "step": 24850
    },
    {
      "epoch": 9.943999999999999,
      "grad_norm": 0.8171030282974243,
      "learning_rate": 2.8775510204081634e-07,
      "loss": 0.0498,
      "step": 24860
    },
    {
      "epoch": 9.948,
      "grad_norm": 0.05407192185521126,
      "learning_rate": 2.673469387755102e-07,
      "loss": 0.0524,
      "step": 24870
    },
    {
      "epoch": 9.952,
      "grad_norm": 0.2592136859893799,
      "learning_rate": 2.4693877551020407e-07,
      "loss": 0.036,
      "step": 24880
    },
    {
      "epoch": 9.956,
      "grad_norm": 0.8360477089881897,
      "learning_rate": 2.2653061224489798e-07,
      "loss": 0.0725,
      "step": 24890
    },
    {
      "epoch": 9.96,
      "grad_norm": 0.9700220823287964,
      "learning_rate": 2.0612244897959184e-07,
      "loss": 0.0305,
      "step": 24900
    },
    {
      "epoch": 9.964,
      "grad_norm": 2.240147829055786,
      "learning_rate": 1.8571428571428572e-07,
      "loss": 0.0564,
      "step": 24910
    },
    {
      "epoch": 9.968,
      "grad_norm": 0.7361752986907959,
      "learning_rate": 1.6530612244897958e-07,
      "loss": 0.0637,
      "step": 24920
    },
    {
      "epoch": 9.972,
      "grad_norm": 0.055333591997623444,
      "learning_rate": 1.4489795918367347e-07,
      "loss": 0.0465,
      "step": 24930
    },
    {
      "epoch": 9.975999999999999,
      "grad_norm": 1.3001480102539062,
      "learning_rate": 1.2448979591836736e-07,
      "loss": 0.056,
      "step": 24940
    },
    {
      "epoch": 9.98,
      "grad_norm": 1.047071933746338,
      "learning_rate": 1.0408163265306122e-07,
      "loss": 0.0418,
      "step": 24950
    },
    {
      "epoch": 9.984,
      "grad_norm": 0.3938036262989044,
      "learning_rate": 8.36734693877551e-08,
      "loss": 0.0333,
      "step": 24960
    },
    {
      "epoch": 9.988,
      "grad_norm": 2.4033327102661133,
      "learning_rate": 6.326530612244899e-08,
      "loss": 0.0511,
      "step": 24970
    },
    {
      "epoch": 9.992,
      "grad_norm": 0.9797476530075073,
      "learning_rate": 4.285714285714286e-08,
      "loss": 0.0639,
      "step": 24980
    },
    {
      "epoch": 9.996,
      "grad_norm": 0.1816871017217636,
      "learning_rate": 2.2448979591836735e-08,
      "loss": 0.0792,
      "step": 24990
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.0853395462036133,
      "learning_rate": 2.040816326530612e-09,
      "loss": 0.0594,
      "step": 25000
    }
  ],
  "logging_steps": 10,
  "max_steps": 25000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
