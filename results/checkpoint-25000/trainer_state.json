{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 25000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004,
      "grad_norm": 0.7200278043746948,
      "learning_rate": 9e-07,
      "loss": 0.6849,
      "step": 10
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.6232509613037109,
      "learning_rate": 1.9e-06,
      "loss": 0.6888,
      "step": 20
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.8373543620109558,
      "learning_rate": 2.9e-06,
      "loss": 0.6861,
      "step": 30
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.4947054982185364,
      "learning_rate": 3.9e-06,
      "loss": 0.6892,
      "step": 40
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7132530808448792,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 0.685,
      "step": 50
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.7223619222640991,
      "learning_rate": 5.9e-06,
      "loss": 0.6863,
      "step": 60
    },
    {
      "epoch": 0.028,
      "grad_norm": 1.0889726877212524,
      "learning_rate": 6.900000000000001e-06,
      "loss": 0.6788,
      "step": 70
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.966964602470398,
      "learning_rate": 7.9e-06,
      "loss": 0.6804,
      "step": 80
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.7213804125785828,
      "learning_rate": 8.9e-06,
      "loss": 0.6799,
      "step": 90
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5751448273658752,
      "learning_rate": 9.900000000000002e-06,
      "loss": 0.6744,
      "step": 100
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.7210344076156616,
      "learning_rate": 1.09e-05,
      "loss": 0.6743,
      "step": 110
    },
    {
      "epoch": 0.048,
      "grad_norm": 1.0523947477340698,
      "learning_rate": 1.19e-05,
      "loss": 0.6686,
      "step": 120
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.9329416155815125,
      "learning_rate": 1.29e-05,
      "loss": 0.666,
      "step": 130
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.46468862891197205,
      "learning_rate": 1.3900000000000002e-05,
      "loss": 0.6693,
      "step": 140
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.45693641901016235,
      "learning_rate": 1.49e-05,
      "loss": 0.6632,
      "step": 150
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.698945164680481,
      "learning_rate": 1.59e-05,
      "loss": 0.6678,
      "step": 160
    },
    {
      "epoch": 0.068,
      "grad_norm": 0.859778642654419,
      "learning_rate": 1.69e-05,
      "loss": 0.6574,
      "step": 170
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.706342875957489,
      "learning_rate": 1.79e-05,
      "loss": 0.6523,
      "step": 180
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.5673418641090393,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 0.6458,
      "step": 190
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6141857504844666,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.6562,
      "step": 200
    },
    {
      "epoch": 0.084,
      "grad_norm": 0.4128735065460205,
      "learning_rate": 2.09e-05,
      "loss": 0.6482,
      "step": 210
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.6516937017440796,
      "learning_rate": 2.19e-05,
      "loss": 0.6522,
      "step": 220
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.7548235654830933,
      "learning_rate": 2.29e-05,
      "loss": 0.6342,
      "step": 230
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.8451579213142395,
      "learning_rate": 2.39e-05,
      "loss": 0.6388,
      "step": 240
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6274926662445068,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 0.6284,
      "step": 250
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.7434406876564026,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 0.6341,
      "step": 260
    },
    {
      "epoch": 0.108,
      "grad_norm": 0.7282450795173645,
      "learning_rate": 2.6900000000000003e-05,
      "loss": 0.6166,
      "step": 270
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.607622504234314,
      "learning_rate": 2.7900000000000004e-05,
      "loss": 0.6288,
      "step": 280
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.48621222376823425,
      "learning_rate": 2.8899999999999998e-05,
      "loss": 0.6165,
      "step": 290
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.37055838108062744,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 0.6234,
      "step": 300
    },
    {
      "epoch": 0.124,
      "grad_norm": 0.5907518267631531,
      "learning_rate": 3.09e-05,
      "loss": 0.6254,
      "step": 310
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.7019996643066406,
      "learning_rate": 3.19e-05,
      "loss": 0.5883,
      "step": 320
    },
    {
      "epoch": 0.132,
      "grad_norm": 0.7170929908752441,
      "learning_rate": 3.29e-05,
      "loss": 0.5965,
      "step": 330
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.7450311183929443,
      "learning_rate": 3.3900000000000004e-05,
      "loss": 0.6025,
      "step": 340
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.614876925945282,
      "learning_rate": 3.49e-05,
      "loss": 0.5792,
      "step": 350
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.574694037437439,
      "learning_rate": 3.59e-05,
      "loss": 0.5705,
      "step": 360
    },
    {
      "epoch": 0.148,
      "grad_norm": 0.8612781763076782,
      "learning_rate": 3.69e-05,
      "loss": 0.5798,
      "step": 370
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.4783702790737152,
      "learning_rate": 3.79e-05,
      "loss": 0.5719,
      "step": 380
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.33042800426483154,
      "learning_rate": 3.8900000000000004e-05,
      "loss": 0.5541,
      "step": 390
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8342320322990417,
      "learning_rate": 3.99e-05,
      "loss": 0.5714,
      "step": 400
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.45369523763656616,
      "learning_rate": 4.09e-05,
      "loss": 0.5956,
      "step": 410
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.6605662703514099,
      "learning_rate": 4.19e-05,
      "loss": 0.5748,
      "step": 420
    },
    {
      "epoch": 0.172,
      "grad_norm": 0.5693058967590332,
      "learning_rate": 4.29e-05,
      "loss": 0.5152,
      "step": 430
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.7261828780174255,
      "learning_rate": 4.39e-05,
      "loss": 0.5285,
      "step": 440
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.8266086578369141,
      "learning_rate": 4.49e-05,
      "loss": 0.5438,
      "step": 450
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.5461432337760925,
      "learning_rate": 4.5900000000000004e-05,
      "loss": 0.482,
      "step": 460
    },
    {
      "epoch": 0.188,
      "grad_norm": 0.4797728359699249,
      "learning_rate": 4.69e-05,
      "loss": 0.4919,
      "step": 470
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.6627209186553955,
      "learning_rate": 4.79e-05,
      "loss": 0.5264,
      "step": 480
    },
    {
      "epoch": 0.196,
      "grad_norm": 0.4647793471813202,
      "learning_rate": 4.89e-05,
      "loss": 0.4908,
      "step": 490
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8210972547531128,
      "learning_rate": 4.99e-05,
      "loss": 0.4765,
      "step": 500
    },
    {
      "epoch": 0.204,
      "grad_norm": 0.6307706832885742,
      "learning_rate": 4.998163265306123e-05,
      "loss": 0.4876,
      "step": 510
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.36592525243759155,
      "learning_rate": 4.996122448979592e-05,
      "loss": 0.4776,
      "step": 520
    },
    {
      "epoch": 0.212,
      "grad_norm": 0.3367866277694702,
      "learning_rate": 4.994081632653062e-05,
      "loss": 0.508,
      "step": 530
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.36635568737983704,
      "learning_rate": 4.992040816326531e-05,
      "loss": 0.4459,
      "step": 540
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5216093063354492,
      "learning_rate": 4.99e-05,
      "loss": 0.4863,
      "step": 550
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.5329038500785828,
      "learning_rate": 4.98795918367347e-05,
      "loss": 0.4699,
      "step": 560
    },
    {
      "epoch": 0.228,
      "grad_norm": 0.7666809558868408,
      "learning_rate": 4.985918367346939e-05,
      "loss": 0.4379,
      "step": 570
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.5751156806945801,
      "learning_rate": 4.983877551020408e-05,
      "loss": 0.492,
      "step": 580
    },
    {
      "epoch": 0.236,
      "grad_norm": 0.7108820676803589,
      "learning_rate": 4.981836734693878e-05,
      "loss": 0.5009,
      "step": 590
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5102025270462036,
      "learning_rate": 4.979795918367347e-05,
      "loss": 0.51,
      "step": 600
    },
    {
      "epoch": 0.244,
      "grad_norm": 0.3793566823005676,
      "learning_rate": 4.977755102040816e-05,
      "loss": 0.5026,
      "step": 610
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.5371597409248352,
      "learning_rate": 4.9757142857142855e-05,
      "loss": 0.3979,
      "step": 620
    },
    {
      "epoch": 0.252,
      "grad_norm": 0.8607664704322815,
      "learning_rate": 4.973673469387755e-05,
      "loss": 0.3908,
      "step": 630
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.39876359701156616,
      "learning_rate": 4.9716326530612245e-05,
      "loss": 0.4704,
      "step": 640
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.531631350517273,
      "learning_rate": 4.9695918367346936e-05,
      "loss": 0.504,
      "step": 650
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.5992497801780701,
      "learning_rate": 4.9675510204081634e-05,
      "loss": 0.4648,
      "step": 660
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.6129829287528992,
      "learning_rate": 4.965510204081633e-05,
      "loss": 0.4558,
      "step": 670
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.5012715458869934,
      "learning_rate": 4.9634693877551024e-05,
      "loss": 0.4105,
      "step": 680
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.45027387142181396,
      "learning_rate": 4.9614285714285716e-05,
      "loss": 0.4192,
      "step": 690
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.45178475975990295,
      "learning_rate": 4.9593877551020414e-05,
      "loss": 0.4487,
      "step": 700
    },
    {
      "epoch": 0.284,
      "grad_norm": 0.39399757981300354,
      "learning_rate": 4.9573469387755106e-05,
      "loss": 0.4765,
      "step": 710
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.48881253600120544,
      "learning_rate": 4.95530612244898e-05,
      "loss": 0.5014,
      "step": 720
    },
    {
      "epoch": 0.292,
      "grad_norm": 0.5718034505844116,
      "learning_rate": 4.9532653061224496e-05,
      "loss": 0.3833,
      "step": 730
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.4394875168800354,
      "learning_rate": 4.951224489795919e-05,
      "loss": 0.4712,
      "step": 740
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7849111557006836,
      "learning_rate": 4.949183673469388e-05,
      "loss": 0.4837,
      "step": 750
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.4039812386035919,
      "learning_rate": 4.947142857142858e-05,
      "loss": 0.4811,
      "step": 760
    },
    {
      "epoch": 0.308,
      "grad_norm": 0.40309596061706543,
      "learning_rate": 4.945102040816327e-05,
      "loss": 0.4148,
      "step": 770
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.5344606041908264,
      "learning_rate": 4.943061224489796e-05,
      "loss": 0.383,
      "step": 780
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.45132988691329956,
      "learning_rate": 4.941020408163265e-05,
      "loss": 0.4545,
      "step": 790
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3658098876476288,
      "learning_rate": 4.938979591836735e-05,
      "loss": 0.5075,
      "step": 800
    },
    {
      "epoch": 0.324,
      "grad_norm": 0.4302493631839752,
      "learning_rate": 4.936938775510204e-05,
      "loss": 0.4133,
      "step": 810
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.5707488059997559,
      "learning_rate": 4.9348979591836734e-05,
      "loss": 0.4282,
      "step": 820
    },
    {
      "epoch": 0.332,
      "grad_norm": 0.40364083647727966,
      "learning_rate": 4.932857142857143e-05,
      "loss": 0.3873,
      "step": 830
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.4093915522098541,
      "learning_rate": 4.9308163265306124e-05,
      "loss": 0.4875,
      "step": 840
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.9915804266929626,
      "learning_rate": 4.9287755102040815e-05,
      "loss": 0.5033,
      "step": 850
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.3970949053764343,
      "learning_rate": 4.9267346938775514e-05,
      "loss": 0.4547,
      "step": 860
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.9002030491828918,
      "learning_rate": 4.9246938775510205e-05,
      "loss": 0.4692,
      "step": 870
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.4814218282699585,
      "learning_rate": 4.92265306122449e-05,
      "loss": 0.4453,
      "step": 880
    },
    {
      "epoch": 0.356,
      "grad_norm": 0.44272086024284363,
      "learning_rate": 4.9206122448979595e-05,
      "loss": 0.3975,
      "step": 890
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.37678107619285583,
      "learning_rate": 4.9185714285714293e-05,
      "loss": 0.4143,
      "step": 900
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.5169755220413208,
      "learning_rate": 4.9165306122448985e-05,
      "loss": 0.407,
      "step": 910
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.4439292252063751,
      "learning_rate": 4.914489795918368e-05,
      "loss": 0.4263,
      "step": 920
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.3651827275753021,
      "learning_rate": 4.912448979591837e-05,
      "loss": 0.4033,
      "step": 930
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.3851635158061981,
      "learning_rate": 4.9104081632653067e-05,
      "loss": 0.3799,
      "step": 940
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4333099126815796,
      "learning_rate": 4.908367346938776e-05,
      "loss": 0.3846,
      "step": 950
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.4326310455799103,
      "learning_rate": 4.906326530612245e-05,
      "loss": 0.4414,
      "step": 960
    },
    {
      "epoch": 0.388,
      "grad_norm": 0.5058102607727051,
      "learning_rate": 4.904285714285715e-05,
      "loss": 0.4,
      "step": 970
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.44046905636787415,
      "learning_rate": 4.902244897959184e-05,
      "loss": 0.408,
      "step": 980
    },
    {
      "epoch": 0.396,
      "grad_norm": 0.42164361476898193,
      "learning_rate": 4.900204081632653e-05,
      "loss": 0.4019,
      "step": 990
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5338824391365051,
      "learning_rate": 4.898163265306123e-05,
      "loss": 0.3593,
      "step": 1000
    },
    {
      "epoch": 0.404,
      "grad_norm": 0.46885946393013,
      "learning_rate": 4.896122448979592e-05,
      "loss": 0.4537,
      "step": 1010
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.3861015737056732,
      "learning_rate": 4.894081632653061e-05,
      "loss": 0.3533,
      "step": 1020
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.5611470341682434,
      "learning_rate": 4.8920408163265304e-05,
      "loss": 0.4609,
      "step": 1030
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.554672360420227,
      "learning_rate": 4.89e-05,
      "loss": 0.3618,
      "step": 1040
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5139027237892151,
      "learning_rate": 4.8879591836734694e-05,
      "loss": 0.4468,
      "step": 1050
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.4247305393218994,
      "learning_rate": 4.8859183673469386e-05,
      "loss": 0.3422,
      "step": 1060
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.4411725401878357,
      "learning_rate": 4.8838775510204084e-05,
      "loss": 0.3392,
      "step": 1070
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.5124421119689941,
      "learning_rate": 4.8818367346938776e-05,
      "loss": 0.318,
      "step": 1080
    },
    {
      "epoch": 0.436,
      "grad_norm": 0.9940460324287415,
      "learning_rate": 4.879795918367347e-05,
      "loss": 0.4339,
      "step": 1090
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3867863714694977,
      "learning_rate": 4.8777551020408166e-05,
      "loss": 0.3514,
      "step": 1100
    },
    {
      "epoch": 0.444,
      "grad_norm": 0.45062875747680664,
      "learning_rate": 4.875714285714286e-05,
      "loss": 0.3784,
      "step": 1110
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.9286324977874756,
      "learning_rate": 4.8736734693877556e-05,
      "loss": 0.3352,
      "step": 1120
    },
    {
      "epoch": 0.452,
      "grad_norm": 0.4592302143573761,
      "learning_rate": 4.871632653061225e-05,
      "loss": 0.4436,
      "step": 1130
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.531993567943573,
      "learning_rate": 4.8695918367346946e-05,
      "loss": 0.3834,
      "step": 1140
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6707309484481812,
      "learning_rate": 4.867551020408164e-05,
      "loss": 0.4165,
      "step": 1150
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.49630478024482727,
      "learning_rate": 4.865510204081633e-05,
      "loss": 0.3789,
      "step": 1160
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.4345683455467224,
      "learning_rate": 4.863469387755103e-05,
      "loss": 0.3904,
      "step": 1170
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.5066077709197998,
      "learning_rate": 4.861428571428572e-05,
      "loss": 0.4484,
      "step": 1180
    },
    {
      "epoch": 0.476,
      "grad_norm": 0.5705970525741577,
      "learning_rate": 4.859387755102041e-05,
      "loss": 0.4036,
      "step": 1190
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6245286464691162,
      "learning_rate": 4.85734693877551e-05,
      "loss": 0.3903,
      "step": 1200
    },
    {
      "epoch": 0.484,
      "grad_norm": 0.5594092607498169,
      "learning_rate": 4.85530612244898e-05,
      "loss": 0.3573,
      "step": 1210
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.47637510299682617,
      "learning_rate": 4.853265306122449e-05,
      "loss": 0.3779,
      "step": 1220
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.5219854712486267,
      "learning_rate": 4.8512244897959184e-05,
      "loss": 0.4241,
      "step": 1230
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.5992438197135925,
      "learning_rate": 4.849183673469388e-05,
      "loss": 0.3676,
      "step": 1240
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5852797627449036,
      "learning_rate": 4.8471428571428573e-05,
      "loss": 0.363,
      "step": 1250
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.42890578508377075,
      "learning_rate": 4.8451020408163265e-05,
      "loss": 0.4018,
      "step": 1260
    },
    {
      "epoch": 0.508,
      "grad_norm": 0.41952574253082275,
      "learning_rate": 4.8430612244897963e-05,
      "loss": 0.4049,
      "step": 1270
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.529067873954773,
      "learning_rate": 4.8410204081632655e-05,
      "loss": 0.3428,
      "step": 1280
    },
    {
      "epoch": 0.516,
      "grad_norm": 0.6762955188751221,
      "learning_rate": 4.8389795918367347e-05,
      "loss": 0.3467,
      "step": 1290
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5097962617874146,
      "learning_rate": 4.836938775510204e-05,
      "loss": 0.3319,
      "step": 1300
    },
    {
      "epoch": 0.524,
      "grad_norm": 0.5192493796348572,
      "learning_rate": 4.8348979591836737e-05,
      "loss": 0.3672,
      "step": 1310
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.44750767946243286,
      "learning_rate": 4.832857142857143e-05,
      "loss": 0.3851,
      "step": 1320
    },
    {
      "epoch": 0.532,
      "grad_norm": 0.5219904184341431,
      "learning_rate": 4.830816326530612e-05,
      "loss": 0.3695,
      "step": 1330
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.4654899835586548,
      "learning_rate": 4.828775510204082e-05,
      "loss": 0.3783,
      "step": 1340
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.44132155179977417,
      "learning_rate": 4.8267346938775516e-05,
      "loss": 0.3515,
      "step": 1350
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.44542577862739563,
      "learning_rate": 4.824693877551021e-05,
      "loss": 0.3805,
      "step": 1360
    },
    {
      "epoch": 0.548,
      "grad_norm": 0.4367700219154358,
      "learning_rate": 4.82265306122449e-05,
      "loss": 0.3674,
      "step": 1370
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.6244828701019287,
      "learning_rate": 4.82061224489796e-05,
      "loss": 0.3565,
      "step": 1380
    },
    {
      "epoch": 0.556,
      "grad_norm": 0.42848172783851624,
      "learning_rate": 4.818571428571429e-05,
      "loss": 0.2748,
      "step": 1390
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.44350650906562805,
      "learning_rate": 4.816530612244898e-05,
      "loss": 0.3432,
      "step": 1400
    },
    {
      "epoch": 0.564,
      "grad_norm": 0.49231773614883423,
      "learning_rate": 4.814489795918368e-05,
      "loss": 0.409,
      "step": 1410
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.46245843172073364,
      "learning_rate": 4.812448979591837e-05,
      "loss": 0.3176,
      "step": 1420
    },
    {
      "epoch": 0.572,
      "grad_norm": 0.4299147129058838,
      "learning_rate": 4.810408163265306e-05,
      "loss": 0.3957,
      "step": 1430
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.5581935048103333,
      "learning_rate": 4.808367346938776e-05,
      "loss": 0.3678,
      "step": 1440
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.40924882888793945,
      "learning_rate": 4.806326530612245e-05,
      "loss": 0.3199,
      "step": 1450
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.5450461506843567,
      "learning_rate": 4.8042857142857144e-05,
      "loss": 0.3221,
      "step": 1460
    },
    {
      "epoch": 0.588,
      "grad_norm": 0.5192753076553345,
      "learning_rate": 4.8022448979591836e-05,
      "loss": 0.3553,
      "step": 1470
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.42886215448379517,
      "learning_rate": 4.8002040816326534e-05,
      "loss": 0.3067,
      "step": 1480
    },
    {
      "epoch": 0.596,
      "grad_norm": 0.5594190359115601,
      "learning_rate": 4.7981632653061226e-05,
      "loss": 0.4024,
      "step": 1490
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4486292898654938,
      "learning_rate": 4.796122448979592e-05,
      "loss": 0.3261,
      "step": 1500
    },
    {
      "epoch": 0.604,
      "grad_norm": 0.6222254037857056,
      "learning_rate": 4.7940816326530616e-05,
      "loss": 0.3048,
      "step": 1510
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.6195757389068604,
      "learning_rate": 4.792040816326531e-05,
      "loss": 0.3069,
      "step": 1520
    },
    {
      "epoch": 0.612,
      "grad_norm": 0.4345260560512543,
      "learning_rate": 4.79e-05,
      "loss": 0.3348,
      "step": 1530
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.4290049374103546,
      "learning_rate": 4.78795918367347e-05,
      "loss": 0.3043,
      "step": 1540
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5601701140403748,
      "learning_rate": 4.785918367346939e-05,
      "loss": 0.3514,
      "step": 1550
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.4061795771121979,
      "learning_rate": 4.783877551020408e-05,
      "loss": 0.3056,
      "step": 1560
    },
    {
      "epoch": 0.628,
      "grad_norm": 0.6215702295303345,
      "learning_rate": 4.781836734693878e-05,
      "loss": 0.3378,
      "step": 1570
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.3983025550842285,
      "learning_rate": 4.779795918367348e-05,
      "loss": 0.3515,
      "step": 1580
    },
    {
      "epoch": 0.636,
      "grad_norm": 0.5030673146247864,
      "learning_rate": 4.777755102040817e-05,
      "loss": 0.3657,
      "step": 1590
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3760066628456116,
      "learning_rate": 4.775714285714286e-05,
      "loss": 0.2577,
      "step": 1600
    },
    {
      "epoch": 0.644,
      "grad_norm": 0.5108755826950073,
      "learning_rate": 4.773673469387755e-05,
      "loss": 0.3654,
      "step": 1610
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.4891294240951538,
      "learning_rate": 4.771632653061225e-05,
      "loss": 0.2775,
      "step": 1620
    },
    {
      "epoch": 0.652,
      "grad_norm": 0.6041112542152405,
      "learning_rate": 4.769591836734694e-05,
      "loss": 0.2818,
      "step": 1630
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.3855436146259308,
      "learning_rate": 4.767551020408163e-05,
      "loss": 0.2929,
      "step": 1640
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5381457805633545,
      "learning_rate": 4.765510204081633e-05,
      "loss": 0.3226,
      "step": 1650
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.5085101127624512,
      "learning_rate": 4.763469387755102e-05,
      "loss": 0.2672,
      "step": 1660
    },
    {
      "epoch": 0.668,
      "grad_norm": 0.4957845211029053,
      "learning_rate": 4.7614285714285715e-05,
      "loss": 0.2592,
      "step": 1670
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.5337584614753723,
      "learning_rate": 4.759387755102041e-05,
      "loss": 0.3116,
      "step": 1680
    },
    {
      "epoch": 0.676,
      "grad_norm": 1.1345558166503906,
      "learning_rate": 4.7573469387755105e-05,
      "loss": 0.3215,
      "step": 1690
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.7577997446060181,
      "learning_rate": 4.7553061224489796e-05,
      "loss": 0.2876,
      "step": 1700
    },
    {
      "epoch": 0.684,
      "grad_norm": 0.6879657506942749,
      "learning_rate": 4.7532653061224495e-05,
      "loss": 0.2692,
      "step": 1710
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.4760536849498749,
      "learning_rate": 4.7512244897959186e-05,
      "loss": 0.3369,
      "step": 1720
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.459188312292099,
      "learning_rate": 4.749183673469388e-05,
      "loss": 0.2933,
      "step": 1730
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.5182958841323853,
      "learning_rate": 4.747142857142857e-05,
      "loss": 0.2796,
      "step": 1740
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.49868038296699524,
      "learning_rate": 4.745102040816327e-05,
      "loss": 0.2545,
      "step": 1750
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.7478030323982239,
      "learning_rate": 4.743061224489796e-05,
      "loss": 0.3109,
      "step": 1760
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.5516089797019958,
      "learning_rate": 4.741020408163265e-05,
      "loss": 0.3041,
      "step": 1770
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.8876863121986389,
      "learning_rate": 4.738979591836735e-05,
      "loss": 0.316,
      "step": 1780
    },
    {
      "epoch": 0.716,
      "grad_norm": 0.46935543417930603,
      "learning_rate": 4.736938775510204e-05,
      "loss": 0.2475,
      "step": 1790
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.507258415222168,
      "learning_rate": 4.734897959183674e-05,
      "loss": 0.2162,
      "step": 1800
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.5739200711250305,
      "learning_rate": 4.732857142857143e-05,
      "loss": 0.2821,
      "step": 1810
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.4846153259277344,
      "learning_rate": 4.730816326530613e-05,
      "loss": 0.2554,
      "step": 1820
    },
    {
      "epoch": 0.732,
      "grad_norm": 0.6403459906578064,
      "learning_rate": 4.728775510204082e-05,
      "loss": 0.2889,
      "step": 1830
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.5915482044219971,
      "learning_rate": 4.726734693877551e-05,
      "loss": 0.3053,
      "step": 1840
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4766078293323517,
      "learning_rate": 4.724693877551021e-05,
      "loss": 0.281,
      "step": 1850
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.4816378057003021,
      "learning_rate": 4.72265306122449e-05,
      "loss": 0.2643,
      "step": 1860
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.5138314962387085,
      "learning_rate": 4.7206122448979594e-05,
      "loss": 0.2607,
      "step": 1870
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.4168478548526764,
      "learning_rate": 4.7185714285714286e-05,
      "loss": 0.2563,
      "step": 1880
    },
    {
      "epoch": 0.756,
      "grad_norm": 0.660070538520813,
      "learning_rate": 4.7165306122448984e-05,
      "loss": 0.2951,
      "step": 1890
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4175020754337311,
      "learning_rate": 4.7144897959183675e-05,
      "loss": 0.2435,
      "step": 1900
    },
    {
      "epoch": 0.764,
      "grad_norm": 0.5391448736190796,
      "learning_rate": 4.712448979591837e-05,
      "loss": 0.3539,
      "step": 1910
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.49824801087379456,
      "learning_rate": 4.7104081632653065e-05,
      "loss": 0.2554,
      "step": 1920
    },
    {
      "epoch": 0.772,
      "grad_norm": 0.7344741821289062,
      "learning_rate": 4.708367346938776e-05,
      "loss": 0.2873,
      "step": 1930
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.46179190278053284,
      "learning_rate": 4.706326530612245e-05,
      "loss": 0.2373,
      "step": 1940
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.4532458782196045,
      "learning_rate": 4.704285714285715e-05,
      "loss": 0.2188,
      "step": 1950
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.6894716024398804,
      "learning_rate": 4.702244897959184e-05,
      "loss": 0.2275,
      "step": 1960
    },
    {
      "epoch": 0.788,
      "grad_norm": 0.4714300036430359,
      "learning_rate": 4.700204081632653e-05,
      "loss": 0.2576,
      "step": 1970
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.6870396137237549,
      "learning_rate": 4.698163265306122e-05,
      "loss": 0.2483,
      "step": 1980
    },
    {
      "epoch": 0.796,
      "grad_norm": 0.5591847896575928,
      "learning_rate": 4.696122448979592e-05,
      "loss": 0.2731,
      "step": 1990
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5790648460388184,
      "learning_rate": 4.694081632653061e-05,
      "loss": 0.2564,
      "step": 2000
    },
    {
      "epoch": 0.804,
      "grad_norm": 0.713435173034668,
      "learning_rate": 4.69204081632653e-05,
      "loss": 0.2119,
      "step": 2010
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.8582972884178162,
      "learning_rate": 4.69e-05,
      "loss": 0.2381,
      "step": 2020
    },
    {
      "epoch": 0.812,
      "grad_norm": 0.7223342657089233,
      "learning_rate": 4.68795918367347e-05,
      "loss": 0.245,
      "step": 2030
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.6174259781837463,
      "learning_rate": 4.685918367346939e-05,
      "loss": 0.2706,
      "step": 2040
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.0025460720062256,
      "learning_rate": 4.683877551020408e-05,
      "loss": 0.2248,
      "step": 2050
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.5788561105728149,
      "learning_rate": 4.681836734693878e-05,
      "loss": 0.2197,
      "step": 2060
    },
    {
      "epoch": 0.828,
      "grad_norm": 0.6530305743217468,
      "learning_rate": 4.679795918367347e-05,
      "loss": 0.2134,
      "step": 2070
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.672014594078064,
      "learning_rate": 4.6777551020408165e-05,
      "loss": 0.2356,
      "step": 2080
    },
    {
      "epoch": 0.836,
      "grad_norm": 0.9901846647262573,
      "learning_rate": 4.675714285714286e-05,
      "loss": 0.3043,
      "step": 2090
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6964862942695618,
      "learning_rate": 4.6736734693877555e-05,
      "loss": 0.2527,
      "step": 2100
    },
    {
      "epoch": 0.844,
      "grad_norm": 0.30764228105545044,
      "learning_rate": 4.6716326530612246e-05,
      "loss": 0.2167,
      "step": 2110
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.779815673828125,
      "learning_rate": 4.6695918367346945e-05,
      "loss": 0.2414,
      "step": 2120
    },
    {
      "epoch": 0.852,
      "grad_norm": 0.5061221718788147,
      "learning_rate": 4.6675510204081636e-05,
      "loss": 0.2801,
      "step": 2130
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.7377050518989563,
      "learning_rate": 4.665510204081633e-05,
      "loss": 0.2192,
      "step": 2140
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.848108172416687,
      "learning_rate": 4.663469387755102e-05,
      "loss": 0.2389,
      "step": 2150
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.7693531513214111,
      "learning_rate": 4.661428571428572e-05,
      "loss": 0.2433,
      "step": 2160
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.4580877721309662,
      "learning_rate": 4.659387755102041e-05,
      "loss": 0.2747,
      "step": 2170
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.862794816493988,
      "learning_rate": 4.65734693877551e-05,
      "loss": 0.2321,
      "step": 2180
    },
    {
      "epoch": 0.876,
      "grad_norm": 0.5221237540245056,
      "learning_rate": 4.65530612244898e-05,
      "loss": 0.2061,
      "step": 2190
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5318644642829895,
      "learning_rate": 4.653265306122449e-05,
      "loss": 0.1985,
      "step": 2200
    },
    {
      "epoch": 0.884,
      "grad_norm": 0.986398458480835,
      "learning_rate": 4.651224489795918e-05,
      "loss": 0.2148,
      "step": 2210
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.6203157305717468,
      "learning_rate": 4.649183673469388e-05,
      "loss": 0.2367,
      "step": 2220
    },
    {
      "epoch": 0.892,
      "grad_norm": 0.6395502090454102,
      "learning_rate": 4.647142857142857e-05,
      "loss": 0.2619,
      "step": 2230
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.5625078678131104,
      "learning_rate": 4.6451020408163264e-05,
      "loss": 0.2745,
      "step": 2240
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3764186203479767,
      "learning_rate": 4.643061224489796e-05,
      "loss": 0.1884,
      "step": 2250
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.4888930916786194,
      "learning_rate": 4.641020408163266e-05,
      "loss": 0.2335,
      "step": 2260
    },
    {
      "epoch": 0.908,
      "grad_norm": 0.7135249972343445,
      "learning_rate": 4.638979591836735e-05,
      "loss": 0.214,
      "step": 2270
    },
    {
      "epoch": 0.912,
      "grad_norm": 1.1431472301483154,
      "learning_rate": 4.6369387755102044e-05,
      "loss": 0.2458,
      "step": 2280
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.3600463271141052,
      "learning_rate": 4.6348979591836735e-05,
      "loss": 0.2049,
      "step": 2290
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.4747808277606964,
      "learning_rate": 4.6328571428571434e-05,
      "loss": 0.1814,
      "step": 2300
    },
    {
      "epoch": 0.924,
      "grad_norm": 0.5931788682937622,
      "learning_rate": 4.6308163265306125e-05,
      "loss": 0.2284,
      "step": 2310
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.6137957572937012,
      "learning_rate": 4.628775510204082e-05,
      "loss": 0.2109,
      "step": 2320
    },
    {
      "epoch": 0.932,
      "grad_norm": 1.051040768623352,
      "learning_rate": 4.6267346938775515e-05,
      "loss": 0.2531,
      "step": 2330
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.6724671125411987,
      "learning_rate": 4.624693877551021e-05,
      "loss": 0.2048,
      "step": 2340
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.2772181034088135,
      "learning_rate": 4.62265306122449e-05,
      "loss": 0.2372,
      "step": 2350
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.5299036502838135,
      "learning_rate": 4.62061224489796e-05,
      "loss": 0.2913,
      "step": 2360
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.5059457421302795,
      "learning_rate": 4.618571428571429e-05,
      "loss": 0.1868,
      "step": 2370
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.5514259934425354,
      "learning_rate": 4.616530612244898e-05,
      "loss": 0.2157,
      "step": 2380
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.46464070677757263,
      "learning_rate": 4.614489795918368e-05,
      "loss": 0.2026,
      "step": 2390
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.795216977596283,
      "learning_rate": 4.612448979591837e-05,
      "loss": 0.1929,
      "step": 2400
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.5063718557357788,
      "learning_rate": 4.610408163265306e-05,
      "loss": 0.1915,
      "step": 2410
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.5479342341423035,
      "learning_rate": 4.608367346938775e-05,
      "loss": 0.1916,
      "step": 2420
    },
    {
      "epoch": 0.972,
      "grad_norm": 1.0069372653961182,
      "learning_rate": 4.606326530612245e-05,
      "loss": 0.2177,
      "step": 2430
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.4578430950641632,
      "learning_rate": 4.604285714285714e-05,
      "loss": 0.1998,
      "step": 2440
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.7024282813072205,
      "learning_rate": 4.6022448979591835e-05,
      "loss": 0.1792,
      "step": 2450
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.6894810199737549,
      "learning_rate": 4.600204081632653e-05,
      "loss": 0.2295,
      "step": 2460
    },
    {
      "epoch": 0.988,
      "grad_norm": 0.7526906728744507,
      "learning_rate": 4.5981632653061224e-05,
      "loss": 0.2174,
      "step": 2470
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.5881426930427551,
      "learning_rate": 4.596122448979592e-05,
      "loss": 0.1881,
      "step": 2480
    },
    {
      "epoch": 0.996,
      "grad_norm": 0.7536388039588928,
      "learning_rate": 4.5940816326530614e-05,
      "loss": 0.2255,
      "step": 2490
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.8777292370796204,
      "learning_rate": 4.592040816326531e-05,
      "loss": 0.2445,
      "step": 2500
    },
    {
      "epoch": 1.004,
      "grad_norm": 0.6166940331459045,
      "learning_rate": 4.5900000000000004e-05,
      "loss": 0.1494,
      "step": 2510
    },
    {
      "epoch": 1.008,
      "grad_norm": 1.0267375707626343,
      "learning_rate": 4.5879591836734696e-05,
      "loss": 0.2427,
      "step": 2520
    },
    {
      "epoch": 1.012,
      "grad_norm": 0.9229598045349121,
      "learning_rate": 4.5859183673469394e-05,
      "loss": 0.2312,
      "step": 2530
    },
    {
      "epoch": 1.016,
      "grad_norm": 0.7215874791145325,
      "learning_rate": 4.5838775510204086e-05,
      "loss": 0.2055,
      "step": 2540
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.6600627899169922,
      "learning_rate": 4.581836734693878e-05,
      "loss": 0.2117,
      "step": 2550
    },
    {
      "epoch": 1.024,
      "grad_norm": 1.202625036239624,
      "learning_rate": 4.579795918367347e-05,
      "loss": 0.2066,
      "step": 2560
    },
    {
      "epoch": 1.028,
      "grad_norm": 0.5059140920639038,
      "learning_rate": 4.577755102040817e-05,
      "loss": 0.1652,
      "step": 2570
    },
    {
      "epoch": 1.032,
      "grad_norm": 0.7525455951690674,
      "learning_rate": 4.575714285714286e-05,
      "loss": 0.219,
      "step": 2580
    },
    {
      "epoch": 1.036,
      "grad_norm": 0.5474050641059875,
      "learning_rate": 4.573673469387755e-05,
      "loss": 0.2139,
      "step": 2590
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.5786130428314209,
      "learning_rate": 4.571632653061225e-05,
      "loss": 0.1729,
      "step": 2600
    },
    {
      "epoch": 1.044,
      "grad_norm": 0.599234938621521,
      "learning_rate": 4.569591836734694e-05,
      "loss": 0.1785,
      "step": 2610
    },
    {
      "epoch": 1.048,
      "grad_norm": 0.5227978229522705,
      "learning_rate": 4.567551020408163e-05,
      "loss": 0.1997,
      "step": 2620
    },
    {
      "epoch": 1.052,
      "grad_norm": 0.8954932689666748,
      "learning_rate": 4.565510204081633e-05,
      "loss": 0.235,
      "step": 2630
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.8817391395568848,
      "learning_rate": 4.563469387755102e-05,
      "loss": 0.1578,
      "step": 2640
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.6432201862335205,
      "learning_rate": 4.5614285714285714e-05,
      "loss": 0.22,
      "step": 2650
    },
    {
      "epoch": 1.064,
      "grad_norm": 0.46616387367248535,
      "learning_rate": 4.5593877551020405e-05,
      "loss": 0.2326,
      "step": 2660
    },
    {
      "epoch": 1.068,
      "grad_norm": 0.610985279083252,
      "learning_rate": 4.5573469387755104e-05,
      "loss": 0.1865,
      "step": 2670
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.5456046462059021,
      "learning_rate": 4.5553061224489795e-05,
      "loss": 0.1675,
      "step": 2680
    },
    {
      "epoch": 1.076,
      "grad_norm": 0.6468315720558167,
      "learning_rate": 4.553265306122449e-05,
      "loss": 0.1479,
      "step": 2690
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.615894079208374,
      "learning_rate": 4.5512244897959185e-05,
      "loss": 0.1986,
      "step": 2700
    },
    {
      "epoch": 1.084,
      "grad_norm": 0.4730718433856964,
      "learning_rate": 4.5491836734693883e-05,
      "loss": 0.1676,
      "step": 2710
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.5891376733779907,
      "learning_rate": 4.5471428571428575e-05,
      "loss": 0.1859,
      "step": 2720
    },
    {
      "epoch": 1.092,
      "grad_norm": 0.8040699362754822,
      "learning_rate": 4.545102040816327e-05,
      "loss": 0.1739,
      "step": 2730
    },
    {
      "epoch": 1.096,
      "grad_norm": 0.8605033159255981,
      "learning_rate": 4.5430612244897965e-05,
      "loss": 0.1914,
      "step": 2740
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.873058557510376,
      "learning_rate": 4.5410204081632657e-05,
      "loss": 0.2127,
      "step": 2750
    },
    {
      "epoch": 1.104,
      "grad_norm": 1.123775601387024,
      "learning_rate": 4.538979591836735e-05,
      "loss": 0.2069,
      "step": 2760
    },
    {
      "epoch": 1.108,
      "grad_norm": 0.588079035282135,
      "learning_rate": 4.5369387755102047e-05,
      "loss": 0.2064,
      "step": 2770
    },
    {
      "epoch": 1.112,
      "grad_norm": 0.5556291937828064,
      "learning_rate": 4.534897959183674e-05,
      "loss": 0.1591,
      "step": 2780
    },
    {
      "epoch": 1.116,
      "grad_norm": 0.6183542013168335,
      "learning_rate": 4.532857142857143e-05,
      "loss": 0.1723,
      "step": 2790
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.9343749284744263,
      "learning_rate": 4.530816326530613e-05,
      "loss": 0.1802,
      "step": 2800
    },
    {
      "epoch": 1.124,
      "grad_norm": 0.7442328929901123,
      "learning_rate": 4.528775510204082e-05,
      "loss": 0.1445,
      "step": 2810
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 1.1092770099639893,
      "learning_rate": 4.526734693877551e-05,
      "loss": 0.2128,
      "step": 2820
    },
    {
      "epoch": 1.1320000000000001,
      "grad_norm": 0.9338506460189819,
      "learning_rate": 4.52469387755102e-05,
      "loss": 0.1719,
      "step": 2830
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.7590484023094177,
      "learning_rate": 4.52265306122449e-05,
      "loss": 0.1535,
      "step": 2840
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 0.7102946043014526,
      "learning_rate": 4.520612244897959e-05,
      "loss": 0.1877,
      "step": 2850
    },
    {
      "epoch": 1.144,
      "grad_norm": 0.545494794845581,
      "learning_rate": 4.5185714285714284e-05,
      "loss": 0.1456,
      "step": 2860
    },
    {
      "epoch": 1.148,
      "grad_norm": 0.7321920394897461,
      "learning_rate": 4.516530612244898e-05,
      "loss": 0.168,
      "step": 2870
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.8545647263526917,
      "learning_rate": 4.5144897959183674e-05,
      "loss": 0.1969,
      "step": 2880
    },
    {
      "epoch": 1.156,
      "grad_norm": 0.7267811894416809,
      "learning_rate": 4.5124489795918366e-05,
      "loss": 0.2337,
      "step": 2890
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.422821283340454,
      "learning_rate": 4.5104081632653064e-05,
      "loss": 0.17,
      "step": 2900
    },
    {
      "epoch": 1.164,
      "grad_norm": 0.5315994024276733,
      "learning_rate": 4.5083673469387756e-05,
      "loss": 0.1546,
      "step": 2910
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.9365836381912231,
      "learning_rate": 4.506326530612245e-05,
      "loss": 0.1965,
      "step": 2920
    },
    {
      "epoch": 1.172,
      "grad_norm": 1.266292929649353,
      "learning_rate": 4.5042857142857146e-05,
      "loss": 0.1662,
      "step": 2930
    },
    {
      "epoch": 1.176,
      "grad_norm": 0.5685932040214539,
      "learning_rate": 4.5022448979591844e-05,
      "loss": 0.1407,
      "step": 2940
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.4069683849811554,
      "learning_rate": 4.5002040816326536e-05,
      "loss": 0.1895,
      "step": 2950
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.8368072509765625,
      "learning_rate": 4.498163265306123e-05,
      "loss": 0.1832,
      "step": 2960
    },
    {
      "epoch": 1.188,
      "grad_norm": 0.7960163950920105,
      "learning_rate": 4.4961224489795926e-05,
      "loss": 0.2355,
      "step": 2970
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.843593955039978,
      "learning_rate": 4.494081632653062e-05,
      "loss": 0.1383,
      "step": 2980
    },
    {
      "epoch": 1.196,
      "grad_norm": 0.9033417105674744,
      "learning_rate": 4.492040816326531e-05,
      "loss": 0.1794,
      "step": 2990
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.9621565341949463,
      "learning_rate": 4.49e-05,
      "loss": 0.1555,
      "step": 3000
    },
    {
      "epoch": 1.204,
      "grad_norm": 0.4521133303642273,
      "learning_rate": 4.48795918367347e-05,
      "loss": 0.1959,
      "step": 3010
    },
    {
      "epoch": 1.208,
      "grad_norm": 0.23959490656852722,
      "learning_rate": 4.485918367346939e-05,
      "loss": 0.1439,
      "step": 3020
    },
    {
      "epoch": 1.212,
      "grad_norm": 0.7157130837440491,
      "learning_rate": 4.483877551020408e-05,
      "loss": 0.1617,
      "step": 3030
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.3623369336128235,
      "learning_rate": 4.481836734693878e-05,
      "loss": 0.1542,
      "step": 3040
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.6628059148788452,
      "learning_rate": 4.479795918367347e-05,
      "loss": 0.1441,
      "step": 3050
    },
    {
      "epoch": 1.224,
      "grad_norm": 0.8561573028564453,
      "learning_rate": 4.4777551020408163e-05,
      "loss": 0.164,
      "step": 3060
    },
    {
      "epoch": 1.228,
      "grad_norm": 0.6642175316810608,
      "learning_rate": 4.475714285714286e-05,
      "loss": 0.1884,
      "step": 3070
    },
    {
      "epoch": 1.232,
      "grad_norm": 1.0311596393585205,
      "learning_rate": 4.4736734693877553e-05,
      "loss": 0.1712,
      "step": 3080
    },
    {
      "epoch": 1.236,
      "grad_norm": 0.40608590841293335,
      "learning_rate": 4.4716326530612245e-05,
      "loss": 0.1935,
      "step": 3090
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.28959906101226807,
      "learning_rate": 4.4695918367346937e-05,
      "loss": 0.1362,
      "step": 3100
    },
    {
      "epoch": 1.244,
      "grad_norm": 0.9085718393325806,
      "learning_rate": 4.4675510204081635e-05,
      "loss": 0.1746,
      "step": 3110
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.9254425764083862,
      "learning_rate": 4.4655102040816327e-05,
      "loss": 0.1678,
      "step": 3120
    },
    {
      "epoch": 1.252,
      "grad_norm": 0.3965035080909729,
      "learning_rate": 4.463469387755102e-05,
      "loss": 0.1551,
      "step": 3130
    },
    {
      "epoch": 1.256,
      "grad_norm": 0.8111324310302734,
      "learning_rate": 4.4614285714285716e-05,
      "loss": 0.148,
      "step": 3140
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.4662543535232544,
      "learning_rate": 4.459387755102041e-05,
      "loss": 0.1279,
      "step": 3150
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.7287784218788147,
      "learning_rate": 4.4573469387755106e-05,
      "loss": 0.1728,
      "step": 3160
    },
    {
      "epoch": 1.268,
      "grad_norm": 0.4373532235622406,
      "learning_rate": 4.45530612244898e-05,
      "loss": 0.1454,
      "step": 3170
    },
    {
      "epoch": 1.272,
      "grad_norm": 0.6487559080123901,
      "learning_rate": 4.4532653061224496e-05,
      "loss": 0.1373,
      "step": 3180
    },
    {
      "epoch": 1.276,
      "grad_norm": 0.48729631304740906,
      "learning_rate": 4.451224489795919e-05,
      "loss": 0.1807,
      "step": 3190
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.7648264765739441,
      "learning_rate": 4.449183673469388e-05,
      "loss": 0.1567,
      "step": 3200
    },
    {
      "epoch": 1.284,
      "grad_norm": 0.5833612084388733,
      "learning_rate": 4.447142857142858e-05,
      "loss": 0.1878,
      "step": 3210
    },
    {
      "epoch": 1.288,
      "grad_norm": 0.6540875434875488,
      "learning_rate": 4.445102040816327e-05,
      "loss": 0.1466,
      "step": 3220
    },
    {
      "epoch": 1.292,
      "grad_norm": 0.5547824501991272,
      "learning_rate": 4.443061224489796e-05,
      "loss": 0.1588,
      "step": 3230
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.19746269285678864,
      "learning_rate": 4.441020408163265e-05,
      "loss": 0.1273,
      "step": 3240
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.7926318049430847,
      "learning_rate": 4.438979591836735e-05,
      "loss": 0.1556,
      "step": 3250
    },
    {
      "epoch": 1.304,
      "grad_norm": 0.2924756407737732,
      "learning_rate": 4.436938775510204e-05,
      "loss": 0.1333,
      "step": 3260
    },
    {
      "epoch": 1.308,
      "grad_norm": 1.0629737377166748,
      "learning_rate": 4.4348979591836734e-05,
      "loss": 0.1721,
      "step": 3270
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.17782621085643768,
      "learning_rate": 4.432857142857143e-05,
      "loss": 0.1387,
      "step": 3280
    },
    {
      "epoch": 1.316,
      "grad_norm": 0.4740324020385742,
      "learning_rate": 4.4308163265306124e-05,
      "loss": 0.1501,
      "step": 3290
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.9369229674339294,
      "learning_rate": 4.4287755102040816e-05,
      "loss": 0.1888,
      "step": 3300
    },
    {
      "epoch": 1.324,
      "grad_norm": 1.4183834791183472,
      "learning_rate": 4.4267346938775514e-05,
      "loss": 0.2165,
      "step": 3310
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.6017440557479858,
      "learning_rate": 4.4246938775510206e-05,
      "loss": 0.1315,
      "step": 3320
    },
    {
      "epoch": 1.332,
      "grad_norm": 0.47300219535827637,
      "learning_rate": 4.42265306122449e-05,
      "loss": 0.16,
      "step": 3330
    },
    {
      "epoch": 1.336,
      "grad_norm": 0.3253158628940582,
      "learning_rate": 4.4206122448979596e-05,
      "loss": 0.1222,
      "step": 3340
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.31784170866012573,
      "learning_rate": 4.418571428571429e-05,
      "loss": 0.1208,
      "step": 3350
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.7403609156608582,
      "learning_rate": 4.416530612244898e-05,
      "loss": 0.1882,
      "step": 3360
    },
    {
      "epoch": 1.3479999999999999,
      "grad_norm": 0.8394477963447571,
      "learning_rate": 4.414489795918367e-05,
      "loss": 0.1584,
      "step": 3370
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 0.7101966142654419,
      "learning_rate": 4.412448979591837e-05,
      "loss": 0.1513,
      "step": 3380
    },
    {
      "epoch": 1.3559999999999999,
      "grad_norm": 0.6170527338981628,
      "learning_rate": 4.410408163265307e-05,
      "loss": 0.1478,
      "step": 3390
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.27906468510627747,
      "learning_rate": 4.408367346938776e-05,
      "loss": 0.1719,
      "step": 3400
    },
    {
      "epoch": 1.3639999999999999,
      "grad_norm": 0.7972534894943237,
      "learning_rate": 4.406326530612245e-05,
      "loss": 0.1379,
      "step": 3410
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 0.6721949577331543,
      "learning_rate": 4.404285714285715e-05,
      "loss": 0.1266,
      "step": 3420
    },
    {
      "epoch": 1.3719999999999999,
      "grad_norm": 0.674297571182251,
      "learning_rate": 4.402244897959184e-05,
      "loss": 0.1333,
      "step": 3430
    },
    {
      "epoch": 1.376,
      "grad_norm": 1.1519337892532349,
      "learning_rate": 4.400204081632653e-05,
      "loss": 0.1313,
      "step": 3440
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.3938422203063965,
      "learning_rate": 4.398163265306123e-05,
      "loss": 0.1594,
      "step": 3450
    },
    {
      "epoch": 1.384,
      "grad_norm": 0.381197452545166,
      "learning_rate": 4.396122448979592e-05,
      "loss": 0.1103,
      "step": 3460
    },
    {
      "epoch": 1.388,
      "grad_norm": 0.5541788935661316,
      "learning_rate": 4.394081632653061e-05,
      "loss": 0.1525,
      "step": 3470
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.5180906653404236,
      "learning_rate": 4.392040816326531e-05,
      "loss": 0.1561,
      "step": 3480
    },
    {
      "epoch": 1.396,
      "grad_norm": 1.113696575164795,
      "learning_rate": 4.39e-05,
      "loss": 0.1751,
      "step": 3490
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.561621367931366,
      "learning_rate": 4.3879591836734695e-05,
      "loss": 0.1387,
      "step": 3500
    },
    {
      "epoch": 1.404,
      "grad_norm": 0.9895995259284973,
      "learning_rate": 4.3859183673469386e-05,
      "loss": 0.1385,
      "step": 3510
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.7610751986503601,
      "learning_rate": 4.3838775510204085e-05,
      "loss": 0.1408,
      "step": 3520
    },
    {
      "epoch": 1.412,
      "grad_norm": 0.8577067852020264,
      "learning_rate": 4.3818367346938776e-05,
      "loss": 0.1535,
      "step": 3530
    },
    {
      "epoch": 1.416,
      "grad_norm": 0.4363575875759125,
      "learning_rate": 4.379795918367347e-05,
      "loss": 0.1597,
      "step": 3540
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.4147976040840149,
      "learning_rate": 4.3777551020408166e-05,
      "loss": 0.1495,
      "step": 3550
    },
    {
      "epoch": 1.424,
      "grad_norm": 1.0775318145751953,
      "learning_rate": 4.375714285714286e-05,
      "loss": 0.124,
      "step": 3560
    },
    {
      "epoch": 1.428,
      "grad_norm": 0.9860104322433472,
      "learning_rate": 4.373673469387755e-05,
      "loss": 0.1347,
      "step": 3570
    },
    {
      "epoch": 1.432,
      "grad_norm": 0.6891405582427979,
      "learning_rate": 4.371632653061225e-05,
      "loss": 0.1615,
      "step": 3580
    },
    {
      "epoch": 1.436,
      "grad_norm": 0.6256957054138184,
      "learning_rate": 4.369591836734694e-05,
      "loss": 0.0924,
      "step": 3590
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.8655704855918884,
      "learning_rate": 4.367551020408163e-05,
      "loss": 0.1436,
      "step": 3600
    },
    {
      "epoch": 1.444,
      "grad_norm": 1.1152722835540771,
      "learning_rate": 4.365510204081633e-05,
      "loss": 0.1403,
      "step": 3610
    },
    {
      "epoch": 1.448,
      "grad_norm": 0.9915167689323425,
      "learning_rate": 4.363469387755103e-05,
      "loss": 0.1346,
      "step": 3620
    },
    {
      "epoch": 1.452,
      "grad_norm": 1.1708170175552368,
      "learning_rate": 4.361428571428572e-05,
      "loss": 0.1787,
      "step": 3630
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.701532244682312,
      "learning_rate": 4.359387755102041e-05,
      "loss": 0.1191,
      "step": 3640
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.6530252695083618,
      "learning_rate": 4.357346938775511e-05,
      "loss": 0.135,
      "step": 3650
    },
    {
      "epoch": 1.464,
      "grad_norm": 0.8089445233345032,
      "learning_rate": 4.35530612244898e-05,
      "loss": 0.1556,
      "step": 3660
    },
    {
      "epoch": 1.468,
      "grad_norm": 0.9097164273262024,
      "learning_rate": 4.353265306122449e-05,
      "loss": 0.1323,
      "step": 3670
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.7521053552627563,
      "learning_rate": 4.3512244897959184e-05,
      "loss": 0.1892,
      "step": 3680
    },
    {
      "epoch": 1.476,
      "grad_norm": 0.6441570520401001,
      "learning_rate": 4.349183673469388e-05,
      "loss": 0.1535,
      "step": 3690
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.8577582836151123,
      "learning_rate": 4.3471428571428574e-05,
      "loss": 0.1486,
      "step": 3700
    },
    {
      "epoch": 1.484,
      "grad_norm": 0.5458441972732544,
      "learning_rate": 4.3451020408163265e-05,
      "loss": 0.1175,
      "step": 3710
    },
    {
      "epoch": 1.488,
      "grad_norm": 1.0012532472610474,
      "learning_rate": 4.3430612244897964e-05,
      "loss": 0.1878,
      "step": 3720
    },
    {
      "epoch": 1.492,
      "grad_norm": 0.5639974474906921,
      "learning_rate": 4.3410204081632655e-05,
      "loss": 0.0951,
      "step": 3730
    },
    {
      "epoch": 1.496,
      "grad_norm": 0.672703742980957,
      "learning_rate": 4.338979591836735e-05,
      "loss": 0.1216,
      "step": 3740
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.839748203754425,
      "learning_rate": 4.3369387755102045e-05,
      "loss": 0.0977,
      "step": 3750
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.9948480129241943,
      "learning_rate": 4.334897959183674e-05,
      "loss": 0.1177,
      "step": 3760
    },
    {
      "epoch": 1.508,
      "grad_norm": 0.12811341881752014,
      "learning_rate": 4.332857142857143e-05,
      "loss": 0.1148,
      "step": 3770
    },
    {
      "epoch": 1.512,
      "grad_norm": 0.8028940558433533,
      "learning_rate": 4.330816326530612e-05,
      "loss": 0.1127,
      "step": 3780
    },
    {
      "epoch": 1.516,
      "grad_norm": 0.6977787613868713,
      "learning_rate": 4.328775510204082e-05,
      "loss": 0.1578,
      "step": 3790
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.3279891312122345,
      "learning_rate": 4.326734693877551e-05,
      "loss": 0.0882,
      "step": 3800
    },
    {
      "epoch": 1.524,
      "grad_norm": 0.8557311296463013,
      "learning_rate": 4.32469387755102e-05,
      "loss": 0.1368,
      "step": 3810
    },
    {
      "epoch": 1.528,
      "grad_norm": 1.1108893156051636,
      "learning_rate": 4.32265306122449e-05,
      "loss": 0.1509,
      "step": 3820
    },
    {
      "epoch": 1.532,
      "grad_norm": 0.9896657466888428,
      "learning_rate": 4.320612244897959e-05,
      "loss": 0.1364,
      "step": 3830
    },
    {
      "epoch": 1.536,
      "grad_norm": 1.1650527715682983,
      "learning_rate": 4.318571428571429e-05,
      "loss": 0.1605,
      "step": 3840
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.0272964239120483,
      "learning_rate": 4.316530612244898e-05,
      "loss": 0.1084,
      "step": 3850
    },
    {
      "epoch": 1.544,
      "grad_norm": 0.850496768951416,
      "learning_rate": 4.314489795918368e-05,
      "loss": 0.1387,
      "step": 3860
    },
    {
      "epoch": 1.548,
      "grad_norm": 0.521071195602417,
      "learning_rate": 4.312448979591837e-05,
      "loss": 0.1648,
      "step": 3870
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.9371471405029297,
      "learning_rate": 4.310408163265306e-05,
      "loss": 0.1499,
      "step": 3880
    },
    {
      "epoch": 1.556,
      "grad_norm": 1.0751811265945435,
      "learning_rate": 4.308367346938776e-05,
      "loss": 0.1487,
      "step": 3890
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.7768468856811523,
      "learning_rate": 4.306326530612245e-05,
      "loss": 0.138,
      "step": 3900
    },
    {
      "epoch": 1.564,
      "grad_norm": 0.7911216020584106,
      "learning_rate": 4.3042857142857145e-05,
      "loss": 0.15,
      "step": 3910
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.7492040395736694,
      "learning_rate": 4.3022448979591836e-05,
      "loss": 0.1306,
      "step": 3920
    },
    {
      "epoch": 1.572,
      "grad_norm": 0.5440932512283325,
      "learning_rate": 4.3002040816326535e-05,
      "loss": 0.1463,
      "step": 3930
    },
    {
      "epoch": 1.576,
      "grad_norm": 0.9466317296028137,
      "learning_rate": 4.2981632653061226e-05,
      "loss": 0.1234,
      "step": 3940
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.2771961688995361,
      "learning_rate": 4.296122448979592e-05,
      "loss": 0.1381,
      "step": 3950
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.4274367690086365,
      "learning_rate": 4.2940816326530616e-05,
      "loss": 0.134,
      "step": 3960
    },
    {
      "epoch": 1.588,
      "grad_norm": 0.9141886234283447,
      "learning_rate": 4.292040816326531e-05,
      "loss": 0.1317,
      "step": 3970
    },
    {
      "epoch": 1.592,
      "grad_norm": 0.9774602055549622,
      "learning_rate": 4.29e-05,
      "loss": 0.1125,
      "step": 3980
    },
    {
      "epoch": 1.596,
      "grad_norm": 0.6975077390670776,
      "learning_rate": 4.28795918367347e-05,
      "loss": 0.1131,
      "step": 3990
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.6945481896400452,
      "learning_rate": 4.285918367346939e-05,
      "loss": 0.1106,
      "step": 4000
    },
    {
      "epoch": 1.604,
      "grad_norm": 0.7842737436294556,
      "learning_rate": 4.283877551020408e-05,
      "loss": 0.1572,
      "step": 4010
    },
    {
      "epoch": 1.608,
      "grad_norm": 0.9276938438415527,
      "learning_rate": 4.281836734693878e-05,
      "loss": 0.1435,
      "step": 4020
    },
    {
      "epoch": 1.612,
      "grad_norm": 0.9041757583618164,
      "learning_rate": 4.279795918367347e-05,
      "loss": 0.1343,
      "step": 4030
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.9365710020065308,
      "learning_rate": 4.277755102040816e-05,
      "loss": 0.16,
      "step": 4040
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.7772891521453857,
      "learning_rate": 4.2757142857142854e-05,
      "loss": 0.0904,
      "step": 4050
    },
    {
      "epoch": 1.624,
      "grad_norm": 0.7093608975410461,
      "learning_rate": 4.273673469387755e-05,
      "loss": 0.2081,
      "step": 4060
    },
    {
      "epoch": 1.6280000000000001,
      "grad_norm": 1.1911005973815918,
      "learning_rate": 4.271632653061225e-05,
      "loss": 0.1763,
      "step": 4070
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.447370707988739,
      "learning_rate": 4.269591836734694e-05,
      "loss": 0.1432,
      "step": 4080
    },
    {
      "epoch": 1.6360000000000001,
      "grad_norm": 0.6955992579460144,
      "learning_rate": 4.2675510204081634e-05,
      "loss": 0.1374,
      "step": 4090
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.917694091796875,
      "learning_rate": 4.265510204081633e-05,
      "loss": 0.1477,
      "step": 4100
    },
    {
      "epoch": 1.6440000000000001,
      "grad_norm": 1.071996808052063,
      "learning_rate": 4.2634693877551024e-05,
      "loss": 0.1087,
      "step": 4110
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.8052111864089966,
      "learning_rate": 4.2614285714285715e-05,
      "loss": 0.1122,
      "step": 4120
    },
    {
      "epoch": 1.6520000000000001,
      "grad_norm": 0.38095715641975403,
      "learning_rate": 4.2593877551020414e-05,
      "loss": 0.0914,
      "step": 4130
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 0.767583966255188,
      "learning_rate": 4.2573469387755105e-05,
      "loss": 0.1286,
      "step": 4140
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 0.8949418663978577,
      "learning_rate": 4.25530612244898e-05,
      "loss": 0.1046,
      "step": 4150
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 1.401581048965454,
      "learning_rate": 4.2532653061224495e-05,
      "loss": 0.1556,
      "step": 4160
    },
    {
      "epoch": 1.6680000000000001,
      "grad_norm": 1.498254418373108,
      "learning_rate": 4.251224489795919e-05,
      "loss": 0.138,
      "step": 4170
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.5907883048057556,
      "learning_rate": 4.249183673469388e-05,
      "loss": 0.1062,
      "step": 4180
    },
    {
      "epoch": 1.6760000000000002,
      "grad_norm": 0.48198795318603516,
      "learning_rate": 4.247142857142857e-05,
      "loss": 0.1598,
      "step": 4190
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.9001292586326599,
      "learning_rate": 4.245102040816327e-05,
      "loss": 0.1485,
      "step": 4200
    },
    {
      "epoch": 1.6840000000000002,
      "grad_norm": 0.42229703068733215,
      "learning_rate": 4.243061224489796e-05,
      "loss": 0.1422,
      "step": 4210
    },
    {
      "epoch": 1.688,
      "grad_norm": 0.5629280209541321,
      "learning_rate": 4.241020408163265e-05,
      "loss": 0.1242,
      "step": 4220
    },
    {
      "epoch": 1.692,
      "grad_norm": 1.4693461656570435,
      "learning_rate": 4.238979591836735e-05,
      "loss": 0.1246,
      "step": 4230
    },
    {
      "epoch": 1.696,
      "grad_norm": 1.213908314704895,
      "learning_rate": 4.236938775510204e-05,
      "loss": 0.156,
      "step": 4240
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.7992209792137146,
      "learning_rate": 4.234897959183673e-05,
      "loss": 0.1468,
      "step": 4250
    },
    {
      "epoch": 1.704,
      "grad_norm": 0.4698833227157593,
      "learning_rate": 4.232857142857143e-05,
      "loss": 0.0777,
      "step": 4260
    },
    {
      "epoch": 1.708,
      "grad_norm": 0.8684170842170715,
      "learning_rate": 4.230816326530612e-05,
      "loss": 0.1416,
      "step": 4270
    },
    {
      "epoch": 1.712,
      "grad_norm": 1.1222702264785767,
      "learning_rate": 4.2287755102040814e-05,
      "loss": 0.1678,
      "step": 4280
    },
    {
      "epoch": 1.716,
      "grad_norm": 1.2735742330551147,
      "learning_rate": 4.226734693877551e-05,
      "loss": 0.15,
      "step": 4290
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.7401994466781616,
      "learning_rate": 4.224693877551021e-05,
      "loss": 0.1817,
      "step": 4300
    },
    {
      "epoch": 1.724,
      "grad_norm": 1.382813811302185,
      "learning_rate": 4.22265306122449e-05,
      "loss": 0.1288,
      "step": 4310
    },
    {
      "epoch": 1.728,
      "grad_norm": 1.051713466644287,
      "learning_rate": 4.2206122448979594e-05,
      "loss": 0.1418,
      "step": 4320
    },
    {
      "epoch": 1.732,
      "grad_norm": 0.9963268041610718,
      "learning_rate": 4.218571428571429e-05,
      "loss": 0.1195,
      "step": 4330
    },
    {
      "epoch": 1.736,
      "grad_norm": 1.1672145128250122,
      "learning_rate": 4.2165306122448984e-05,
      "loss": 0.1367,
      "step": 4340
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.7029899954795837,
      "learning_rate": 4.2144897959183676e-05,
      "loss": 0.1115,
      "step": 4350
    },
    {
      "epoch": 1.744,
      "grad_norm": 1.2748165130615234,
      "learning_rate": 4.212448979591837e-05,
      "loss": 0.1245,
      "step": 4360
    },
    {
      "epoch": 1.748,
      "grad_norm": 0.5547485947608948,
      "learning_rate": 4.2104081632653066e-05,
      "loss": 0.1319,
      "step": 4370
    },
    {
      "epoch": 1.752,
      "grad_norm": 1.2086067199707031,
      "learning_rate": 4.208367346938776e-05,
      "loss": 0.1525,
      "step": 4380
    },
    {
      "epoch": 1.756,
      "grad_norm": 0.38706955313682556,
      "learning_rate": 4.206326530612245e-05,
      "loss": 0.1563,
      "step": 4390
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.4921596050262451,
      "learning_rate": 4.204285714285715e-05,
      "loss": 0.1221,
      "step": 4400
    },
    {
      "epoch": 1.764,
      "grad_norm": 0.6836885213851929,
      "learning_rate": 4.202244897959184e-05,
      "loss": 0.1014,
      "step": 4410
    },
    {
      "epoch": 1.768,
      "grad_norm": 0.9439792037010193,
      "learning_rate": 4.200204081632653e-05,
      "loss": 0.1105,
      "step": 4420
    },
    {
      "epoch": 1.772,
      "grad_norm": 0.8800674676895142,
      "learning_rate": 4.198163265306123e-05,
      "loss": 0.1031,
      "step": 4430
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.32969242334365845,
      "learning_rate": 4.196122448979592e-05,
      "loss": 0.1369,
      "step": 4440
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.736118733882904,
      "learning_rate": 4.194081632653061e-05,
      "loss": 0.12,
      "step": 4450
    },
    {
      "epoch": 1.784,
      "grad_norm": 1.0252848863601685,
      "learning_rate": 4.1920408163265304e-05,
      "loss": 0.1097,
      "step": 4460
    },
    {
      "epoch": 1.788,
      "grad_norm": 1.3789411783218384,
      "learning_rate": 4.19e-05,
      "loss": 0.1729,
      "step": 4470
    },
    {
      "epoch": 1.792,
      "grad_norm": 1.7635517120361328,
      "learning_rate": 4.1879591836734694e-05,
      "loss": 0.1456,
      "step": 4480
    },
    {
      "epoch": 1.796,
      "grad_norm": 0.8360357284545898,
      "learning_rate": 4.1859183673469385e-05,
      "loss": 0.124,
      "step": 4490
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.825793981552124,
      "learning_rate": 4.1838775510204084e-05,
      "loss": 0.121,
      "step": 4500
    },
    {
      "epoch": 1.804,
      "grad_norm": 1.598983645439148,
      "learning_rate": 4.1818367346938775e-05,
      "loss": 0.1247,
      "step": 4510
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.22505667805671692,
      "learning_rate": 4.1797959183673473e-05,
      "loss": 0.1155,
      "step": 4520
    },
    {
      "epoch": 1.812,
      "grad_norm": 0.26281192898750305,
      "learning_rate": 4.1777551020408165e-05,
      "loss": 0.1006,
      "step": 4530
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 0.41204917430877686,
      "learning_rate": 4.1757142857142863e-05,
      "loss": 0.1261,
      "step": 4540
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 0.8835668563842773,
      "learning_rate": 4.1736734693877555e-05,
      "loss": 0.1146,
      "step": 4550
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 1.3766893148422241,
      "learning_rate": 4.1716326530612247e-05,
      "loss": 0.155,
      "step": 4560
    },
    {
      "epoch": 1.8279999999999998,
      "grad_norm": 0.3590899407863617,
      "learning_rate": 4.1695918367346945e-05,
      "loss": 0.101,
      "step": 4570
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 0.8565157651901245,
      "learning_rate": 4.1675510204081637e-05,
      "loss": 0.156,
      "step": 4580
    },
    {
      "epoch": 1.8359999999999999,
      "grad_norm": 0.29177695512771606,
      "learning_rate": 4.165510204081633e-05,
      "loss": 0.1446,
      "step": 4590
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 1.5507782697677612,
      "learning_rate": 4.1634693877551026e-05,
      "loss": 0.1672,
      "step": 4600
    },
    {
      "epoch": 1.8439999999999999,
      "grad_norm": 0.3075481653213501,
      "learning_rate": 4.161428571428572e-05,
      "loss": 0.1425,
      "step": 4610
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 0.3319953978061676,
      "learning_rate": 4.159387755102041e-05,
      "loss": 0.0704,
      "step": 4620
    },
    {
      "epoch": 1.8519999999999999,
      "grad_norm": 0.5245780348777771,
      "learning_rate": 4.15734693877551e-05,
      "loss": 0.1166,
      "step": 4630
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 1.3635034561157227,
      "learning_rate": 4.15530612244898e-05,
      "loss": 0.1479,
      "step": 4640
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 1.0205574035644531,
      "learning_rate": 4.153265306122449e-05,
      "loss": 0.1217,
      "step": 4650
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 0.5127224326133728,
      "learning_rate": 4.151224489795918e-05,
      "loss": 0.1136,
      "step": 4660
    },
    {
      "epoch": 1.8679999999999999,
      "grad_norm": 0.6618216037750244,
      "learning_rate": 4.149183673469388e-05,
      "loss": 0.1044,
      "step": 4670
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 1.2237789630889893,
      "learning_rate": 4.147142857142857e-05,
      "loss": 0.1718,
      "step": 4680
    },
    {
      "epoch": 1.876,
      "grad_norm": 0.8207338452339172,
      "learning_rate": 4.1451020408163264e-05,
      "loss": 0.1665,
      "step": 4690
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.35937047004699707,
      "learning_rate": 4.143061224489796e-05,
      "loss": 0.0903,
      "step": 4700
    },
    {
      "epoch": 1.884,
      "grad_norm": 1.143616795539856,
      "learning_rate": 4.1410204081632654e-05,
      "loss": 0.1296,
      "step": 4710
    },
    {
      "epoch": 1.888,
      "grad_norm": 1.1600944995880127,
      "learning_rate": 4.1389795918367346e-05,
      "loss": 0.1225,
      "step": 4720
    },
    {
      "epoch": 1.892,
      "grad_norm": 1.105043888092041,
      "learning_rate": 4.136938775510204e-05,
      "loss": 0.1123,
      "step": 4730
    },
    {
      "epoch": 1.896,
      "grad_norm": 1.5563559532165527,
      "learning_rate": 4.1348979591836736e-05,
      "loss": 0.147,
      "step": 4740
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.296926349401474,
      "learning_rate": 4.1328571428571434e-05,
      "loss": 0.1143,
      "step": 4750
    },
    {
      "epoch": 1.904,
      "grad_norm": 1.0417706966400146,
      "learning_rate": 4.1308163265306126e-05,
      "loss": 0.1197,
      "step": 4760
    },
    {
      "epoch": 1.908,
      "grad_norm": 0.9126445055007935,
      "learning_rate": 4.128775510204082e-05,
      "loss": 0.1507,
      "step": 4770
    },
    {
      "epoch": 1.912,
      "grad_norm": 0.7170850038528442,
      "learning_rate": 4.1267346938775516e-05,
      "loss": 0.1187,
      "step": 4780
    },
    {
      "epoch": 1.916,
      "grad_norm": 1.2119197845458984,
      "learning_rate": 4.124693877551021e-05,
      "loss": 0.1248,
      "step": 4790
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.8504021167755127,
      "learning_rate": 4.12265306122449e-05,
      "loss": 0.1398,
      "step": 4800
    },
    {
      "epoch": 1.924,
      "grad_norm": 1.2074223756790161,
      "learning_rate": 4.12061224489796e-05,
      "loss": 0.098,
      "step": 4810
    },
    {
      "epoch": 1.928,
      "grad_norm": 0.8947327136993408,
      "learning_rate": 4.118571428571429e-05,
      "loss": 0.1533,
      "step": 4820
    },
    {
      "epoch": 1.932,
      "grad_norm": 0.28745853900909424,
      "learning_rate": 4.116530612244898e-05,
      "loss": 0.1194,
      "step": 4830
    },
    {
      "epoch": 1.936,
      "grad_norm": 1.1269299983978271,
      "learning_rate": 4.114489795918368e-05,
      "loss": 0.1372,
      "step": 4840
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.4949488639831543,
      "learning_rate": 4.112448979591837e-05,
      "loss": 0.1257,
      "step": 4850
    },
    {
      "epoch": 1.944,
      "grad_norm": 0.3413962423801422,
      "learning_rate": 4.110408163265306e-05,
      "loss": 0.0998,
      "step": 4860
    },
    {
      "epoch": 1.948,
      "grad_norm": 0.8292732834815979,
      "learning_rate": 4.1083673469387753e-05,
      "loss": 0.1342,
      "step": 4870
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.33242928981781006,
      "learning_rate": 4.106326530612245e-05,
      "loss": 0.1594,
      "step": 4880
    },
    {
      "epoch": 1.956,
      "grad_norm": 0.9468963742256165,
      "learning_rate": 4.1042857142857143e-05,
      "loss": 0.1491,
      "step": 4890
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.3610638976097107,
      "learning_rate": 4.1022448979591835e-05,
      "loss": 0.1067,
      "step": 4900
    },
    {
      "epoch": 1.964,
      "grad_norm": 1.8231827020645142,
      "learning_rate": 4.100204081632653e-05,
      "loss": 0.0953,
      "step": 4910
    },
    {
      "epoch": 1.968,
      "grad_norm": 1.3017799854278564,
      "learning_rate": 4.0981632653061225e-05,
      "loss": 0.163,
      "step": 4920
    },
    {
      "epoch": 1.972,
      "grad_norm": 1.3896043300628662,
      "learning_rate": 4.0961224489795917e-05,
      "loss": 0.158,
      "step": 4930
    },
    {
      "epoch": 1.976,
      "grad_norm": 0.70732182264328,
      "learning_rate": 4.0940816326530615e-05,
      "loss": 0.1079,
      "step": 4940
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.49337446689605713,
      "learning_rate": 4.0920408163265306e-05,
      "loss": 0.1689,
      "step": 4950
    },
    {
      "epoch": 1.984,
      "grad_norm": 1.1702240705490112,
      "learning_rate": 4.09e-05,
      "loss": 0.1612,
      "step": 4960
    },
    {
      "epoch": 1.988,
      "grad_norm": 0.6010273098945618,
      "learning_rate": 4.0879591836734696e-05,
      "loss": 0.1139,
      "step": 4970
    },
    {
      "epoch": 1.992,
      "grad_norm": 1.437185287475586,
      "learning_rate": 4.0859183673469395e-05,
      "loss": 0.1592,
      "step": 4980
    },
    {
      "epoch": 1.996,
      "grad_norm": 1.222092628479004,
      "learning_rate": 4.0838775510204086e-05,
      "loss": 0.0991,
      "step": 4990
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.5200824737548828,
      "learning_rate": 4.081836734693878e-05,
      "loss": 0.1267,
      "step": 5000
    },
    {
      "epoch": 2.004,
      "grad_norm": 0.44720959663391113,
      "learning_rate": 4.0797959183673476e-05,
      "loss": 0.0986,
      "step": 5010
    },
    {
      "epoch": 2.008,
      "grad_norm": 0.8146798014640808,
      "learning_rate": 4.077755102040817e-05,
      "loss": 0.1437,
      "step": 5020
    },
    {
      "epoch": 2.012,
      "grad_norm": 0.4838826358318329,
      "learning_rate": 4.075714285714286e-05,
      "loss": 0.1122,
      "step": 5030
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.9918479323387146,
      "learning_rate": 4.073673469387755e-05,
      "loss": 0.1699,
      "step": 5040
    },
    {
      "epoch": 2.02,
      "grad_norm": 1.2112230062484741,
      "learning_rate": 4.071632653061225e-05,
      "loss": 0.121,
      "step": 5050
    },
    {
      "epoch": 2.024,
      "grad_norm": 0.6790614128112793,
      "learning_rate": 4.069591836734694e-05,
      "loss": 0.1033,
      "step": 5060
    },
    {
      "epoch": 2.028,
      "grad_norm": 0.5615316033363342,
      "learning_rate": 4.067551020408163e-05,
      "loss": 0.1352,
      "step": 5070
    },
    {
      "epoch": 2.032,
      "grad_norm": 0.5172392725944519,
      "learning_rate": 4.065510204081633e-05,
      "loss": 0.1085,
      "step": 5080
    },
    {
      "epoch": 2.036,
      "grad_norm": 0.33907005190849304,
      "learning_rate": 4.063469387755102e-05,
      "loss": 0.128,
      "step": 5090
    },
    {
      "epoch": 2.04,
      "grad_norm": 1.0959970951080322,
      "learning_rate": 4.0614285714285714e-05,
      "loss": 0.1153,
      "step": 5100
    },
    {
      "epoch": 2.044,
      "grad_norm": 1.0671271085739136,
      "learning_rate": 4.059387755102041e-05,
      "loss": 0.1313,
      "step": 5110
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.6326383352279663,
      "learning_rate": 4.0573469387755104e-05,
      "loss": 0.1008,
      "step": 5120
    },
    {
      "epoch": 2.052,
      "grad_norm": 0.5688740611076355,
      "learning_rate": 4.0553061224489796e-05,
      "loss": 0.1032,
      "step": 5130
    },
    {
      "epoch": 2.056,
      "grad_norm": 1.0885885953903198,
      "learning_rate": 4.053265306122449e-05,
      "loss": 0.1355,
      "step": 5140
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.37382304668426514,
      "learning_rate": 4.0512244897959186e-05,
      "loss": 0.1396,
      "step": 5150
    },
    {
      "epoch": 2.064,
      "grad_norm": 0.9870918393135071,
      "learning_rate": 4.049183673469388e-05,
      "loss": 0.1084,
      "step": 5160
    },
    {
      "epoch": 2.068,
      "grad_norm": 1.0809084177017212,
      "learning_rate": 4.047142857142857e-05,
      "loss": 0.1309,
      "step": 5170
    },
    {
      "epoch": 2.072,
      "grad_norm": 0.8650383353233337,
      "learning_rate": 4.045102040816327e-05,
      "loss": 0.1612,
      "step": 5180
    },
    {
      "epoch": 2.076,
      "grad_norm": 1.3966296911239624,
      "learning_rate": 4.043061224489796e-05,
      "loss": 0.1102,
      "step": 5190
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.9301879405975342,
      "learning_rate": 4.041020408163266e-05,
      "loss": 0.1081,
      "step": 5200
    },
    {
      "epoch": 2.084,
      "grad_norm": 0.6780424118041992,
      "learning_rate": 4.038979591836735e-05,
      "loss": 0.1243,
      "step": 5210
    },
    {
      "epoch": 2.088,
      "grad_norm": 0.7843974828720093,
      "learning_rate": 4.036938775510205e-05,
      "loss": 0.0736,
      "step": 5220
    },
    {
      "epoch": 2.092,
      "grad_norm": 1.3768799304962158,
      "learning_rate": 4.034897959183674e-05,
      "loss": 0.1508,
      "step": 5230
    },
    {
      "epoch": 2.096,
      "grad_norm": 1.0596022605895996,
      "learning_rate": 4.032857142857143e-05,
      "loss": 0.084,
      "step": 5240
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.8406970500946045,
      "learning_rate": 4.030816326530613e-05,
      "loss": 0.0975,
      "step": 5250
    },
    {
      "epoch": 2.104,
      "grad_norm": 1.5117928981781006,
      "learning_rate": 4.028775510204082e-05,
      "loss": 0.1018,
      "step": 5260
    },
    {
      "epoch": 2.108,
      "grad_norm": 1.243659496307373,
      "learning_rate": 4.026734693877551e-05,
      "loss": 0.1317,
      "step": 5270
    },
    {
      "epoch": 2.112,
      "grad_norm": 1.5595972537994385,
      "learning_rate": 4.024693877551021e-05,
      "loss": 0.1359,
      "step": 5280
    },
    {
      "epoch": 2.116,
      "grad_norm": 0.8394964933395386,
      "learning_rate": 4.02265306122449e-05,
      "loss": 0.1381,
      "step": 5290
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.2582867443561554,
      "learning_rate": 4.020612244897959e-05,
      "loss": 0.0904,
      "step": 5300
    },
    {
      "epoch": 2.124,
      "grad_norm": 0.9424661993980408,
      "learning_rate": 4.0185714285714285e-05,
      "loss": 0.145,
      "step": 5310
    },
    {
      "epoch": 2.128,
      "grad_norm": 1.1930783987045288,
      "learning_rate": 4.016530612244898e-05,
      "loss": 0.1099,
      "step": 5320
    },
    {
      "epoch": 2.132,
      "grad_norm": 0.4963379502296448,
      "learning_rate": 4.0144897959183675e-05,
      "loss": 0.126,
      "step": 5330
    },
    {
      "epoch": 2.136,
      "grad_norm": 1.1549856662750244,
      "learning_rate": 4.0124489795918366e-05,
      "loss": 0.1262,
      "step": 5340
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.6237683296203613,
      "learning_rate": 4.0104081632653065e-05,
      "loss": 0.1045,
      "step": 5350
    },
    {
      "epoch": 2.144,
      "grad_norm": 0.3418363034725189,
      "learning_rate": 4.0083673469387756e-05,
      "loss": 0.0616,
      "step": 5360
    },
    {
      "epoch": 2.148,
      "grad_norm": 1.1938083171844482,
      "learning_rate": 4.006326530612245e-05,
      "loss": 0.1208,
      "step": 5370
    },
    {
      "epoch": 2.152,
      "grad_norm": 0.7906909584999084,
      "learning_rate": 4.0042857142857146e-05,
      "loss": 0.1377,
      "step": 5380
    },
    {
      "epoch": 2.156,
      "grad_norm": 0.5645875334739685,
      "learning_rate": 4.002244897959184e-05,
      "loss": 0.0782,
      "step": 5390
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.8251773715019226,
      "learning_rate": 4.000204081632653e-05,
      "loss": 0.1197,
      "step": 5400
    },
    {
      "epoch": 2.164,
      "grad_norm": 0.9321247935295105,
      "learning_rate": 3.998163265306122e-05,
      "loss": 0.1277,
      "step": 5410
    },
    {
      "epoch": 2.168,
      "grad_norm": 0.6751883625984192,
      "learning_rate": 3.996122448979592e-05,
      "loss": 0.0802,
      "step": 5420
    },
    {
      "epoch": 2.172,
      "grad_norm": 0.5683044195175171,
      "learning_rate": 3.994081632653062e-05,
      "loss": 0.049,
      "step": 5430
    },
    {
      "epoch": 2.176,
      "grad_norm": 0.9661363363265991,
      "learning_rate": 3.992040816326531e-05,
      "loss": 0.1091,
      "step": 5440
    },
    {
      "epoch": 2.18,
      "grad_norm": 1.0745478868484497,
      "learning_rate": 3.99e-05,
      "loss": 0.1484,
      "step": 5450
    },
    {
      "epoch": 2.184,
      "grad_norm": 0.6361058950424194,
      "learning_rate": 3.98795918367347e-05,
      "loss": 0.1305,
      "step": 5460
    },
    {
      "epoch": 2.188,
      "grad_norm": 0.8673081398010254,
      "learning_rate": 3.985918367346939e-05,
      "loss": 0.0889,
      "step": 5470
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.10053229331970215,
      "learning_rate": 3.983877551020408e-05,
      "loss": 0.0682,
      "step": 5480
    },
    {
      "epoch": 2.196,
      "grad_norm": 1.1215035915374756,
      "learning_rate": 3.981836734693878e-05,
      "loss": 0.1188,
      "step": 5490
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.376036286354065,
      "learning_rate": 3.979795918367347e-05,
      "loss": 0.1238,
      "step": 5500
    },
    {
      "epoch": 2.204,
      "grad_norm": 1.299423098564148,
      "learning_rate": 3.9777551020408164e-05,
      "loss": 0.0912,
      "step": 5510
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.9619693756103516,
      "learning_rate": 3.975714285714286e-05,
      "loss": 0.1147,
      "step": 5520
    },
    {
      "epoch": 2.212,
      "grad_norm": 1.2329992055892944,
      "learning_rate": 3.9736734693877554e-05,
      "loss": 0.1323,
      "step": 5530
    },
    {
      "epoch": 2.216,
      "grad_norm": 0.9035835266113281,
      "learning_rate": 3.9716326530612245e-05,
      "loss": 0.1884,
      "step": 5540
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.7141592502593994,
      "learning_rate": 3.969591836734694e-05,
      "loss": 0.1094,
      "step": 5550
    },
    {
      "epoch": 2.224,
      "grad_norm": 0.49088943004608154,
      "learning_rate": 3.9675510204081635e-05,
      "loss": 0.1254,
      "step": 5560
    },
    {
      "epoch": 2.228,
      "grad_norm": 1.260298252105713,
      "learning_rate": 3.965510204081633e-05,
      "loss": 0.1165,
      "step": 5570
    },
    {
      "epoch": 2.232,
      "grad_norm": 0.7220616340637207,
      "learning_rate": 3.963469387755102e-05,
      "loss": 0.068,
      "step": 5580
    },
    {
      "epoch": 2.2359999999999998,
      "grad_norm": 0.7637261748313904,
      "learning_rate": 3.961428571428572e-05,
      "loss": 0.1149,
      "step": 5590
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.3371131420135498,
      "learning_rate": 3.959387755102041e-05,
      "loss": 0.1292,
      "step": 5600
    },
    {
      "epoch": 2.2439999999999998,
      "grad_norm": 0.6182735562324524,
      "learning_rate": 3.95734693877551e-05,
      "loss": 0.1248,
      "step": 5610
    },
    {
      "epoch": 2.248,
      "grad_norm": 0.3009319007396698,
      "learning_rate": 3.95530612244898e-05,
      "loss": 0.0682,
      "step": 5620
    },
    {
      "epoch": 2.252,
      "grad_norm": 0.48638466000556946,
      "learning_rate": 3.953265306122449e-05,
      "loss": 0.1172,
      "step": 5630
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 0.41060441732406616,
      "learning_rate": 3.951224489795918e-05,
      "loss": 0.1176,
      "step": 5640
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.9020552635192871,
      "learning_rate": 3.949183673469388e-05,
      "loss": 0.1664,
      "step": 5650
    },
    {
      "epoch": 2.2640000000000002,
      "grad_norm": 1.057731032371521,
      "learning_rate": 3.947142857142858e-05,
      "loss": 0.1087,
      "step": 5660
    },
    {
      "epoch": 2.268,
      "grad_norm": 0.9438547492027283,
      "learning_rate": 3.945102040816327e-05,
      "loss": 0.1198,
      "step": 5670
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 1.1226898431777954,
      "learning_rate": 3.943061224489796e-05,
      "loss": 0.1286,
      "step": 5680
    },
    {
      "epoch": 2.276,
      "grad_norm": 1.0102479457855225,
      "learning_rate": 3.941020408163266e-05,
      "loss": 0.1244,
      "step": 5690
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 1.1963924169540405,
      "learning_rate": 3.938979591836735e-05,
      "loss": 0.1196,
      "step": 5700
    },
    {
      "epoch": 2.284,
      "grad_norm": 0.8492966890335083,
      "learning_rate": 3.936938775510204e-05,
      "loss": 0.1428,
      "step": 5710
    },
    {
      "epoch": 2.288,
      "grad_norm": 0.9380969405174255,
      "learning_rate": 3.9348979591836735e-05,
      "loss": 0.1097,
      "step": 5720
    },
    {
      "epoch": 2.292,
      "grad_norm": 0.5518185496330261,
      "learning_rate": 3.932857142857143e-05,
      "loss": 0.1492,
      "step": 5730
    },
    {
      "epoch": 2.296,
      "grad_norm": 1.136063575744629,
      "learning_rate": 3.9308163265306125e-05,
      "loss": 0.1924,
      "step": 5740
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.3365428149700165,
      "learning_rate": 3.9287755102040816e-05,
      "loss": 0.1047,
      "step": 5750
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.9941599369049072,
      "learning_rate": 3.9267346938775514e-05,
      "loss": 0.1475,
      "step": 5760
    },
    {
      "epoch": 2.308,
      "grad_norm": 0.8147762417793274,
      "learning_rate": 3.9246938775510206e-05,
      "loss": 0.1019,
      "step": 5770
    },
    {
      "epoch": 2.312,
      "grad_norm": 0.327401340007782,
      "learning_rate": 3.92265306122449e-05,
      "loss": 0.0968,
      "step": 5780
    },
    {
      "epoch": 2.316,
      "grad_norm": 0.5658368468284607,
      "learning_rate": 3.9206122448979596e-05,
      "loss": 0.0987,
      "step": 5790
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.9250720739364624,
      "learning_rate": 3.918571428571429e-05,
      "loss": 0.1179,
      "step": 5800
    },
    {
      "epoch": 2.324,
      "grad_norm": 0.9484335780143738,
      "learning_rate": 3.916530612244898e-05,
      "loss": 0.1211,
      "step": 5810
    },
    {
      "epoch": 2.328,
      "grad_norm": 0.45334047079086304,
      "learning_rate": 3.914489795918367e-05,
      "loss": 0.0878,
      "step": 5820
    },
    {
      "epoch": 2.332,
      "grad_norm": 0.28522998094558716,
      "learning_rate": 3.912448979591837e-05,
      "loss": 0.1316,
      "step": 5830
    },
    {
      "epoch": 2.336,
      "grad_norm": 0.45988956093788147,
      "learning_rate": 3.910408163265306e-05,
      "loss": 0.1158,
      "step": 5840
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.839152455329895,
      "learning_rate": 3.908367346938775e-05,
      "loss": 0.079,
      "step": 5850
    },
    {
      "epoch": 2.344,
      "grad_norm": 0.3126968741416931,
      "learning_rate": 3.906326530612245e-05,
      "loss": 0.1314,
      "step": 5860
    },
    {
      "epoch": 2.348,
      "grad_norm": 1.156325340270996,
      "learning_rate": 3.904285714285714e-05,
      "loss": 0.1183,
      "step": 5870
    },
    {
      "epoch": 2.352,
      "grad_norm": 1.5183032751083374,
      "learning_rate": 3.902244897959184e-05,
      "loss": 0.1284,
      "step": 5880
    },
    {
      "epoch": 2.356,
      "grad_norm": 0.5826101303100586,
      "learning_rate": 3.900204081632653e-05,
      "loss": 0.0837,
      "step": 5890
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.6371526122093201,
      "learning_rate": 3.898163265306123e-05,
      "loss": 0.1252,
      "step": 5900
    },
    {
      "epoch": 2.364,
      "grad_norm": 1.6166337728500366,
      "learning_rate": 3.896122448979592e-05,
      "loss": 0.0965,
      "step": 5910
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.5818530321121216,
      "learning_rate": 3.8940816326530614e-05,
      "loss": 0.0983,
      "step": 5920
    },
    {
      "epoch": 2.372,
      "grad_norm": 0.41914233565330505,
      "learning_rate": 3.892040816326531e-05,
      "loss": 0.112,
      "step": 5930
    },
    {
      "epoch": 2.376,
      "grad_norm": 1.0626076459884644,
      "learning_rate": 3.8900000000000004e-05,
      "loss": 0.1455,
      "step": 5940
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.5531870722770691,
      "learning_rate": 3.8879591836734695e-05,
      "loss": 0.1267,
      "step": 5950
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.8147287368774414,
      "learning_rate": 3.8859183673469394e-05,
      "loss": 0.1308,
      "step": 5960
    },
    {
      "epoch": 2.388,
      "grad_norm": 0.9159300327301025,
      "learning_rate": 3.8838775510204085e-05,
      "loss": 0.1308,
      "step": 5970
    },
    {
      "epoch": 2.392,
      "grad_norm": 0.531168520450592,
      "learning_rate": 3.881836734693878e-05,
      "loss": 0.066,
      "step": 5980
    },
    {
      "epoch": 2.396,
      "grad_norm": 0.3272112309932709,
      "learning_rate": 3.879795918367347e-05,
      "loss": 0.1234,
      "step": 5990
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.636816143989563,
      "learning_rate": 3.877755102040817e-05,
      "loss": 0.1472,
      "step": 6000
    },
    {
      "epoch": 2.404,
      "grad_norm": 0.5088996887207031,
      "learning_rate": 3.875714285714286e-05,
      "loss": 0.0975,
      "step": 6010
    },
    {
      "epoch": 2.408,
      "grad_norm": 0.7660236358642578,
      "learning_rate": 3.873673469387755e-05,
      "loss": 0.1116,
      "step": 6020
    },
    {
      "epoch": 2.412,
      "grad_norm": 1.1632126569747925,
      "learning_rate": 3.871632653061225e-05,
      "loss": 0.0717,
      "step": 6030
    },
    {
      "epoch": 2.416,
      "grad_norm": 1.5334768295288086,
      "learning_rate": 3.869591836734694e-05,
      "loss": 0.1362,
      "step": 6040
    },
    {
      "epoch": 2.42,
      "grad_norm": 1.0331406593322754,
      "learning_rate": 3.867551020408163e-05,
      "loss": 0.087,
      "step": 6050
    },
    {
      "epoch": 2.424,
      "grad_norm": 0.5441977381706238,
      "learning_rate": 3.865510204081633e-05,
      "loss": 0.1063,
      "step": 6060
    },
    {
      "epoch": 2.428,
      "grad_norm": 0.6906660795211792,
      "learning_rate": 3.863469387755102e-05,
      "loss": 0.0858,
      "step": 6070
    },
    {
      "epoch": 2.432,
      "grad_norm": 1.969913363456726,
      "learning_rate": 3.861428571428571e-05,
      "loss": 0.1018,
      "step": 6080
    },
    {
      "epoch": 2.436,
      "grad_norm": 0.3185945153236389,
      "learning_rate": 3.8593877551020405e-05,
      "loss": 0.1501,
      "step": 6090
    },
    {
      "epoch": 2.44,
      "grad_norm": 1.0040069818496704,
      "learning_rate": 3.85734693877551e-05,
      "loss": 0.0926,
      "step": 6100
    },
    {
      "epoch": 2.444,
      "grad_norm": 1.2358328104019165,
      "learning_rate": 3.85530612244898e-05,
      "loss": 0.1396,
      "step": 6110
    },
    {
      "epoch": 2.448,
      "grad_norm": 0.052480559796094894,
      "learning_rate": 3.853265306122449e-05,
      "loss": 0.0906,
      "step": 6120
    },
    {
      "epoch": 2.452,
      "grad_norm": 1.0826811790466309,
      "learning_rate": 3.8512244897959184e-05,
      "loss": 0.1272,
      "step": 6130
    },
    {
      "epoch": 2.456,
      "grad_norm": 0.822700560092926,
      "learning_rate": 3.849183673469388e-05,
      "loss": 0.0885,
      "step": 6140
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.44145092368125916,
      "learning_rate": 3.8471428571428574e-05,
      "loss": 0.1479,
      "step": 6150
    },
    {
      "epoch": 2.464,
      "grad_norm": 0.2782541811466217,
      "learning_rate": 3.8451020408163266e-05,
      "loss": 0.0595,
      "step": 6160
    },
    {
      "epoch": 2.468,
      "grad_norm": 0.7295171022415161,
      "learning_rate": 3.8430612244897964e-05,
      "loss": 0.1304,
      "step": 6170
    },
    {
      "epoch": 2.472,
      "grad_norm": 0.7921155691146851,
      "learning_rate": 3.8410204081632656e-05,
      "loss": 0.1136,
      "step": 6180
    },
    {
      "epoch": 2.476,
      "grad_norm": 0.4499291181564331,
      "learning_rate": 3.838979591836735e-05,
      "loss": 0.0737,
      "step": 6190
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.20642822980880737,
      "learning_rate": 3.8369387755102046e-05,
      "loss": 0.1205,
      "step": 6200
    },
    {
      "epoch": 2.484,
      "grad_norm": 1.7103663682937622,
      "learning_rate": 3.834897959183674e-05,
      "loss": 0.1005,
      "step": 6210
    },
    {
      "epoch": 2.488,
      "grad_norm": 1.2159720659255981,
      "learning_rate": 3.832857142857143e-05,
      "loss": 0.1141,
      "step": 6220
    },
    {
      "epoch": 2.492,
      "grad_norm": 0.46551957726478577,
      "learning_rate": 3.830816326530613e-05,
      "loss": 0.1062,
      "step": 6230
    },
    {
      "epoch": 2.496,
      "grad_norm": 0.45893603563308716,
      "learning_rate": 3.828775510204082e-05,
      "loss": 0.1231,
      "step": 6240
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.4087197184562683,
      "learning_rate": 3.826734693877551e-05,
      "loss": 0.1042,
      "step": 6250
    },
    {
      "epoch": 2.504,
      "grad_norm": 0.8825960755348206,
      "learning_rate": 3.82469387755102e-05,
      "loss": 0.1177,
      "step": 6260
    },
    {
      "epoch": 2.508,
      "grad_norm": 0.17429029941558838,
      "learning_rate": 3.82265306122449e-05,
      "loss": 0.093,
      "step": 6270
    },
    {
      "epoch": 2.512,
      "grad_norm": 1.110186219215393,
      "learning_rate": 3.820612244897959e-05,
      "loss": 0.1127,
      "step": 6280
    },
    {
      "epoch": 2.516,
      "grad_norm": 0.6606132388114929,
      "learning_rate": 3.8185714285714284e-05,
      "loss": 0.0895,
      "step": 6290
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.6325615644454956,
      "learning_rate": 3.816530612244898e-05,
      "loss": 0.1278,
      "step": 6300
    },
    {
      "epoch": 2.524,
      "grad_norm": 0.4849611818790436,
      "learning_rate": 3.8144897959183674e-05,
      "loss": 0.1174,
      "step": 6310
    },
    {
      "epoch": 2.528,
      "grad_norm": 1.353924036026001,
      "learning_rate": 3.8124489795918365e-05,
      "loss": 0.1249,
      "step": 6320
    },
    {
      "epoch": 2.532,
      "grad_norm": 1.380128026008606,
      "learning_rate": 3.8104081632653063e-05,
      "loss": 0.1306,
      "step": 6330
    },
    {
      "epoch": 2.536,
      "grad_norm": 1.0107510089874268,
      "learning_rate": 3.808367346938776e-05,
      "loss": 0.1165,
      "step": 6340
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.6765312552452087,
      "learning_rate": 3.8063265306122453e-05,
      "loss": 0.142,
      "step": 6350
    },
    {
      "epoch": 2.544,
      "grad_norm": 0.6710941195487976,
      "learning_rate": 3.8042857142857145e-05,
      "loss": 0.0688,
      "step": 6360
    },
    {
      "epoch": 2.548,
      "grad_norm": 0.3364604711532593,
      "learning_rate": 3.802244897959184e-05,
      "loss": 0.0903,
      "step": 6370
    },
    {
      "epoch": 2.552,
      "grad_norm": 1.0115761756896973,
      "learning_rate": 3.8002040816326535e-05,
      "loss": 0.1336,
      "step": 6380
    },
    {
      "epoch": 2.556,
      "grad_norm": 0.28316083550453186,
      "learning_rate": 3.7981632653061227e-05,
      "loss": 0.0994,
      "step": 6390
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.770195722579956,
      "learning_rate": 3.796122448979592e-05,
      "loss": 0.1019,
      "step": 6400
    },
    {
      "epoch": 2.564,
      "grad_norm": 1.22247314453125,
      "learning_rate": 3.7940816326530616e-05,
      "loss": 0.1225,
      "step": 6410
    },
    {
      "epoch": 2.568,
      "grad_norm": 1.2308868169784546,
      "learning_rate": 3.792040816326531e-05,
      "loss": 0.1348,
      "step": 6420
    },
    {
      "epoch": 2.572,
      "grad_norm": 0.5090605020523071,
      "learning_rate": 3.79e-05,
      "loss": 0.1333,
      "step": 6430
    },
    {
      "epoch": 2.576,
      "grad_norm": 1.1167060136795044,
      "learning_rate": 3.78795918367347e-05,
      "loss": 0.102,
      "step": 6440
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.49313315749168396,
      "learning_rate": 3.785918367346939e-05,
      "loss": 0.0971,
      "step": 6450
    },
    {
      "epoch": 2.584,
      "grad_norm": 1.5756800174713135,
      "learning_rate": 3.783877551020408e-05,
      "loss": 0.0929,
      "step": 6460
    },
    {
      "epoch": 2.588,
      "grad_norm": 1.1612132787704468,
      "learning_rate": 3.781836734693878e-05,
      "loss": 0.1077,
      "step": 6470
    },
    {
      "epoch": 2.592,
      "grad_norm": 0.5889245867729187,
      "learning_rate": 3.779795918367347e-05,
      "loss": 0.0865,
      "step": 6480
    },
    {
      "epoch": 2.596,
      "grad_norm": 0.8198868036270142,
      "learning_rate": 3.777755102040816e-05,
      "loss": 0.1329,
      "step": 6490
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.0454384088516235,
      "learning_rate": 3.7757142857142854e-05,
      "loss": 0.1074,
      "step": 6500
    },
    {
      "epoch": 2.604,
      "grad_norm": 1.0994291305541992,
      "learning_rate": 3.773673469387755e-05,
      "loss": 0.1315,
      "step": 6510
    },
    {
      "epoch": 2.608,
      "grad_norm": 1.683315396308899,
      "learning_rate": 3.7716326530612244e-05,
      "loss": 0.0992,
      "step": 6520
    },
    {
      "epoch": 2.612,
      "grad_norm": 0.4596331715583801,
      "learning_rate": 3.7695918367346936e-05,
      "loss": 0.0805,
      "step": 6530
    },
    {
      "epoch": 2.616,
      "grad_norm": 1.2047117948532104,
      "learning_rate": 3.7675510204081634e-05,
      "loss": 0.1234,
      "step": 6540
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.3993174135684967,
      "learning_rate": 3.7655102040816326e-05,
      "loss": 0.1202,
      "step": 6550
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.4187379777431488,
      "learning_rate": 3.7634693877551024e-05,
      "loss": 0.1227,
      "step": 6560
    },
    {
      "epoch": 2.628,
      "grad_norm": 0.8046290278434753,
      "learning_rate": 3.7614285714285716e-05,
      "loss": 0.14,
      "step": 6570
    },
    {
      "epoch": 2.632,
      "grad_norm": 1.1780141592025757,
      "learning_rate": 3.7593877551020414e-05,
      "loss": 0.1529,
      "step": 6580
    },
    {
      "epoch": 2.636,
      "grad_norm": 0.6381128430366516,
      "learning_rate": 3.7573469387755106e-05,
      "loss": 0.0987,
      "step": 6590
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.17051923274993896,
      "learning_rate": 3.75530612244898e-05,
      "loss": 0.075,
      "step": 6600
    },
    {
      "epoch": 2.644,
      "grad_norm": 0.8627868294715881,
      "learning_rate": 3.7532653061224496e-05,
      "loss": 0.0886,
      "step": 6610
    },
    {
      "epoch": 2.648,
      "grad_norm": 0.3448525369167328,
      "learning_rate": 3.751224489795919e-05,
      "loss": 0.0693,
      "step": 6620
    },
    {
      "epoch": 2.652,
      "grad_norm": 1.085919976234436,
      "learning_rate": 3.749183673469388e-05,
      "loss": 0.0989,
      "step": 6630
    },
    {
      "epoch": 2.656,
      "grad_norm": 1.1484923362731934,
      "learning_rate": 3.747142857142858e-05,
      "loss": 0.1537,
      "step": 6640
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.8346222639083862,
      "learning_rate": 3.745102040816327e-05,
      "loss": 0.0756,
      "step": 6650
    },
    {
      "epoch": 2.664,
      "grad_norm": 1.075540542602539,
      "learning_rate": 3.743061224489796e-05,
      "loss": 0.133,
      "step": 6660
    },
    {
      "epoch": 2.668,
      "grad_norm": 0.8512619137763977,
      "learning_rate": 3.741020408163265e-05,
      "loss": 0.0991,
      "step": 6670
    },
    {
      "epoch": 2.672,
      "grad_norm": 0.8826019167900085,
      "learning_rate": 3.738979591836735e-05,
      "loss": 0.1217,
      "step": 6680
    },
    {
      "epoch": 2.676,
      "grad_norm": 1.0335724353790283,
      "learning_rate": 3.736938775510204e-05,
      "loss": 0.1132,
      "step": 6690
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.6342015266418457,
      "learning_rate": 3.7348979591836733e-05,
      "loss": 0.079,
      "step": 6700
    },
    {
      "epoch": 2.684,
      "grad_norm": 1.1731586456298828,
      "learning_rate": 3.732857142857143e-05,
      "loss": 0.1174,
      "step": 6710
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 0.7983055114746094,
      "learning_rate": 3.730816326530612e-05,
      "loss": 0.1065,
      "step": 6720
    },
    {
      "epoch": 2.692,
      "grad_norm": 0.3796791434288025,
      "learning_rate": 3.7287755102040815e-05,
      "loss": 0.0928,
      "step": 6730
    },
    {
      "epoch": 2.6959999999999997,
      "grad_norm": 1.1812691688537598,
      "learning_rate": 3.726734693877551e-05,
      "loss": 0.1141,
      "step": 6740
    },
    {
      "epoch": 2.7,
      "grad_norm": 1.3592206239700317,
      "learning_rate": 3.7246938775510205e-05,
      "loss": 0.1218,
      "step": 6750
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 0.2907107472419739,
      "learning_rate": 3.7226530612244896e-05,
      "loss": 0.1102,
      "step": 6760
    },
    {
      "epoch": 2.708,
      "grad_norm": 0.013191056437790394,
      "learning_rate": 3.720612244897959e-05,
      "loss": 0.1274,
      "step": 6770
    },
    {
      "epoch": 2.7119999999999997,
      "grad_norm": 1.0171067714691162,
      "learning_rate": 3.7185714285714286e-05,
      "loss": 0.0853,
      "step": 6780
    },
    {
      "epoch": 2.716,
      "grad_norm": 0.5056126117706299,
      "learning_rate": 3.7165306122448985e-05,
      "loss": 0.0995,
      "step": 6790
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 1.7555209398269653,
      "learning_rate": 3.7144897959183676e-05,
      "loss": 0.1523,
      "step": 6800
    },
    {
      "epoch": 2.724,
      "grad_norm": 0.8617768287658691,
      "learning_rate": 3.712448979591837e-05,
      "loss": 0.1173,
      "step": 6810
    },
    {
      "epoch": 2.7279999999999998,
      "grad_norm": 1.2422027587890625,
      "learning_rate": 3.7104081632653066e-05,
      "loss": 0.1439,
      "step": 6820
    },
    {
      "epoch": 2.732,
      "grad_norm": 0.9558113813400269,
      "learning_rate": 3.708367346938776e-05,
      "loss": 0.1265,
      "step": 6830
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.556098997592926,
      "learning_rate": 3.706326530612245e-05,
      "loss": 0.1232,
      "step": 6840
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.7231431007385254,
      "learning_rate": 3.704285714285715e-05,
      "loss": 0.0972,
      "step": 6850
    },
    {
      "epoch": 2.7439999999999998,
      "grad_norm": 0.7578044533729553,
      "learning_rate": 3.702244897959184e-05,
      "loss": 0.1464,
      "step": 6860
    },
    {
      "epoch": 2.748,
      "grad_norm": 0.19006672501564026,
      "learning_rate": 3.700204081632653e-05,
      "loss": 0.1061,
      "step": 6870
    },
    {
      "epoch": 2.752,
      "grad_norm": 0.7496872544288635,
      "learning_rate": 3.698163265306123e-05,
      "loss": 0.0554,
      "step": 6880
    },
    {
      "epoch": 2.7560000000000002,
      "grad_norm": 0.18913397192955017,
      "learning_rate": 3.696122448979592e-05,
      "loss": 0.0987,
      "step": 6890
    },
    {
      "epoch": 2.76,
      "grad_norm": 1.2350682020187378,
      "learning_rate": 3.694081632653061e-05,
      "loss": 0.1387,
      "step": 6900
    },
    {
      "epoch": 2.7640000000000002,
      "grad_norm": 0.642295777797699,
      "learning_rate": 3.692040816326531e-05,
      "loss": 0.1482,
      "step": 6910
    },
    {
      "epoch": 2.768,
      "grad_norm": 1.0240938663482666,
      "learning_rate": 3.69e-05,
      "loss": 0.1697,
      "step": 6920
    },
    {
      "epoch": 2.7720000000000002,
      "grad_norm": 1.0969916582107544,
      "learning_rate": 3.6879591836734694e-05,
      "loss": 0.0765,
      "step": 6930
    },
    {
      "epoch": 2.776,
      "grad_norm": 0.3412562310695648,
      "learning_rate": 3.6859183673469386e-05,
      "loss": 0.0719,
      "step": 6940
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 1.1444059610366821,
      "learning_rate": 3.6838775510204084e-05,
      "loss": 0.1003,
      "step": 6950
    },
    {
      "epoch": 2.784,
      "grad_norm": 1.1293697357177734,
      "learning_rate": 3.6818367346938776e-05,
      "loss": 0.0861,
      "step": 6960
    },
    {
      "epoch": 2.7880000000000003,
      "grad_norm": 1.2136168479919434,
      "learning_rate": 3.679795918367347e-05,
      "loss": 0.0991,
      "step": 6970
    },
    {
      "epoch": 2.792,
      "grad_norm": 1.1747844219207764,
      "learning_rate": 3.6777551020408166e-05,
      "loss": 0.1606,
      "step": 6980
    },
    {
      "epoch": 2.7960000000000003,
      "grad_norm": 0.12062593549489975,
      "learning_rate": 3.675714285714286e-05,
      "loss": 0.0947,
      "step": 6990
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.6903504133224487,
      "learning_rate": 3.673673469387755e-05,
      "loss": 0.1209,
      "step": 7000
    },
    {
      "epoch": 2.8040000000000003,
      "grad_norm": 1.2281508445739746,
      "learning_rate": 3.671632653061225e-05,
      "loss": 0.1383,
      "step": 7010
    },
    {
      "epoch": 2.808,
      "grad_norm": 1.6338920593261719,
      "learning_rate": 3.6695918367346945e-05,
      "loss": 0.1026,
      "step": 7020
    },
    {
      "epoch": 2.8120000000000003,
      "grad_norm": 0.5611322522163391,
      "learning_rate": 3.667551020408164e-05,
      "loss": 0.0841,
      "step": 7030
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.34622621536254883,
      "learning_rate": 3.665510204081633e-05,
      "loss": 0.0864,
      "step": 7040
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.243973508477211,
      "learning_rate": 3.663469387755103e-05,
      "loss": 0.1121,
      "step": 7050
    },
    {
      "epoch": 2.824,
      "grad_norm": 0.2773455083370209,
      "learning_rate": 3.661428571428572e-05,
      "loss": 0.1126,
      "step": 7060
    },
    {
      "epoch": 2.828,
      "grad_norm": 0.09318733960390091,
      "learning_rate": 3.659387755102041e-05,
      "loss": 0.0575,
      "step": 7070
    },
    {
      "epoch": 2.832,
      "grad_norm": 1.0657052993774414,
      "learning_rate": 3.65734693877551e-05,
      "loss": 0.1133,
      "step": 7080
    },
    {
      "epoch": 2.836,
      "grad_norm": 0.2105262279510498,
      "learning_rate": 3.65530612244898e-05,
      "loss": 0.0954,
      "step": 7090
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.4666725993156433,
      "learning_rate": 3.653265306122449e-05,
      "loss": 0.0954,
      "step": 7100
    },
    {
      "epoch": 2.844,
      "grad_norm": 1.1747969388961792,
      "learning_rate": 3.651224489795918e-05,
      "loss": 0.1371,
      "step": 7110
    },
    {
      "epoch": 2.848,
      "grad_norm": 0.35879215598106384,
      "learning_rate": 3.649183673469388e-05,
      "loss": 0.1066,
      "step": 7120
    },
    {
      "epoch": 2.852,
      "grad_norm": 1.8370803594589233,
      "learning_rate": 3.647142857142857e-05,
      "loss": 0.136,
      "step": 7130
    },
    {
      "epoch": 2.856,
      "grad_norm": 0.10332932323217392,
      "learning_rate": 3.6451020408163265e-05,
      "loss": 0.0991,
      "step": 7140
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.6162501573562622,
      "learning_rate": 3.643061224489796e-05,
      "loss": 0.102,
      "step": 7150
    },
    {
      "epoch": 2.864,
      "grad_norm": 0.11699149012565613,
      "learning_rate": 3.6410204081632655e-05,
      "loss": 0.12,
      "step": 7160
    },
    {
      "epoch": 2.868,
      "grad_norm": 0.5226727724075317,
      "learning_rate": 3.6389795918367346e-05,
      "loss": 0.0787,
      "step": 7170
    },
    {
      "epoch": 2.872,
      "grad_norm": 0.2687130272388458,
      "learning_rate": 3.636938775510204e-05,
      "loss": 0.1013,
      "step": 7180
    },
    {
      "epoch": 2.876,
      "grad_norm": 0.6173446774482727,
      "learning_rate": 3.6348979591836736e-05,
      "loss": 0.0931,
      "step": 7190
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.2983390688896179,
      "learning_rate": 3.632857142857143e-05,
      "loss": 0.11,
      "step": 7200
    },
    {
      "epoch": 2.884,
      "grad_norm": 0.9850022196769714,
      "learning_rate": 3.630816326530612e-05,
      "loss": 0.1122,
      "step": 7210
    },
    {
      "epoch": 2.888,
      "grad_norm": 0.8214746713638306,
      "learning_rate": 3.628775510204082e-05,
      "loss": 0.1092,
      "step": 7220
    },
    {
      "epoch": 2.892,
      "grad_norm": 1.0774942636489868,
      "learning_rate": 3.626734693877551e-05,
      "loss": 0.0911,
      "step": 7230
    },
    {
      "epoch": 2.896,
      "grad_norm": 0.2235076129436493,
      "learning_rate": 3.624693877551021e-05,
      "loss": 0.0797,
      "step": 7240
    },
    {
      "epoch": 2.9,
      "grad_norm": 1.1425062417984009,
      "learning_rate": 3.62265306122449e-05,
      "loss": 0.1664,
      "step": 7250
    },
    {
      "epoch": 2.904,
      "grad_norm": 0.3364225924015045,
      "learning_rate": 3.62061224489796e-05,
      "loss": 0.1033,
      "step": 7260
    },
    {
      "epoch": 2.908,
      "grad_norm": 1.0538947582244873,
      "learning_rate": 3.618571428571429e-05,
      "loss": 0.1055,
      "step": 7270
    },
    {
      "epoch": 2.912,
      "grad_norm": 0.9815793037414551,
      "learning_rate": 3.616530612244898e-05,
      "loss": 0.1075,
      "step": 7280
    },
    {
      "epoch": 2.916,
      "grad_norm": 0.41817253828048706,
      "learning_rate": 3.614489795918368e-05,
      "loss": 0.106,
      "step": 7290
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.6448959112167358,
      "learning_rate": 3.612448979591837e-05,
      "loss": 0.0998,
      "step": 7300
    },
    {
      "epoch": 2.924,
      "grad_norm": 1.3252944946289062,
      "learning_rate": 3.610408163265306e-05,
      "loss": 0.1272,
      "step": 7310
    },
    {
      "epoch": 2.928,
      "grad_norm": 0.1498854011297226,
      "learning_rate": 3.608367346938776e-05,
      "loss": 0.1108,
      "step": 7320
    },
    {
      "epoch": 2.932,
      "grad_norm": 0.39226678013801575,
      "learning_rate": 3.606326530612245e-05,
      "loss": 0.0702,
      "step": 7330
    },
    {
      "epoch": 2.936,
      "grad_norm": 0.5856245160102844,
      "learning_rate": 3.6042857142857144e-05,
      "loss": 0.1296,
      "step": 7340
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.4974263310432434,
      "learning_rate": 3.6022448979591835e-05,
      "loss": 0.0333,
      "step": 7350
    },
    {
      "epoch": 2.944,
      "grad_norm": 1.378027319908142,
      "learning_rate": 3.6002040816326534e-05,
      "loss": 0.1612,
      "step": 7360
    },
    {
      "epoch": 2.948,
      "grad_norm": 1.1722290515899658,
      "learning_rate": 3.5981632653061225e-05,
      "loss": 0.0654,
      "step": 7370
    },
    {
      "epoch": 2.952,
      "grad_norm": 1.4612263441085815,
      "learning_rate": 3.596122448979592e-05,
      "loss": 0.0968,
      "step": 7380
    },
    {
      "epoch": 2.956,
      "grad_norm": 0.3414138853549957,
      "learning_rate": 3.5940816326530615e-05,
      "loss": 0.1186,
      "step": 7390
    },
    {
      "epoch": 2.96,
      "grad_norm": 1.6379119157791138,
      "learning_rate": 3.592040816326531e-05,
      "loss": 0.1665,
      "step": 7400
    },
    {
      "epoch": 2.964,
      "grad_norm": 0.5209378600120544,
      "learning_rate": 3.59e-05,
      "loss": 0.0802,
      "step": 7410
    },
    {
      "epoch": 2.968,
      "grad_norm": 1.4651219844818115,
      "learning_rate": 3.58795918367347e-05,
      "loss": 0.1388,
      "step": 7420
    },
    {
      "epoch": 2.972,
      "grad_norm": 1.0024733543395996,
      "learning_rate": 3.585918367346939e-05,
      "loss": 0.1124,
      "step": 7430
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.06461810320615768,
      "learning_rate": 3.583877551020408e-05,
      "loss": 0.0818,
      "step": 7440
    },
    {
      "epoch": 2.98,
      "grad_norm": 1.3042664527893066,
      "learning_rate": 3.581836734693877e-05,
      "loss": 0.134,
      "step": 7450
    },
    {
      "epoch": 2.984,
      "grad_norm": 1.5882967710494995,
      "learning_rate": 3.579795918367347e-05,
      "loss": 0.0922,
      "step": 7460
    },
    {
      "epoch": 2.988,
      "grad_norm": 1.546911597251892,
      "learning_rate": 3.577755102040817e-05,
      "loss": 0.0846,
      "step": 7470
    },
    {
      "epoch": 2.992,
      "grad_norm": 1.190755009651184,
      "learning_rate": 3.575714285714286e-05,
      "loss": 0.0796,
      "step": 7480
    },
    {
      "epoch": 2.996,
      "grad_norm": 0.9368481636047363,
      "learning_rate": 3.573673469387756e-05,
      "loss": 0.0957,
      "step": 7490
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.232434868812561,
      "learning_rate": 3.571632653061225e-05,
      "loss": 0.1462,
      "step": 7500
    },
    {
      "epoch": 3.004,
      "grad_norm": 0.15951254963874817,
      "learning_rate": 3.569591836734694e-05,
      "loss": 0.1229,
      "step": 7510
    },
    {
      "epoch": 3.008,
      "grad_norm": 0.9440902471542358,
      "learning_rate": 3.567551020408163e-05,
      "loss": 0.1502,
      "step": 7520
    },
    {
      "epoch": 3.012,
      "grad_norm": 0.7006139159202576,
      "learning_rate": 3.565510204081633e-05,
      "loss": 0.1353,
      "step": 7530
    },
    {
      "epoch": 3.016,
      "grad_norm": 0.35914960503578186,
      "learning_rate": 3.563469387755102e-05,
      "loss": 0.1083,
      "step": 7540
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.7652978301048279,
      "learning_rate": 3.5614285714285715e-05,
      "loss": 0.1135,
      "step": 7550
    },
    {
      "epoch": 3.024,
      "grad_norm": 0.6400370597839355,
      "learning_rate": 3.559387755102041e-05,
      "loss": 0.0891,
      "step": 7560
    },
    {
      "epoch": 3.028,
      "grad_norm": 0.5654453635215759,
      "learning_rate": 3.5573469387755104e-05,
      "loss": 0.1407,
      "step": 7570
    },
    {
      "epoch": 3.032,
      "grad_norm": 1.2097209692001343,
      "learning_rate": 3.5553061224489796e-05,
      "loss": 0.1186,
      "step": 7580
    },
    {
      "epoch": 3.036,
      "grad_norm": 0.7615281343460083,
      "learning_rate": 3.5532653061224494e-05,
      "loss": 0.0752,
      "step": 7590
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.8017748594284058,
      "learning_rate": 3.5512244897959186e-05,
      "loss": 0.0746,
      "step": 7600
    },
    {
      "epoch": 3.044,
      "grad_norm": 0.4591899514198303,
      "learning_rate": 3.549183673469388e-05,
      "loss": 0.0941,
      "step": 7610
    },
    {
      "epoch": 3.048,
      "grad_norm": 0.43829146027565,
      "learning_rate": 3.547142857142857e-05,
      "loss": 0.07,
      "step": 7620
    },
    {
      "epoch": 3.052,
      "grad_norm": 0.6748525500297546,
      "learning_rate": 3.545102040816327e-05,
      "loss": 0.0847,
      "step": 7630
    },
    {
      "epoch": 3.056,
      "grad_norm": 0.6653810739517212,
      "learning_rate": 3.543061224489796e-05,
      "loss": 0.0801,
      "step": 7640
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.5464931726455688,
      "learning_rate": 3.541020408163265e-05,
      "loss": 0.0775,
      "step": 7650
    },
    {
      "epoch": 3.064,
      "grad_norm": 0.8601648211479187,
      "learning_rate": 3.538979591836735e-05,
      "loss": 0.0466,
      "step": 7660
    },
    {
      "epoch": 3.068,
      "grad_norm": 0.41261425614356995,
      "learning_rate": 3.536938775510204e-05,
      "loss": 0.1432,
      "step": 7670
    },
    {
      "epoch": 3.072,
      "grad_norm": 1.4530407190322876,
      "learning_rate": 3.534897959183673e-05,
      "loss": 0.1109,
      "step": 7680
    },
    {
      "epoch": 3.076,
      "grad_norm": 0.7409079074859619,
      "learning_rate": 3.532857142857143e-05,
      "loss": 0.0959,
      "step": 7690
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.7816370725631714,
      "learning_rate": 3.530816326530613e-05,
      "loss": 0.1217,
      "step": 7700
    },
    {
      "epoch": 3.084,
      "grad_norm": 1.0619617700576782,
      "learning_rate": 3.528775510204082e-05,
      "loss": 0.102,
      "step": 7710
    },
    {
      "epoch": 3.088,
      "grad_norm": 0.8217161893844604,
      "learning_rate": 3.526734693877551e-05,
      "loss": 0.1012,
      "step": 7720
    },
    {
      "epoch": 3.092,
      "grad_norm": 0.7596626877784729,
      "learning_rate": 3.524693877551021e-05,
      "loss": 0.0687,
      "step": 7730
    },
    {
      "epoch": 3.096,
      "grad_norm": 1.785920262336731,
      "learning_rate": 3.52265306122449e-05,
      "loss": 0.1375,
      "step": 7740
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.5936115980148315,
      "learning_rate": 3.5206122448979594e-05,
      "loss": 0.101,
      "step": 7750
    },
    {
      "epoch": 3.104,
      "grad_norm": 0.47131776809692383,
      "learning_rate": 3.5185714285714285e-05,
      "loss": 0.0843,
      "step": 7760
    },
    {
      "epoch": 3.108,
      "grad_norm": 0.49253740906715393,
      "learning_rate": 3.5165306122448984e-05,
      "loss": 0.1006,
      "step": 7770
    },
    {
      "epoch": 3.112,
      "grad_norm": 0.3182067573070526,
      "learning_rate": 3.5144897959183675e-05,
      "loss": 0.1361,
      "step": 7780
    },
    {
      "epoch": 3.116,
      "grad_norm": 0.8234447240829468,
      "learning_rate": 3.512448979591837e-05,
      "loss": 0.1309,
      "step": 7790
    },
    {
      "epoch": 3.12,
      "grad_norm": 1.7597081661224365,
      "learning_rate": 3.5104081632653065e-05,
      "loss": 0.0993,
      "step": 7800
    },
    {
      "epoch": 3.124,
      "grad_norm": 1.6677865982055664,
      "learning_rate": 3.508367346938776e-05,
      "loss": 0.1445,
      "step": 7810
    },
    {
      "epoch": 3.128,
      "grad_norm": 0.47249680757522583,
      "learning_rate": 3.506326530612245e-05,
      "loss": 0.067,
      "step": 7820
    },
    {
      "epoch": 3.132,
      "grad_norm": 1.1692899465560913,
      "learning_rate": 3.504285714285715e-05,
      "loss": 0.1253,
      "step": 7830
    },
    {
      "epoch": 3.136,
      "grad_norm": 0.7694913744926453,
      "learning_rate": 3.502244897959184e-05,
      "loss": 0.1079,
      "step": 7840
    },
    {
      "epoch": 3.14,
      "grad_norm": 0.37724193930625916,
      "learning_rate": 3.500204081632653e-05,
      "loss": 0.0847,
      "step": 7850
    },
    {
      "epoch": 3.144,
      "grad_norm": 1.1800938844680786,
      "learning_rate": 3.498163265306123e-05,
      "loss": 0.1135,
      "step": 7860
    },
    {
      "epoch": 3.148,
      "grad_norm": 0.6334355473518372,
      "learning_rate": 3.496122448979592e-05,
      "loss": 0.0765,
      "step": 7870
    },
    {
      "epoch": 3.152,
      "grad_norm": 1.5491318702697754,
      "learning_rate": 3.494081632653061e-05,
      "loss": 0.1714,
      "step": 7880
    },
    {
      "epoch": 3.156,
      "grad_norm": 0.944580614566803,
      "learning_rate": 3.49204081632653e-05,
      "loss": 0.0877,
      "step": 7890
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.14256025850772858,
      "learning_rate": 3.49e-05,
      "loss": 0.0645,
      "step": 7900
    },
    {
      "epoch": 3.164,
      "grad_norm": 0.19538938999176025,
      "learning_rate": 3.487959183673469e-05,
      "loss": 0.1005,
      "step": 7910
    },
    {
      "epoch": 3.168,
      "grad_norm": 0.04869396239519119,
      "learning_rate": 3.485918367346939e-05,
      "loss": 0.1005,
      "step": 7920
    },
    {
      "epoch": 3.172,
      "grad_norm": 0.5947319269180298,
      "learning_rate": 3.483877551020408e-05,
      "loss": 0.1203,
      "step": 7930
    },
    {
      "epoch": 3.176,
      "grad_norm": 1.4283283948898315,
      "learning_rate": 3.481836734693878e-05,
      "loss": 0.1083,
      "step": 7940
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.8789852261543274,
      "learning_rate": 3.479795918367347e-05,
      "loss": 0.1057,
      "step": 7950
    },
    {
      "epoch": 3.184,
      "grad_norm": 0.4829173982143402,
      "learning_rate": 3.4777551020408164e-05,
      "loss": 0.0639,
      "step": 7960
    },
    {
      "epoch": 3.188,
      "grad_norm": 0.9088369011878967,
      "learning_rate": 3.475714285714286e-05,
      "loss": 0.1246,
      "step": 7970
    },
    {
      "epoch": 3.192,
      "grad_norm": 1.091129183769226,
      "learning_rate": 3.4736734693877554e-05,
      "loss": 0.1245,
      "step": 7980
    },
    {
      "epoch": 3.196,
      "grad_norm": 0.4606515169143677,
      "learning_rate": 3.4716326530612246e-05,
      "loss": 0.0605,
      "step": 7990
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.6549959778785706,
      "learning_rate": 3.4695918367346944e-05,
      "loss": 0.0739,
      "step": 8000
    },
    {
      "epoch": 3.204,
      "grad_norm": 0.8262611031532288,
      "learning_rate": 3.4675510204081636e-05,
      "loss": 0.0974,
      "step": 8010
    },
    {
      "epoch": 3.208,
      "grad_norm": 1.1894727945327759,
      "learning_rate": 3.465510204081633e-05,
      "loss": 0.1403,
      "step": 8020
    },
    {
      "epoch": 3.212,
      "grad_norm": 0.7682685256004333,
      "learning_rate": 3.463469387755102e-05,
      "loss": 0.1183,
      "step": 8030
    },
    {
      "epoch": 3.216,
      "grad_norm": 0.32444527745246887,
      "learning_rate": 3.461428571428572e-05,
      "loss": 0.0883,
      "step": 8040
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.7282382845878601,
      "learning_rate": 3.459387755102041e-05,
      "loss": 0.07,
      "step": 8050
    },
    {
      "epoch": 3.224,
      "grad_norm": 0.45088520646095276,
      "learning_rate": 3.45734693877551e-05,
      "loss": 0.0686,
      "step": 8060
    },
    {
      "epoch": 3.228,
      "grad_norm": 0.9027349352836609,
      "learning_rate": 3.45530612244898e-05,
      "loss": 0.0666,
      "step": 8070
    },
    {
      "epoch": 3.232,
      "grad_norm": 0.1375618278980255,
      "learning_rate": 3.453265306122449e-05,
      "loss": 0.0715,
      "step": 8080
    },
    {
      "epoch": 3.2359999999999998,
      "grad_norm": 0.7820031642913818,
      "learning_rate": 3.451224489795918e-05,
      "loss": 0.1154,
      "step": 8090
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.9648025631904602,
      "learning_rate": 3.449183673469388e-05,
      "loss": 0.0939,
      "step": 8100
    },
    {
      "epoch": 3.2439999999999998,
      "grad_norm": 1.322622299194336,
      "learning_rate": 3.447142857142857e-05,
      "loss": 0.1382,
      "step": 8110
    },
    {
      "epoch": 3.248,
      "grad_norm": 0.11289896816015244,
      "learning_rate": 3.4451020408163264e-05,
      "loss": 0.089,
      "step": 8120
    },
    {
      "epoch": 3.252,
      "grad_norm": 0.34189432859420776,
      "learning_rate": 3.4430612244897955e-05,
      "loss": 0.0844,
      "step": 8130
    },
    {
      "epoch": 3.2560000000000002,
      "grad_norm": 0.8031615018844604,
      "learning_rate": 3.4410204081632653e-05,
      "loss": 0.09,
      "step": 8140
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.6060293912887573,
      "learning_rate": 3.438979591836735e-05,
      "loss": 0.1332,
      "step": 8150
    },
    {
      "epoch": 3.2640000000000002,
      "grad_norm": 0.326141893863678,
      "learning_rate": 3.4369387755102043e-05,
      "loss": 0.1331,
      "step": 8160
    },
    {
      "epoch": 3.268,
      "grad_norm": 0.19629116356372833,
      "learning_rate": 3.434897959183674e-05,
      "loss": 0.0848,
      "step": 8170
    },
    {
      "epoch": 3.2720000000000002,
      "grad_norm": 1.1366161108016968,
      "learning_rate": 3.432857142857143e-05,
      "loss": 0.0788,
      "step": 8180
    },
    {
      "epoch": 3.276,
      "grad_norm": 0.5627721548080444,
      "learning_rate": 3.4308163265306125e-05,
      "loss": 0.0764,
      "step": 8190
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 1.2478669881820679,
      "learning_rate": 3.4287755102040817e-05,
      "loss": 0.1334,
      "step": 8200
    },
    {
      "epoch": 3.284,
      "grad_norm": 0.07987917959690094,
      "learning_rate": 3.4267346938775515e-05,
      "loss": 0.0529,
      "step": 8210
    },
    {
      "epoch": 3.288,
      "grad_norm": 0.916469395160675,
      "learning_rate": 3.4246938775510206e-05,
      "loss": 0.0963,
      "step": 8220
    },
    {
      "epoch": 3.292,
      "grad_norm": 0.836481511592865,
      "learning_rate": 3.42265306122449e-05,
      "loss": 0.0773,
      "step": 8230
    },
    {
      "epoch": 3.296,
      "grad_norm": 1.2436949014663696,
      "learning_rate": 3.4206122448979596e-05,
      "loss": 0.0521,
      "step": 8240
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.843298614025116,
      "learning_rate": 3.418571428571429e-05,
      "loss": 0.1192,
      "step": 8250
    },
    {
      "epoch": 3.304,
      "grad_norm": 1.0699739456176758,
      "learning_rate": 3.416530612244898e-05,
      "loss": 0.0994,
      "step": 8260
    },
    {
      "epoch": 3.308,
      "grad_norm": 0.14024131000041962,
      "learning_rate": 3.414489795918368e-05,
      "loss": 0.0839,
      "step": 8270
    },
    {
      "epoch": 3.312,
      "grad_norm": 1.513956904411316,
      "learning_rate": 3.412448979591837e-05,
      "loss": 0.0715,
      "step": 8280
    },
    {
      "epoch": 3.316,
      "grad_norm": 0.4546230137348175,
      "learning_rate": 3.410408163265306e-05,
      "loss": 0.073,
      "step": 8290
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.1713794469833374,
      "learning_rate": 3.408367346938775e-05,
      "loss": 0.066,
      "step": 8300
    },
    {
      "epoch": 3.324,
      "grad_norm": 0.07230079919099808,
      "learning_rate": 3.406326530612245e-05,
      "loss": 0.0945,
      "step": 8310
    },
    {
      "epoch": 3.328,
      "grad_norm": 0.22372277081012726,
      "learning_rate": 3.404285714285714e-05,
      "loss": 0.1031,
      "step": 8320
    },
    {
      "epoch": 3.332,
      "grad_norm": 0.8041588068008423,
      "learning_rate": 3.4022448979591834e-05,
      "loss": 0.1601,
      "step": 8330
    },
    {
      "epoch": 3.336,
      "grad_norm": 0.7311348915100098,
      "learning_rate": 3.400204081632653e-05,
      "loss": 0.1047,
      "step": 8340
    },
    {
      "epoch": 3.34,
      "grad_norm": 0.029990484938025475,
      "learning_rate": 3.3981632653061224e-05,
      "loss": 0.0976,
      "step": 8350
    },
    {
      "epoch": 3.344,
      "grad_norm": 0.9519626498222351,
      "learning_rate": 3.3961224489795916e-05,
      "loss": 0.1502,
      "step": 8360
    },
    {
      "epoch": 3.348,
      "grad_norm": 0.6613471508026123,
      "learning_rate": 3.3940816326530614e-05,
      "loss": 0.0774,
      "step": 8370
    },
    {
      "epoch": 3.352,
      "grad_norm": 1.4566149711608887,
      "learning_rate": 3.392040816326531e-05,
      "loss": 0.129,
      "step": 8380
    },
    {
      "epoch": 3.356,
      "grad_norm": 1.0589207410812378,
      "learning_rate": 3.3900000000000004e-05,
      "loss": 0.1015,
      "step": 8390
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.9319005608558655,
      "learning_rate": 3.3879591836734696e-05,
      "loss": 0.1067,
      "step": 8400
    },
    {
      "epoch": 3.364,
      "grad_norm": 0.7399531006813049,
      "learning_rate": 3.3859183673469394e-05,
      "loss": 0.1303,
      "step": 8410
    },
    {
      "epoch": 3.368,
      "grad_norm": 0.9751105308532715,
      "learning_rate": 3.3838775510204086e-05,
      "loss": 0.0611,
      "step": 8420
    },
    {
      "epoch": 3.372,
      "grad_norm": 0.24082618951797485,
      "learning_rate": 3.381836734693878e-05,
      "loss": 0.0969,
      "step": 8430
    },
    {
      "epoch": 3.376,
      "grad_norm": 0.8220314979553223,
      "learning_rate": 3.379795918367347e-05,
      "loss": 0.0925,
      "step": 8440
    },
    {
      "epoch": 3.38,
      "grad_norm": 1.3283827304840088,
      "learning_rate": 3.377755102040817e-05,
      "loss": 0.0836,
      "step": 8450
    },
    {
      "epoch": 3.384,
      "grad_norm": 0.44932276010513306,
      "learning_rate": 3.375714285714286e-05,
      "loss": 0.0669,
      "step": 8460
    },
    {
      "epoch": 3.388,
      "grad_norm": 1.5147576332092285,
      "learning_rate": 3.373673469387755e-05,
      "loss": 0.1166,
      "step": 8470
    },
    {
      "epoch": 3.392,
      "grad_norm": 0.020580744370818138,
      "learning_rate": 3.371632653061225e-05,
      "loss": 0.0567,
      "step": 8480
    },
    {
      "epoch": 3.396,
      "grad_norm": 0.2960284948348999,
      "learning_rate": 3.369591836734694e-05,
      "loss": 0.1058,
      "step": 8490
    },
    {
      "epoch": 3.4,
      "grad_norm": 1.0445435047149658,
      "learning_rate": 3.367551020408163e-05,
      "loss": 0.0763,
      "step": 8500
    },
    {
      "epoch": 3.404,
      "grad_norm": 1.8882964849472046,
      "learning_rate": 3.365510204081633e-05,
      "loss": 0.1298,
      "step": 8510
    },
    {
      "epoch": 3.408,
      "grad_norm": 1.0418833494186401,
      "learning_rate": 3.363469387755102e-05,
      "loss": 0.1044,
      "step": 8520
    },
    {
      "epoch": 3.412,
      "grad_norm": 0.3715280592441559,
      "learning_rate": 3.361428571428571e-05,
      "loss": 0.1069,
      "step": 8530
    },
    {
      "epoch": 3.416,
      "grad_norm": 1.9173343181610107,
      "learning_rate": 3.359387755102041e-05,
      "loss": 0.1474,
      "step": 8540
    },
    {
      "epoch": 3.42,
      "grad_norm": 1.5915749073028564,
      "learning_rate": 3.35734693877551e-05,
      "loss": 0.1428,
      "step": 8550
    },
    {
      "epoch": 3.424,
      "grad_norm": 0.9428795576095581,
      "learning_rate": 3.3553061224489795e-05,
      "loss": 0.1014,
      "step": 8560
    },
    {
      "epoch": 3.428,
      "grad_norm": 1.6053637266159058,
      "learning_rate": 3.3532653061224486e-05,
      "loss": 0.072,
      "step": 8570
    },
    {
      "epoch": 3.432,
      "grad_norm": 0.32474038004875183,
      "learning_rate": 3.3512244897959185e-05,
      "loss": 0.1357,
      "step": 8580
    },
    {
      "epoch": 3.436,
      "grad_norm": 0.6762837767601013,
      "learning_rate": 3.3491836734693876e-05,
      "loss": 0.1624,
      "step": 8590
    },
    {
      "epoch": 3.44,
      "grad_norm": 1.2386066913604736,
      "learning_rate": 3.3471428571428575e-05,
      "loss": 0.0868,
      "step": 8600
    },
    {
      "epoch": 3.444,
      "grad_norm": 1.2845484018325806,
      "learning_rate": 3.3451020408163266e-05,
      "loss": 0.1144,
      "step": 8610
    },
    {
      "epoch": 3.448,
      "grad_norm": 0.5332303047180176,
      "learning_rate": 3.3430612244897965e-05,
      "loss": 0.0815,
      "step": 8620
    },
    {
      "epoch": 3.452,
      "grad_norm": 1.222115159034729,
      "learning_rate": 3.3410204081632656e-05,
      "loss": 0.0853,
      "step": 8630
    },
    {
      "epoch": 3.456,
      "grad_norm": 0.4886358976364136,
      "learning_rate": 3.338979591836735e-05,
      "loss": 0.0765,
      "step": 8640
    },
    {
      "epoch": 3.46,
      "grad_norm": 1.7149266004562378,
      "learning_rate": 3.3369387755102046e-05,
      "loss": 0.0853,
      "step": 8650
    },
    {
      "epoch": 3.464,
      "grad_norm": 1.625046730041504,
      "learning_rate": 3.334897959183674e-05,
      "loss": 0.1252,
      "step": 8660
    },
    {
      "epoch": 3.468,
      "grad_norm": 1.4123539924621582,
      "learning_rate": 3.332857142857143e-05,
      "loss": 0.1277,
      "step": 8670
    },
    {
      "epoch": 3.472,
      "grad_norm": 0.6512954831123352,
      "learning_rate": 3.330816326530613e-05,
      "loss": 0.0702,
      "step": 8680
    },
    {
      "epoch": 3.476,
      "grad_norm": 1.3021786212921143,
      "learning_rate": 3.328775510204082e-05,
      "loss": 0.1294,
      "step": 8690
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.6723281145095825,
      "learning_rate": 3.326734693877551e-05,
      "loss": 0.1,
      "step": 8700
    },
    {
      "epoch": 3.484,
      "grad_norm": 1.1668031215667725,
      "learning_rate": 3.32469387755102e-05,
      "loss": 0.1087,
      "step": 8710
    },
    {
      "epoch": 3.488,
      "grad_norm": 2.02825927734375,
      "learning_rate": 3.32265306122449e-05,
      "loss": 0.1041,
      "step": 8720
    },
    {
      "epoch": 3.492,
      "grad_norm": 0.34667888283729553,
      "learning_rate": 3.320612244897959e-05,
      "loss": 0.0965,
      "step": 8730
    },
    {
      "epoch": 3.496,
      "grad_norm": 0.6695929169654846,
      "learning_rate": 3.3185714285714284e-05,
      "loss": 0.0746,
      "step": 8740
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.20906241238117218,
      "learning_rate": 3.316530612244898e-05,
      "loss": 0.0779,
      "step": 8750
    },
    {
      "epoch": 3.504,
      "grad_norm": 0.6419376134872437,
      "learning_rate": 3.3144897959183674e-05,
      "loss": 0.091,
      "step": 8760
    },
    {
      "epoch": 3.508,
      "grad_norm": 1.0683420896530151,
      "learning_rate": 3.3124489795918366e-05,
      "loss": 0.1015,
      "step": 8770
    },
    {
      "epoch": 3.512,
      "grad_norm": 1.1192610263824463,
      "learning_rate": 3.3104081632653064e-05,
      "loss": 0.1058,
      "step": 8780
    },
    {
      "epoch": 3.516,
      "grad_norm": 0.20841622352600098,
      "learning_rate": 3.3083673469387756e-05,
      "loss": 0.0795,
      "step": 8790
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.5551062226295471,
      "learning_rate": 3.306326530612245e-05,
      "loss": 0.0617,
      "step": 8800
    },
    {
      "epoch": 3.524,
      "grad_norm": 0.06654324382543564,
      "learning_rate": 3.304285714285714e-05,
      "loss": 0.0817,
      "step": 8810
    },
    {
      "epoch": 3.528,
      "grad_norm": 0.23981086909770966,
      "learning_rate": 3.302244897959184e-05,
      "loss": 0.0575,
      "step": 8820
    },
    {
      "epoch": 3.532,
      "grad_norm": 1.1071898937225342,
      "learning_rate": 3.3002040816326535e-05,
      "loss": 0.1014,
      "step": 8830
    },
    {
      "epoch": 3.536,
      "grad_norm": 1.5619341135025024,
      "learning_rate": 3.298163265306123e-05,
      "loss": 0.1707,
      "step": 8840
    },
    {
      "epoch": 3.54,
      "grad_norm": 1.8297921419143677,
      "learning_rate": 3.2961224489795925e-05,
      "loss": 0.1198,
      "step": 8850
    },
    {
      "epoch": 3.544,
      "grad_norm": 0.07211775332689285,
      "learning_rate": 3.294081632653062e-05,
      "loss": 0.1204,
      "step": 8860
    },
    {
      "epoch": 3.548,
      "grad_norm": 0.4094439446926117,
      "learning_rate": 3.292040816326531e-05,
      "loss": 0.076,
      "step": 8870
    },
    {
      "epoch": 3.552,
      "grad_norm": 0.8122222423553467,
      "learning_rate": 3.29e-05,
      "loss": 0.0974,
      "step": 8880
    },
    {
      "epoch": 3.556,
      "grad_norm": 1.2993358373641968,
      "learning_rate": 3.28795918367347e-05,
      "loss": 0.0937,
      "step": 8890
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.26965028047561646,
      "learning_rate": 3.285918367346939e-05,
      "loss": 0.0565,
      "step": 8900
    },
    {
      "epoch": 3.564,
      "grad_norm": 0.9036181569099426,
      "learning_rate": 3.283877551020408e-05,
      "loss": 0.0684,
      "step": 8910
    },
    {
      "epoch": 3.568,
      "grad_norm": 1.677641749382019,
      "learning_rate": 3.281836734693878e-05,
      "loss": 0.0962,
      "step": 8920
    },
    {
      "epoch": 3.572,
      "grad_norm": 1.416917085647583,
      "learning_rate": 3.279795918367347e-05,
      "loss": 0.104,
      "step": 8930
    },
    {
      "epoch": 3.576,
      "grad_norm": 1.503119707107544,
      "learning_rate": 3.277755102040816e-05,
      "loss": 0.107,
      "step": 8940
    },
    {
      "epoch": 3.58,
      "grad_norm": 0.6164574027061462,
      "learning_rate": 3.275714285714286e-05,
      "loss": 0.0789,
      "step": 8950
    },
    {
      "epoch": 3.584,
      "grad_norm": 1.3085856437683105,
      "learning_rate": 3.273673469387755e-05,
      "loss": 0.0999,
      "step": 8960
    },
    {
      "epoch": 3.588,
      "grad_norm": 1.564644455909729,
      "learning_rate": 3.2716326530612245e-05,
      "loss": 0.1259,
      "step": 8970
    },
    {
      "epoch": 3.592,
      "grad_norm": 0.7908555865287781,
      "learning_rate": 3.2695918367346936e-05,
      "loss": 0.0916,
      "step": 8980
    },
    {
      "epoch": 3.596,
      "grad_norm": 0.1997164934873581,
      "learning_rate": 3.2675510204081635e-05,
      "loss": 0.1108,
      "step": 8990
    },
    {
      "epoch": 3.6,
      "grad_norm": 1.1088719367980957,
      "learning_rate": 3.2655102040816326e-05,
      "loss": 0.1495,
      "step": 9000
    },
    {
      "epoch": 3.604,
      "grad_norm": 0.7726561427116394,
      "learning_rate": 3.263469387755102e-05,
      "loss": 0.0828,
      "step": 9010
    },
    {
      "epoch": 3.608,
      "grad_norm": 0.5795843601226807,
      "learning_rate": 3.2614285714285716e-05,
      "loss": 0.0633,
      "step": 9020
    },
    {
      "epoch": 3.612,
      "grad_norm": 1.0782979726791382,
      "learning_rate": 3.259387755102041e-05,
      "loss": 0.0685,
      "step": 9030
    },
    {
      "epoch": 3.616,
      "grad_norm": 0.9716560244560242,
      "learning_rate": 3.25734693877551e-05,
      "loss": 0.061,
      "step": 9040
    },
    {
      "epoch": 3.62,
      "grad_norm": 0.6737464666366577,
      "learning_rate": 3.25530612244898e-05,
      "loss": 0.1102,
      "step": 9050
    },
    {
      "epoch": 3.624,
      "grad_norm": 1.4865763187408447,
      "learning_rate": 3.2532653061224496e-05,
      "loss": 0.1298,
      "step": 9060
    },
    {
      "epoch": 3.628,
      "grad_norm": 1.3428696393966675,
      "learning_rate": 3.251224489795919e-05,
      "loss": 0.0712,
      "step": 9070
    },
    {
      "epoch": 3.632,
      "grad_norm": 0.8652762174606323,
      "learning_rate": 3.249183673469388e-05,
      "loss": 0.0559,
      "step": 9080
    },
    {
      "epoch": 3.636,
      "grad_norm": 1.90299391746521,
      "learning_rate": 3.247142857142858e-05,
      "loss": 0.1091,
      "step": 9090
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.34114953875541687,
      "learning_rate": 3.245102040816327e-05,
      "loss": 0.059,
      "step": 9100
    },
    {
      "epoch": 3.644,
      "grad_norm": 0.0976356789469719,
      "learning_rate": 3.243061224489796e-05,
      "loss": 0.1166,
      "step": 9110
    },
    {
      "epoch": 3.648,
      "grad_norm": 0.756712794303894,
      "learning_rate": 3.241020408163266e-05,
      "loss": 0.0935,
      "step": 9120
    },
    {
      "epoch": 3.652,
      "grad_norm": 0.45035260915756226,
      "learning_rate": 3.238979591836735e-05,
      "loss": 0.0927,
      "step": 9130
    },
    {
      "epoch": 3.656,
      "grad_norm": 0.9132885932922363,
      "learning_rate": 3.236938775510204e-05,
      "loss": 0.1003,
      "step": 9140
    },
    {
      "epoch": 3.66,
      "grad_norm": 1.0656859874725342,
      "learning_rate": 3.2348979591836734e-05,
      "loss": 0.0491,
      "step": 9150
    },
    {
      "epoch": 3.664,
      "grad_norm": 1.2810097932815552,
      "learning_rate": 3.232857142857143e-05,
      "loss": 0.084,
      "step": 9160
    },
    {
      "epoch": 3.668,
      "grad_norm": 2.3495352268218994,
      "learning_rate": 3.2308163265306124e-05,
      "loss": 0.1046,
      "step": 9170
    },
    {
      "epoch": 3.672,
      "grad_norm": 0.4540199041366577,
      "learning_rate": 3.2287755102040815e-05,
      "loss": 0.0589,
      "step": 9180
    },
    {
      "epoch": 3.676,
      "grad_norm": 0.2967362701892853,
      "learning_rate": 3.2267346938775514e-05,
      "loss": 0.0744,
      "step": 9190
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.9787976741790771,
      "learning_rate": 3.2246938775510205e-05,
      "loss": 0.1047,
      "step": 9200
    },
    {
      "epoch": 3.684,
      "grad_norm": 1.1527637243270874,
      "learning_rate": 3.22265306122449e-05,
      "loss": 0.1292,
      "step": 9210
    },
    {
      "epoch": 3.6879999999999997,
      "grad_norm": 0.12127210199832916,
      "learning_rate": 3.2206122448979595e-05,
      "loss": 0.0634,
      "step": 9220
    },
    {
      "epoch": 3.692,
      "grad_norm": 0.3663424253463745,
      "learning_rate": 3.218571428571429e-05,
      "loss": 0.084,
      "step": 9230
    },
    {
      "epoch": 3.6959999999999997,
      "grad_norm": 0.35878321528434753,
      "learning_rate": 3.216530612244898e-05,
      "loss": 0.0886,
      "step": 9240
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.3425658643245697,
      "learning_rate": 3.214489795918367e-05,
      "loss": 0.0825,
      "step": 9250
    },
    {
      "epoch": 3.7039999999999997,
      "grad_norm": 0.6655341982841492,
      "learning_rate": 3.212448979591837e-05,
      "loss": 0.0896,
      "step": 9260
    },
    {
      "epoch": 3.708,
      "grad_norm": 1.279293179512024,
      "learning_rate": 3.210408163265306e-05,
      "loss": 0.1288,
      "step": 9270
    },
    {
      "epoch": 3.7119999999999997,
      "grad_norm": 1.220531702041626,
      "learning_rate": 3.208367346938775e-05,
      "loss": 0.1078,
      "step": 9280
    },
    {
      "epoch": 3.716,
      "grad_norm": 0.25881439447402954,
      "learning_rate": 3.206326530612245e-05,
      "loss": 0.0805,
      "step": 9290
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 0.08303829282522202,
      "learning_rate": 3.204285714285715e-05,
      "loss": 0.0517,
      "step": 9300
    },
    {
      "epoch": 3.724,
      "grad_norm": 0.43021678924560547,
      "learning_rate": 3.202244897959184e-05,
      "loss": 0.0835,
      "step": 9310
    },
    {
      "epoch": 3.7279999999999998,
      "grad_norm": 0.6175296306610107,
      "learning_rate": 3.200204081632653e-05,
      "loss": 0.0917,
      "step": 9320
    },
    {
      "epoch": 3.732,
      "grad_norm": 0.21167922019958496,
      "learning_rate": 3.198163265306123e-05,
      "loss": 0.1157,
      "step": 9330
    },
    {
      "epoch": 3.7359999999999998,
      "grad_norm": 0.979530394077301,
      "learning_rate": 3.196122448979592e-05,
      "loss": 0.1058,
      "step": 9340
    },
    {
      "epoch": 3.74,
      "grad_norm": 0.9682109355926514,
      "learning_rate": 3.194081632653061e-05,
      "loss": 0.1265,
      "step": 9350
    },
    {
      "epoch": 3.7439999999999998,
      "grad_norm": 1.5804964303970337,
      "learning_rate": 3.192040816326531e-05,
      "loss": 0.0688,
      "step": 9360
    },
    {
      "epoch": 3.748,
      "grad_norm": 0.14917881786823273,
      "learning_rate": 3.19e-05,
      "loss": 0.0645,
      "step": 9370
    },
    {
      "epoch": 3.752,
      "grad_norm": 0.23360031843185425,
      "learning_rate": 3.1879591836734694e-05,
      "loss": 0.059,
      "step": 9380
    },
    {
      "epoch": 3.7560000000000002,
      "grad_norm": 1.2661292552947998,
      "learning_rate": 3.1859183673469386e-05,
      "loss": 0.0909,
      "step": 9390
    },
    {
      "epoch": 3.76,
      "grad_norm": 1.6627811193466187,
      "learning_rate": 3.1838775510204084e-05,
      "loss": 0.1491,
      "step": 9400
    },
    {
      "epoch": 3.7640000000000002,
      "grad_norm": 1.0227583646774292,
      "learning_rate": 3.1818367346938776e-05,
      "loss": 0.0721,
      "step": 9410
    },
    {
      "epoch": 3.768,
      "grad_norm": 1.8107539415359497,
      "learning_rate": 3.179795918367347e-05,
      "loss": 0.0742,
      "step": 9420
    },
    {
      "epoch": 3.7720000000000002,
      "grad_norm": 1.1825441122055054,
      "learning_rate": 3.1777551020408166e-05,
      "loss": 0.1097,
      "step": 9430
    },
    {
      "epoch": 3.776,
      "grad_norm": 1.6615740060806274,
      "learning_rate": 3.175714285714286e-05,
      "loss": 0.1073,
      "step": 9440
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 0.4081893861293793,
      "learning_rate": 3.173673469387755e-05,
      "loss": 0.0931,
      "step": 9450
    },
    {
      "epoch": 3.784,
      "grad_norm": 0.10582757741212845,
      "learning_rate": 3.171632653061225e-05,
      "loss": 0.1261,
      "step": 9460
    },
    {
      "epoch": 3.7880000000000003,
      "grad_norm": 0.5922810435295105,
      "learning_rate": 3.169591836734694e-05,
      "loss": 0.0703,
      "step": 9470
    },
    {
      "epoch": 3.792,
      "grad_norm": 0.3247838020324707,
      "learning_rate": 3.167551020408163e-05,
      "loss": 0.0735,
      "step": 9480
    },
    {
      "epoch": 3.7960000000000003,
      "grad_norm": 1.5601282119750977,
      "learning_rate": 3.165510204081633e-05,
      "loss": 0.092,
      "step": 9490
    },
    {
      "epoch": 3.8,
      "grad_norm": 1.446768879890442,
      "learning_rate": 3.163469387755102e-05,
      "loss": 0.1207,
      "step": 9500
    },
    {
      "epoch": 3.8040000000000003,
      "grad_norm": 1.2489652633666992,
      "learning_rate": 3.161428571428572e-05,
      "loss": 0.076,
      "step": 9510
    },
    {
      "epoch": 3.808,
      "grad_norm": 0.5163878202438354,
      "learning_rate": 3.159387755102041e-05,
      "loss": 0.0572,
      "step": 9520
    },
    {
      "epoch": 3.8120000000000003,
      "grad_norm": 1.559112548828125,
      "learning_rate": 3.157346938775511e-05,
      "loss": 0.1348,
      "step": 9530
    },
    {
      "epoch": 3.816,
      "grad_norm": 0.6762480735778809,
      "learning_rate": 3.15530612244898e-05,
      "loss": 0.1154,
      "step": 9540
    },
    {
      "epoch": 3.82,
      "grad_norm": 2.375133991241455,
      "learning_rate": 3.153265306122449e-05,
      "loss": 0.1371,
      "step": 9550
    },
    {
      "epoch": 3.824,
      "grad_norm": 0.4840081036090851,
      "learning_rate": 3.1512244897959184e-05,
      "loss": 0.0585,
      "step": 9560
    },
    {
      "epoch": 3.828,
      "grad_norm": 0.3016497492790222,
      "learning_rate": 3.149183673469388e-05,
      "loss": 0.0721,
      "step": 9570
    },
    {
      "epoch": 3.832,
      "grad_norm": 1.1665276288986206,
      "learning_rate": 3.1471428571428574e-05,
      "loss": 0.0984,
      "step": 9580
    },
    {
      "epoch": 3.836,
      "grad_norm": 1.5707675218582153,
      "learning_rate": 3.1451020408163265e-05,
      "loss": 0.1045,
      "step": 9590
    },
    {
      "epoch": 3.84,
      "grad_norm": 1.8311222791671753,
      "learning_rate": 3.1430612244897964e-05,
      "loss": 0.1338,
      "step": 9600
    },
    {
      "epoch": 3.844,
      "grad_norm": 0.580033540725708,
      "learning_rate": 3.1410204081632655e-05,
      "loss": 0.0646,
      "step": 9610
    },
    {
      "epoch": 3.848,
      "grad_norm": 0.7192138433456421,
      "learning_rate": 3.138979591836735e-05,
      "loss": 0.0893,
      "step": 9620
    },
    {
      "epoch": 3.852,
      "grad_norm": 0.04841620475053787,
      "learning_rate": 3.1369387755102045e-05,
      "loss": 0.0883,
      "step": 9630
    },
    {
      "epoch": 3.856,
      "grad_norm": 1.023664116859436,
      "learning_rate": 3.134897959183674e-05,
      "loss": 0.1133,
      "step": 9640
    },
    {
      "epoch": 3.86,
      "grad_norm": 0.1401461362838745,
      "learning_rate": 3.132857142857143e-05,
      "loss": 0.0812,
      "step": 9650
    },
    {
      "epoch": 3.864,
      "grad_norm": 0.8926811218261719,
      "learning_rate": 3.130816326530612e-05,
      "loss": 0.0734,
      "step": 9660
    },
    {
      "epoch": 3.868,
      "grad_norm": 0.9822810292243958,
      "learning_rate": 3.128775510204082e-05,
      "loss": 0.0665,
      "step": 9670
    },
    {
      "epoch": 3.872,
      "grad_norm": 0.8234477043151855,
      "learning_rate": 3.126734693877551e-05,
      "loss": 0.1151,
      "step": 9680
    },
    {
      "epoch": 3.876,
      "grad_norm": 0.37420180439949036,
      "learning_rate": 3.12469387755102e-05,
      "loss": 0.1062,
      "step": 9690
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.8149988055229187,
      "learning_rate": 3.12265306122449e-05,
      "loss": 0.0613,
      "step": 9700
    },
    {
      "epoch": 3.884,
      "grad_norm": 0.7796170711517334,
      "learning_rate": 3.120612244897959e-05,
      "loss": 0.0471,
      "step": 9710
    },
    {
      "epoch": 3.888,
      "grad_norm": 1.4128854274749756,
      "learning_rate": 3.118571428571428e-05,
      "loss": 0.0586,
      "step": 9720
    },
    {
      "epoch": 3.892,
      "grad_norm": 0.984207272529602,
      "learning_rate": 3.116530612244898e-05,
      "loss": 0.1093,
      "step": 9730
    },
    {
      "epoch": 3.896,
      "grad_norm": 0.540962815284729,
      "learning_rate": 3.114489795918368e-05,
      "loss": 0.0689,
      "step": 9740
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.28264012932777405,
      "learning_rate": 3.112448979591837e-05,
      "loss": 0.0625,
      "step": 9750
    },
    {
      "epoch": 3.904,
      "grad_norm": 0.7050940990447998,
      "learning_rate": 3.110408163265306e-05,
      "loss": 0.15,
      "step": 9760
    },
    {
      "epoch": 3.908,
      "grad_norm": 0.3493594229221344,
      "learning_rate": 3.108367346938776e-05,
      "loss": 0.0757,
      "step": 9770
    },
    {
      "epoch": 3.912,
      "grad_norm": 1.6835464239120483,
      "learning_rate": 3.106326530612245e-05,
      "loss": 0.0687,
      "step": 9780
    },
    {
      "epoch": 3.916,
      "grad_norm": 0.6256951093673706,
      "learning_rate": 3.1042857142857144e-05,
      "loss": 0.0657,
      "step": 9790
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.7987253665924072,
      "learning_rate": 3.102244897959184e-05,
      "loss": 0.087,
      "step": 9800
    },
    {
      "epoch": 3.924,
      "grad_norm": 0.2792578935623169,
      "learning_rate": 3.1002040816326534e-05,
      "loss": 0.0518,
      "step": 9810
    },
    {
      "epoch": 3.928,
      "grad_norm": 0.6277539730072021,
      "learning_rate": 3.0981632653061226e-05,
      "loss": 0.1083,
      "step": 9820
    },
    {
      "epoch": 3.932,
      "grad_norm": 0.07159871608018875,
      "learning_rate": 3.096122448979592e-05,
      "loss": 0.0679,
      "step": 9830
    },
    {
      "epoch": 3.936,
      "grad_norm": 1.0551522970199585,
      "learning_rate": 3.0940816326530616e-05,
      "loss": 0.104,
      "step": 9840
    },
    {
      "epoch": 3.94,
      "grad_norm": 0.38264206051826477,
      "learning_rate": 3.092040816326531e-05,
      "loss": 0.0968,
      "step": 9850
    },
    {
      "epoch": 3.944,
      "grad_norm": 1.0098717212677002,
      "learning_rate": 3.09e-05,
      "loss": 0.107,
      "step": 9860
    },
    {
      "epoch": 3.948,
      "grad_norm": 1.1416875123977661,
      "learning_rate": 3.08795918367347e-05,
      "loss": 0.0778,
      "step": 9870
    },
    {
      "epoch": 3.952,
      "grad_norm": 0.5904814004898071,
      "learning_rate": 3.085918367346939e-05,
      "loss": 0.0354,
      "step": 9880
    },
    {
      "epoch": 3.956,
      "grad_norm": 1.2169232368469238,
      "learning_rate": 3.083877551020408e-05,
      "loss": 0.057,
      "step": 9890
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.06310983747243881,
      "learning_rate": 3.081836734693878e-05,
      "loss": 0.0864,
      "step": 9900
    },
    {
      "epoch": 3.964,
      "grad_norm": 0.5113400220870972,
      "learning_rate": 3.079795918367347e-05,
      "loss": 0.1223,
      "step": 9910
    },
    {
      "epoch": 3.968,
      "grad_norm": 0.12550069391727448,
      "learning_rate": 3.077755102040816e-05,
      "loss": 0.0917,
      "step": 9920
    },
    {
      "epoch": 3.972,
      "grad_norm": 0.2565764784812927,
      "learning_rate": 3.0757142857142854e-05,
      "loss": 0.0778,
      "step": 9930
    },
    {
      "epoch": 3.976,
      "grad_norm": 0.29925036430358887,
      "learning_rate": 3.073673469387755e-05,
      "loss": 0.0957,
      "step": 9940
    },
    {
      "epoch": 3.98,
      "grad_norm": 1.1463509798049927,
      "learning_rate": 3.0716326530612244e-05,
      "loss": 0.0814,
      "step": 9950
    },
    {
      "epoch": 3.984,
      "grad_norm": 0.6333595514297485,
      "learning_rate": 3.0695918367346935e-05,
      "loss": 0.0512,
      "step": 9960
    },
    {
      "epoch": 3.988,
      "grad_norm": 1.025373101234436,
      "learning_rate": 3.0675510204081633e-05,
      "loss": 0.1468,
      "step": 9970
    },
    {
      "epoch": 3.992,
      "grad_norm": 0.5543425679206848,
      "learning_rate": 3.065510204081633e-05,
      "loss": 0.0679,
      "step": 9980
    },
    {
      "epoch": 3.996,
      "grad_norm": 1.8982279300689697,
      "learning_rate": 3.0634693877551023e-05,
      "loss": 0.0804,
      "step": 9990
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.14808416366577148,
      "learning_rate": 3.0614285714285715e-05,
      "loss": 0.0946,
      "step": 10000
    },
    {
      "epoch": 4.004,
      "grad_norm": 0.9893717169761658,
      "learning_rate": 3.059387755102041e-05,
      "loss": 0.0718,
      "step": 10010
    },
    {
      "epoch": 4.008,
      "grad_norm": 0.6350484490394592,
      "learning_rate": 3.0573469387755105e-05,
      "loss": 0.119,
      "step": 10020
    },
    {
      "epoch": 4.012,
      "grad_norm": 1.1877199411392212,
      "learning_rate": 3.0553061224489796e-05,
      "loss": 0.1493,
      "step": 10030
    },
    {
      "epoch": 4.016,
      "grad_norm": 0.524625301361084,
      "learning_rate": 3.0532653061224495e-05,
      "loss": 0.052,
      "step": 10040
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.9385992884635925,
      "learning_rate": 3.0512244897959186e-05,
      "loss": 0.0874,
      "step": 10050
    },
    {
      "epoch": 4.024,
      "grad_norm": 1.459989309310913,
      "learning_rate": 3.0491836734693878e-05,
      "loss": 0.1253,
      "step": 10060
    },
    {
      "epoch": 4.028,
      "grad_norm": 0.8817052245140076,
      "learning_rate": 3.0471428571428573e-05,
      "loss": 0.0545,
      "step": 10070
    },
    {
      "epoch": 4.032,
      "grad_norm": 1.639710545539856,
      "learning_rate": 3.0451020408163268e-05,
      "loss": 0.093,
      "step": 10080
    },
    {
      "epoch": 4.036,
      "grad_norm": 0.9314733743667603,
      "learning_rate": 3.043061224489796e-05,
      "loss": 0.0889,
      "step": 10090
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.23296275734901428,
      "learning_rate": 3.0410204081632655e-05,
      "loss": 0.0757,
      "step": 10100
    },
    {
      "epoch": 4.044,
      "grad_norm": 1.5490001440048218,
      "learning_rate": 3.0389795918367346e-05,
      "loss": 0.1223,
      "step": 10110
    },
    {
      "epoch": 4.048,
      "grad_norm": 1.1475625038146973,
      "learning_rate": 3.036938775510204e-05,
      "loss": 0.1006,
      "step": 10120
    },
    {
      "epoch": 4.052,
      "grad_norm": 0.4104214608669281,
      "learning_rate": 3.0348979591836736e-05,
      "loss": 0.0979,
      "step": 10130
    },
    {
      "epoch": 4.056,
      "grad_norm": 1.0199294090270996,
      "learning_rate": 3.0328571428571428e-05,
      "loss": 0.0661,
      "step": 10140
    },
    {
      "epoch": 4.06,
      "grad_norm": 0.3757729232311249,
      "learning_rate": 3.0308163265306123e-05,
      "loss": 0.092,
      "step": 10150
    },
    {
      "epoch": 4.064,
      "grad_norm": 1.2755180597305298,
      "learning_rate": 3.0287755102040814e-05,
      "loss": 0.1127,
      "step": 10160
    },
    {
      "epoch": 4.068,
      "grad_norm": 1.00067138671875,
      "learning_rate": 3.026734693877551e-05,
      "loss": 0.0907,
      "step": 10170
    },
    {
      "epoch": 4.072,
      "grad_norm": 0.012303175404667854,
      "learning_rate": 3.0246938775510204e-05,
      "loss": 0.0717,
      "step": 10180
    },
    {
      "epoch": 4.076,
      "grad_norm": 0.1791451871395111,
      "learning_rate": 3.0226530612244902e-05,
      "loss": 0.1435,
      "step": 10190
    },
    {
      "epoch": 4.08,
      "grad_norm": 1.2445300817489624,
      "learning_rate": 3.0206122448979594e-05,
      "loss": 0.1037,
      "step": 10200
    },
    {
      "epoch": 4.084,
      "grad_norm": 0.9496753215789795,
      "learning_rate": 3.018571428571429e-05,
      "loss": 0.0752,
      "step": 10210
    },
    {
      "epoch": 4.088,
      "grad_norm": 1.5772955417633057,
      "learning_rate": 3.0165306122448984e-05,
      "loss": 0.065,
      "step": 10220
    },
    {
      "epoch": 4.092,
      "grad_norm": 1.585828185081482,
      "learning_rate": 3.0144897959183676e-05,
      "loss": 0.1069,
      "step": 10230
    },
    {
      "epoch": 4.096,
      "grad_norm": 0.575644850730896,
      "learning_rate": 3.012448979591837e-05,
      "loss": 0.0744,
      "step": 10240
    },
    {
      "epoch": 4.1,
      "grad_norm": 1.9456422328948975,
      "learning_rate": 3.0104081632653066e-05,
      "loss": 0.093,
      "step": 10250
    },
    {
      "epoch": 4.104,
      "grad_norm": 0.7669060230255127,
      "learning_rate": 3.0083673469387757e-05,
      "loss": 0.1242,
      "step": 10260
    },
    {
      "epoch": 4.108,
      "grad_norm": 1.185667634010315,
      "learning_rate": 3.0063265306122452e-05,
      "loss": 0.0798,
      "step": 10270
    },
    {
      "epoch": 4.112,
      "grad_norm": 1.3989452123641968,
      "learning_rate": 3.0042857142857144e-05,
      "loss": 0.0905,
      "step": 10280
    },
    {
      "epoch": 4.116,
      "grad_norm": 1.2520041465759277,
      "learning_rate": 3.002244897959184e-05,
      "loss": 0.1094,
      "step": 10290
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.1400599479675293,
      "learning_rate": 3.0002040816326534e-05,
      "loss": 0.1534,
      "step": 10300
    },
    {
      "epoch": 4.124,
      "grad_norm": 0.11229813098907471,
      "learning_rate": 2.9981632653061225e-05,
      "loss": 0.1013,
      "step": 10310
    },
    {
      "epoch": 4.128,
      "grad_norm": 0.965252697467804,
      "learning_rate": 2.996122448979592e-05,
      "loss": 0.1126,
      "step": 10320
    },
    {
      "epoch": 4.132,
      "grad_norm": 1.4939359426498413,
      "learning_rate": 2.9940816326530612e-05,
      "loss": 0.1258,
      "step": 10330
    },
    {
      "epoch": 4.136,
      "grad_norm": 0.704626202583313,
      "learning_rate": 2.9920408163265307e-05,
      "loss": 0.0537,
      "step": 10340
    },
    {
      "epoch": 4.14,
      "grad_norm": 0.9152147173881531,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 0.0426,
      "step": 10350
    },
    {
      "epoch": 4.144,
      "grad_norm": 1.0191426277160645,
      "learning_rate": 2.9879591836734693e-05,
      "loss": 0.0635,
      "step": 10360
    },
    {
      "epoch": 4.148,
      "grad_norm": 0.7964937090873718,
      "learning_rate": 2.9859183673469388e-05,
      "loss": 0.0692,
      "step": 10370
    },
    {
      "epoch": 4.152,
      "grad_norm": 0.09249819070100784,
      "learning_rate": 2.983877551020408e-05,
      "loss": 0.0538,
      "step": 10380
    },
    {
      "epoch": 4.156,
      "grad_norm": 0.9980114698410034,
      "learning_rate": 2.9818367346938775e-05,
      "loss": 0.084,
      "step": 10390
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.6251333951950073,
      "learning_rate": 2.979795918367347e-05,
      "loss": 0.1022,
      "step": 10400
    },
    {
      "epoch": 4.164,
      "grad_norm": 0.3500467836856842,
      "learning_rate": 2.977755102040816e-05,
      "loss": 0.0884,
      "step": 10410
    },
    {
      "epoch": 4.168,
      "grad_norm": 0.9271804094314575,
      "learning_rate": 2.975714285714286e-05,
      "loss": 0.0681,
      "step": 10420
    },
    {
      "epoch": 4.172,
      "grad_norm": 1.409868597984314,
      "learning_rate": 2.9736734693877555e-05,
      "loss": 0.0669,
      "step": 10430
    },
    {
      "epoch": 4.176,
      "grad_norm": 0.4703715145587921,
      "learning_rate": 2.971632653061225e-05,
      "loss": 0.0838,
      "step": 10440
    },
    {
      "epoch": 4.18,
      "grad_norm": 0.8568121194839478,
      "learning_rate": 2.969591836734694e-05,
      "loss": 0.0844,
      "step": 10450
    },
    {
      "epoch": 4.184,
      "grad_norm": 0.4503638446331024,
      "learning_rate": 2.9675510204081636e-05,
      "loss": 0.0905,
      "step": 10460
    },
    {
      "epoch": 4.188,
      "grad_norm": 1.3151096105575562,
      "learning_rate": 2.9655102040816328e-05,
      "loss": 0.0822,
      "step": 10470
    },
    {
      "epoch": 4.192,
      "grad_norm": 1.1937499046325684,
      "learning_rate": 2.9634693877551023e-05,
      "loss": 0.128,
      "step": 10480
    },
    {
      "epoch": 4.196,
      "grad_norm": 0.4527648091316223,
      "learning_rate": 2.9614285714285718e-05,
      "loss": 0.1002,
      "step": 10490
    },
    {
      "epoch": 4.2,
      "grad_norm": 1.5099141597747803,
      "learning_rate": 2.959387755102041e-05,
      "loss": 0.0775,
      "step": 10500
    },
    {
      "epoch": 4.204,
      "grad_norm": 1.1581727266311646,
      "learning_rate": 2.9573469387755104e-05,
      "loss": 0.1015,
      "step": 10510
    },
    {
      "epoch": 4.208,
      "grad_norm": 0.49761006236076355,
      "learning_rate": 2.9553061224489796e-05,
      "loss": 0.0651,
      "step": 10520
    },
    {
      "epoch": 4.212,
      "grad_norm": 2.105851411819458,
      "learning_rate": 2.953265306122449e-05,
      "loss": 0.0904,
      "step": 10530
    },
    {
      "epoch": 4.216,
      "grad_norm": 1.9252398014068604,
      "learning_rate": 2.9512244897959186e-05,
      "loss": 0.104,
      "step": 10540
    },
    {
      "epoch": 4.22,
      "grad_norm": 0.6813110709190369,
      "learning_rate": 2.9491836734693877e-05,
      "loss": 0.0763,
      "step": 10550
    },
    {
      "epoch": 4.224,
      "grad_norm": 0.6753226518630981,
      "learning_rate": 2.9471428571428572e-05,
      "loss": 0.0818,
      "step": 10560
    },
    {
      "epoch": 4.228,
      "grad_norm": 1.5931997299194336,
      "learning_rate": 2.9451020408163264e-05,
      "loss": 0.1316,
      "step": 10570
    },
    {
      "epoch": 4.232,
      "grad_norm": 0.45096588134765625,
      "learning_rate": 2.943061224489796e-05,
      "loss": 0.0449,
      "step": 10580
    },
    {
      "epoch": 4.236,
      "grad_norm": 0.8129266500473022,
      "learning_rate": 2.9410204081632654e-05,
      "loss": 0.0516,
      "step": 10590
    },
    {
      "epoch": 4.24,
      "grad_norm": 1.0816375017166138,
      "learning_rate": 2.9389795918367346e-05,
      "loss": 0.0675,
      "step": 10600
    },
    {
      "epoch": 4.244,
      "grad_norm": 0.43487098813056946,
      "learning_rate": 2.936938775510204e-05,
      "loss": 0.0816,
      "step": 10610
    },
    {
      "epoch": 4.248,
      "grad_norm": 0.5379337668418884,
      "learning_rate": 2.9348979591836735e-05,
      "loss": 0.0575,
      "step": 10620
    },
    {
      "epoch": 4.252,
      "grad_norm": 0.5037140846252441,
      "learning_rate": 2.9328571428571427e-05,
      "loss": 0.091,
      "step": 10630
    },
    {
      "epoch": 4.256,
      "grad_norm": 0.8152226805686951,
      "learning_rate": 2.9308163265306122e-05,
      "loss": 0.0776,
      "step": 10640
    },
    {
      "epoch": 4.26,
      "grad_norm": 1.4986268281936646,
      "learning_rate": 2.928775510204082e-05,
      "loss": 0.0504,
      "step": 10650
    },
    {
      "epoch": 4.264,
      "grad_norm": 0.865163266658783,
      "learning_rate": 2.9267346938775515e-05,
      "loss": 0.0932,
      "step": 10660
    },
    {
      "epoch": 4.268,
      "grad_norm": 0.9698511958122253,
      "learning_rate": 2.9246938775510207e-05,
      "loss": 0.0784,
      "step": 10670
    },
    {
      "epoch": 4.272,
      "grad_norm": 0.860970139503479,
      "learning_rate": 2.9226530612244902e-05,
      "loss": 0.0932,
      "step": 10680
    },
    {
      "epoch": 4.276,
      "grad_norm": 1.0642991065979004,
      "learning_rate": 2.9206122448979593e-05,
      "loss": 0.0871,
      "step": 10690
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.37502622604370117,
      "learning_rate": 2.918571428571429e-05,
      "loss": 0.1037,
      "step": 10700
    },
    {
      "epoch": 4.284,
      "grad_norm": 0.8785640597343445,
      "learning_rate": 2.9165306122448983e-05,
      "loss": 0.0849,
      "step": 10710
    },
    {
      "epoch": 4.288,
      "grad_norm": 1.4801675081253052,
      "learning_rate": 2.9144897959183675e-05,
      "loss": 0.1115,
      "step": 10720
    },
    {
      "epoch": 4.292,
      "grad_norm": 1.215867042541504,
      "learning_rate": 2.912448979591837e-05,
      "loss": 0.0665,
      "step": 10730
    },
    {
      "epoch": 4.296,
      "grad_norm": 0.46904799342155457,
      "learning_rate": 2.910408163265306e-05,
      "loss": 0.0436,
      "step": 10740
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.46279287338256836,
      "learning_rate": 2.9083673469387757e-05,
      "loss": 0.0984,
      "step": 10750
    },
    {
      "epoch": 4.304,
      "grad_norm": 0.7157999873161316,
      "learning_rate": 2.906326530612245e-05,
      "loss": 0.0679,
      "step": 10760
    },
    {
      "epoch": 4.308,
      "grad_norm": 1.5555837154388428,
      "learning_rate": 2.9042857142857143e-05,
      "loss": 0.0753,
      "step": 10770
    },
    {
      "epoch": 4.312,
      "grad_norm": 0.7496569752693176,
      "learning_rate": 2.9022448979591838e-05,
      "loss": 0.0469,
      "step": 10780
    },
    {
      "epoch": 4.316,
      "grad_norm": 1.3464089632034302,
      "learning_rate": 2.900204081632653e-05,
      "loss": 0.0904,
      "step": 10790
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.5721212029457092,
      "learning_rate": 2.8981632653061225e-05,
      "loss": 0.0869,
      "step": 10800
    },
    {
      "epoch": 4.324,
      "grad_norm": 0.47301924228668213,
      "learning_rate": 2.896122448979592e-05,
      "loss": 0.0775,
      "step": 10810
    },
    {
      "epoch": 4.328,
      "grad_norm": 0.5802053213119507,
      "learning_rate": 2.894081632653061e-05,
      "loss": 0.0845,
      "step": 10820
    },
    {
      "epoch": 4.332,
      "grad_norm": 0.6218518614768982,
      "learning_rate": 2.8920408163265306e-05,
      "loss": 0.0741,
      "step": 10830
    },
    {
      "epoch": 4.336,
      "grad_norm": 0.46167367696762085,
      "learning_rate": 2.8899999999999998e-05,
      "loss": 0.0803,
      "step": 10840
    },
    {
      "epoch": 4.34,
      "grad_norm": 0.7537761330604553,
      "learning_rate": 2.8879591836734693e-05,
      "loss": 0.0636,
      "step": 10850
    },
    {
      "epoch": 4.344,
      "grad_norm": 0.962011456489563,
      "learning_rate": 2.8859183673469388e-05,
      "loss": 0.0857,
      "step": 10860
    },
    {
      "epoch": 4.348,
      "grad_norm": 2.5086922645568848,
      "learning_rate": 2.8838775510204086e-05,
      "loss": 0.0823,
      "step": 10870
    },
    {
      "epoch": 4.352,
      "grad_norm": 0.2703421413898468,
      "learning_rate": 2.881836734693878e-05,
      "loss": 0.0967,
      "step": 10880
    },
    {
      "epoch": 4.356,
      "grad_norm": 0.4560353755950928,
      "learning_rate": 2.8797959183673473e-05,
      "loss": 0.1074,
      "step": 10890
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.4642963111400604,
      "learning_rate": 2.8777551020408168e-05,
      "loss": 0.0317,
      "step": 10900
    },
    {
      "epoch": 4.364,
      "grad_norm": 1.1296501159667969,
      "learning_rate": 2.875714285714286e-05,
      "loss": 0.0821,
      "step": 10910
    },
    {
      "epoch": 4.368,
      "grad_norm": 1.5701919794082642,
      "learning_rate": 2.8736734693877554e-05,
      "loss": 0.0849,
      "step": 10920
    },
    {
      "epoch": 4.372,
      "grad_norm": 0.24755257368087769,
      "learning_rate": 2.871632653061225e-05,
      "loss": 0.0887,
      "step": 10930
    },
    {
      "epoch": 4.376,
      "grad_norm": 1.172181248664856,
      "learning_rate": 2.869591836734694e-05,
      "loss": 0.0979,
      "step": 10940
    },
    {
      "epoch": 4.38,
      "grad_norm": 0.8180504441261292,
      "learning_rate": 2.8675510204081636e-05,
      "loss": 0.1123,
      "step": 10950
    },
    {
      "epoch": 4.384,
      "grad_norm": 0.7910627126693726,
      "learning_rate": 2.8655102040816327e-05,
      "loss": 0.0558,
      "step": 10960
    },
    {
      "epoch": 4.388,
      "grad_norm": 0.9967752695083618,
      "learning_rate": 2.8634693877551022e-05,
      "loss": 0.0971,
      "step": 10970
    },
    {
      "epoch": 4.392,
      "grad_norm": 0.9821752309799194,
      "learning_rate": 2.8614285714285717e-05,
      "loss": 0.0685,
      "step": 10980
    },
    {
      "epoch": 4.396,
      "grad_norm": 0.742906391620636,
      "learning_rate": 2.859387755102041e-05,
      "loss": 0.0566,
      "step": 10990
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.31893348693847656,
      "learning_rate": 2.8573469387755104e-05,
      "loss": 0.0866,
      "step": 11000
    },
    {
      "epoch": 4.404,
      "grad_norm": 0.8296216726303101,
      "learning_rate": 2.8553061224489795e-05,
      "loss": 0.0526,
      "step": 11010
    },
    {
      "epoch": 4.408,
      "grad_norm": 1.761819839477539,
      "learning_rate": 2.853265306122449e-05,
      "loss": 0.0875,
      "step": 11020
    },
    {
      "epoch": 4.412,
      "grad_norm": 1.17782723903656,
      "learning_rate": 2.8512244897959185e-05,
      "loss": 0.066,
      "step": 11030
    },
    {
      "epoch": 4.416,
      "grad_norm": 1.1366808414459229,
      "learning_rate": 2.8491836734693877e-05,
      "loss": 0.0841,
      "step": 11040
    },
    {
      "epoch": 4.42,
      "grad_norm": 0.5492202639579773,
      "learning_rate": 2.8471428571428572e-05,
      "loss": 0.0829,
      "step": 11050
    },
    {
      "epoch": 4.424,
      "grad_norm": 0.5202580094337463,
      "learning_rate": 2.8451020408163263e-05,
      "loss": 0.0704,
      "step": 11060
    },
    {
      "epoch": 4.428,
      "grad_norm": 0.31984785199165344,
      "learning_rate": 2.843061224489796e-05,
      "loss": 0.0511,
      "step": 11070
    },
    {
      "epoch": 4.432,
      "grad_norm": 0.9919275641441345,
      "learning_rate": 2.8410204081632653e-05,
      "loss": 0.0615,
      "step": 11080
    },
    {
      "epoch": 4.436,
      "grad_norm": 0.6347261071205139,
      "learning_rate": 2.8389795918367345e-05,
      "loss": 0.106,
      "step": 11090
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.4174613952636719,
      "learning_rate": 2.8369387755102043e-05,
      "loss": 0.0796,
      "step": 11100
    },
    {
      "epoch": 4.444,
      "grad_norm": 2.208078145980835,
      "learning_rate": 2.8348979591836738e-05,
      "loss": 0.1407,
      "step": 11110
    },
    {
      "epoch": 4.448,
      "grad_norm": 1.209009051322937,
      "learning_rate": 2.8328571428571433e-05,
      "loss": 0.0557,
      "step": 11120
    },
    {
      "epoch": 4.452,
      "grad_norm": 0.25368648767471313,
      "learning_rate": 2.8308163265306125e-05,
      "loss": 0.0524,
      "step": 11130
    },
    {
      "epoch": 4.456,
      "grad_norm": 1.2367222309112549,
      "learning_rate": 2.828775510204082e-05,
      "loss": 0.0631,
      "step": 11140
    },
    {
      "epoch": 4.46,
      "grad_norm": 1.5825726985931396,
      "learning_rate": 2.826734693877551e-05,
      "loss": 0.1332,
      "step": 11150
    },
    {
      "epoch": 4.464,
      "grad_norm": 0.2573316693305969,
      "learning_rate": 2.8246938775510206e-05,
      "loss": 0.1014,
      "step": 11160
    },
    {
      "epoch": 4.468,
      "grad_norm": 0.5712378621101379,
      "learning_rate": 2.82265306122449e-05,
      "loss": 0.0794,
      "step": 11170
    },
    {
      "epoch": 4.4719999999999995,
      "grad_norm": 1.2621296644210815,
      "learning_rate": 2.8206122448979593e-05,
      "loss": 0.0758,
      "step": 11180
    },
    {
      "epoch": 4.476,
      "grad_norm": 0.9804542064666748,
      "learning_rate": 2.8185714285714288e-05,
      "loss": 0.0882,
      "step": 11190
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.9634189605712891,
      "learning_rate": 2.816530612244898e-05,
      "loss": 0.1058,
      "step": 11200
    },
    {
      "epoch": 4.484,
      "grad_norm": 0.04986313730478287,
      "learning_rate": 2.8144897959183674e-05,
      "loss": 0.1026,
      "step": 11210
    },
    {
      "epoch": 4.4879999999999995,
      "grad_norm": 1.1086143255233765,
      "learning_rate": 2.812448979591837e-05,
      "loss": 0.063,
      "step": 11220
    },
    {
      "epoch": 4.492,
      "grad_norm": 0.2950786352157593,
      "learning_rate": 2.810408163265306e-05,
      "loss": 0.0837,
      "step": 11230
    },
    {
      "epoch": 4.496,
      "grad_norm": 0.08989426493644714,
      "learning_rate": 2.8083673469387756e-05,
      "loss": 0.0809,
      "step": 11240
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.1992703378200531,
      "learning_rate": 2.806326530612245e-05,
      "loss": 0.0585,
      "step": 11250
    },
    {
      "epoch": 4.504,
      "grad_norm": 0.6440330743789673,
      "learning_rate": 2.8042857142857143e-05,
      "loss": 0.1224,
      "step": 11260
    },
    {
      "epoch": 4.508,
      "grad_norm": 1.551523208618164,
      "learning_rate": 2.8022448979591837e-05,
      "loss": 0.1174,
      "step": 11270
    },
    {
      "epoch": 4.5120000000000005,
      "grad_norm": 1.062394142150879,
      "learning_rate": 2.800204081632653e-05,
      "loss": 0.1312,
      "step": 11280
    },
    {
      "epoch": 4.516,
      "grad_norm": 0.32599934935569763,
      "learning_rate": 2.7981632653061224e-05,
      "loss": 0.066,
      "step": 11290
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.2123740315437317,
      "learning_rate": 2.796122448979592e-05,
      "loss": 0.0483,
      "step": 11300
    },
    {
      "epoch": 4.524,
      "grad_norm": 0.12223661690950394,
      "learning_rate": 2.794081632653061e-05,
      "loss": 0.0426,
      "step": 11310
    },
    {
      "epoch": 4.5280000000000005,
      "grad_norm": 0.18640576303005219,
      "learning_rate": 2.7920408163265306e-05,
      "loss": 0.0715,
      "step": 11320
    },
    {
      "epoch": 4.532,
      "grad_norm": 0.9344807267189026,
      "learning_rate": 2.7900000000000004e-05,
      "loss": 0.1314,
      "step": 11330
    },
    {
      "epoch": 4.536,
      "grad_norm": 0.8213091492652893,
      "learning_rate": 2.78795918367347e-05,
      "loss": 0.0623,
      "step": 11340
    },
    {
      "epoch": 4.54,
      "grad_norm": 1.1152489185333252,
      "learning_rate": 2.785918367346939e-05,
      "loss": 0.1036,
      "step": 11350
    },
    {
      "epoch": 4.5440000000000005,
      "grad_norm": 1.6028953790664673,
      "learning_rate": 2.7838775510204085e-05,
      "loss": 0.0993,
      "step": 11360
    },
    {
      "epoch": 4.548,
      "grad_norm": 0.119320347905159,
      "learning_rate": 2.7818367346938777e-05,
      "loss": 0.0653,
      "step": 11370
    },
    {
      "epoch": 4.552,
      "grad_norm": 0.1685752421617508,
      "learning_rate": 2.7797959183673472e-05,
      "loss": 0.0938,
      "step": 11380
    },
    {
      "epoch": 4.556,
      "grad_norm": 0.36733680963516235,
      "learning_rate": 2.7777551020408167e-05,
      "loss": 0.0777,
      "step": 11390
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 1.7284271717071533,
      "learning_rate": 2.775714285714286e-05,
      "loss": 0.0809,
      "step": 11400
    },
    {
      "epoch": 4.564,
      "grad_norm": 0.0464174747467041,
      "learning_rate": 2.7736734693877554e-05,
      "loss": 0.0644,
      "step": 11410
    },
    {
      "epoch": 4.568,
      "grad_norm": 0.7325793504714966,
      "learning_rate": 2.7716326530612245e-05,
      "loss": 0.1399,
      "step": 11420
    },
    {
      "epoch": 4.572,
      "grad_norm": 1.4245188236236572,
      "learning_rate": 2.769591836734694e-05,
      "loss": 0.1387,
      "step": 11430
    },
    {
      "epoch": 4.576,
      "grad_norm": 0.41214704513549805,
      "learning_rate": 2.7675510204081635e-05,
      "loss": 0.0779,
      "step": 11440
    },
    {
      "epoch": 4.58,
      "grad_norm": 0.8160681128501892,
      "learning_rate": 2.7655102040816327e-05,
      "loss": 0.0794,
      "step": 11450
    },
    {
      "epoch": 4.584,
      "grad_norm": 0.1035461276769638,
      "learning_rate": 2.763469387755102e-05,
      "loss": 0.1054,
      "step": 11460
    },
    {
      "epoch": 4.588,
      "grad_norm": 0.88913893699646,
      "learning_rate": 2.7614285714285713e-05,
      "loss": 0.1027,
      "step": 11470
    },
    {
      "epoch": 4.592,
      "grad_norm": 0.8721124529838562,
      "learning_rate": 2.7593877551020408e-05,
      "loss": 0.0901,
      "step": 11480
    },
    {
      "epoch": 4.596,
      "grad_norm": 0.22538580000400543,
      "learning_rate": 2.7573469387755103e-05,
      "loss": 0.0508,
      "step": 11490
    },
    {
      "epoch": 4.6,
      "grad_norm": 1.273746132850647,
      "learning_rate": 2.7553061224489795e-05,
      "loss": 0.0893,
      "step": 11500
    },
    {
      "epoch": 4.604,
      "grad_norm": 0.3165937066078186,
      "learning_rate": 2.753265306122449e-05,
      "loss": 0.0624,
      "step": 11510
    },
    {
      "epoch": 4.608,
      "grad_norm": 1.1367239952087402,
      "learning_rate": 2.751224489795918e-05,
      "loss": 0.1041,
      "step": 11520
    },
    {
      "epoch": 4.612,
      "grad_norm": 0.31051740050315857,
      "learning_rate": 2.7491836734693876e-05,
      "loss": 0.0902,
      "step": 11530
    },
    {
      "epoch": 4.616,
      "grad_norm": 0.2751171886920929,
      "learning_rate": 2.747142857142857e-05,
      "loss": 0.0723,
      "step": 11540
    },
    {
      "epoch": 4.62,
      "grad_norm": 0.5862656831741333,
      "learning_rate": 2.745102040816327e-05,
      "loss": 0.0846,
      "step": 11550
    },
    {
      "epoch": 4.624,
      "grad_norm": 0.9003230333328247,
      "learning_rate": 2.7430612244897965e-05,
      "loss": 0.0582,
      "step": 11560
    },
    {
      "epoch": 4.628,
      "grad_norm": 0.3185661733150482,
      "learning_rate": 2.7410204081632656e-05,
      "loss": 0.0679,
      "step": 11570
    },
    {
      "epoch": 4.632,
      "grad_norm": 0.2574995160102844,
      "learning_rate": 2.738979591836735e-05,
      "loss": 0.0523,
      "step": 11580
    },
    {
      "epoch": 4.636,
      "grad_norm": 0.6589235663414001,
      "learning_rate": 2.7369387755102043e-05,
      "loss": 0.1115,
      "step": 11590
    },
    {
      "epoch": 4.64,
      "grad_norm": 1.7869958877563477,
      "learning_rate": 2.7348979591836738e-05,
      "loss": 0.0824,
      "step": 11600
    },
    {
      "epoch": 4.644,
      "grad_norm": 0.631368100643158,
      "learning_rate": 2.7328571428571433e-05,
      "loss": 0.0592,
      "step": 11610
    },
    {
      "epoch": 4.648,
      "grad_norm": 0.41906654834747314,
      "learning_rate": 2.7308163265306124e-05,
      "loss": 0.0487,
      "step": 11620
    },
    {
      "epoch": 4.652,
      "grad_norm": 1.4332391023635864,
      "learning_rate": 2.728775510204082e-05,
      "loss": 0.0673,
      "step": 11630
    },
    {
      "epoch": 4.656,
      "grad_norm": 1.237676978111267,
      "learning_rate": 2.726734693877551e-05,
      "loss": 0.1156,
      "step": 11640
    },
    {
      "epoch": 4.66,
      "grad_norm": 1.42214834690094,
      "learning_rate": 2.7246938775510206e-05,
      "loss": 0.1013,
      "step": 11650
    },
    {
      "epoch": 4.664,
      "grad_norm": 1.0834966897964478,
      "learning_rate": 2.72265306122449e-05,
      "loss": 0.063,
      "step": 11660
    },
    {
      "epoch": 4.668,
      "grad_norm": 1.7417469024658203,
      "learning_rate": 2.7206122448979592e-05,
      "loss": 0.1089,
      "step": 11670
    },
    {
      "epoch": 4.672,
      "grad_norm": 0.829871654510498,
      "learning_rate": 2.7185714285714287e-05,
      "loss": 0.089,
      "step": 11680
    },
    {
      "epoch": 4.676,
      "grad_norm": 0.8370938301086426,
      "learning_rate": 2.716530612244898e-05,
      "loss": 0.0625,
      "step": 11690
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.4852534234523773,
      "learning_rate": 2.7144897959183674e-05,
      "loss": 0.0861,
      "step": 11700
    },
    {
      "epoch": 4.684,
      "grad_norm": 0.6590036749839783,
      "learning_rate": 2.712448979591837e-05,
      "loss": 0.0614,
      "step": 11710
    },
    {
      "epoch": 4.688,
      "grad_norm": 1.3838849067687988,
      "learning_rate": 2.710408163265306e-05,
      "loss": 0.1182,
      "step": 11720
    },
    {
      "epoch": 4.692,
      "grad_norm": 0.6515149474143982,
      "learning_rate": 2.7083673469387755e-05,
      "loss": 0.0778,
      "step": 11730
    },
    {
      "epoch": 4.696,
      "grad_norm": 0.6334150433540344,
      "learning_rate": 2.7063265306122447e-05,
      "loss": 0.0554,
      "step": 11740
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.05090158432722092,
      "learning_rate": 2.7042857142857142e-05,
      "loss": 0.0765,
      "step": 11750
    },
    {
      "epoch": 4.704,
      "grad_norm": 1.8095324039459229,
      "learning_rate": 2.7022448979591837e-05,
      "loss": 0.0665,
      "step": 11760
    },
    {
      "epoch": 4.708,
      "grad_norm": 1.3632864952087402,
      "learning_rate": 2.700204081632653e-05,
      "loss": 0.1055,
      "step": 11770
    },
    {
      "epoch": 4.712,
      "grad_norm": 0.6408673524856567,
      "learning_rate": 2.6981632653061227e-05,
      "loss": 0.058,
      "step": 11780
    },
    {
      "epoch": 4.716,
      "grad_norm": 1.0205169916152954,
      "learning_rate": 2.6961224489795922e-05,
      "loss": 0.0623,
      "step": 11790
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.49082791805267334,
      "learning_rate": 2.6940816326530617e-05,
      "loss": 0.0979,
      "step": 11800
    },
    {
      "epoch": 4.724,
      "grad_norm": 0.46186643838882446,
      "learning_rate": 2.692040816326531e-05,
      "loss": 0.1139,
      "step": 11810
    },
    {
      "epoch": 4.728,
      "grad_norm": 1.1682127714157104,
      "learning_rate": 2.6900000000000003e-05,
      "loss": 0.084,
      "step": 11820
    },
    {
      "epoch": 4.732,
      "grad_norm": 1.825641393661499,
      "learning_rate": 2.6879591836734695e-05,
      "loss": 0.1078,
      "step": 11830
    },
    {
      "epoch": 4.736,
      "grad_norm": 1.2208493947982788,
      "learning_rate": 2.685918367346939e-05,
      "loss": 0.0776,
      "step": 11840
    },
    {
      "epoch": 4.74,
      "grad_norm": 0.7923349738121033,
      "learning_rate": 2.6838775510204085e-05,
      "loss": 0.0859,
      "step": 11850
    },
    {
      "epoch": 4.744,
      "grad_norm": 1.1901789903640747,
      "learning_rate": 2.6818367346938776e-05,
      "loss": 0.072,
      "step": 11860
    },
    {
      "epoch": 4.748,
      "grad_norm": 0.11036454886198044,
      "learning_rate": 2.679795918367347e-05,
      "loss": 0.1003,
      "step": 11870
    },
    {
      "epoch": 4.752,
      "grad_norm": 1.2243919372558594,
      "learning_rate": 2.6777551020408166e-05,
      "loss": 0.0864,
      "step": 11880
    },
    {
      "epoch": 4.756,
      "grad_norm": 1.231553554534912,
      "learning_rate": 2.6757142857142858e-05,
      "loss": 0.116,
      "step": 11890
    },
    {
      "epoch": 4.76,
      "grad_norm": 1.1281827688217163,
      "learning_rate": 2.6736734693877553e-05,
      "loss": 0.0977,
      "step": 11900
    },
    {
      "epoch": 4.764,
      "grad_norm": 0.9936717748641968,
      "learning_rate": 2.6716326530612245e-05,
      "loss": 0.1077,
      "step": 11910
    },
    {
      "epoch": 4.768,
      "grad_norm": 0.3853437304496765,
      "learning_rate": 2.669591836734694e-05,
      "loss": 0.0383,
      "step": 11920
    },
    {
      "epoch": 4.772,
      "grad_norm": 1.0697171688079834,
      "learning_rate": 2.6675510204081634e-05,
      "loss": 0.0839,
      "step": 11930
    },
    {
      "epoch": 4.776,
      "grad_norm": 1.8495694398880005,
      "learning_rate": 2.6655102040816326e-05,
      "loss": 0.1064,
      "step": 11940
    },
    {
      "epoch": 4.78,
      "grad_norm": 0.16865216195583344,
      "learning_rate": 2.663469387755102e-05,
      "loss": 0.0422,
      "step": 11950
    },
    {
      "epoch": 4.784,
      "grad_norm": 1.4240894317626953,
      "learning_rate": 2.6614285714285713e-05,
      "loss": 0.0948,
      "step": 11960
    },
    {
      "epoch": 4.788,
      "grad_norm": 1.051128625869751,
      "learning_rate": 2.6593877551020408e-05,
      "loss": 0.1185,
      "step": 11970
    },
    {
      "epoch": 4.792,
      "grad_norm": 0.7871676087379456,
      "learning_rate": 2.6573469387755103e-05,
      "loss": 0.0882,
      "step": 11980
    },
    {
      "epoch": 4.796,
      "grad_norm": 1.4006977081298828,
      "learning_rate": 2.6553061224489794e-05,
      "loss": 0.0505,
      "step": 11990
    },
    {
      "epoch": 4.8,
      "grad_norm": 1.0628085136413574,
      "learning_rate": 2.653265306122449e-05,
      "loss": 0.0534,
      "step": 12000
    },
    {
      "epoch": 4.804,
      "grad_norm": 0.547419548034668,
      "learning_rate": 2.6512244897959187e-05,
      "loss": 0.0814,
      "step": 12010
    },
    {
      "epoch": 4.808,
      "grad_norm": 0.24164962768554688,
      "learning_rate": 2.6491836734693882e-05,
      "loss": 0.0546,
      "step": 12020
    },
    {
      "epoch": 4.812,
      "grad_norm": 1.5498826503753662,
      "learning_rate": 2.6471428571428574e-05,
      "loss": 0.1552,
      "step": 12030
    },
    {
      "epoch": 4.816,
      "grad_norm": 0.6652799844741821,
      "learning_rate": 2.645102040816327e-05,
      "loss": 0.053,
      "step": 12040
    },
    {
      "epoch": 4.82,
      "grad_norm": 0.02645883895456791,
      "learning_rate": 2.643061224489796e-05,
      "loss": 0.0773,
      "step": 12050
    },
    {
      "epoch": 4.824,
      "grad_norm": 0.4254833459854126,
      "learning_rate": 2.6410204081632656e-05,
      "loss": 0.0523,
      "step": 12060
    },
    {
      "epoch": 4.828,
      "grad_norm": 0.6853489279747009,
      "learning_rate": 2.638979591836735e-05,
      "loss": 0.0569,
      "step": 12070
    },
    {
      "epoch": 4.832,
      "grad_norm": 0.37639808654785156,
      "learning_rate": 2.6369387755102042e-05,
      "loss": 0.071,
      "step": 12080
    },
    {
      "epoch": 4.836,
      "grad_norm": 0.027153698727488518,
      "learning_rate": 2.6348979591836737e-05,
      "loss": 0.061,
      "step": 12090
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.8067848682403564,
      "learning_rate": 2.632857142857143e-05,
      "loss": 0.0758,
      "step": 12100
    },
    {
      "epoch": 4.844,
      "grad_norm": 0.5212842226028442,
      "learning_rate": 2.6308163265306124e-05,
      "loss": 0.0667,
      "step": 12110
    },
    {
      "epoch": 4.848,
      "grad_norm": 0.6062985062599182,
      "learning_rate": 2.628775510204082e-05,
      "loss": 0.1143,
      "step": 12120
    },
    {
      "epoch": 4.852,
      "grad_norm": 1.062430500984192,
      "learning_rate": 2.626734693877551e-05,
      "loss": 0.0667,
      "step": 12130
    },
    {
      "epoch": 4.856,
      "grad_norm": 1.380776286125183,
      "learning_rate": 2.6246938775510205e-05,
      "loss": 0.0801,
      "step": 12140
    },
    {
      "epoch": 4.86,
      "grad_norm": 1.3050870895385742,
      "learning_rate": 2.6226530612244897e-05,
      "loss": 0.0935,
      "step": 12150
    },
    {
      "epoch": 4.864,
      "grad_norm": 0.08487647026777267,
      "learning_rate": 2.6206122448979592e-05,
      "loss": 0.1042,
      "step": 12160
    },
    {
      "epoch": 4.868,
      "grad_norm": 0.7191552519798279,
      "learning_rate": 2.6185714285714287e-05,
      "loss": 0.0997,
      "step": 12170
    },
    {
      "epoch": 4.872,
      "grad_norm": 0.08253287523984909,
      "learning_rate": 2.6165306122448978e-05,
      "loss": 0.0467,
      "step": 12180
    },
    {
      "epoch": 4.876,
      "grad_norm": 0.802207350730896,
      "learning_rate": 2.6144897959183673e-05,
      "loss": 0.051,
      "step": 12190
    },
    {
      "epoch": 4.88,
      "grad_norm": 1.3883074522018433,
      "learning_rate": 2.6124489795918368e-05,
      "loss": 0.1028,
      "step": 12200
    },
    {
      "epoch": 4.884,
      "grad_norm": 0.1806328296661377,
      "learning_rate": 2.610408163265306e-05,
      "loss": 0.0746,
      "step": 12210
    },
    {
      "epoch": 4.888,
      "grad_norm": 0.4635293185710907,
      "learning_rate": 2.6083673469387755e-05,
      "loss": 0.0847,
      "step": 12220
    },
    {
      "epoch": 4.892,
      "grad_norm": 0.3570343255996704,
      "learning_rate": 2.6063265306122453e-05,
      "loss": 0.0867,
      "step": 12230
    },
    {
      "epoch": 4.896,
      "grad_norm": 1.6722371578216553,
      "learning_rate": 2.6042857142857148e-05,
      "loss": 0.1017,
      "step": 12240
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.2181110382080078,
      "learning_rate": 2.602244897959184e-05,
      "loss": 0.1214,
      "step": 12250
    },
    {
      "epoch": 4.904,
      "grad_norm": 0.1727835088968277,
      "learning_rate": 2.6002040816326535e-05,
      "loss": 0.0707,
      "step": 12260
    },
    {
      "epoch": 4.908,
      "grad_norm": 0.9825887680053711,
      "learning_rate": 2.5981632653061226e-05,
      "loss": 0.1121,
      "step": 12270
    },
    {
      "epoch": 4.912,
      "grad_norm": 0.46334221959114075,
      "learning_rate": 2.596122448979592e-05,
      "loss": 0.1095,
      "step": 12280
    },
    {
      "epoch": 4.916,
      "grad_norm": 0.475780725479126,
      "learning_rate": 2.5940816326530616e-05,
      "loss": 0.0308,
      "step": 12290
    },
    {
      "epoch": 4.92,
      "grad_norm": 1.2035155296325684,
      "learning_rate": 2.5920408163265308e-05,
      "loss": 0.0874,
      "step": 12300
    },
    {
      "epoch": 4.924,
      "grad_norm": 0.7948132753372192,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 0.0645,
      "step": 12310
    },
    {
      "epoch": 4.928,
      "grad_norm": 1.2551791667938232,
      "learning_rate": 2.5879591836734694e-05,
      "loss": 0.0898,
      "step": 12320
    },
    {
      "epoch": 4.932,
      "grad_norm": 1.6096354722976685,
      "learning_rate": 2.585918367346939e-05,
      "loss": 0.0646,
      "step": 12330
    },
    {
      "epoch": 4.936,
      "grad_norm": 2.442746162414551,
      "learning_rate": 2.5838775510204084e-05,
      "loss": 0.0874,
      "step": 12340
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 0.5277868509292603,
      "learning_rate": 2.5818367346938776e-05,
      "loss": 0.1564,
      "step": 12350
    },
    {
      "epoch": 4.944,
      "grad_norm": 1.2785183191299438,
      "learning_rate": 2.579795918367347e-05,
      "loss": 0.1449,
      "step": 12360
    },
    {
      "epoch": 4.948,
      "grad_norm": 0.7747678160667419,
      "learning_rate": 2.5777551020408162e-05,
      "loss": 0.0515,
      "step": 12370
    },
    {
      "epoch": 4.952,
      "grad_norm": 1.2066055536270142,
      "learning_rate": 2.5757142857142857e-05,
      "loss": 0.078,
      "step": 12380
    },
    {
      "epoch": 4.9559999999999995,
      "grad_norm": 0.0253286249935627,
      "learning_rate": 2.5736734693877552e-05,
      "loss": 0.0629,
      "step": 12390
    },
    {
      "epoch": 4.96,
      "grad_norm": 1.2927864789962769,
      "learning_rate": 2.5716326530612244e-05,
      "loss": 0.0897,
      "step": 12400
    },
    {
      "epoch": 4.964,
      "grad_norm": 0.6157477498054504,
      "learning_rate": 2.569591836734694e-05,
      "loss": 0.0953,
      "step": 12410
    },
    {
      "epoch": 4.968,
      "grad_norm": 1.736196517944336,
      "learning_rate": 2.567551020408163e-05,
      "loss": 0.1412,
      "step": 12420
    },
    {
      "epoch": 4.9719999999999995,
      "grad_norm": 1.9938331842422485,
      "learning_rate": 2.5655102040816325e-05,
      "loss": 0.1268,
      "step": 12430
    },
    {
      "epoch": 4.976,
      "grad_norm": 0.29272469878196716,
      "learning_rate": 2.563469387755102e-05,
      "loss": 0.0492,
      "step": 12440
    },
    {
      "epoch": 4.98,
      "grad_norm": 0.29286617040634155,
      "learning_rate": 2.5614285714285712e-05,
      "loss": 0.0348,
      "step": 12450
    },
    {
      "epoch": 4.984,
      "grad_norm": 1.4202991724014282,
      "learning_rate": 2.559387755102041e-05,
      "loss": 0.0826,
      "step": 12460
    },
    {
      "epoch": 4.9879999999999995,
      "grad_norm": 1.2801871299743652,
      "learning_rate": 2.5573469387755105e-05,
      "loss": 0.0964,
      "step": 12470
    },
    {
      "epoch": 4.992,
      "grad_norm": 0.9185558557510376,
      "learning_rate": 2.55530612244898e-05,
      "loss": 0.0845,
      "step": 12480
    },
    {
      "epoch": 4.996,
      "grad_norm": 2.154778003692627,
      "learning_rate": 2.5532653061224492e-05,
      "loss": 0.1019,
      "step": 12490
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.3413829803466797,
      "learning_rate": 2.5512244897959187e-05,
      "loss": 0.0635,
      "step": 12500
    },
    {
      "epoch": 5.004,
      "grad_norm": 1.1096510887145996,
      "learning_rate": 2.5491836734693882e-05,
      "loss": 0.0854,
      "step": 12510
    },
    {
      "epoch": 5.008,
      "grad_norm": 1.182828664779663,
      "learning_rate": 2.5471428571428573e-05,
      "loss": 0.0696,
      "step": 12520
    },
    {
      "epoch": 5.012,
      "grad_norm": 0.27849477529525757,
      "learning_rate": 2.545102040816327e-05,
      "loss": 0.0713,
      "step": 12530
    },
    {
      "epoch": 5.016,
      "grad_norm": 0.8577656745910645,
      "learning_rate": 2.543061224489796e-05,
      "loss": 0.0624,
      "step": 12540
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.2601470649242401,
      "learning_rate": 2.5410204081632655e-05,
      "loss": 0.0579,
      "step": 12550
    },
    {
      "epoch": 5.024,
      "grad_norm": 1.1034833192825317,
      "learning_rate": 2.538979591836735e-05,
      "loss": 0.0841,
      "step": 12560
    },
    {
      "epoch": 5.028,
      "grad_norm": 0.026197204366326332,
      "learning_rate": 2.536938775510204e-05,
      "loss": 0.0662,
      "step": 12570
    },
    {
      "epoch": 5.032,
      "grad_norm": 1.1789002418518066,
      "learning_rate": 2.5348979591836736e-05,
      "loss": 0.0909,
      "step": 12580
    },
    {
      "epoch": 5.036,
      "grad_norm": 0.24950318038463593,
      "learning_rate": 2.5328571428571428e-05,
      "loss": 0.0531,
      "step": 12590
    },
    {
      "epoch": 5.04,
      "grad_norm": 0.08435399830341339,
      "learning_rate": 2.5308163265306123e-05,
      "loss": 0.0907,
      "step": 12600
    },
    {
      "epoch": 5.044,
      "grad_norm": 1.2285425662994385,
      "learning_rate": 2.5287755102040818e-05,
      "loss": 0.0876,
      "step": 12610
    },
    {
      "epoch": 5.048,
      "grad_norm": 1.6098958253860474,
      "learning_rate": 2.526734693877551e-05,
      "loss": 0.1228,
      "step": 12620
    },
    {
      "epoch": 5.052,
      "grad_norm": 0.626900315284729,
      "learning_rate": 2.5246938775510205e-05,
      "loss": 0.0989,
      "step": 12630
    },
    {
      "epoch": 5.056,
      "grad_norm": 0.3963848054409027,
      "learning_rate": 2.5226530612244896e-05,
      "loss": 0.04,
      "step": 12640
    },
    {
      "epoch": 5.06,
      "grad_norm": 0.9261982440948486,
      "learning_rate": 2.520612244897959e-05,
      "loss": 0.0611,
      "step": 12650
    },
    {
      "epoch": 5.064,
      "grad_norm": 0.3792131245136261,
      "learning_rate": 2.5185714285714286e-05,
      "loss": 0.0477,
      "step": 12660
    },
    {
      "epoch": 5.068,
      "grad_norm": 1.5303906202316284,
      "learning_rate": 2.5165306122448978e-05,
      "loss": 0.1016,
      "step": 12670
    },
    {
      "epoch": 5.072,
      "grad_norm": 1.1862238645553589,
      "learning_rate": 2.5144897959183673e-05,
      "loss": 0.0643,
      "step": 12680
    },
    {
      "epoch": 5.076,
      "grad_norm": 0.7532921433448792,
      "learning_rate": 2.512448979591837e-05,
      "loss": 0.0672,
      "step": 12690
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.19231081008911133,
      "learning_rate": 2.5104081632653066e-05,
      "loss": 0.0455,
      "step": 12700
    },
    {
      "epoch": 5.084,
      "grad_norm": 1.4136093854904175,
      "learning_rate": 2.5083673469387758e-05,
      "loss": 0.0907,
      "step": 12710
    },
    {
      "epoch": 5.088,
      "grad_norm": 2.096684455871582,
      "learning_rate": 2.5063265306122453e-05,
      "loss": 0.1557,
      "step": 12720
    },
    {
      "epoch": 5.092,
      "grad_norm": 1.329911231994629,
      "learning_rate": 2.5042857142857144e-05,
      "loss": 0.046,
      "step": 12730
    },
    {
      "epoch": 5.096,
      "grad_norm": 0.09543982893228531,
      "learning_rate": 2.502244897959184e-05,
      "loss": 0.052,
      "step": 12740
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.8790479302406311,
      "learning_rate": 2.5002040816326534e-05,
      "loss": 0.0544,
      "step": 12750
    },
    {
      "epoch": 5.104,
      "grad_norm": 0.17144162952899933,
      "learning_rate": 2.4981632653061226e-05,
      "loss": 0.0637,
      "step": 12760
    },
    {
      "epoch": 5.108,
      "grad_norm": 1.505780816078186,
      "learning_rate": 2.496122448979592e-05,
      "loss": 0.0729,
      "step": 12770
    },
    {
      "epoch": 5.112,
      "grad_norm": 0.4581427574157715,
      "learning_rate": 2.4940816326530612e-05,
      "loss": 0.0505,
      "step": 12780
    },
    {
      "epoch": 5.116,
      "grad_norm": 1.6658202409744263,
      "learning_rate": 2.4920408163265307e-05,
      "loss": 0.0951,
      "step": 12790
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.7261630892753601,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 0.1128,
      "step": 12800
    },
    {
      "epoch": 5.124,
      "grad_norm": 0.5377570986747742,
      "learning_rate": 2.4879591836734694e-05,
      "loss": 0.0517,
      "step": 12810
    },
    {
      "epoch": 5.128,
      "grad_norm": 0.5378736853599548,
      "learning_rate": 2.485918367346939e-05,
      "loss": 0.0656,
      "step": 12820
    },
    {
      "epoch": 5.132,
      "grad_norm": 0.8476403951644897,
      "learning_rate": 2.4838775510204084e-05,
      "loss": 0.0495,
      "step": 12830
    },
    {
      "epoch": 5.136,
      "grad_norm": 1.6199448108673096,
      "learning_rate": 2.4818367346938775e-05,
      "loss": 0.1328,
      "step": 12840
    },
    {
      "epoch": 5.14,
      "grad_norm": 0.8939533233642578,
      "learning_rate": 2.479795918367347e-05,
      "loss": 0.0815,
      "step": 12850
    },
    {
      "epoch": 5.144,
      "grad_norm": 0.8746981024742126,
      "learning_rate": 2.4777551020408165e-05,
      "loss": 0.0813,
      "step": 12860
    },
    {
      "epoch": 5.148,
      "grad_norm": 1.3994688987731934,
      "learning_rate": 2.475714285714286e-05,
      "loss": 0.053,
      "step": 12870
    },
    {
      "epoch": 5.152,
      "grad_norm": 0.6735461354255676,
      "learning_rate": 2.4736734693877552e-05,
      "loss": 0.065,
      "step": 12880
    },
    {
      "epoch": 5.156,
      "grad_norm": 1.0259629487991333,
      "learning_rate": 2.4716326530612247e-05,
      "loss": 0.0807,
      "step": 12890
    },
    {
      "epoch": 5.16,
      "grad_norm": 0.16370418667793274,
      "learning_rate": 2.4695918367346942e-05,
      "loss": 0.0798,
      "step": 12900
    },
    {
      "epoch": 5.164,
      "grad_norm": 0.43477705121040344,
      "learning_rate": 2.4675510204081633e-05,
      "loss": 0.0691,
      "step": 12910
    },
    {
      "epoch": 5.168,
      "grad_norm": 1.12813401222229,
      "learning_rate": 2.4655102040816328e-05,
      "loss": 0.0728,
      "step": 12920
    },
    {
      "epoch": 5.172,
      "grad_norm": 0.9970506429672241,
      "learning_rate": 2.463469387755102e-05,
      "loss": 0.0515,
      "step": 12930
    },
    {
      "epoch": 5.176,
      "grad_norm": 0.39779284596443176,
      "learning_rate": 2.4614285714285715e-05,
      "loss": 0.0399,
      "step": 12940
    },
    {
      "epoch": 5.18,
      "grad_norm": 0.30443063378334045,
      "learning_rate": 2.459387755102041e-05,
      "loss": 0.0746,
      "step": 12950
    },
    {
      "epoch": 5.184,
      "grad_norm": 1.888221025466919,
      "learning_rate": 2.45734693877551e-05,
      "loss": 0.0836,
      "step": 12960
    },
    {
      "epoch": 5.188,
      "grad_norm": 1.60891854763031,
      "learning_rate": 2.45530612244898e-05,
      "loss": 0.0752,
      "step": 12970
    },
    {
      "epoch": 5.192,
      "grad_norm": 1.4410016536712646,
      "learning_rate": 2.453265306122449e-05,
      "loss": 0.0644,
      "step": 12980
    },
    {
      "epoch": 5.196,
      "grad_norm": 0.9081825613975525,
      "learning_rate": 2.4512244897959186e-05,
      "loss": 0.0847,
      "step": 12990
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.3934813439846039,
      "learning_rate": 2.4491836734693878e-05,
      "loss": 0.0417,
      "step": 13000
    },
    {
      "epoch": 5.204,
      "grad_norm": 0.9266319870948792,
      "learning_rate": 2.4471428571428573e-05,
      "loss": 0.0697,
      "step": 13010
    },
    {
      "epoch": 5.208,
      "grad_norm": 1.4946471452713013,
      "learning_rate": 2.4451020408163268e-05,
      "loss": 0.0859,
      "step": 13020
    },
    {
      "epoch": 5.212,
      "grad_norm": 0.8525747060775757,
      "learning_rate": 2.443061224489796e-05,
      "loss": 0.0786,
      "step": 13030
    },
    {
      "epoch": 5.216,
      "grad_norm": 0.5361803770065308,
      "learning_rate": 2.4410204081632654e-05,
      "loss": 0.1058,
      "step": 13040
    },
    {
      "epoch": 5.22,
      "grad_norm": 1.1675586700439453,
      "learning_rate": 2.4389795918367346e-05,
      "loss": 0.0815,
      "step": 13050
    },
    {
      "epoch": 5.224,
      "grad_norm": 1.2198472023010254,
      "learning_rate": 2.436938775510204e-05,
      "loss": 0.0655,
      "step": 13060
    },
    {
      "epoch": 5.228,
      "grad_norm": 1.238275408744812,
      "learning_rate": 2.4348979591836736e-05,
      "loss": 0.0624,
      "step": 13070
    },
    {
      "epoch": 5.232,
      "grad_norm": 1.1828218698501587,
      "learning_rate": 2.432857142857143e-05,
      "loss": 0.0818,
      "step": 13080
    },
    {
      "epoch": 5.236,
      "grad_norm": 1.0887371301651,
      "learning_rate": 2.4308163265306126e-05,
      "loss": 0.0664,
      "step": 13090
    },
    {
      "epoch": 5.24,
      "grad_norm": 1.2172783613204956,
      "learning_rate": 2.4287755102040817e-05,
      "loss": 0.098,
      "step": 13100
    },
    {
      "epoch": 5.244,
      "grad_norm": 0.7202033996582031,
      "learning_rate": 2.4267346938775512e-05,
      "loss": 0.0661,
      "step": 13110
    },
    {
      "epoch": 5.248,
      "grad_norm": 0.169624462723732,
      "learning_rate": 2.4246938775510204e-05,
      "loss": 0.0796,
      "step": 13120
    },
    {
      "epoch": 5.252,
      "grad_norm": 0.4635012149810791,
      "learning_rate": 2.42265306122449e-05,
      "loss": 0.0632,
      "step": 13130
    },
    {
      "epoch": 5.256,
      "grad_norm": 0.8362759947776794,
      "learning_rate": 2.4206122448979594e-05,
      "loss": 0.0395,
      "step": 13140
    },
    {
      "epoch": 5.26,
      "grad_norm": 0.03956606239080429,
      "learning_rate": 2.4185714285714286e-05,
      "loss": 0.0976,
      "step": 13150
    },
    {
      "epoch": 5.264,
      "grad_norm": 0.9722302556037903,
      "learning_rate": 2.416530612244898e-05,
      "loss": 0.0752,
      "step": 13160
    },
    {
      "epoch": 5.268,
      "grad_norm": 0.8247765302658081,
      "learning_rate": 2.4144897959183675e-05,
      "loss": 0.0692,
      "step": 13170
    },
    {
      "epoch": 5.272,
      "grad_norm": 0.2223081886768341,
      "learning_rate": 2.4124489795918367e-05,
      "loss": 0.1124,
      "step": 13180
    },
    {
      "epoch": 5.276,
      "grad_norm": 0.3230349123477936,
      "learning_rate": 2.4104081632653062e-05,
      "loss": 0.0893,
      "step": 13190
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.5127138495445251,
      "learning_rate": 2.4083673469387757e-05,
      "loss": 0.0808,
      "step": 13200
    },
    {
      "epoch": 5.284,
      "grad_norm": 1.7326902151107788,
      "learning_rate": 2.4063265306122452e-05,
      "loss": 0.1007,
      "step": 13210
    },
    {
      "epoch": 5.288,
      "grad_norm": 1.9781558513641357,
      "learning_rate": 2.4042857142857144e-05,
      "loss": 0.0773,
      "step": 13220
    },
    {
      "epoch": 5.292,
      "grad_norm": 1.2433171272277832,
      "learning_rate": 2.402244897959184e-05,
      "loss": 0.107,
      "step": 13230
    },
    {
      "epoch": 5.296,
      "grad_norm": 0.3040829598903656,
      "learning_rate": 2.4002040816326533e-05,
      "loss": 0.0427,
      "step": 13240
    },
    {
      "epoch": 5.3,
      "grad_norm": 1.3936411142349243,
      "learning_rate": 2.3981632653061225e-05,
      "loss": 0.0865,
      "step": 13250
    },
    {
      "epoch": 5.304,
      "grad_norm": 0.3223479688167572,
      "learning_rate": 2.396122448979592e-05,
      "loss": 0.0354,
      "step": 13260
    },
    {
      "epoch": 5.308,
      "grad_norm": 0.9476471543312073,
      "learning_rate": 2.394081632653061e-05,
      "loss": 0.0688,
      "step": 13270
    },
    {
      "epoch": 5.312,
      "grad_norm": 0.22407779097557068,
      "learning_rate": 2.3920408163265307e-05,
      "loss": 0.0782,
      "step": 13280
    },
    {
      "epoch": 5.316,
      "grad_norm": 0.32519808411598206,
      "learning_rate": 2.39e-05,
      "loss": 0.0736,
      "step": 13290
    },
    {
      "epoch": 5.32,
      "grad_norm": 1.739087462425232,
      "learning_rate": 2.3879591836734693e-05,
      "loss": 0.0925,
      "step": 13300
    },
    {
      "epoch": 5.324,
      "grad_norm": 1.1638693809509277,
      "learning_rate": 2.385918367346939e-05,
      "loss": 0.0694,
      "step": 13310
    },
    {
      "epoch": 5.328,
      "grad_norm": 0.3201720714569092,
      "learning_rate": 2.3838775510204083e-05,
      "loss": 0.0858,
      "step": 13320
    },
    {
      "epoch": 5.332,
      "grad_norm": 0.8040814995765686,
      "learning_rate": 2.3818367346938778e-05,
      "loss": 0.098,
      "step": 13330
    },
    {
      "epoch": 5.336,
      "grad_norm": 0.474247545003891,
      "learning_rate": 2.379795918367347e-05,
      "loss": 0.0526,
      "step": 13340
    },
    {
      "epoch": 5.34,
      "grad_norm": 0.7827216386795044,
      "learning_rate": 2.3777551020408165e-05,
      "loss": 0.0868,
      "step": 13350
    },
    {
      "epoch": 5.344,
      "grad_norm": 2.3787214756011963,
      "learning_rate": 2.375714285714286e-05,
      "loss": 0.1259,
      "step": 13360
    },
    {
      "epoch": 5.348,
      "grad_norm": 2.0034353733062744,
      "learning_rate": 2.373673469387755e-05,
      "loss": 0.0519,
      "step": 13370
    },
    {
      "epoch": 5.352,
      "grad_norm": 0.5009838342666626,
      "learning_rate": 2.3716326530612246e-05,
      "loss": 0.0641,
      "step": 13380
    },
    {
      "epoch": 5.356,
      "grad_norm": 0.20480287075042725,
      "learning_rate": 2.3695918367346938e-05,
      "loss": 0.1198,
      "step": 13390
    },
    {
      "epoch": 5.36,
      "grad_norm": 1.1618388891220093,
      "learning_rate": 2.3675510204081633e-05,
      "loss": 0.0563,
      "step": 13400
    },
    {
      "epoch": 5.364,
      "grad_norm": 1.0033053159713745,
      "learning_rate": 2.3655102040816328e-05,
      "loss": 0.0965,
      "step": 13410
    },
    {
      "epoch": 5.368,
      "grad_norm": 0.5065154433250427,
      "learning_rate": 2.363469387755102e-05,
      "loss": 0.0802,
      "step": 13420
    },
    {
      "epoch": 5.372,
      "grad_norm": 1.4400477409362793,
      "learning_rate": 2.3614285714285718e-05,
      "loss": 0.0997,
      "step": 13430
    },
    {
      "epoch": 5.376,
      "grad_norm": 0.17171432077884674,
      "learning_rate": 2.359387755102041e-05,
      "loss": 0.0895,
      "step": 13440
    },
    {
      "epoch": 5.38,
      "grad_norm": 1.1214851140975952,
      "learning_rate": 2.3573469387755104e-05,
      "loss": 0.0764,
      "step": 13450
    },
    {
      "epoch": 5.384,
      "grad_norm": 0.30805179476737976,
      "learning_rate": 2.35530612244898e-05,
      "loss": 0.0745,
      "step": 13460
    },
    {
      "epoch": 5.388,
      "grad_norm": 0.9629544615745544,
      "learning_rate": 2.353265306122449e-05,
      "loss": 0.0846,
      "step": 13470
    },
    {
      "epoch": 5.392,
      "grad_norm": 1.2240248918533325,
      "learning_rate": 2.3512244897959186e-05,
      "loss": 0.0516,
      "step": 13480
    },
    {
      "epoch": 5.396,
      "grad_norm": 0.6216139793395996,
      "learning_rate": 2.3491836734693877e-05,
      "loss": 0.0683,
      "step": 13490
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.5461960434913635,
      "learning_rate": 2.3471428571428572e-05,
      "loss": 0.1076,
      "step": 13500
    },
    {
      "epoch": 5.404,
      "grad_norm": 0.05075546354055405,
      "learning_rate": 2.3451020408163267e-05,
      "loss": 0.0859,
      "step": 13510
    },
    {
      "epoch": 5.408,
      "grad_norm": 1.2805848121643066,
      "learning_rate": 2.343061224489796e-05,
      "loss": 0.0989,
      "step": 13520
    },
    {
      "epoch": 5.412,
      "grad_norm": 0.5510507822036743,
      "learning_rate": 2.3410204081632654e-05,
      "loss": 0.0726,
      "step": 13530
    },
    {
      "epoch": 5.416,
      "grad_norm": 0.2879861891269684,
      "learning_rate": 2.338979591836735e-05,
      "loss": 0.0439,
      "step": 13540
    },
    {
      "epoch": 5.42,
      "grad_norm": 0.34459877014160156,
      "learning_rate": 2.3369387755102044e-05,
      "loss": 0.0514,
      "step": 13550
    },
    {
      "epoch": 5.424,
      "grad_norm": 0.088059201836586,
      "learning_rate": 2.3348979591836735e-05,
      "loss": 0.0448,
      "step": 13560
    },
    {
      "epoch": 5.428,
      "grad_norm": 1.6784112453460693,
      "learning_rate": 2.332857142857143e-05,
      "loss": 0.0488,
      "step": 13570
    },
    {
      "epoch": 5.432,
      "grad_norm": 1.4443976879119873,
      "learning_rate": 2.3308163265306125e-05,
      "loss": 0.0776,
      "step": 13580
    },
    {
      "epoch": 5.436,
      "grad_norm": 1.2302155494689941,
      "learning_rate": 2.3287755102040817e-05,
      "loss": 0.085,
      "step": 13590
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.574752688407898,
      "learning_rate": 2.3267346938775512e-05,
      "loss": 0.1339,
      "step": 13600
    },
    {
      "epoch": 5.444,
      "grad_norm": 0.6513800024986267,
      "learning_rate": 2.3246938775510203e-05,
      "loss": 0.074,
      "step": 13610
    },
    {
      "epoch": 5.448,
      "grad_norm": 0.322593629360199,
      "learning_rate": 2.32265306122449e-05,
      "loss": 0.0623,
      "step": 13620
    },
    {
      "epoch": 5.452,
      "grad_norm": 1.3023443222045898,
      "learning_rate": 2.3206122448979593e-05,
      "loss": 0.1081,
      "step": 13630
    },
    {
      "epoch": 5.456,
      "grad_norm": 0.20980297029018402,
      "learning_rate": 2.3185714285714285e-05,
      "loss": 0.0474,
      "step": 13640
    },
    {
      "epoch": 5.46,
      "grad_norm": 0.3606547713279724,
      "learning_rate": 2.3165306122448983e-05,
      "loss": 0.0437,
      "step": 13650
    },
    {
      "epoch": 5.464,
      "grad_norm": 0.2478078156709671,
      "learning_rate": 2.3144897959183675e-05,
      "loss": 0.0706,
      "step": 13660
    },
    {
      "epoch": 5.468,
      "grad_norm": 0.6515759825706482,
      "learning_rate": 2.312448979591837e-05,
      "loss": 0.1123,
      "step": 13670
    },
    {
      "epoch": 5.4719999999999995,
      "grad_norm": 0.6224873065948486,
      "learning_rate": 2.310408163265306e-05,
      "loss": 0.0546,
      "step": 13680
    },
    {
      "epoch": 5.476,
      "grad_norm": 1.2061777114868164,
      "learning_rate": 2.3083673469387756e-05,
      "loss": 0.0853,
      "step": 13690
    },
    {
      "epoch": 5.48,
      "grad_norm": 0.8971431255340576,
      "learning_rate": 2.306326530612245e-05,
      "loss": 0.0634,
      "step": 13700
    },
    {
      "epoch": 5.484,
      "grad_norm": 0.5313040614128113,
      "learning_rate": 2.3042857142857143e-05,
      "loss": 0.0595,
      "step": 13710
    },
    {
      "epoch": 5.4879999999999995,
      "grad_norm": 1.1702896356582642,
      "learning_rate": 2.3022448979591838e-05,
      "loss": 0.0413,
      "step": 13720
    },
    {
      "epoch": 5.492,
      "grad_norm": 1.2432249784469604,
      "learning_rate": 2.300204081632653e-05,
      "loss": 0.0716,
      "step": 13730
    },
    {
      "epoch": 5.496,
      "grad_norm": 1.2429141998291016,
      "learning_rate": 2.2981632653061224e-05,
      "loss": 0.0738,
      "step": 13740
    },
    {
      "epoch": 5.5,
      "grad_norm": 1.3202043771743774,
      "learning_rate": 2.296122448979592e-05,
      "loss": 0.115,
      "step": 13750
    },
    {
      "epoch": 5.504,
      "grad_norm": 0.9774664640426636,
      "learning_rate": 2.294081632653061e-05,
      "loss": 0.0494,
      "step": 13760
    },
    {
      "epoch": 5.508,
      "grad_norm": 1.0573041439056396,
      "learning_rate": 2.292040816326531e-05,
      "loss": 0.0963,
      "step": 13770
    },
    {
      "epoch": 5.5120000000000005,
      "grad_norm": 1.2080267667770386,
      "learning_rate": 2.29e-05,
      "loss": 0.0852,
      "step": 13780
    },
    {
      "epoch": 5.516,
      "grad_norm": 0.7481449842453003,
      "learning_rate": 2.2879591836734696e-05,
      "loss": 0.0546,
      "step": 13790
    },
    {
      "epoch": 5.52,
      "grad_norm": 0.9845393300056458,
      "learning_rate": 2.285918367346939e-05,
      "loss": 0.0746,
      "step": 13800
    },
    {
      "epoch": 5.524,
      "grad_norm": 0.04393192380666733,
      "learning_rate": 2.2838775510204083e-05,
      "loss": 0.0608,
      "step": 13810
    },
    {
      "epoch": 5.5280000000000005,
      "grad_norm": 0.6931016445159912,
      "learning_rate": 2.2818367346938777e-05,
      "loss": 0.0763,
      "step": 13820
    },
    {
      "epoch": 5.532,
      "grad_norm": 1.259020209312439,
      "learning_rate": 2.279795918367347e-05,
      "loss": 0.0779,
      "step": 13830
    },
    {
      "epoch": 5.536,
      "grad_norm": 0.6791973114013672,
      "learning_rate": 2.2777551020408164e-05,
      "loss": 0.0619,
      "step": 13840
    },
    {
      "epoch": 5.54,
      "grad_norm": 0.2820100486278534,
      "learning_rate": 2.275714285714286e-05,
      "loss": 0.0529,
      "step": 13850
    },
    {
      "epoch": 5.5440000000000005,
      "grad_norm": 0.07511989027261734,
      "learning_rate": 2.273673469387755e-05,
      "loss": 0.0507,
      "step": 13860
    },
    {
      "epoch": 5.548,
      "grad_norm": 0.3535555601119995,
      "learning_rate": 2.2716326530612246e-05,
      "loss": 0.0605,
      "step": 13870
    },
    {
      "epoch": 5.552,
      "grad_norm": 0.8206498622894287,
      "learning_rate": 2.269591836734694e-05,
      "loss": 0.0566,
      "step": 13880
    },
    {
      "epoch": 5.556,
      "grad_norm": 0.2131519913673401,
      "learning_rate": 2.2675510204081636e-05,
      "loss": 0.0718,
      "step": 13890
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 1.5782283544540405,
      "learning_rate": 2.2655102040816327e-05,
      "loss": 0.075,
      "step": 13900
    },
    {
      "epoch": 5.564,
      "grad_norm": 0.5115322470664978,
      "learning_rate": 2.2634693877551022e-05,
      "loss": 0.054,
      "step": 13910
    },
    {
      "epoch": 5.568,
      "grad_norm": 0.5013133883476257,
      "learning_rate": 2.2614285714285717e-05,
      "loss": 0.1195,
      "step": 13920
    },
    {
      "epoch": 5.572,
      "grad_norm": 0.4457007348537445,
      "learning_rate": 2.259387755102041e-05,
      "loss": 0.0477,
      "step": 13930
    },
    {
      "epoch": 5.576,
      "grad_norm": 1.1531847715377808,
      "learning_rate": 2.2573469387755104e-05,
      "loss": 0.0684,
      "step": 13940
    },
    {
      "epoch": 5.58,
      "grad_norm": 0.35010457038879395,
      "learning_rate": 2.2553061224489795e-05,
      "loss": 0.0772,
      "step": 13950
    },
    {
      "epoch": 5.584,
      "grad_norm": 0.7346904277801514,
      "learning_rate": 2.253265306122449e-05,
      "loss": 0.1139,
      "step": 13960
    },
    {
      "epoch": 5.588,
      "grad_norm": 0.47771963477134705,
      "learning_rate": 2.2512244897959185e-05,
      "loss": 0.0672,
      "step": 13970
    },
    {
      "epoch": 5.592,
      "grad_norm": 0.23267439007759094,
      "learning_rate": 2.2491836734693877e-05,
      "loss": 0.0823,
      "step": 13980
    },
    {
      "epoch": 5.596,
      "grad_norm": 0.6879465579986572,
      "learning_rate": 2.2471428571428575e-05,
      "loss": 0.0644,
      "step": 13990
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.336913526058197,
      "learning_rate": 2.2451020408163267e-05,
      "loss": 0.115,
      "step": 14000
    },
    {
      "epoch": 5.604,
      "grad_norm": 0.03433110937476158,
      "learning_rate": 2.243061224489796e-05,
      "loss": 0.0787,
      "step": 14010
    },
    {
      "epoch": 5.608,
      "grad_norm": 1.7821545600891113,
      "learning_rate": 2.2410204081632653e-05,
      "loss": 0.0862,
      "step": 14020
    },
    {
      "epoch": 5.612,
      "grad_norm": 1.0743658542633057,
      "learning_rate": 2.2389795918367348e-05,
      "loss": 0.0562,
      "step": 14030
    },
    {
      "epoch": 5.616,
      "grad_norm": 0.3307858407497406,
      "learning_rate": 2.2369387755102043e-05,
      "loss": 0.074,
      "step": 14040
    },
    {
      "epoch": 5.62,
      "grad_norm": 0.5953844785690308,
      "learning_rate": 2.2348979591836735e-05,
      "loss": 0.0603,
      "step": 14050
    },
    {
      "epoch": 5.624,
      "grad_norm": 1.1321700811386108,
      "learning_rate": 2.232857142857143e-05,
      "loss": 0.1136,
      "step": 14060
    },
    {
      "epoch": 5.628,
      "grad_norm": 1.2853411436080933,
      "learning_rate": 2.230816326530612e-05,
      "loss": 0.0674,
      "step": 14070
    },
    {
      "epoch": 5.632,
      "grad_norm": 0.35587894916534424,
      "learning_rate": 2.2287755102040816e-05,
      "loss": 0.0527,
      "step": 14080
    },
    {
      "epoch": 5.636,
      "grad_norm": 0.6901254653930664,
      "learning_rate": 2.226734693877551e-05,
      "loss": 0.0431,
      "step": 14090
    },
    {
      "epoch": 5.64,
      "grad_norm": 1.6113688945770264,
      "learning_rate": 2.2246938775510203e-05,
      "loss": 0.0634,
      "step": 14100
    },
    {
      "epoch": 5.644,
      "grad_norm": 2.1435091495513916,
      "learning_rate": 2.22265306122449e-05,
      "loss": 0.0986,
      "step": 14110
    },
    {
      "epoch": 5.648,
      "grad_norm": 1.1296898126602173,
      "learning_rate": 2.2206122448979593e-05,
      "loss": 0.0489,
      "step": 14120
    },
    {
      "epoch": 5.652,
      "grad_norm": 0.8166046738624573,
      "learning_rate": 2.2185714285714288e-05,
      "loss": 0.0414,
      "step": 14130
    },
    {
      "epoch": 5.656,
      "grad_norm": 1.7777765989303589,
      "learning_rate": 2.2165306122448983e-05,
      "loss": 0.0787,
      "step": 14140
    },
    {
      "epoch": 5.66,
      "grad_norm": 1.8907840251922607,
      "learning_rate": 2.2144897959183674e-05,
      "loss": 0.0806,
      "step": 14150
    },
    {
      "epoch": 5.664,
      "grad_norm": 1.5632760524749756,
      "learning_rate": 2.212448979591837e-05,
      "loss": 0.1279,
      "step": 14160
    },
    {
      "epoch": 5.668,
      "grad_norm": 0.4654831886291504,
      "learning_rate": 2.210408163265306e-05,
      "loss": 0.0988,
      "step": 14170
    },
    {
      "epoch": 5.672,
      "grad_norm": 0.31557697057724,
      "learning_rate": 2.2083673469387756e-05,
      "loss": 0.0573,
      "step": 14180
    },
    {
      "epoch": 5.676,
      "grad_norm": 0.8508023023605347,
      "learning_rate": 2.206326530612245e-05,
      "loss": 0.1011,
      "step": 14190
    },
    {
      "epoch": 5.68,
      "grad_norm": 0.3341432511806488,
      "learning_rate": 2.2042857142857142e-05,
      "loss": 0.0923,
      "step": 14200
    },
    {
      "epoch": 5.684,
      "grad_norm": 0.7655826210975647,
      "learning_rate": 2.2022448979591837e-05,
      "loss": 0.051,
      "step": 14210
    },
    {
      "epoch": 5.688,
      "grad_norm": 0.009973304346203804,
      "learning_rate": 2.2002040816326532e-05,
      "loss": 0.0847,
      "step": 14220
    },
    {
      "epoch": 5.692,
      "grad_norm": 1.3658185005187988,
      "learning_rate": 2.1981632653061227e-05,
      "loss": 0.0798,
      "step": 14230
    },
    {
      "epoch": 5.696,
      "grad_norm": 0.2629229426383972,
      "learning_rate": 2.196122448979592e-05,
      "loss": 0.086,
      "step": 14240
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.49024614691734314,
      "learning_rate": 2.1940816326530614e-05,
      "loss": 0.0736,
      "step": 14250
    },
    {
      "epoch": 5.704,
      "grad_norm": 0.5234871506690979,
      "learning_rate": 2.192040816326531e-05,
      "loss": 0.0754,
      "step": 14260
    },
    {
      "epoch": 5.708,
      "grad_norm": 0.4763803780078888,
      "learning_rate": 2.19e-05,
      "loss": 0.1213,
      "step": 14270
    },
    {
      "epoch": 5.712,
      "grad_norm": 0.7539423108100891,
      "learning_rate": 2.1879591836734695e-05,
      "loss": 0.1003,
      "step": 14280
    },
    {
      "epoch": 5.716,
      "grad_norm": 1.0033173561096191,
      "learning_rate": 2.1859183673469387e-05,
      "loss": 0.1447,
      "step": 14290
    },
    {
      "epoch": 5.72,
      "grad_norm": 1.668310284614563,
      "learning_rate": 2.1838775510204082e-05,
      "loss": 0.1063,
      "step": 14300
    },
    {
      "epoch": 5.724,
      "grad_norm": 0.8660283088684082,
      "learning_rate": 2.1818367346938777e-05,
      "loss": 0.0605,
      "step": 14310
    },
    {
      "epoch": 5.728,
      "grad_norm": 0.6514356732368469,
      "learning_rate": 2.179795918367347e-05,
      "loss": 0.0786,
      "step": 14320
    },
    {
      "epoch": 5.732,
      "grad_norm": 0.12042085826396942,
      "learning_rate": 2.1777551020408167e-05,
      "loss": 0.0679,
      "step": 14330
    },
    {
      "epoch": 5.736,
      "grad_norm": 1.3227882385253906,
      "learning_rate": 2.175714285714286e-05,
      "loss": 0.1313,
      "step": 14340
    },
    {
      "epoch": 5.74,
      "grad_norm": 0.10474633425474167,
      "learning_rate": 2.1736734693877553e-05,
      "loss": 0.0902,
      "step": 14350
    },
    {
      "epoch": 5.744,
      "grad_norm": 1.6006098985671997,
      "learning_rate": 2.1716326530612245e-05,
      "loss": 0.1022,
      "step": 14360
    },
    {
      "epoch": 5.748,
      "grad_norm": 0.3483678698539734,
      "learning_rate": 2.169591836734694e-05,
      "loss": 0.046,
      "step": 14370
    },
    {
      "epoch": 5.752,
      "grad_norm": 1.0972483158111572,
      "learning_rate": 2.1675510204081635e-05,
      "loss": 0.0629,
      "step": 14380
    },
    {
      "epoch": 5.756,
      "grad_norm": 0.041651349514722824,
      "learning_rate": 2.1655102040816326e-05,
      "loss": 0.0753,
      "step": 14390
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.27240586280822754,
      "learning_rate": 2.163469387755102e-05,
      "loss": 0.1169,
      "step": 14400
    },
    {
      "epoch": 5.764,
      "grad_norm": 0.35067397356033325,
      "learning_rate": 2.1614285714285713e-05,
      "loss": 0.0773,
      "step": 14410
    },
    {
      "epoch": 5.768,
      "grad_norm": 0.2708209455013275,
      "learning_rate": 2.1593877551020408e-05,
      "loss": 0.0825,
      "step": 14420
    },
    {
      "epoch": 5.772,
      "grad_norm": 0.4398573040962219,
      "learning_rate": 2.1573469387755103e-05,
      "loss": 0.0935,
      "step": 14430
    },
    {
      "epoch": 5.776,
      "grad_norm": 0.6282364726066589,
      "learning_rate": 2.1553061224489795e-05,
      "loss": 0.0909,
      "step": 14440
    },
    {
      "epoch": 5.78,
      "grad_norm": 1.6796536445617676,
      "learning_rate": 2.1532653061224493e-05,
      "loss": 0.0583,
      "step": 14450
    },
    {
      "epoch": 5.784,
      "grad_norm": 0.7919293642044067,
      "learning_rate": 2.1512244897959185e-05,
      "loss": 0.0749,
      "step": 14460
    },
    {
      "epoch": 5.788,
      "grad_norm": 1.6774355173110962,
      "learning_rate": 2.149183673469388e-05,
      "loss": 0.0423,
      "step": 14470
    },
    {
      "epoch": 5.792,
      "grad_norm": 0.1050020083785057,
      "learning_rate": 2.1471428571428574e-05,
      "loss": 0.0566,
      "step": 14480
    },
    {
      "epoch": 5.796,
      "grad_norm": 0.580906867980957,
      "learning_rate": 2.1451020408163266e-05,
      "loss": 0.0669,
      "step": 14490
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.6027015447616577,
      "learning_rate": 2.143061224489796e-05,
      "loss": 0.0492,
      "step": 14500
    },
    {
      "epoch": 5.804,
      "grad_norm": 0.7112531065940857,
      "learning_rate": 2.1410204081632653e-05,
      "loss": 0.0938,
      "step": 14510
    },
    {
      "epoch": 5.808,
      "grad_norm": 0.06624175608158112,
      "learning_rate": 2.1389795918367348e-05,
      "loss": 0.0576,
      "step": 14520
    },
    {
      "epoch": 5.812,
      "grad_norm": 1.6051318645477295,
      "learning_rate": 2.1369387755102043e-05,
      "loss": 0.0655,
      "step": 14530
    },
    {
      "epoch": 5.816,
      "grad_norm": 1.8035613298416138,
      "learning_rate": 2.1348979591836734e-05,
      "loss": 0.0755,
      "step": 14540
    },
    {
      "epoch": 5.82,
      "grad_norm": 1.6120545864105225,
      "learning_rate": 2.132857142857143e-05,
      "loss": 0.0776,
      "step": 14550
    },
    {
      "epoch": 5.824,
      "grad_norm": 0.29541197419166565,
      "learning_rate": 2.1308163265306124e-05,
      "loss": 0.0198,
      "step": 14560
    },
    {
      "epoch": 5.828,
      "grad_norm": 0.9442601203918457,
      "learning_rate": 2.128775510204082e-05,
      "loss": 0.0758,
      "step": 14570
    },
    {
      "epoch": 5.832,
      "grad_norm": 0.02488035522401333,
      "learning_rate": 2.126734693877551e-05,
      "loss": 0.0621,
      "step": 14580
    },
    {
      "epoch": 5.836,
      "grad_norm": 0.010470445267856121,
      "learning_rate": 2.1246938775510206e-05,
      "loss": 0.0491,
      "step": 14590
    },
    {
      "epoch": 5.84,
      "grad_norm": 1.802884817123413,
      "learning_rate": 2.12265306122449e-05,
      "loss": 0.0895,
      "step": 14600
    },
    {
      "epoch": 5.844,
      "grad_norm": 1.1450804471969604,
      "learning_rate": 2.1206122448979592e-05,
      "loss": 0.0516,
      "step": 14610
    },
    {
      "epoch": 5.848,
      "grad_norm": 1.0000454187393188,
      "learning_rate": 2.1185714285714287e-05,
      "loss": 0.0954,
      "step": 14620
    },
    {
      "epoch": 5.852,
      "grad_norm": 0.025964198634028435,
      "learning_rate": 2.116530612244898e-05,
      "loss": 0.096,
      "step": 14630
    },
    {
      "epoch": 5.856,
      "grad_norm": 0.015089872293174267,
      "learning_rate": 2.1144897959183674e-05,
      "loss": 0.0417,
      "step": 14640
    },
    {
      "epoch": 5.86,
      "grad_norm": 0.8333842158317566,
      "learning_rate": 2.112448979591837e-05,
      "loss": 0.0438,
      "step": 14650
    },
    {
      "epoch": 5.864,
      "grad_norm": 1.9580432176589966,
      "learning_rate": 2.110408163265306e-05,
      "loss": 0.0883,
      "step": 14660
    },
    {
      "epoch": 5.868,
      "grad_norm": 0.2218472957611084,
      "learning_rate": 2.108367346938776e-05,
      "loss": 0.0605,
      "step": 14670
    },
    {
      "epoch": 5.872,
      "grad_norm": 1.0996816158294678,
      "learning_rate": 2.106326530612245e-05,
      "loss": 0.0828,
      "step": 14680
    },
    {
      "epoch": 5.876,
      "grad_norm": 0.33379170298576355,
      "learning_rate": 2.1042857142857145e-05,
      "loss": 0.0872,
      "step": 14690
    },
    {
      "epoch": 5.88,
      "grad_norm": 0.23966732621192932,
      "learning_rate": 2.1022448979591837e-05,
      "loss": 0.0689,
      "step": 14700
    },
    {
      "epoch": 5.884,
      "grad_norm": 0.7514361143112183,
      "learning_rate": 2.1002040816326532e-05,
      "loss": 0.1334,
      "step": 14710
    },
    {
      "epoch": 5.888,
      "grad_norm": 1.5690802335739136,
      "learning_rate": 2.0981632653061227e-05,
      "loss": 0.0565,
      "step": 14720
    },
    {
      "epoch": 5.892,
      "grad_norm": 0.6263271570205688,
      "learning_rate": 2.0961224489795918e-05,
      "loss": 0.0702,
      "step": 14730
    },
    {
      "epoch": 5.896,
      "grad_norm": 0.9003996849060059,
      "learning_rate": 2.0940816326530613e-05,
      "loss": 0.0475,
      "step": 14740
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.812785267829895,
      "learning_rate": 2.0920408163265305e-05,
      "loss": 0.0731,
      "step": 14750
    },
    {
      "epoch": 5.904,
      "grad_norm": 1.7483798265457153,
      "learning_rate": 2.09e-05,
      "loss": 0.0957,
      "step": 14760
    },
    {
      "epoch": 5.908,
      "grad_norm": 1.116909384727478,
      "learning_rate": 2.0879591836734695e-05,
      "loss": 0.1043,
      "step": 14770
    },
    {
      "epoch": 5.912,
      "grad_norm": 0.11427672207355499,
      "learning_rate": 2.0859183673469386e-05,
      "loss": 0.092,
      "step": 14780
    },
    {
      "epoch": 5.916,
      "grad_norm": 0.735008955001831,
      "learning_rate": 2.0838775510204085e-05,
      "loss": 0.0476,
      "step": 14790
    },
    {
      "epoch": 5.92,
      "grad_norm": 0.10816764086484909,
      "learning_rate": 2.0818367346938776e-05,
      "loss": 0.0669,
      "step": 14800
    },
    {
      "epoch": 5.924,
      "grad_norm": 1.419960379600525,
      "learning_rate": 2.079795918367347e-05,
      "loss": 0.1028,
      "step": 14810
    },
    {
      "epoch": 5.928,
      "grad_norm": 2.267308473587036,
      "learning_rate": 2.0777551020408166e-05,
      "loss": 0.0818,
      "step": 14820
    },
    {
      "epoch": 5.932,
      "grad_norm": 1.2061591148376465,
      "learning_rate": 2.0757142857142858e-05,
      "loss": 0.0551,
      "step": 14830
    },
    {
      "epoch": 5.936,
      "grad_norm": 1.1839181184768677,
      "learning_rate": 2.0736734693877553e-05,
      "loss": 0.0719,
      "step": 14840
    },
    {
      "epoch": 5.9399999999999995,
      "grad_norm": 1.3250662088394165,
      "learning_rate": 2.0716326530612244e-05,
      "loss": 0.083,
      "step": 14850
    },
    {
      "epoch": 5.944,
      "grad_norm": 1.030900001525879,
      "learning_rate": 2.069591836734694e-05,
      "loss": 0.0465,
      "step": 14860
    },
    {
      "epoch": 5.948,
      "grad_norm": 1.0640145540237427,
      "learning_rate": 2.0675510204081634e-05,
      "loss": 0.0988,
      "step": 14870
    },
    {
      "epoch": 5.952,
      "grad_norm": 1.534806728363037,
      "learning_rate": 2.0655102040816326e-05,
      "loss": 0.0953,
      "step": 14880
    },
    {
      "epoch": 5.9559999999999995,
      "grad_norm": 0.9762691855430603,
      "learning_rate": 2.063469387755102e-05,
      "loss": 0.0363,
      "step": 14890
    },
    {
      "epoch": 5.96,
      "grad_norm": 1.3853843212127686,
      "learning_rate": 2.0614285714285716e-05,
      "loss": 0.0683,
      "step": 14900
    },
    {
      "epoch": 5.964,
      "grad_norm": 1.0433576107025146,
      "learning_rate": 2.059387755102041e-05,
      "loss": 0.0871,
      "step": 14910
    },
    {
      "epoch": 5.968,
      "grad_norm": 0.22816696763038635,
      "learning_rate": 2.0573469387755102e-05,
      "loss": 0.0504,
      "step": 14920
    },
    {
      "epoch": 5.9719999999999995,
      "grad_norm": 0.6822801828384399,
      "learning_rate": 2.0553061224489797e-05,
      "loss": 0.0473,
      "step": 14930
    },
    {
      "epoch": 5.976,
      "grad_norm": 1.0725430250167847,
      "learning_rate": 2.0532653061224492e-05,
      "loss": 0.0868,
      "step": 14940
    },
    {
      "epoch": 5.98,
      "grad_norm": 0.1262124925851822,
      "learning_rate": 2.0512244897959184e-05,
      "loss": 0.0563,
      "step": 14950
    },
    {
      "epoch": 5.984,
      "grad_norm": 1.7484992742538452,
      "learning_rate": 2.049183673469388e-05,
      "loss": 0.0988,
      "step": 14960
    },
    {
      "epoch": 5.9879999999999995,
      "grad_norm": 0.5824194550514221,
      "learning_rate": 2.047142857142857e-05,
      "loss": 0.0878,
      "step": 14970
    },
    {
      "epoch": 5.992,
      "grad_norm": 1.9193692207336426,
      "learning_rate": 2.0451020408163265e-05,
      "loss": 0.0637,
      "step": 14980
    },
    {
      "epoch": 5.996,
      "grad_norm": 0.279193252325058,
      "learning_rate": 2.043061224489796e-05,
      "loss": 0.0699,
      "step": 14990
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.47195500135421753,
      "learning_rate": 2.0410204081632652e-05,
      "loss": 0.0533,
      "step": 15000
    },
    {
      "epoch": 6.004,
      "grad_norm": 0.41753554344177246,
      "learning_rate": 2.038979591836735e-05,
      "loss": 0.0583,
      "step": 15010
    },
    {
      "epoch": 6.008,
      "grad_norm": 0.7604476809501648,
      "learning_rate": 2.0369387755102042e-05,
      "loss": 0.1028,
      "step": 15020
    },
    {
      "epoch": 6.012,
      "grad_norm": 0.9736009240150452,
      "learning_rate": 2.0348979591836737e-05,
      "loss": 0.0901,
      "step": 15030
    },
    {
      "epoch": 6.016,
      "grad_norm": 0.8468413949012756,
      "learning_rate": 2.032857142857143e-05,
      "loss": 0.053,
      "step": 15040
    },
    {
      "epoch": 6.02,
      "grad_norm": 1.3024967908859253,
      "learning_rate": 2.0308163265306123e-05,
      "loss": 0.0643,
      "step": 15050
    },
    {
      "epoch": 6.024,
      "grad_norm": 1.1124391555786133,
      "learning_rate": 2.028775510204082e-05,
      "loss": 0.0947,
      "step": 15060
    },
    {
      "epoch": 6.028,
      "grad_norm": 0.23798377811908722,
      "learning_rate": 2.026734693877551e-05,
      "loss": 0.0657,
      "step": 15070
    },
    {
      "epoch": 6.032,
      "grad_norm": 0.6942969560623169,
      "learning_rate": 2.0246938775510205e-05,
      "loss": 0.0782,
      "step": 15080
    },
    {
      "epoch": 6.036,
      "grad_norm": 0.38324764370918274,
      "learning_rate": 2.02265306122449e-05,
      "loss": 0.0837,
      "step": 15090
    },
    {
      "epoch": 6.04,
      "grad_norm": 1.4619959592819214,
      "learning_rate": 2.020612244897959e-05,
      "loss": 0.0577,
      "step": 15100
    },
    {
      "epoch": 6.044,
      "grad_norm": 0.07501386851072311,
      "learning_rate": 2.0185714285714287e-05,
      "loss": 0.0721,
      "step": 15110
    },
    {
      "epoch": 6.048,
      "grad_norm": 0.38343918323516846,
      "learning_rate": 2.0165306122448978e-05,
      "loss": 0.1075,
      "step": 15120
    },
    {
      "epoch": 6.052,
      "grad_norm": 0.12384291738271713,
      "learning_rate": 2.0144897959183676e-05,
      "loss": 0.0624,
      "step": 15130
    },
    {
      "epoch": 6.056,
      "grad_norm": 0.9479514360427856,
      "learning_rate": 2.0124489795918368e-05,
      "loss": 0.0256,
      "step": 15140
    },
    {
      "epoch": 6.06,
      "grad_norm": 0.5093588829040527,
      "learning_rate": 2.0104081632653063e-05,
      "loss": 0.08,
      "step": 15150
    },
    {
      "epoch": 6.064,
      "grad_norm": 1.1230230331420898,
      "learning_rate": 2.0083673469387758e-05,
      "loss": 0.0629,
      "step": 15160
    },
    {
      "epoch": 6.068,
      "grad_norm": 0.027925578877329826,
      "learning_rate": 2.006326530612245e-05,
      "loss": 0.0412,
      "step": 15170
    },
    {
      "epoch": 6.072,
      "grad_norm": 0.6553789377212524,
      "learning_rate": 2.0042857142857145e-05,
      "loss": 0.0963,
      "step": 15180
    },
    {
      "epoch": 6.076,
      "grad_norm": 0.6692960262298584,
      "learning_rate": 2.0022448979591836e-05,
      "loss": 0.0668,
      "step": 15190
    },
    {
      "epoch": 6.08,
      "grad_norm": 0.43706434965133667,
      "learning_rate": 2.000204081632653e-05,
      "loss": 0.0799,
      "step": 15200
    },
    {
      "epoch": 6.084,
      "grad_norm": 0.33344903588294983,
      "learning_rate": 1.9981632653061226e-05,
      "loss": 0.0638,
      "step": 15210
    },
    {
      "epoch": 6.088,
      "grad_norm": 0.5714703798294067,
      "learning_rate": 1.9961224489795918e-05,
      "loss": 0.0781,
      "step": 15220
    },
    {
      "epoch": 6.092,
      "grad_norm": 1.8629405498504639,
      "learning_rate": 1.9940816326530613e-05,
      "loss": 0.092,
      "step": 15230
    },
    {
      "epoch": 6.096,
      "grad_norm": 1.606151819229126,
      "learning_rate": 1.9920408163265308e-05,
      "loss": 0.0639,
      "step": 15240
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.10484813898801804,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.0338,
      "step": 15250
    },
    {
      "epoch": 6.104,
      "grad_norm": 0.09940820187330246,
      "learning_rate": 1.9879591836734694e-05,
      "loss": 0.0682,
      "step": 15260
    },
    {
      "epoch": 6.108,
      "grad_norm": 1.9278392791748047,
      "learning_rate": 1.985918367346939e-05,
      "loss": 0.0928,
      "step": 15270
    },
    {
      "epoch": 6.112,
      "grad_norm": 0.8145284056663513,
      "learning_rate": 1.9838775510204084e-05,
      "loss": 0.0806,
      "step": 15280
    },
    {
      "epoch": 6.116,
      "grad_norm": 1.4734416007995605,
      "learning_rate": 1.9818367346938776e-05,
      "loss": 0.0538,
      "step": 15290
    },
    {
      "epoch": 6.12,
      "grad_norm": 0.7386665940284729,
      "learning_rate": 1.979795918367347e-05,
      "loss": 0.0409,
      "step": 15300
    },
    {
      "epoch": 6.124,
      "grad_norm": 0.9298443794250488,
      "learning_rate": 1.9777551020408162e-05,
      "loss": 0.0796,
      "step": 15310
    },
    {
      "epoch": 6.128,
      "grad_norm": 0.1938319206237793,
      "learning_rate": 1.9757142857142857e-05,
      "loss": 0.0678,
      "step": 15320
    },
    {
      "epoch": 6.132,
      "grad_norm": 0.31324684619903564,
      "learning_rate": 1.9736734693877552e-05,
      "loss": 0.0524,
      "step": 15330
    },
    {
      "epoch": 6.136,
      "grad_norm": 0.3288232684135437,
      "learning_rate": 1.9716326530612244e-05,
      "loss": 0.0456,
      "step": 15340
    },
    {
      "epoch": 6.14,
      "grad_norm": 0.44363000988960266,
      "learning_rate": 1.9695918367346942e-05,
      "loss": 0.0661,
      "step": 15350
    },
    {
      "epoch": 6.144,
      "grad_norm": 1.5058672428131104,
      "learning_rate": 1.9675510204081634e-05,
      "loss": 0.0564,
      "step": 15360
    },
    {
      "epoch": 6.148,
      "grad_norm": 0.217143252491951,
      "learning_rate": 1.965510204081633e-05,
      "loss": 0.0671,
      "step": 15370
    },
    {
      "epoch": 6.152,
      "grad_norm": 1.6749905347824097,
      "learning_rate": 1.963469387755102e-05,
      "loss": 0.0954,
      "step": 15380
    },
    {
      "epoch": 6.156,
      "grad_norm": 1.055311679840088,
      "learning_rate": 1.9614285714285715e-05,
      "loss": 0.093,
      "step": 15390
    },
    {
      "epoch": 6.16,
      "grad_norm": 0.7430922985076904,
      "learning_rate": 1.959387755102041e-05,
      "loss": 0.0744,
      "step": 15400
    },
    {
      "epoch": 6.164,
      "grad_norm": 0.4093906283378601,
      "learning_rate": 1.9573469387755102e-05,
      "loss": 0.0594,
      "step": 15410
    },
    {
      "epoch": 6.168,
      "grad_norm": 1.8307682275772095,
      "learning_rate": 1.9553061224489797e-05,
      "loss": 0.0886,
      "step": 15420
    },
    {
      "epoch": 6.172,
      "grad_norm": 1.487191915512085,
      "learning_rate": 1.9532653061224492e-05,
      "loss": 0.0833,
      "step": 15430
    },
    {
      "epoch": 6.176,
      "grad_norm": 0.7904835343360901,
      "learning_rate": 1.9512244897959183e-05,
      "loss": 0.0645,
      "step": 15440
    },
    {
      "epoch": 6.18,
      "grad_norm": 0.3446801006793976,
      "learning_rate": 1.949183673469388e-05,
      "loss": 0.0772,
      "step": 15450
    },
    {
      "epoch": 6.184,
      "grad_norm": 1.2514307498931885,
      "learning_rate": 1.947142857142857e-05,
      "loss": 0.0405,
      "step": 15460
    },
    {
      "epoch": 6.188,
      "grad_norm": 0.10295155644416809,
      "learning_rate": 1.9451020408163268e-05,
      "loss": 0.0209,
      "step": 15470
    },
    {
      "epoch": 6.192,
      "grad_norm": 0.0770825445652008,
      "learning_rate": 1.943061224489796e-05,
      "loss": 0.1022,
      "step": 15480
    },
    {
      "epoch": 6.196,
      "grad_norm": 0.9676030278205872,
      "learning_rate": 1.9410204081632655e-05,
      "loss": 0.0667,
      "step": 15490
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.23434561491012573,
      "learning_rate": 1.938979591836735e-05,
      "loss": 0.0402,
      "step": 15500
    },
    {
      "epoch": 6.204,
      "grad_norm": 1.2503753900527954,
      "learning_rate": 1.936938775510204e-05,
      "loss": 0.1067,
      "step": 15510
    },
    {
      "epoch": 6.208,
      "grad_norm": 0.17857573926448822,
      "learning_rate": 1.9348979591836736e-05,
      "loss": 0.0355,
      "step": 15520
    },
    {
      "epoch": 6.212,
      "grad_norm": 1.0509947538375854,
      "learning_rate": 1.9328571428571428e-05,
      "loss": 0.0513,
      "step": 15530
    },
    {
      "epoch": 6.216,
      "grad_norm": 1.1390254497528076,
      "learning_rate": 1.9308163265306123e-05,
      "loss": 0.0906,
      "step": 15540
    },
    {
      "epoch": 6.22,
      "grad_norm": 0.5051781535148621,
      "learning_rate": 1.9287755102040818e-05,
      "loss": 0.0392,
      "step": 15550
    },
    {
      "epoch": 6.224,
      "grad_norm": 1.5927178859710693,
      "learning_rate": 1.926734693877551e-05,
      "loss": 0.1031,
      "step": 15560
    },
    {
      "epoch": 6.228,
      "grad_norm": 0.06942305713891983,
      "learning_rate": 1.9246938775510204e-05,
      "loss": 0.1121,
      "step": 15570
    },
    {
      "epoch": 6.232,
      "grad_norm": 1.3289738893508911,
      "learning_rate": 1.92265306122449e-05,
      "loss": 0.1258,
      "step": 15580
    },
    {
      "epoch": 6.236,
      "grad_norm": 1.2102301120758057,
      "learning_rate": 1.9206122448979594e-05,
      "loss": 0.035,
      "step": 15590
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.2151031345129013,
      "learning_rate": 1.9185714285714286e-05,
      "loss": 0.0304,
      "step": 15600
    },
    {
      "epoch": 6.244,
      "grad_norm": 1.1355072259902954,
      "learning_rate": 1.916530612244898e-05,
      "loss": 0.0663,
      "step": 15610
    },
    {
      "epoch": 6.248,
      "grad_norm": 0.417778342962265,
      "learning_rate": 1.9144897959183676e-05,
      "loss": 0.0598,
      "step": 15620
    },
    {
      "epoch": 6.252,
      "grad_norm": 0.1626659780740738,
      "learning_rate": 1.9124489795918367e-05,
      "loss": 0.0702,
      "step": 15630
    },
    {
      "epoch": 6.256,
      "grad_norm": 1.357877492904663,
      "learning_rate": 1.9104081632653062e-05,
      "loss": 0.0717,
      "step": 15640
    },
    {
      "epoch": 6.26,
      "grad_norm": 1.0861523151397705,
      "learning_rate": 1.9083673469387754e-05,
      "loss": 0.0404,
      "step": 15650
    },
    {
      "epoch": 6.264,
      "grad_norm": 0.6652631163597107,
      "learning_rate": 1.906326530612245e-05,
      "loss": 0.0607,
      "step": 15660
    },
    {
      "epoch": 6.268,
      "grad_norm": 0.9292488098144531,
      "learning_rate": 1.9042857142857144e-05,
      "loss": 0.0802,
      "step": 15670
    },
    {
      "epoch": 6.272,
      "grad_norm": 0.3652473986148834,
      "learning_rate": 1.9022448979591836e-05,
      "loss": 0.0848,
      "step": 15680
    },
    {
      "epoch": 6.276,
      "grad_norm": 0.37768056988716125,
      "learning_rate": 1.9002040816326534e-05,
      "loss": 0.0409,
      "step": 15690
    },
    {
      "epoch": 6.28,
      "grad_norm": 0.6311066746711731,
      "learning_rate": 1.8981632653061226e-05,
      "loss": 0.0617,
      "step": 15700
    },
    {
      "epoch": 6.284,
      "grad_norm": 1.6234017610549927,
      "learning_rate": 1.896122448979592e-05,
      "loss": 0.0695,
      "step": 15710
    },
    {
      "epoch": 6.288,
      "grad_norm": 0.4778682589530945,
      "learning_rate": 1.8940816326530615e-05,
      "loss": 0.0334,
      "step": 15720
    },
    {
      "epoch": 6.292,
      "grad_norm": 1.1157811880111694,
      "learning_rate": 1.8920408163265307e-05,
      "loss": 0.0464,
      "step": 15730
    },
    {
      "epoch": 6.296,
      "grad_norm": 1.9171998500823975,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 0.0789,
      "step": 15740
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.198647603392601,
      "learning_rate": 1.8879591836734694e-05,
      "loss": 0.0613,
      "step": 15750
    },
    {
      "epoch": 6.304,
      "grad_norm": 1.086785912513733,
      "learning_rate": 1.885918367346939e-05,
      "loss": 0.0471,
      "step": 15760
    },
    {
      "epoch": 6.308,
      "grad_norm": 0.9923765063285828,
      "learning_rate": 1.8838775510204084e-05,
      "loss": 0.067,
      "step": 15770
    },
    {
      "epoch": 6.312,
      "grad_norm": 0.7893626689910889,
      "learning_rate": 1.8818367346938775e-05,
      "loss": 0.0625,
      "step": 15780
    },
    {
      "epoch": 6.316,
      "grad_norm": 0.7061327695846558,
      "learning_rate": 1.879795918367347e-05,
      "loss": 0.0874,
      "step": 15790
    },
    {
      "epoch": 6.32,
      "grad_norm": 1.0664819478988647,
      "learning_rate": 1.877755102040816e-05,
      "loss": 0.0828,
      "step": 15800
    },
    {
      "epoch": 6.324,
      "grad_norm": 1.0631401538848877,
      "learning_rate": 1.875714285714286e-05,
      "loss": 0.1106,
      "step": 15810
    },
    {
      "epoch": 6.328,
      "grad_norm": 2.0509698390960693,
      "learning_rate": 1.873673469387755e-05,
      "loss": 0.0901,
      "step": 15820
    },
    {
      "epoch": 6.332,
      "grad_norm": 0.6909928917884827,
      "learning_rate": 1.8716326530612247e-05,
      "loss": 0.0503,
      "step": 15830
    },
    {
      "epoch": 6.336,
      "grad_norm": 0.09605979174375534,
      "learning_rate": 1.869591836734694e-05,
      "loss": 0.1189,
      "step": 15840
    },
    {
      "epoch": 6.34,
      "grad_norm": 0.4518791735172272,
      "learning_rate": 1.8675510204081633e-05,
      "loss": 0.1082,
      "step": 15850
    },
    {
      "epoch": 6.344,
      "grad_norm": 0.47015294432640076,
      "learning_rate": 1.8655102040816328e-05,
      "loss": 0.1105,
      "step": 15860
    },
    {
      "epoch": 6.348,
      "grad_norm": 0.7057037353515625,
      "learning_rate": 1.863469387755102e-05,
      "loss": 0.0715,
      "step": 15870
    },
    {
      "epoch": 6.352,
      "grad_norm": 0.4542151391506195,
      "learning_rate": 1.8614285714285715e-05,
      "loss": 0.0411,
      "step": 15880
    },
    {
      "epoch": 6.356,
      "grad_norm": 1.0269256830215454,
      "learning_rate": 1.859387755102041e-05,
      "loss": 0.1054,
      "step": 15890
    },
    {
      "epoch": 6.36,
      "grad_norm": 0.005694123450666666,
      "learning_rate": 1.85734693877551e-05,
      "loss": 0.0391,
      "step": 15900
    },
    {
      "epoch": 6.364,
      "grad_norm": 1.5879149436950684,
      "learning_rate": 1.8553061224489796e-05,
      "loss": 0.069,
      "step": 15910
    },
    {
      "epoch": 6.368,
      "grad_norm": 1.462435245513916,
      "learning_rate": 1.853265306122449e-05,
      "loss": 0.0705,
      "step": 15920
    },
    {
      "epoch": 6.372,
      "grad_norm": 0.5103213787078857,
      "learning_rate": 1.8512244897959186e-05,
      "loss": 0.0683,
      "step": 15930
    },
    {
      "epoch": 6.376,
      "grad_norm": 0.21383483707904816,
      "learning_rate": 1.8491836734693878e-05,
      "loss": 0.0518,
      "step": 15940
    },
    {
      "epoch": 6.38,
      "grad_norm": 0.4293437898159027,
      "learning_rate": 1.8471428571428573e-05,
      "loss": 0.0743,
      "step": 15950
    },
    {
      "epoch": 6.384,
      "grad_norm": 0.5978835225105286,
      "learning_rate": 1.8451020408163268e-05,
      "loss": 0.0904,
      "step": 15960
    },
    {
      "epoch": 6.388,
      "grad_norm": 0.05693350359797478,
      "learning_rate": 1.843061224489796e-05,
      "loss": 0.0745,
      "step": 15970
    },
    {
      "epoch": 6.392,
      "grad_norm": 0.22276531159877777,
      "learning_rate": 1.8410204081632654e-05,
      "loss": 0.0614,
      "step": 15980
    },
    {
      "epoch": 6.396,
      "grad_norm": 0.08059271425008774,
      "learning_rate": 1.8389795918367346e-05,
      "loss": 0.0298,
      "step": 15990
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.6158034801483154,
      "learning_rate": 1.836938775510204e-05,
      "loss": 0.0688,
      "step": 16000
    },
    {
      "epoch": 6.404,
      "grad_norm": 1.4296537637710571,
      "learning_rate": 1.8348979591836736e-05,
      "loss": 0.056,
      "step": 16010
    },
    {
      "epoch": 6.408,
      "grad_norm": 1.2218230962753296,
      "learning_rate": 1.8328571428571427e-05,
      "loss": 0.0837,
      "step": 16020
    },
    {
      "epoch": 6.412,
      "grad_norm": 1.0362894535064697,
      "learning_rate": 1.8308163265306126e-05,
      "loss": 0.0544,
      "step": 16030
    },
    {
      "epoch": 6.416,
      "grad_norm": 0.5767056941986084,
      "learning_rate": 1.8287755102040817e-05,
      "loss": 0.0729,
      "step": 16040
    },
    {
      "epoch": 6.42,
      "grad_norm": 0.6764686107635498,
      "learning_rate": 1.8267346938775512e-05,
      "loss": 0.0806,
      "step": 16050
    },
    {
      "epoch": 6.424,
      "grad_norm": 0.9054017066955566,
      "learning_rate": 1.8246938775510207e-05,
      "loss": 0.0662,
      "step": 16060
    },
    {
      "epoch": 6.428,
      "grad_norm": 0.5440062880516052,
      "learning_rate": 1.82265306122449e-05,
      "loss": 0.0624,
      "step": 16070
    },
    {
      "epoch": 6.432,
      "grad_norm": 1.6874709129333496,
      "learning_rate": 1.8206122448979594e-05,
      "loss": 0.0387,
      "step": 16080
    },
    {
      "epoch": 6.436,
      "grad_norm": 0.6702940464019775,
      "learning_rate": 1.8185714285714285e-05,
      "loss": 0.062,
      "step": 16090
    },
    {
      "epoch": 6.44,
      "grad_norm": 0.6887354850769043,
      "learning_rate": 1.816530612244898e-05,
      "loss": 0.0422,
      "step": 16100
    },
    {
      "epoch": 6.444,
      "grad_norm": 0.8080170154571533,
      "learning_rate": 1.8144897959183675e-05,
      "loss": 0.0769,
      "step": 16110
    },
    {
      "epoch": 6.448,
      "grad_norm": 2.1839218139648438,
      "learning_rate": 1.8124489795918367e-05,
      "loss": 0.0791,
      "step": 16120
    },
    {
      "epoch": 6.452,
      "grad_norm": 0.20980431139469147,
      "learning_rate": 1.8104081632653062e-05,
      "loss": 0.0831,
      "step": 16130
    },
    {
      "epoch": 6.456,
      "grad_norm": 0.08122625201940536,
      "learning_rate": 1.8083673469387753e-05,
      "loss": 0.079,
      "step": 16140
    },
    {
      "epoch": 6.46,
      "grad_norm": 0.8502933382987976,
      "learning_rate": 1.8063265306122452e-05,
      "loss": 0.0621,
      "step": 16150
    },
    {
      "epoch": 6.464,
      "grad_norm": 0.6676087379455566,
      "learning_rate": 1.8042857142857143e-05,
      "loss": 0.0703,
      "step": 16160
    },
    {
      "epoch": 6.468,
      "grad_norm": 0.6928871273994446,
      "learning_rate": 1.802244897959184e-05,
      "loss": 0.0582,
      "step": 16170
    },
    {
      "epoch": 6.4719999999999995,
      "grad_norm": 0.955535352230072,
      "learning_rate": 1.8002040816326533e-05,
      "loss": 0.045,
      "step": 16180
    },
    {
      "epoch": 6.476,
      "grad_norm": 1.839426040649414,
      "learning_rate": 1.7981632653061225e-05,
      "loss": 0.1053,
      "step": 16190
    },
    {
      "epoch": 6.48,
      "grad_norm": 0.3783012628555298,
      "learning_rate": 1.796122448979592e-05,
      "loss": 0.1073,
      "step": 16200
    },
    {
      "epoch": 6.484,
      "grad_norm": 1.8728679418563843,
      "learning_rate": 1.794081632653061e-05,
      "loss": 0.0779,
      "step": 16210
    },
    {
      "epoch": 6.4879999999999995,
      "grad_norm": 1.6855542659759521,
      "learning_rate": 1.7920408163265306e-05,
      "loss": 0.0601,
      "step": 16220
    },
    {
      "epoch": 6.492,
      "grad_norm": 0.9967520833015442,
      "learning_rate": 1.79e-05,
      "loss": 0.0814,
      "step": 16230
    },
    {
      "epoch": 6.496,
      "grad_norm": 2.3190741539001465,
      "learning_rate": 1.7879591836734693e-05,
      "loss": 0.0828,
      "step": 16240
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.0746142864227295,
      "learning_rate": 1.7859183673469388e-05,
      "loss": 0.0484,
      "step": 16250
    },
    {
      "epoch": 6.504,
      "grad_norm": 0.9218617677688599,
      "learning_rate": 1.7838775510204083e-05,
      "loss": 0.049,
      "step": 16260
    },
    {
      "epoch": 6.508,
      "grad_norm": 0.8563480973243713,
      "learning_rate": 1.7818367346938778e-05,
      "loss": 0.0334,
      "step": 16270
    },
    {
      "epoch": 6.5120000000000005,
      "grad_norm": 1.4094446897506714,
      "learning_rate": 1.779795918367347e-05,
      "loss": 0.1021,
      "step": 16280
    },
    {
      "epoch": 6.516,
      "grad_norm": 0.27749016880989075,
      "learning_rate": 1.7777551020408164e-05,
      "loss": 0.0837,
      "step": 16290
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.8050122857093811,
      "learning_rate": 1.775714285714286e-05,
      "loss": 0.0584,
      "step": 16300
    },
    {
      "epoch": 6.524,
      "grad_norm": 1.2738962173461914,
      "learning_rate": 1.773673469387755e-05,
      "loss": 0.106,
      "step": 16310
    },
    {
      "epoch": 6.5280000000000005,
      "grad_norm": 0.2793809771537781,
      "learning_rate": 1.7716326530612246e-05,
      "loss": 0.0421,
      "step": 16320
    },
    {
      "epoch": 6.532,
      "grad_norm": 1.3695868253707886,
      "learning_rate": 1.7695918367346938e-05,
      "loss": 0.0535,
      "step": 16330
    },
    {
      "epoch": 6.536,
      "grad_norm": 0.020279906690120697,
      "learning_rate": 1.7675510204081633e-05,
      "loss": 0.0972,
      "step": 16340
    },
    {
      "epoch": 6.54,
      "grad_norm": 1.4305014610290527,
      "learning_rate": 1.7655102040816328e-05,
      "loss": 0.1,
      "step": 16350
    },
    {
      "epoch": 6.5440000000000005,
      "grad_norm": 2.263711452484131,
      "learning_rate": 1.763469387755102e-05,
      "loss": 0.0958,
      "step": 16360
    },
    {
      "epoch": 6.548,
      "grad_norm": 1.1039094924926758,
      "learning_rate": 1.7614285714285717e-05,
      "loss": 0.0838,
      "step": 16370
    },
    {
      "epoch": 6.552,
      "grad_norm": 1.5420260429382324,
      "learning_rate": 1.759387755102041e-05,
      "loss": 0.075,
      "step": 16380
    },
    {
      "epoch": 6.556,
      "grad_norm": 0.7107291221618652,
      "learning_rate": 1.7573469387755104e-05,
      "loss": 0.0593,
      "step": 16390
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 1.0745474100112915,
      "learning_rate": 1.75530612244898e-05,
      "loss": 0.0594,
      "step": 16400
    },
    {
      "epoch": 6.564,
      "grad_norm": 0.3955363631248474,
      "learning_rate": 1.753265306122449e-05,
      "loss": 0.056,
      "step": 16410
    },
    {
      "epoch": 6.568,
      "grad_norm": 1.0222265720367432,
      "learning_rate": 1.7512244897959186e-05,
      "loss": 0.0585,
      "step": 16420
    },
    {
      "epoch": 6.572,
      "grad_norm": 0.7695204019546509,
      "learning_rate": 1.7491836734693877e-05,
      "loss": 0.0455,
      "step": 16430
    },
    {
      "epoch": 6.576,
      "grad_norm": 1.258582592010498,
      "learning_rate": 1.7471428571428572e-05,
      "loss": 0.0606,
      "step": 16440
    },
    {
      "epoch": 6.58,
      "grad_norm": 1.4280791282653809,
      "learning_rate": 1.7451020408163267e-05,
      "loss": 0.0704,
      "step": 16450
    },
    {
      "epoch": 6.584,
      "grad_norm": 0.33988282084465027,
      "learning_rate": 1.743061224489796e-05,
      "loss": 0.0415,
      "step": 16460
    },
    {
      "epoch": 6.588,
      "grad_norm": 1.2522897720336914,
      "learning_rate": 1.7410204081632654e-05,
      "loss": 0.0623,
      "step": 16470
    },
    {
      "epoch": 6.592,
      "grad_norm": 1.0483840703964233,
      "learning_rate": 1.7389795918367345e-05,
      "loss": 0.0974,
      "step": 16480
    },
    {
      "epoch": 6.596,
      "grad_norm": 0.4721985459327698,
      "learning_rate": 1.7369387755102044e-05,
      "loss": 0.1016,
      "step": 16490
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.5205724239349365,
      "learning_rate": 1.7348979591836735e-05,
      "loss": 0.0721,
      "step": 16500
    },
    {
      "epoch": 6.604,
      "grad_norm": 0.12426839023828506,
      "learning_rate": 1.732857142857143e-05,
      "loss": 0.0476,
      "step": 16510
    },
    {
      "epoch": 6.608,
      "grad_norm": 0.7410253286361694,
      "learning_rate": 1.7308163265306125e-05,
      "loss": 0.093,
      "step": 16520
    },
    {
      "epoch": 6.612,
      "grad_norm": 1.494238257408142,
      "learning_rate": 1.7287755102040817e-05,
      "loss": 0.1081,
      "step": 16530
    },
    {
      "epoch": 6.616,
      "grad_norm": 0.2565805912017822,
      "learning_rate": 1.726734693877551e-05,
      "loss": 0.0558,
      "step": 16540
    },
    {
      "epoch": 6.62,
      "grad_norm": 0.5204024910926819,
      "learning_rate": 1.7246938775510203e-05,
      "loss": 0.0611,
      "step": 16550
    },
    {
      "epoch": 6.624,
      "grad_norm": 1.7597200870513916,
      "learning_rate": 1.7226530612244898e-05,
      "loss": 0.0751,
      "step": 16560
    },
    {
      "epoch": 6.628,
      "grad_norm": 0.28847646713256836,
      "learning_rate": 1.7206122448979593e-05,
      "loss": 0.0376,
      "step": 16570
    },
    {
      "epoch": 6.632,
      "grad_norm": 1.7932318449020386,
      "learning_rate": 1.7185714285714285e-05,
      "loss": 0.0682,
      "step": 16580
    },
    {
      "epoch": 6.636,
      "grad_norm": 1.7162036895751953,
      "learning_rate": 1.716530612244898e-05,
      "loss": 0.0834,
      "step": 16590
    },
    {
      "epoch": 6.64,
      "grad_norm": 0.8748374581336975,
      "learning_rate": 1.7144897959183675e-05,
      "loss": 0.0384,
      "step": 16600
    },
    {
      "epoch": 6.644,
      "grad_norm": 1.405161738395691,
      "learning_rate": 1.712448979591837e-05,
      "loss": 0.0587,
      "step": 16610
    },
    {
      "epoch": 6.648,
      "grad_norm": 0.22869445383548737,
      "learning_rate": 1.710408163265306e-05,
      "loss": 0.0462,
      "step": 16620
    },
    {
      "epoch": 6.652,
      "grad_norm": 1.2793470621109009,
      "learning_rate": 1.7083673469387756e-05,
      "loss": 0.0705,
      "step": 16630
    },
    {
      "epoch": 6.656,
      "grad_norm": 1.1206731796264648,
      "learning_rate": 1.706326530612245e-05,
      "loss": 0.0611,
      "step": 16640
    },
    {
      "epoch": 6.66,
      "grad_norm": 0.20367807149887085,
      "learning_rate": 1.7042857142857143e-05,
      "loss": 0.0681,
      "step": 16650
    },
    {
      "epoch": 6.664,
      "grad_norm": 1.5651499032974243,
      "learning_rate": 1.7022448979591838e-05,
      "loss": 0.0603,
      "step": 16660
    },
    {
      "epoch": 6.668,
      "grad_norm": 1.5389052629470825,
      "learning_rate": 1.700204081632653e-05,
      "loss": 0.0889,
      "step": 16670
    },
    {
      "epoch": 6.672,
      "grad_norm": 1.8132513761520386,
      "learning_rate": 1.6981632653061224e-05,
      "loss": 0.0846,
      "step": 16680
    },
    {
      "epoch": 6.676,
      "grad_norm": 0.7130184173583984,
      "learning_rate": 1.696122448979592e-05,
      "loss": 0.0416,
      "step": 16690
    },
    {
      "epoch": 6.68,
      "grad_norm": 0.1044873595237732,
      "learning_rate": 1.694081632653061e-05,
      "loss": 0.1158,
      "step": 16700
    },
    {
      "epoch": 6.684,
      "grad_norm": 1.2118557691574097,
      "learning_rate": 1.692040816326531e-05,
      "loss": 0.1038,
      "step": 16710
    },
    {
      "epoch": 6.688,
      "grad_norm": 1.7966557741165161,
      "learning_rate": 1.69e-05,
      "loss": 0.0692,
      "step": 16720
    },
    {
      "epoch": 6.692,
      "grad_norm": 0.5423929691314697,
      "learning_rate": 1.6879591836734696e-05,
      "loss": 0.088,
      "step": 16730
    },
    {
      "epoch": 6.696,
      "grad_norm": 0.8827940225601196,
      "learning_rate": 1.685918367346939e-05,
      "loss": 0.0656,
      "step": 16740
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.11564506590366364,
      "learning_rate": 1.6838775510204082e-05,
      "loss": 0.0424,
      "step": 16750
    },
    {
      "epoch": 6.704,
      "grad_norm": 0.33640849590301514,
      "learning_rate": 1.6818367346938777e-05,
      "loss": 0.0691,
      "step": 16760
    },
    {
      "epoch": 6.708,
      "grad_norm": 1.4162988662719727,
      "learning_rate": 1.679795918367347e-05,
      "loss": 0.0751,
      "step": 16770
    },
    {
      "epoch": 6.712,
      "grad_norm": 1.1740632057189941,
      "learning_rate": 1.6777551020408164e-05,
      "loss": 0.046,
      "step": 16780
    },
    {
      "epoch": 6.716,
      "grad_norm": 0.2205861210823059,
      "learning_rate": 1.675714285714286e-05,
      "loss": 0.0712,
      "step": 16790
    },
    {
      "epoch": 6.72,
      "grad_norm": 0.5186512470245361,
      "learning_rate": 1.673673469387755e-05,
      "loss": 0.0293,
      "step": 16800
    },
    {
      "epoch": 6.724,
      "grad_norm": 1.127981424331665,
      "learning_rate": 1.6716326530612245e-05,
      "loss": 0.0673,
      "step": 16810
    },
    {
      "epoch": 6.728,
      "grad_norm": 0.4143516719341278,
      "learning_rate": 1.6695918367346937e-05,
      "loss": 0.0819,
      "step": 16820
    },
    {
      "epoch": 6.732,
      "grad_norm": 1.1302833557128906,
      "learning_rate": 1.6675510204081635e-05,
      "loss": 0.0895,
      "step": 16830
    },
    {
      "epoch": 6.736,
      "grad_norm": 0.5238115191459656,
      "learning_rate": 1.6655102040816327e-05,
      "loss": 0.0928,
      "step": 16840
    },
    {
      "epoch": 6.74,
      "grad_norm": 0.07044567912817001,
      "learning_rate": 1.6634693877551022e-05,
      "loss": 0.0641,
      "step": 16850
    },
    {
      "epoch": 6.744,
      "grad_norm": 0.09440682083368301,
      "learning_rate": 1.6614285714285717e-05,
      "loss": 0.0673,
      "step": 16860
    },
    {
      "epoch": 6.748,
      "grad_norm": 0.6518594026565552,
      "learning_rate": 1.659387755102041e-05,
      "loss": 0.0661,
      "step": 16870
    },
    {
      "epoch": 6.752,
      "grad_norm": 0.20699922740459442,
      "learning_rate": 1.6573469387755103e-05,
      "loss": 0.0697,
      "step": 16880
    },
    {
      "epoch": 6.756,
      "grad_norm": 1.4469289779663086,
      "learning_rate": 1.6553061224489795e-05,
      "loss": 0.1067,
      "step": 16890
    },
    {
      "epoch": 6.76,
      "grad_norm": 0.9589133262634277,
      "learning_rate": 1.653265306122449e-05,
      "loss": 0.059,
      "step": 16900
    },
    {
      "epoch": 6.764,
      "grad_norm": 0.5300633311271667,
      "learning_rate": 1.6512244897959185e-05,
      "loss": 0.0683,
      "step": 16910
    },
    {
      "epoch": 6.768,
      "grad_norm": 0.8013410568237305,
      "learning_rate": 1.6491836734693877e-05,
      "loss": 0.0458,
      "step": 16920
    },
    {
      "epoch": 6.772,
      "grad_norm": 0.47903892397880554,
      "learning_rate": 1.647142857142857e-05,
      "loss": 0.0524,
      "step": 16930
    },
    {
      "epoch": 6.776,
      "grad_norm": 0.10233771055936813,
      "learning_rate": 1.6451020408163266e-05,
      "loss": 0.0993,
      "step": 16940
    },
    {
      "epoch": 6.78,
      "grad_norm": 0.3744578957557678,
      "learning_rate": 1.643061224489796e-05,
      "loss": 0.0759,
      "step": 16950
    },
    {
      "epoch": 6.784,
      "grad_norm": 1.5889869928359985,
      "learning_rate": 1.6410204081632653e-05,
      "loss": 0.0929,
      "step": 16960
    },
    {
      "epoch": 6.788,
      "grad_norm": 1.1198115348815918,
      "learning_rate": 1.6389795918367348e-05,
      "loss": 0.0609,
      "step": 16970
    },
    {
      "epoch": 6.792,
      "grad_norm": 0.14542557299137115,
      "learning_rate": 1.6369387755102043e-05,
      "loss": 0.0458,
      "step": 16980
    },
    {
      "epoch": 6.796,
      "grad_norm": 0.8048271536827087,
      "learning_rate": 1.6348979591836735e-05,
      "loss": 0.0343,
      "step": 16990
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.4896673560142517,
      "learning_rate": 1.632857142857143e-05,
      "loss": 0.057,
      "step": 17000
    },
    {
      "epoch": 6.804,
      "grad_norm": 1.5473318099975586,
      "learning_rate": 1.630816326530612e-05,
      "loss": 0.1274,
      "step": 17010
    },
    {
      "epoch": 6.808,
      "grad_norm": 1.2323949337005615,
      "learning_rate": 1.6287755102040816e-05,
      "loss": 0.0489,
      "step": 17020
    },
    {
      "epoch": 6.812,
      "grad_norm": 1.663859486579895,
      "learning_rate": 1.626734693877551e-05,
      "loss": 0.1116,
      "step": 17030
    },
    {
      "epoch": 6.816,
      "grad_norm": 1.6870077848434448,
      "learning_rate": 1.6246938775510203e-05,
      "loss": 0.1008,
      "step": 17040
    },
    {
      "epoch": 6.82,
      "grad_norm": 0.23096030950546265,
      "learning_rate": 1.62265306122449e-05,
      "loss": 0.053,
      "step": 17050
    },
    {
      "epoch": 6.824,
      "grad_norm": 1.3106507062911987,
      "learning_rate": 1.6206122448979593e-05,
      "loss": 0.0865,
      "step": 17060
    },
    {
      "epoch": 6.828,
      "grad_norm": 0.5892961025238037,
      "learning_rate": 1.6185714285714288e-05,
      "loss": 0.07,
      "step": 17070
    },
    {
      "epoch": 6.832,
      "grad_norm": 0.010714632458984852,
      "learning_rate": 1.6165306122448983e-05,
      "loss": 0.0968,
      "step": 17080
    },
    {
      "epoch": 6.836,
      "grad_norm": 0.8057425022125244,
      "learning_rate": 1.6144897959183674e-05,
      "loss": 0.062,
      "step": 17090
    },
    {
      "epoch": 6.84,
      "grad_norm": 0.05087338387966156,
      "learning_rate": 1.612448979591837e-05,
      "loss": 0.0327,
      "step": 17100
    },
    {
      "epoch": 6.844,
      "grad_norm": 1.3697904348373413,
      "learning_rate": 1.610408163265306e-05,
      "loss": 0.0669,
      "step": 17110
    },
    {
      "epoch": 6.848,
      "grad_norm": 1.225456714630127,
      "learning_rate": 1.6083673469387756e-05,
      "loss": 0.0877,
      "step": 17120
    },
    {
      "epoch": 6.852,
      "grad_norm": 0.7315611839294434,
      "learning_rate": 1.606326530612245e-05,
      "loss": 0.0463,
      "step": 17130
    },
    {
      "epoch": 6.856,
      "grad_norm": 1.649080753326416,
      "learning_rate": 1.6042857142857142e-05,
      "loss": 0.1012,
      "step": 17140
    },
    {
      "epoch": 6.86,
      "grad_norm": 0.040336690843105316,
      "learning_rate": 1.6022448979591837e-05,
      "loss": 0.0744,
      "step": 17150
    },
    {
      "epoch": 6.864,
      "grad_norm": 0.09665811061859131,
      "learning_rate": 1.600204081632653e-05,
      "loss": 0.0492,
      "step": 17160
    },
    {
      "epoch": 6.868,
      "grad_norm": 0.9763783812522888,
      "learning_rate": 1.5981632653061227e-05,
      "loss": 0.0683,
      "step": 17170
    },
    {
      "epoch": 6.872,
      "grad_norm": 0.32758480310440063,
      "learning_rate": 1.596122448979592e-05,
      "loss": 0.0571,
      "step": 17180
    },
    {
      "epoch": 6.876,
      "grad_norm": 0.8966422080993652,
      "learning_rate": 1.5940816326530614e-05,
      "loss": 0.0486,
      "step": 17190
    },
    {
      "epoch": 6.88,
      "grad_norm": 0.7604725360870361,
      "learning_rate": 1.592040816326531e-05,
      "loss": 0.077,
      "step": 17200
    },
    {
      "epoch": 6.884,
      "grad_norm": 0.8857267498970032,
      "learning_rate": 1.59e-05,
      "loss": 0.0803,
      "step": 17210
    },
    {
      "epoch": 6.888,
      "grad_norm": 0.2987154424190521,
      "learning_rate": 1.5879591836734695e-05,
      "loss": 0.079,
      "step": 17220
    },
    {
      "epoch": 6.892,
      "grad_norm": 1.9750338792800903,
      "learning_rate": 1.5859183673469387e-05,
      "loss": 0.0735,
      "step": 17230
    },
    {
      "epoch": 6.896,
      "grad_norm": 1.3483874797821045,
      "learning_rate": 1.5838775510204082e-05,
      "loss": 0.0617,
      "step": 17240
    },
    {
      "epoch": 6.9,
      "grad_norm": 0.07957533001899719,
      "learning_rate": 1.5818367346938777e-05,
      "loss": 0.0644,
      "step": 17250
    },
    {
      "epoch": 6.904,
      "grad_norm": 0.981320858001709,
      "learning_rate": 1.579795918367347e-05,
      "loss": 0.0583,
      "step": 17260
    },
    {
      "epoch": 6.908,
      "grad_norm": 0.8213077783584595,
      "learning_rate": 1.5777551020408163e-05,
      "loss": 0.121,
      "step": 17270
    },
    {
      "epoch": 6.912,
      "grad_norm": 0.2819150388240814,
      "learning_rate": 1.5757142857142858e-05,
      "loss": 0.0777,
      "step": 17280
    },
    {
      "epoch": 6.916,
      "grad_norm": 0.5852605104446411,
      "learning_rate": 1.5736734693877553e-05,
      "loss": 0.095,
      "step": 17290
    },
    {
      "epoch": 6.92,
      "grad_norm": 1.1664572954177856,
      "learning_rate": 1.5716326530612245e-05,
      "loss": 0.0561,
      "step": 17300
    },
    {
      "epoch": 6.924,
      "grad_norm": 0.9553225040435791,
      "learning_rate": 1.569591836734694e-05,
      "loss": 0.0655,
      "step": 17310
    },
    {
      "epoch": 6.928,
      "grad_norm": 0.5324457883834839,
      "learning_rate": 1.5675510204081635e-05,
      "loss": 0.0668,
      "step": 17320
    },
    {
      "epoch": 6.932,
      "grad_norm": 0.7122902870178223,
      "learning_rate": 1.5655102040816326e-05,
      "loss": 0.0739,
      "step": 17330
    },
    {
      "epoch": 6.936,
      "grad_norm": 1.255038857460022,
      "learning_rate": 1.563469387755102e-05,
      "loss": 0.0582,
      "step": 17340
    },
    {
      "epoch": 6.9399999999999995,
      "grad_norm": 0.6538757681846619,
      "learning_rate": 1.5614285714285716e-05,
      "loss": 0.1052,
      "step": 17350
    },
    {
      "epoch": 6.944,
      "grad_norm": 0.03528723865747452,
      "learning_rate": 1.5593877551020408e-05,
      "loss": 0.0624,
      "step": 17360
    },
    {
      "epoch": 6.948,
      "grad_norm": 2.059752941131592,
      "learning_rate": 1.5573469387755103e-05,
      "loss": 0.0982,
      "step": 17370
    },
    {
      "epoch": 6.952,
      "grad_norm": 1.0856449604034424,
      "learning_rate": 1.5553061224489794e-05,
      "loss": 0.0423,
      "step": 17380
    },
    {
      "epoch": 6.9559999999999995,
      "grad_norm": 0.11318943649530411,
      "learning_rate": 1.553265306122449e-05,
      "loss": 0.0757,
      "step": 17390
    },
    {
      "epoch": 6.96,
      "grad_norm": 0.6910138726234436,
      "learning_rate": 1.5512244897959184e-05,
      "loss": 0.0519,
      "step": 17400
    },
    {
      "epoch": 6.964,
      "grad_norm": 0.5716705918312073,
      "learning_rate": 1.549183673469388e-05,
      "loss": 0.0271,
      "step": 17410
    },
    {
      "epoch": 6.968,
      "grad_norm": 1.4501080513000488,
      "learning_rate": 1.5471428571428574e-05,
      "loss": 0.0291,
      "step": 17420
    },
    {
      "epoch": 6.9719999999999995,
      "grad_norm": 0.619358479976654,
      "learning_rate": 1.5451020408163266e-05,
      "loss": 0.113,
      "step": 17430
    },
    {
      "epoch": 6.976,
      "grad_norm": 0.463052898645401,
      "learning_rate": 1.543061224489796e-05,
      "loss": 0.0505,
      "step": 17440
    },
    {
      "epoch": 6.98,
      "grad_norm": 1.206961989402771,
      "learning_rate": 1.5410204081632652e-05,
      "loss": 0.0637,
      "step": 17450
    },
    {
      "epoch": 6.984,
      "grad_norm": 0.5293464064598083,
      "learning_rate": 1.5389795918367347e-05,
      "loss": 0.1004,
      "step": 17460
    },
    {
      "epoch": 6.9879999999999995,
      "grad_norm": 1.2424023151397705,
      "learning_rate": 1.5369387755102042e-05,
      "loss": 0.0474,
      "step": 17470
    },
    {
      "epoch": 6.992,
      "grad_norm": 0.30374160408973694,
      "learning_rate": 1.5348979591836734e-05,
      "loss": 0.0689,
      "step": 17480
    },
    {
      "epoch": 6.996,
      "grad_norm": 0.40843233466148376,
      "learning_rate": 1.532857142857143e-05,
      "loss": 0.0887,
      "step": 17490
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.8134373426437378,
      "learning_rate": 1.530816326530612e-05,
      "loss": 0.0656,
      "step": 17500
    },
    {
      "epoch": 7.004,
      "grad_norm": 0.514050304889679,
      "learning_rate": 1.528775510204082e-05,
      "loss": 0.0626,
      "step": 17510
    },
    {
      "epoch": 7.008,
      "grad_norm": 1.9514601230621338,
      "learning_rate": 1.526734693877551e-05,
      "loss": 0.0808,
      "step": 17520
    },
    {
      "epoch": 7.012,
      "grad_norm": 1.6261142492294312,
      "learning_rate": 1.5246938775510205e-05,
      "loss": 0.0977,
      "step": 17530
    },
    {
      "epoch": 7.016,
      "grad_norm": 0.12008330971002579,
      "learning_rate": 1.5226530612244899e-05,
      "loss": 0.0244,
      "step": 17540
    },
    {
      "epoch": 7.02,
      "grad_norm": 1.1666569709777832,
      "learning_rate": 1.5206122448979592e-05,
      "loss": 0.0678,
      "step": 17550
    },
    {
      "epoch": 7.024,
      "grad_norm": 0.3266807496547699,
      "learning_rate": 1.5185714285714287e-05,
      "loss": 0.0598,
      "step": 17560
    },
    {
      "epoch": 7.028,
      "grad_norm": 1.2631956338882446,
      "learning_rate": 1.516530612244898e-05,
      "loss": 0.0682,
      "step": 17570
    },
    {
      "epoch": 7.032,
      "grad_norm": 0.11049696803092957,
      "learning_rate": 1.5144897959183674e-05,
      "loss": 0.0165,
      "step": 17580
    },
    {
      "epoch": 7.036,
      "grad_norm": 1.674898624420166,
      "learning_rate": 1.5124489795918367e-05,
      "loss": 0.122,
      "step": 17590
    },
    {
      "epoch": 7.04,
      "grad_norm": 0.4920070469379425,
      "learning_rate": 1.5104081632653062e-05,
      "loss": 0.0558,
      "step": 17600
    },
    {
      "epoch": 7.044,
      "grad_norm": 0.8511152863502502,
      "learning_rate": 1.5083673469387755e-05,
      "loss": 0.0439,
      "step": 17610
    },
    {
      "epoch": 7.048,
      "grad_norm": 1.4219640493392944,
      "learning_rate": 1.5063265306122452e-05,
      "loss": 0.0315,
      "step": 17620
    },
    {
      "epoch": 7.052,
      "grad_norm": 0.3266175389289856,
      "learning_rate": 1.5042857142857145e-05,
      "loss": 0.0623,
      "step": 17630
    },
    {
      "epoch": 7.056,
      "grad_norm": 1.1148751974105835,
      "learning_rate": 1.5022448979591838e-05,
      "loss": 0.0578,
      "step": 17640
    },
    {
      "epoch": 7.06,
      "grad_norm": 0.5013390183448792,
      "learning_rate": 1.5002040816326532e-05,
      "loss": 0.0547,
      "step": 17650
    },
    {
      "epoch": 7.064,
      "grad_norm": 0.23123478889465332,
      "learning_rate": 1.4981632653061225e-05,
      "loss": 0.0945,
      "step": 17660
    },
    {
      "epoch": 7.068,
      "grad_norm": 0.4547010064125061,
      "learning_rate": 1.496122448979592e-05,
      "loss": 0.0792,
      "step": 17670
    },
    {
      "epoch": 7.072,
      "grad_norm": 0.10570725053548813,
      "learning_rate": 1.4940816326530613e-05,
      "loss": 0.0605,
      "step": 17680
    },
    {
      "epoch": 7.076,
      "grad_norm": 0.6999341249465942,
      "learning_rate": 1.4920408163265306e-05,
      "loss": 0.0547,
      "step": 17690
    },
    {
      "epoch": 7.08,
      "grad_norm": 0.5272121429443359,
      "learning_rate": 1.49e-05,
      "loss": 0.0719,
      "step": 17700
    },
    {
      "epoch": 7.084,
      "grad_norm": 0.8467863202095032,
      "learning_rate": 1.4879591836734693e-05,
      "loss": 0.0834,
      "step": 17710
    },
    {
      "epoch": 7.088,
      "grad_norm": 1.3756979703903198,
      "learning_rate": 1.4859183673469388e-05,
      "loss": 0.0809,
      "step": 17720
    },
    {
      "epoch": 7.092,
      "grad_norm": 1.1072847843170166,
      "learning_rate": 1.4838775510204081e-05,
      "loss": 0.0517,
      "step": 17730
    },
    {
      "epoch": 7.096,
      "grad_norm": 1.0814930200576782,
      "learning_rate": 1.4818367346938778e-05,
      "loss": 0.0854,
      "step": 17740
    },
    {
      "epoch": 7.1,
      "grad_norm": 2.130755662918091,
      "learning_rate": 1.4797959183673471e-05,
      "loss": 0.0715,
      "step": 17750
    },
    {
      "epoch": 7.104,
      "grad_norm": 1.4630521535873413,
      "learning_rate": 1.4777551020408164e-05,
      "loss": 0.0819,
      "step": 17760
    },
    {
      "epoch": 7.108,
      "grad_norm": 0.46924352645874023,
      "learning_rate": 1.4757142857142858e-05,
      "loss": 0.0352,
      "step": 17770
    },
    {
      "epoch": 7.112,
      "grad_norm": 0.7114757299423218,
      "learning_rate": 1.4736734693877553e-05,
      "loss": 0.0648,
      "step": 17780
    },
    {
      "epoch": 7.116,
      "grad_norm": 0.5210878252983093,
      "learning_rate": 1.4716326530612246e-05,
      "loss": 0.0421,
      "step": 17790
    },
    {
      "epoch": 7.12,
      "grad_norm": 1.4805212020874023,
      "learning_rate": 1.469591836734694e-05,
      "loss": 0.0876,
      "step": 17800
    },
    {
      "epoch": 7.124,
      "grad_norm": 0.2555529475212097,
      "learning_rate": 1.4675510204081632e-05,
      "loss": 0.0832,
      "step": 17810
    },
    {
      "epoch": 7.128,
      "grad_norm": 0.2493569403886795,
      "learning_rate": 1.4655102040816326e-05,
      "loss": 0.0643,
      "step": 17820
    },
    {
      "epoch": 7.132,
      "grad_norm": 1.9335455894470215,
      "learning_rate": 1.463469387755102e-05,
      "loss": 0.0684,
      "step": 17830
    },
    {
      "epoch": 7.136,
      "grad_norm": 0.9874733686447144,
      "learning_rate": 1.4614285714285714e-05,
      "loss": 0.0732,
      "step": 17840
    },
    {
      "epoch": 7.14,
      "grad_norm": 2.039849042892456,
      "learning_rate": 1.459387755102041e-05,
      "loss": 0.1132,
      "step": 17850
    },
    {
      "epoch": 7.144,
      "grad_norm": 0.6926344037055969,
      "learning_rate": 1.4573469387755104e-05,
      "loss": 0.0475,
      "step": 17860
    },
    {
      "epoch": 7.148,
      "grad_norm": 0.300904780626297,
      "learning_rate": 1.4553061224489797e-05,
      "loss": 0.0698,
      "step": 17870
    },
    {
      "epoch": 7.152,
      "grad_norm": 1.4941767454147339,
      "learning_rate": 1.453265306122449e-05,
      "loss": 0.0552,
      "step": 17880
    },
    {
      "epoch": 7.156,
      "grad_norm": 1.2692102193832397,
      "learning_rate": 1.4512244897959185e-05,
      "loss": 0.0463,
      "step": 17890
    },
    {
      "epoch": 7.16,
      "grad_norm": 0.6517243981361389,
      "learning_rate": 1.4491836734693879e-05,
      "loss": 0.0663,
      "step": 17900
    },
    {
      "epoch": 7.164,
      "grad_norm": 1.2008092403411865,
      "learning_rate": 1.4471428571428572e-05,
      "loss": 0.0631,
      "step": 17910
    },
    {
      "epoch": 7.168,
      "grad_norm": 0.7010400295257568,
      "learning_rate": 1.4451020408163265e-05,
      "loss": 0.0896,
      "step": 17920
    },
    {
      "epoch": 7.172,
      "grad_norm": 0.8632755279541016,
      "learning_rate": 1.4430612244897959e-05,
      "loss": 0.0311,
      "step": 17930
    },
    {
      "epoch": 7.176,
      "grad_norm": 0.4188610911369324,
      "learning_rate": 1.4410204081632654e-05,
      "loss": 0.0789,
      "step": 17940
    },
    {
      "epoch": 7.18,
      "grad_norm": 0.8343381285667419,
      "learning_rate": 1.4389795918367347e-05,
      "loss": 0.0875,
      "step": 17950
    },
    {
      "epoch": 7.184,
      "grad_norm": 1.7825992107391357,
      "learning_rate": 1.4369387755102044e-05,
      "loss": 0.0685,
      "step": 17960
    },
    {
      "epoch": 7.188,
      "grad_norm": 0.04259064793586731,
      "learning_rate": 1.4348979591836737e-05,
      "loss": 0.0443,
      "step": 17970
    },
    {
      "epoch": 7.192,
      "grad_norm": 0.33144575357437134,
      "learning_rate": 1.432857142857143e-05,
      "loss": 0.0493,
      "step": 17980
    },
    {
      "epoch": 7.196,
      "grad_norm": 1.842799186706543,
      "learning_rate": 1.4308163265306123e-05,
      "loss": 0.0733,
      "step": 17990
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.26544588804244995,
      "learning_rate": 1.4287755102040817e-05,
      "loss": 0.0445,
      "step": 18000
    },
    {
      "epoch": 7.204,
      "grad_norm": 1.5275839567184448,
      "learning_rate": 1.4267346938775512e-05,
      "loss": 0.0929,
      "step": 18010
    },
    {
      "epoch": 7.208,
      "grad_norm": 0.46261340379714966,
      "learning_rate": 1.4246938775510205e-05,
      "loss": 0.0448,
      "step": 18020
    },
    {
      "epoch": 7.212,
      "grad_norm": 0.19517263770103455,
      "learning_rate": 1.4226530612244898e-05,
      "loss": 0.0394,
      "step": 18030
    },
    {
      "epoch": 7.216,
      "grad_norm": 0.4683815836906433,
      "learning_rate": 1.4206122448979591e-05,
      "loss": 0.0694,
      "step": 18040
    },
    {
      "epoch": 7.22,
      "grad_norm": 1.6949596405029297,
      "learning_rate": 1.4185714285714285e-05,
      "loss": 0.0647,
      "step": 18050
    },
    {
      "epoch": 7.224,
      "grad_norm": 0.20823630690574646,
      "learning_rate": 1.416530612244898e-05,
      "loss": 0.0682,
      "step": 18060
    },
    {
      "epoch": 7.228,
      "grad_norm": 1.3217090368270874,
      "learning_rate": 1.4144897959183673e-05,
      "loss": 0.0482,
      "step": 18070
    },
    {
      "epoch": 7.232,
      "grad_norm": 0.25125589966773987,
      "learning_rate": 1.412448979591837e-05,
      "loss": 0.0511,
      "step": 18080
    },
    {
      "epoch": 7.236,
      "grad_norm": 1.6536422967910767,
      "learning_rate": 1.4104081632653063e-05,
      "loss": 0.0942,
      "step": 18090
    },
    {
      "epoch": 7.24,
      "grad_norm": 0.14623704552650452,
      "learning_rate": 1.4083673469387756e-05,
      "loss": 0.0232,
      "step": 18100
    },
    {
      "epoch": 7.244,
      "grad_norm": 1.5766358375549316,
      "learning_rate": 1.406326530612245e-05,
      "loss": 0.0508,
      "step": 18110
    },
    {
      "epoch": 7.248,
      "grad_norm": 0.7193964123725891,
      "learning_rate": 1.4042857142857144e-05,
      "loss": 0.0719,
      "step": 18120
    },
    {
      "epoch": 7.252,
      "grad_norm": 1.315058946609497,
      "learning_rate": 1.4022448979591838e-05,
      "loss": 0.0485,
      "step": 18130
    },
    {
      "epoch": 7.256,
      "grad_norm": 0.04819364473223686,
      "learning_rate": 1.4002040816326531e-05,
      "loss": 0.0467,
      "step": 18140
    },
    {
      "epoch": 7.26,
      "grad_norm": 0.9316926002502441,
      "learning_rate": 1.3981632653061224e-05,
      "loss": 0.0411,
      "step": 18150
    },
    {
      "epoch": 7.264,
      "grad_norm": 0.14119088649749756,
      "learning_rate": 1.3961224489795918e-05,
      "loss": 0.0717,
      "step": 18160
    },
    {
      "epoch": 7.268,
      "grad_norm": 1.1107560396194458,
      "learning_rate": 1.3940816326530612e-05,
      "loss": 0.0659,
      "step": 18170
    },
    {
      "epoch": 7.272,
      "grad_norm": 1.5630921125411987,
      "learning_rate": 1.3920408163265306e-05,
      "loss": 0.0473,
      "step": 18180
    },
    {
      "epoch": 7.276,
      "grad_norm": 0.07775966823101044,
      "learning_rate": 1.3900000000000002e-05,
      "loss": 0.0611,
      "step": 18190
    },
    {
      "epoch": 7.28,
      "grad_norm": 2.2171151638031006,
      "learning_rate": 1.3879591836734696e-05,
      "loss": 0.0737,
      "step": 18200
    },
    {
      "epoch": 7.284,
      "grad_norm": 1.3316763639450073,
      "learning_rate": 1.3859183673469389e-05,
      "loss": 0.0771,
      "step": 18210
    },
    {
      "epoch": 7.288,
      "grad_norm": 0.3472050726413727,
      "learning_rate": 1.3838775510204082e-05,
      "loss": 0.0651,
      "step": 18220
    },
    {
      "epoch": 7.292,
      "grad_norm": 0.6832900643348694,
      "learning_rate": 1.3818367346938777e-05,
      "loss": 0.0542,
      "step": 18230
    },
    {
      "epoch": 7.296,
      "grad_norm": 0.1453193873167038,
      "learning_rate": 1.379795918367347e-05,
      "loss": 0.0773,
      "step": 18240
    },
    {
      "epoch": 7.3,
      "grad_norm": 0.11882452666759491,
      "learning_rate": 1.3777551020408164e-05,
      "loss": 0.0705,
      "step": 18250
    },
    {
      "epoch": 7.304,
      "grad_norm": 1.1903679370880127,
      "learning_rate": 1.3757142857142857e-05,
      "loss": 0.0524,
      "step": 18260
    },
    {
      "epoch": 7.308,
      "grad_norm": 0.40482935309410095,
      "learning_rate": 1.373673469387755e-05,
      "loss": 0.0508,
      "step": 18270
    },
    {
      "epoch": 7.312,
      "grad_norm": 0.5937176942825317,
      "learning_rate": 1.3716326530612245e-05,
      "loss": 0.0536,
      "step": 18280
    },
    {
      "epoch": 7.316,
      "grad_norm": 0.2923588454723358,
      "learning_rate": 1.3695918367346939e-05,
      "loss": 0.0764,
      "step": 18290
    },
    {
      "epoch": 7.32,
      "grad_norm": 0.7335258722305298,
      "learning_rate": 1.3675510204081635e-05,
      "loss": 0.0539,
      "step": 18300
    },
    {
      "epoch": 7.324,
      "grad_norm": 1.7498499155044556,
      "learning_rate": 1.3655102040816329e-05,
      "loss": 0.0549,
      "step": 18310
    },
    {
      "epoch": 7.328,
      "grad_norm": 0.25893813371658325,
      "learning_rate": 1.3634693877551022e-05,
      "loss": 0.0632,
      "step": 18320
    },
    {
      "epoch": 7.332,
      "grad_norm": 0.8097575902938843,
      "learning_rate": 1.3614285714285715e-05,
      "loss": 0.1175,
      "step": 18330
    },
    {
      "epoch": 7.336,
      "grad_norm": 0.7343191504478455,
      "learning_rate": 1.3593877551020408e-05,
      "loss": 0.0657,
      "step": 18340
    },
    {
      "epoch": 7.34,
      "grad_norm": 0.8797561526298523,
      "learning_rate": 1.3573469387755103e-05,
      "loss": 0.0815,
      "step": 18350
    },
    {
      "epoch": 7.344,
      "grad_norm": 0.6667425036430359,
      "learning_rate": 1.3553061224489797e-05,
      "loss": 0.0765,
      "step": 18360
    },
    {
      "epoch": 7.348,
      "grad_norm": 2.1183290481567383,
      "learning_rate": 1.353265306122449e-05,
      "loss": 0.0598,
      "step": 18370
    },
    {
      "epoch": 7.352,
      "grad_norm": 1.152990460395813,
      "learning_rate": 1.3512244897959183e-05,
      "loss": 0.0592,
      "step": 18380
    },
    {
      "epoch": 7.356,
      "grad_norm": 0.9609631299972534,
      "learning_rate": 1.3491836734693878e-05,
      "loss": 0.069,
      "step": 18390
    },
    {
      "epoch": 7.36,
      "grad_norm": 0.9099262356758118,
      "learning_rate": 1.3471428571428571e-05,
      "loss": 0.0519,
      "step": 18400
    },
    {
      "epoch": 7.364,
      "grad_norm": 1.0882303714752197,
      "learning_rate": 1.3451020408163265e-05,
      "loss": 0.0748,
      "step": 18410
    },
    {
      "epoch": 7.368,
      "grad_norm": 1.4168190956115723,
      "learning_rate": 1.3430612244897961e-05,
      "loss": 0.0503,
      "step": 18420
    },
    {
      "epoch": 7.372,
      "grad_norm": 0.10499920696020126,
      "learning_rate": 1.3410204081632655e-05,
      "loss": 0.0807,
      "step": 18430
    },
    {
      "epoch": 7.376,
      "grad_norm": 0.48907095193862915,
      "learning_rate": 1.3389795918367348e-05,
      "loss": 0.0553,
      "step": 18440
    },
    {
      "epoch": 7.38,
      "grad_norm": 0.4612656235694885,
      "learning_rate": 1.3369387755102041e-05,
      "loss": 0.0427,
      "step": 18450
    },
    {
      "epoch": 7.384,
      "grad_norm": 0.11511680483818054,
      "learning_rate": 1.3348979591836736e-05,
      "loss": 0.1149,
      "step": 18460
    },
    {
      "epoch": 7.388,
      "grad_norm": 0.1657729595899582,
      "learning_rate": 1.332857142857143e-05,
      "loss": 0.0522,
      "step": 18470
    },
    {
      "epoch": 7.392,
      "grad_norm": 0.17677628993988037,
      "learning_rate": 1.3308163265306123e-05,
      "loss": 0.0613,
      "step": 18480
    },
    {
      "epoch": 7.396,
      "grad_norm": 0.2643475830554962,
      "learning_rate": 1.3287755102040816e-05,
      "loss": 0.0474,
      "step": 18490
    },
    {
      "epoch": 7.4,
      "grad_norm": 1.0601716041564941,
      "learning_rate": 1.326734693877551e-05,
      "loss": 0.0612,
      "step": 18500
    },
    {
      "epoch": 7.404,
      "grad_norm": 0.0025748477783054113,
      "learning_rate": 1.3246938775510204e-05,
      "loss": 0.0416,
      "step": 18510
    },
    {
      "epoch": 7.408,
      "grad_norm": 1.2218610048294067,
      "learning_rate": 1.3226530612244898e-05,
      "loss": 0.0715,
      "step": 18520
    },
    {
      "epoch": 7.412,
      "grad_norm": 0.5279141664505005,
      "learning_rate": 1.3206122448979594e-05,
      "loss": 0.0334,
      "step": 18530
    },
    {
      "epoch": 7.416,
      "grad_norm": 1.5472488403320312,
      "learning_rate": 1.3185714285714287e-05,
      "loss": 0.0599,
      "step": 18540
    },
    {
      "epoch": 7.42,
      "grad_norm": 0.3605060577392578,
      "learning_rate": 1.316530612244898e-05,
      "loss": 0.0578,
      "step": 18550
    },
    {
      "epoch": 7.424,
      "grad_norm": 1.1463673114776611,
      "learning_rate": 1.3144897959183674e-05,
      "loss": 0.0441,
      "step": 18560
    },
    {
      "epoch": 7.428,
      "grad_norm": 0.8569638729095459,
      "learning_rate": 1.3124489795918369e-05,
      "loss": 0.0748,
      "step": 18570
    },
    {
      "epoch": 7.432,
      "grad_norm": 0.49779564142227173,
      "learning_rate": 1.3104081632653062e-05,
      "loss": 0.0585,
      "step": 18580
    },
    {
      "epoch": 7.436,
      "grad_norm": 0.5486836433410645,
      "learning_rate": 1.3083673469387756e-05,
      "loss": 0.0483,
      "step": 18590
    },
    {
      "epoch": 7.44,
      "grad_norm": 0.6000205278396606,
      "learning_rate": 1.3063265306122449e-05,
      "loss": 0.0586,
      "step": 18600
    },
    {
      "epoch": 7.444,
      "grad_norm": 1.5784834623336792,
      "learning_rate": 1.3042857142857142e-05,
      "loss": 0.0706,
      "step": 18610
    },
    {
      "epoch": 7.448,
      "grad_norm": 1.0604544878005981,
      "learning_rate": 1.3022448979591837e-05,
      "loss": 0.0744,
      "step": 18620
    },
    {
      "epoch": 7.452,
      "grad_norm": 0.4437656104564667,
      "learning_rate": 1.300204081632653e-05,
      "loss": 0.0519,
      "step": 18630
    },
    {
      "epoch": 7.456,
      "grad_norm": 1.5138497352600098,
      "learning_rate": 1.2981632653061227e-05,
      "loss": 0.0809,
      "step": 18640
    },
    {
      "epoch": 7.46,
      "grad_norm": 0.4596967101097107,
      "learning_rate": 1.296122448979592e-05,
      "loss": 0.065,
      "step": 18650
    },
    {
      "epoch": 7.464,
      "grad_norm": 0.7880493998527527,
      "learning_rate": 1.2940816326530614e-05,
      "loss": 0.0726,
      "step": 18660
    },
    {
      "epoch": 7.468,
      "grad_norm": 0.19362176954746246,
      "learning_rate": 1.2920408163265307e-05,
      "loss": 0.0449,
      "step": 18670
    },
    {
      "epoch": 7.4719999999999995,
      "grad_norm": 1.6724296808242798,
      "learning_rate": 1.29e-05,
      "loss": 0.0982,
      "step": 18680
    },
    {
      "epoch": 7.476,
      "grad_norm": 0.751269519329071,
      "learning_rate": 1.2879591836734695e-05,
      "loss": 0.0447,
      "step": 18690
    },
    {
      "epoch": 7.48,
      "grad_norm": 0.068935826420784,
      "learning_rate": 1.2859183673469388e-05,
      "loss": 0.1076,
      "step": 18700
    },
    {
      "epoch": 7.484,
      "grad_norm": 0.12858688831329346,
      "learning_rate": 1.2838775510204082e-05,
      "loss": 0.0437,
      "step": 18710
    },
    {
      "epoch": 7.4879999999999995,
      "grad_norm": 0.7200573086738586,
      "learning_rate": 1.2818367346938775e-05,
      "loss": 0.0528,
      "step": 18720
    },
    {
      "epoch": 7.492,
      "grad_norm": 1.0058693885803223,
      "learning_rate": 1.279795918367347e-05,
      "loss": 0.0958,
      "step": 18730
    },
    {
      "epoch": 7.496,
      "grad_norm": 0.7652706503868103,
      "learning_rate": 1.2777551020408163e-05,
      "loss": 0.0582,
      "step": 18740
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.4275403022766113,
      "learning_rate": 1.2757142857142856e-05,
      "loss": 0.0754,
      "step": 18750
    },
    {
      "epoch": 7.504,
      "grad_norm": 0.1765926331281662,
      "learning_rate": 1.2736734693877553e-05,
      "loss": 0.0565,
      "step": 18760
    },
    {
      "epoch": 7.508,
      "grad_norm": 0.27151304483413696,
      "learning_rate": 1.2716326530612246e-05,
      "loss": 0.0327,
      "step": 18770
    },
    {
      "epoch": 7.5120000000000005,
      "grad_norm": 0.985033392906189,
      "learning_rate": 1.269591836734694e-05,
      "loss": 0.0425,
      "step": 18780
    },
    {
      "epoch": 7.516,
      "grad_norm": 1.8041367530822754,
      "learning_rate": 1.2675510204081633e-05,
      "loss": 0.0583,
      "step": 18790
    },
    {
      "epoch": 7.52,
      "grad_norm": 0.6995663046836853,
      "learning_rate": 1.2655102040816328e-05,
      "loss": 0.1007,
      "step": 18800
    },
    {
      "epoch": 7.524,
      "grad_norm": 1.012915015220642,
      "learning_rate": 1.2634693877551021e-05,
      "loss": 0.0412,
      "step": 18810
    },
    {
      "epoch": 7.5280000000000005,
      "grad_norm": 0.42033740878105164,
      "learning_rate": 1.2614285714285715e-05,
      "loss": 0.0264,
      "step": 18820
    },
    {
      "epoch": 7.532,
      "grad_norm": 1.9447474479675293,
      "learning_rate": 1.2593877551020408e-05,
      "loss": 0.0752,
      "step": 18830
    },
    {
      "epoch": 7.536,
      "grad_norm": 1.1230229139328003,
      "learning_rate": 1.2573469387755101e-05,
      "loss": 0.0536,
      "step": 18840
    },
    {
      "epoch": 7.54,
      "grad_norm": 0.5610507130622864,
      "learning_rate": 1.2553061224489796e-05,
      "loss": 0.0419,
      "step": 18850
    },
    {
      "epoch": 7.5440000000000005,
      "grad_norm": 1.2711106538772583,
      "learning_rate": 1.253265306122449e-05,
      "loss": 0.0406,
      "step": 18860
    },
    {
      "epoch": 7.548,
      "grad_norm": 1.7312849760055542,
      "learning_rate": 1.2512244897959186e-05,
      "loss": 0.0703,
      "step": 18870
    },
    {
      "epoch": 7.552,
      "grad_norm": 1.8871033191680908,
      "learning_rate": 1.2491836734693878e-05,
      "loss": 0.0773,
      "step": 18880
    },
    {
      "epoch": 7.556,
      "grad_norm": 0.0827174112200737,
      "learning_rate": 1.2471428571428571e-05,
      "loss": 0.0768,
      "step": 18890
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 1.8442491292953491,
      "learning_rate": 1.2451020408163266e-05,
      "loss": 0.0477,
      "step": 18900
    },
    {
      "epoch": 7.564,
      "grad_norm": 0.9196521043777466,
      "learning_rate": 1.243061224489796e-05,
      "loss": 0.0387,
      "step": 18910
    },
    {
      "epoch": 7.568,
      "grad_norm": 0.1285012662410736,
      "learning_rate": 1.2410204081632654e-05,
      "loss": 0.0852,
      "step": 18920
    },
    {
      "epoch": 7.572,
      "grad_norm": 0.7831681370735168,
      "learning_rate": 1.2389795918367347e-05,
      "loss": 0.0928,
      "step": 18930
    },
    {
      "epoch": 7.576,
      "grad_norm": 0.12303699553012848,
      "learning_rate": 1.236938775510204e-05,
      "loss": 0.0668,
      "step": 18940
    },
    {
      "epoch": 7.58,
      "grad_norm": 0.4830686151981354,
      "learning_rate": 1.2348979591836736e-05,
      "loss": 0.0612,
      "step": 18950
    },
    {
      "epoch": 7.584,
      "grad_norm": 1.5737665891647339,
      "learning_rate": 1.2328571428571429e-05,
      "loss": 0.0917,
      "step": 18960
    },
    {
      "epoch": 7.588,
      "grad_norm": 1.5420747995376587,
      "learning_rate": 1.2308163265306124e-05,
      "loss": 0.1038,
      "step": 18970
    },
    {
      "epoch": 7.592,
      "grad_norm": 0.3535310626029968,
      "learning_rate": 1.2287755102040817e-05,
      "loss": 0.0663,
      "step": 18980
    },
    {
      "epoch": 7.596,
      "grad_norm": 1.118524432182312,
      "learning_rate": 1.226734693877551e-05,
      "loss": 0.0612,
      "step": 18990
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.748365581035614,
      "learning_rate": 1.2246938775510204e-05,
      "loss": 0.0432,
      "step": 19000
    },
    {
      "epoch": 7.604,
      "grad_norm": 0.7509408593177795,
      "learning_rate": 1.2226530612244899e-05,
      "loss": 0.0753,
      "step": 19010
    },
    {
      "epoch": 7.608,
      "grad_norm": 0.16326159238815308,
      "learning_rate": 1.2206122448979594e-05,
      "loss": 0.0509,
      "step": 19020
    },
    {
      "epoch": 7.612,
      "grad_norm": 0.7077596783638,
      "learning_rate": 1.2185714285714287e-05,
      "loss": 0.036,
      "step": 19030
    },
    {
      "epoch": 7.616,
      "grad_norm": 1.5545872449874878,
      "learning_rate": 1.216530612244898e-05,
      "loss": 0.0827,
      "step": 19040
    },
    {
      "epoch": 7.62,
      "grad_norm": 0.8825254440307617,
      "learning_rate": 1.2144897959183673e-05,
      "loss": 0.0882,
      "step": 19050
    },
    {
      "epoch": 7.624,
      "grad_norm": 1.4643089771270752,
      "learning_rate": 1.2124489795918367e-05,
      "loss": 0.0638,
      "step": 19060
    },
    {
      "epoch": 7.628,
      "grad_norm": 0.6747699975967407,
      "learning_rate": 1.2104081632653062e-05,
      "loss": 0.0682,
      "step": 19070
    },
    {
      "epoch": 7.632,
      "grad_norm": 0.8607743978500366,
      "learning_rate": 1.2083673469387757e-05,
      "loss": 0.0897,
      "step": 19080
    },
    {
      "epoch": 7.636,
      "grad_norm": 0.6564971804618835,
      "learning_rate": 1.206326530612245e-05,
      "loss": 0.0799,
      "step": 19090
    },
    {
      "epoch": 7.64,
      "grad_norm": 0.596249520778656,
      "learning_rate": 1.2042857142857143e-05,
      "loss": 0.0635,
      "step": 19100
    },
    {
      "epoch": 7.644,
      "grad_norm": 1.4480055570602417,
      "learning_rate": 1.2022448979591837e-05,
      "loss": 0.0957,
      "step": 19110
    },
    {
      "epoch": 7.648,
      "grad_norm": 1.4645673036575317,
      "learning_rate": 1.2002040816326531e-05,
      "loss": 0.1087,
      "step": 19120
    },
    {
      "epoch": 7.652,
      "grad_norm": 0.9018569588661194,
      "learning_rate": 1.1981632653061225e-05,
      "loss": 0.0625,
      "step": 19130
    },
    {
      "epoch": 7.656,
      "grad_norm": 0.9647674560546875,
      "learning_rate": 1.196122448979592e-05,
      "loss": 0.0523,
      "step": 19140
    },
    {
      "epoch": 7.66,
      "grad_norm": 1.2472635507583618,
      "learning_rate": 1.1940816326530613e-05,
      "loss": 0.0914,
      "step": 19150
    },
    {
      "epoch": 7.664,
      "grad_norm": 0.1418094038963318,
      "learning_rate": 1.1920408163265306e-05,
      "loss": 0.0458,
      "step": 19160
    },
    {
      "epoch": 7.668,
      "grad_norm": 0.9960906505584717,
      "learning_rate": 1.19e-05,
      "loss": 0.0597,
      "step": 19170
    },
    {
      "epoch": 7.672,
      "grad_norm": 1.3061530590057373,
      "learning_rate": 1.1879591836734695e-05,
      "loss": 0.0684,
      "step": 19180
    },
    {
      "epoch": 7.676,
      "grad_norm": 0.989063560962677,
      "learning_rate": 1.185918367346939e-05,
      "loss": 0.1319,
      "step": 19190
    },
    {
      "epoch": 7.68,
      "grad_norm": 1.7689003944396973,
      "learning_rate": 1.1838775510204083e-05,
      "loss": 0.0718,
      "step": 19200
    },
    {
      "epoch": 7.684,
      "grad_norm": 0.1942005157470703,
      "learning_rate": 1.1818367346938776e-05,
      "loss": 0.0767,
      "step": 19210
    },
    {
      "epoch": 7.688,
      "grad_norm": 1.4219963550567627,
      "learning_rate": 1.179795918367347e-05,
      "loss": 0.0705,
      "step": 19220
    },
    {
      "epoch": 7.692,
      "grad_norm": 0.9545945525169373,
      "learning_rate": 1.1777551020408163e-05,
      "loss": 0.0712,
      "step": 19230
    },
    {
      "epoch": 7.696,
      "grad_norm": 0.184955433011055,
      "learning_rate": 1.1757142857142858e-05,
      "loss": 0.0642,
      "step": 19240
    },
    {
      "epoch": 7.7,
      "grad_norm": 0.12460111081600189,
      "learning_rate": 1.1736734693877553e-05,
      "loss": 0.0605,
      "step": 19250
    },
    {
      "epoch": 7.704,
      "grad_norm": 0.5360735058784485,
      "learning_rate": 1.1716326530612246e-05,
      "loss": 0.0559,
      "step": 19260
    },
    {
      "epoch": 7.708,
      "grad_norm": 0.8628742098808289,
      "learning_rate": 1.1695918367346939e-05,
      "loss": 0.0408,
      "step": 19270
    },
    {
      "epoch": 7.712,
      "grad_norm": 1.252890706062317,
      "learning_rate": 1.1675510204081632e-05,
      "loss": 0.0978,
      "step": 19280
    },
    {
      "epoch": 7.716,
      "grad_norm": 0.575986385345459,
      "learning_rate": 1.1655102040816326e-05,
      "loss": 0.0692,
      "step": 19290
    },
    {
      "epoch": 7.72,
      "grad_norm": 1.2663867473602295,
      "learning_rate": 1.163469387755102e-05,
      "loss": 0.081,
      "step": 19300
    },
    {
      "epoch": 7.724,
      "grad_norm": 0.48155105113983154,
      "learning_rate": 1.1614285714285716e-05,
      "loss": 0.0553,
      "step": 19310
    },
    {
      "epoch": 7.728,
      "grad_norm": 1.3478645086288452,
      "learning_rate": 1.1593877551020409e-05,
      "loss": 0.0804,
      "step": 19320
    },
    {
      "epoch": 7.732,
      "grad_norm": 0.6498727202415466,
      "learning_rate": 1.1573469387755102e-05,
      "loss": 0.0314,
      "step": 19330
    },
    {
      "epoch": 7.736,
      "grad_norm": 0.6714150309562683,
      "learning_rate": 1.1553061224489795e-05,
      "loss": 0.0441,
      "step": 19340
    },
    {
      "epoch": 7.74,
      "grad_norm": 0.561852216720581,
      "learning_rate": 1.153265306122449e-05,
      "loss": 0.0659,
      "step": 19350
    },
    {
      "epoch": 7.744,
      "grad_norm": 1.4182047843933105,
      "learning_rate": 1.1512244897959185e-05,
      "loss": 0.0621,
      "step": 19360
    },
    {
      "epoch": 7.748,
      "grad_norm": 0.3472466766834259,
      "learning_rate": 1.1491836734693879e-05,
      "loss": 0.1195,
      "step": 19370
    },
    {
      "epoch": 7.752,
      "grad_norm": 1.3402001857757568,
      "learning_rate": 1.1471428571428572e-05,
      "loss": 0.0357,
      "step": 19380
    },
    {
      "epoch": 7.756,
      "grad_norm": 0.2092643827199936,
      "learning_rate": 1.1451020408163265e-05,
      "loss": 0.094,
      "step": 19390
    },
    {
      "epoch": 7.76,
      "grad_norm": 2.0658609867095947,
      "learning_rate": 1.1430612244897959e-05,
      "loss": 0.0974,
      "step": 19400
    },
    {
      "epoch": 7.764,
      "grad_norm": 1.7041560411453247,
      "learning_rate": 1.1410204081632653e-05,
      "loss": 0.0796,
      "step": 19410
    },
    {
      "epoch": 7.768,
      "grad_norm": 0.39693471789360046,
      "learning_rate": 1.1389795918367348e-05,
      "loss": 0.0391,
      "step": 19420
    },
    {
      "epoch": 7.772,
      "grad_norm": 1.2048141956329346,
      "learning_rate": 1.1369387755102042e-05,
      "loss": 0.0577,
      "step": 19430
    },
    {
      "epoch": 7.776,
      "grad_norm": 0.45923614501953125,
      "learning_rate": 1.1348979591836735e-05,
      "loss": 0.0383,
      "step": 19440
    },
    {
      "epoch": 7.78,
      "grad_norm": 0.6876046657562256,
      "learning_rate": 1.1328571428571428e-05,
      "loss": 0.0764,
      "step": 19450
    },
    {
      "epoch": 7.784,
      "grad_norm": 0.7984161376953125,
      "learning_rate": 1.1308163265306122e-05,
      "loss": 0.0695,
      "step": 19460
    },
    {
      "epoch": 7.788,
      "grad_norm": 0.04868084192276001,
      "learning_rate": 1.1287755102040817e-05,
      "loss": 0.0465,
      "step": 19470
    },
    {
      "epoch": 7.792,
      "grad_norm": 0.1087094247341156,
      "learning_rate": 1.1267346938775512e-05,
      "loss": 0.0504,
      "step": 19480
    },
    {
      "epoch": 7.796,
      "grad_norm": 0.7337431311607361,
      "learning_rate": 1.1246938775510205e-05,
      "loss": 0.0537,
      "step": 19490
    },
    {
      "epoch": 7.8,
      "grad_norm": 2.127884864807129,
      "learning_rate": 1.1226530612244898e-05,
      "loss": 0.0801,
      "step": 19500
    },
    {
      "epoch": 7.804,
      "grad_norm": 1.13591730594635,
      "learning_rate": 1.1206122448979591e-05,
      "loss": 0.0644,
      "step": 19510
    },
    {
      "epoch": 7.808,
      "grad_norm": 0.2610950469970703,
      "learning_rate": 1.1185714285714286e-05,
      "loss": 0.0922,
      "step": 19520
    },
    {
      "epoch": 7.812,
      "grad_norm": 0.031053027138113976,
      "learning_rate": 1.1165306122448981e-05,
      "loss": 0.0462,
      "step": 19530
    },
    {
      "epoch": 7.816,
      "grad_norm": 0.2732051610946655,
      "learning_rate": 1.1144897959183675e-05,
      "loss": 0.0292,
      "step": 19540
    },
    {
      "epoch": 7.82,
      "grad_norm": 0.7880823016166687,
      "learning_rate": 1.1124489795918368e-05,
      "loss": 0.0571,
      "step": 19550
    },
    {
      "epoch": 7.824,
      "grad_norm": 0.12491465359926224,
      "learning_rate": 1.1104081632653061e-05,
      "loss": 0.0444,
      "step": 19560
    },
    {
      "epoch": 7.828,
      "grad_norm": 0.37527915835380554,
      "learning_rate": 1.1083673469387754e-05,
      "loss": 0.0295,
      "step": 19570
    },
    {
      "epoch": 7.832,
      "grad_norm": 0.5400674939155579,
      "learning_rate": 1.106326530612245e-05,
      "loss": 0.0655,
      "step": 19580
    },
    {
      "epoch": 7.836,
      "grad_norm": 0.10390499979257584,
      "learning_rate": 1.1042857142857144e-05,
      "loss": 0.034,
      "step": 19590
    },
    {
      "epoch": 7.84,
      "grad_norm": 0.6824573278427124,
      "learning_rate": 1.1022448979591838e-05,
      "loss": 0.077,
      "step": 19600
    },
    {
      "epoch": 7.844,
      "grad_norm": 1.3068745136260986,
      "learning_rate": 1.1002040816326531e-05,
      "loss": 0.0668,
      "step": 19610
    },
    {
      "epoch": 7.848,
      "grad_norm": 0.03785616159439087,
      "learning_rate": 1.0981632653061224e-05,
      "loss": 0.0447,
      "step": 19620
    },
    {
      "epoch": 7.852,
      "grad_norm": 0.5987409353256226,
      "learning_rate": 1.0961224489795917e-05,
      "loss": 0.0518,
      "step": 19630
    },
    {
      "epoch": 7.856,
      "grad_norm": 0.9949602484703064,
      "learning_rate": 1.0940816326530612e-05,
      "loss": 0.0476,
      "step": 19640
    },
    {
      "epoch": 7.86,
      "grad_norm": 1.4176348447799683,
      "learning_rate": 1.0920408163265307e-05,
      "loss": 0.057,
      "step": 19650
    },
    {
      "epoch": 7.864,
      "grad_norm": 2.3196094036102295,
      "learning_rate": 1.09e-05,
      "loss": 0.0878,
      "step": 19660
    },
    {
      "epoch": 7.868,
      "grad_norm": 1.2365832328796387,
      "learning_rate": 1.0879591836734694e-05,
      "loss": 0.0942,
      "step": 19670
    },
    {
      "epoch": 7.872,
      "grad_norm": 2.044788360595703,
      "learning_rate": 1.0859183673469387e-05,
      "loss": 0.0715,
      "step": 19680
    },
    {
      "epoch": 7.876,
      "grad_norm": 0.6305751800537109,
      "learning_rate": 1.0838775510204082e-05,
      "loss": 0.0353,
      "step": 19690
    },
    {
      "epoch": 7.88,
      "grad_norm": 1.3630025386810303,
      "learning_rate": 1.0818367346938777e-05,
      "loss": 0.0877,
      "step": 19700
    },
    {
      "epoch": 7.884,
      "grad_norm": 0.07490849494934082,
      "learning_rate": 1.079795918367347e-05,
      "loss": 0.0983,
      "step": 19710
    },
    {
      "epoch": 7.888,
      "grad_norm": 0.28144940733909607,
      "learning_rate": 1.0777551020408164e-05,
      "loss": 0.0911,
      "step": 19720
    },
    {
      "epoch": 7.892,
      "grad_norm": 1.292868733406067,
      "learning_rate": 1.0757142857142857e-05,
      "loss": 0.0606,
      "step": 19730
    },
    {
      "epoch": 7.896,
      "grad_norm": 1.2974262237548828,
      "learning_rate": 1.073673469387755e-05,
      "loss": 0.0816,
      "step": 19740
    },
    {
      "epoch": 7.9,
      "grad_norm": 1.8675376176834106,
      "learning_rate": 1.0716326530612245e-05,
      "loss": 0.0722,
      "step": 19750
    },
    {
      "epoch": 7.904,
      "grad_norm": 0.2635406255722046,
      "learning_rate": 1.069591836734694e-05,
      "loss": 0.0559,
      "step": 19760
    },
    {
      "epoch": 7.908,
      "grad_norm": 0.6761013865470886,
      "learning_rate": 1.0675510204081634e-05,
      "loss": 0.0601,
      "step": 19770
    },
    {
      "epoch": 7.912,
      "grad_norm": 0.09400537610054016,
      "learning_rate": 1.0655102040816327e-05,
      "loss": 0.079,
      "step": 19780
    },
    {
      "epoch": 7.916,
      "grad_norm": 0.2514006793498993,
      "learning_rate": 1.063469387755102e-05,
      "loss": 0.044,
      "step": 19790
    },
    {
      "epoch": 7.92,
      "grad_norm": 1.0540000200271606,
      "learning_rate": 1.0614285714285713e-05,
      "loss": 0.0687,
      "step": 19800
    },
    {
      "epoch": 7.924,
      "grad_norm": 0.0819811299443245,
      "learning_rate": 1.0593877551020408e-05,
      "loss": 0.0405,
      "step": 19810
    },
    {
      "epoch": 7.928,
      "grad_norm": 0.9737342000007629,
      "learning_rate": 1.0573469387755103e-05,
      "loss": 0.119,
      "step": 19820
    },
    {
      "epoch": 7.932,
      "grad_norm": 0.7505801916122437,
      "learning_rate": 1.0553061224489797e-05,
      "loss": 0.0612,
      "step": 19830
    },
    {
      "epoch": 7.936,
      "grad_norm": 0.4480889141559601,
      "learning_rate": 1.053265306122449e-05,
      "loss": 0.0805,
      "step": 19840
    },
    {
      "epoch": 7.9399999999999995,
      "grad_norm": 0.12514878809452057,
      "learning_rate": 1.0512244897959183e-05,
      "loss": 0.0541,
      "step": 19850
    },
    {
      "epoch": 7.944,
      "grad_norm": 0.28821849822998047,
      "learning_rate": 1.0491836734693878e-05,
      "loss": 0.0669,
      "step": 19860
    },
    {
      "epoch": 7.948,
      "grad_norm": 1.661971926689148,
      "learning_rate": 1.0471428571428573e-05,
      "loss": 0.0959,
      "step": 19870
    },
    {
      "epoch": 7.952,
      "grad_norm": 0.794558048248291,
      "learning_rate": 1.0451020408163266e-05,
      "loss": 0.1032,
      "step": 19880
    },
    {
      "epoch": 7.9559999999999995,
      "grad_norm": 0.9470701813697815,
      "learning_rate": 1.043061224489796e-05,
      "loss": 0.0563,
      "step": 19890
    },
    {
      "epoch": 7.96,
      "grad_norm": 0.06571537256240845,
      "learning_rate": 1.0410204081632653e-05,
      "loss": 0.0692,
      "step": 19900
    },
    {
      "epoch": 7.964,
      "grad_norm": 0.781015932559967,
      "learning_rate": 1.0389795918367346e-05,
      "loss": 0.0617,
      "step": 19910
    },
    {
      "epoch": 7.968,
      "grad_norm": 2.0028674602508545,
      "learning_rate": 1.0369387755102041e-05,
      "loss": 0.0759,
      "step": 19920
    },
    {
      "epoch": 7.9719999999999995,
      "grad_norm": 0.43493902683258057,
      "learning_rate": 1.0348979591836736e-05,
      "loss": 0.0351,
      "step": 19930
    },
    {
      "epoch": 7.976,
      "grad_norm": 0.09709754586219788,
      "learning_rate": 1.032857142857143e-05,
      "loss": 0.0495,
      "step": 19940
    },
    {
      "epoch": 7.98,
      "grad_norm": 0.12469026446342468,
      "learning_rate": 1.0308163265306123e-05,
      "loss": 0.0574,
      "step": 19950
    },
    {
      "epoch": 7.984,
      "grad_norm": 0.14562787115573883,
      "learning_rate": 1.0287755102040816e-05,
      "loss": 0.0723,
      "step": 19960
    },
    {
      "epoch": 7.9879999999999995,
      "grad_norm": 0.31489241123199463,
      "learning_rate": 1.026734693877551e-05,
      "loss": 0.0451,
      "step": 19970
    },
    {
      "epoch": 7.992,
      "grad_norm": 0.2619401812553406,
      "learning_rate": 1.0246938775510204e-05,
      "loss": 0.0544,
      "step": 19980
    },
    {
      "epoch": 7.996,
      "grad_norm": 0.1544412523508072,
      "learning_rate": 1.02265306122449e-05,
      "loss": 0.0447,
      "step": 19990
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.2149863243103027,
      "learning_rate": 1.0206122448979592e-05,
      "loss": 0.0837,
      "step": 20000
    },
    {
      "epoch": 8.004,
      "grad_norm": 1.0657548904418945,
      "learning_rate": 1.0185714285714286e-05,
      "loss": 0.0552,
      "step": 20010
    },
    {
      "epoch": 8.008,
      "grad_norm": 1.187596321105957,
      "learning_rate": 1.0165306122448979e-05,
      "loss": 0.0584,
      "step": 20020
    },
    {
      "epoch": 8.012,
      "grad_norm": 0.09069599956274033,
      "learning_rate": 1.0144897959183674e-05,
      "loss": 0.0799,
      "step": 20030
    },
    {
      "epoch": 8.016,
      "grad_norm": 1.2100657224655151,
      "learning_rate": 1.0124489795918369e-05,
      "loss": 0.087,
      "step": 20040
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.2764580547809601,
      "learning_rate": 1.0104081632653062e-05,
      "loss": 0.046,
      "step": 20050
    },
    {
      "epoch": 8.024,
      "grad_norm": 2.1193809509277344,
      "learning_rate": 1.0083673469387755e-05,
      "loss": 0.0784,
      "step": 20060
    },
    {
      "epoch": 8.028,
      "grad_norm": 0.1420256495475769,
      "learning_rate": 1.0063265306122449e-05,
      "loss": 0.0693,
      "step": 20070
    },
    {
      "epoch": 8.032,
      "grad_norm": 0.9532303810119629,
      "learning_rate": 1.0042857142857142e-05,
      "loss": 0.0852,
      "step": 20080
    },
    {
      "epoch": 8.036,
      "grad_norm": 0.495983749628067,
      "learning_rate": 1.0022448979591837e-05,
      "loss": 0.0336,
      "step": 20090
    },
    {
      "epoch": 8.04,
      "grad_norm": 2.126424789428711,
      "learning_rate": 1.0002040816326532e-05,
      "loss": 0.0935,
      "step": 20100
    },
    {
      "epoch": 8.044,
      "grad_norm": 1.3118352890014648,
      "learning_rate": 9.981632653061225e-06,
      "loss": 0.0874,
      "step": 20110
    },
    {
      "epoch": 8.048,
      "grad_norm": 1.2012301683425903,
      "learning_rate": 9.961224489795919e-06,
      "loss": 0.0903,
      "step": 20120
    },
    {
      "epoch": 8.052,
      "grad_norm": 1.487209439277649,
      "learning_rate": 9.940816326530612e-06,
      "loss": 0.0737,
      "step": 20130
    },
    {
      "epoch": 8.056,
      "grad_norm": 0.39364027976989746,
      "learning_rate": 9.920408163265305e-06,
      "loss": 0.058,
      "step": 20140
    },
    {
      "epoch": 8.06,
      "grad_norm": 1.4627776145935059,
      "learning_rate": 9.900000000000002e-06,
      "loss": 0.0963,
      "step": 20150
    },
    {
      "epoch": 8.064,
      "grad_norm": 1.2008593082427979,
      "learning_rate": 9.879591836734695e-06,
      "loss": 0.071,
      "step": 20160
    },
    {
      "epoch": 8.068,
      "grad_norm": 0.6994799375534058,
      "learning_rate": 9.859183673469388e-06,
      "loss": 0.0303,
      "step": 20170
    },
    {
      "epoch": 8.072,
      "grad_norm": 0.6524596214294434,
      "learning_rate": 9.838775510204082e-06,
      "loss": 0.0653,
      "step": 20180
    },
    {
      "epoch": 8.076,
      "grad_norm": 1.141397476196289,
      "learning_rate": 9.818367346938775e-06,
      "loss": 0.0324,
      "step": 20190
    },
    {
      "epoch": 8.08,
      "grad_norm": 0.17816075682640076,
      "learning_rate": 9.79795918367347e-06,
      "loss": 0.0196,
      "step": 20200
    },
    {
      "epoch": 8.084,
      "grad_norm": 1.0227347612380981,
      "learning_rate": 9.777551020408165e-06,
      "loss": 0.0541,
      "step": 20210
    },
    {
      "epoch": 8.088,
      "grad_norm": 0.44753730297088623,
      "learning_rate": 9.757142857142858e-06,
      "loss": 0.0515,
      "step": 20220
    },
    {
      "epoch": 8.092,
      "grad_norm": 1.1317836046218872,
      "learning_rate": 9.736734693877551e-06,
      "loss": 0.0368,
      "step": 20230
    },
    {
      "epoch": 8.096,
      "grad_norm": 0.11407333612442017,
      "learning_rate": 9.716326530612245e-06,
      "loss": 0.0553,
      "step": 20240
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.49364981055259705,
      "learning_rate": 9.695918367346938e-06,
      "loss": 0.0532,
      "step": 20250
    },
    {
      "epoch": 8.104,
      "grad_norm": 0.27428948879241943,
      "learning_rate": 9.675510204081633e-06,
      "loss": 0.118,
      "step": 20260
    },
    {
      "epoch": 8.108,
      "grad_norm": 0.1022457629442215,
      "learning_rate": 9.655102040816328e-06,
      "loss": 0.0573,
      "step": 20270
    },
    {
      "epoch": 8.112,
      "grad_norm": 1.4387695789337158,
      "learning_rate": 9.634693877551021e-06,
      "loss": 0.0701,
      "step": 20280
    },
    {
      "epoch": 8.116,
      "grad_norm": 0.014705524779856205,
      "learning_rate": 9.614285714285714e-06,
      "loss": 0.0692,
      "step": 20290
    },
    {
      "epoch": 8.12,
      "grad_norm": 1.457299828529358,
      "learning_rate": 9.593877551020408e-06,
      "loss": 0.0808,
      "step": 20300
    },
    {
      "epoch": 8.124,
      "grad_norm": 0.08670387417078018,
      "learning_rate": 9.573469387755101e-06,
      "loss": 0.0412,
      "step": 20310
    },
    {
      "epoch": 8.128,
      "grad_norm": 0.28342801332473755,
      "learning_rate": 9.553061224489798e-06,
      "loss": 0.0559,
      "step": 20320
    },
    {
      "epoch": 8.132,
      "grad_norm": 1.437612771987915,
      "learning_rate": 9.532653061224491e-06,
      "loss": 0.0644,
      "step": 20330
    },
    {
      "epoch": 8.136,
      "grad_norm": 0.23804566264152527,
      "learning_rate": 9.512244897959184e-06,
      "loss": 0.082,
      "step": 20340
    },
    {
      "epoch": 8.14,
      "grad_norm": 0.4637630879878998,
      "learning_rate": 9.491836734693877e-06,
      "loss": 0.0459,
      "step": 20350
    },
    {
      "epoch": 8.144,
      "grad_norm": 0.7068029642105103,
      "learning_rate": 9.47142857142857e-06,
      "loss": 0.0938,
      "step": 20360
    },
    {
      "epoch": 8.148,
      "grad_norm": 0.3326106369495392,
      "learning_rate": 9.451020408163266e-06,
      "loss": 0.0604,
      "step": 20370
    },
    {
      "epoch": 8.152,
      "grad_norm": 0.3943490982055664,
      "learning_rate": 9.43061224489796e-06,
      "loss": 0.045,
      "step": 20380
    },
    {
      "epoch": 8.156,
      "grad_norm": 0.03681977093219757,
      "learning_rate": 9.410204081632654e-06,
      "loss": 0.049,
      "step": 20390
    },
    {
      "epoch": 8.16,
      "grad_norm": 0.35312986373901367,
      "learning_rate": 9.389795918367347e-06,
      "loss": 0.0409,
      "step": 20400
    },
    {
      "epoch": 8.164,
      "grad_norm": 1.2562322616577148,
      "learning_rate": 9.36938775510204e-06,
      "loss": 0.0806,
      "step": 20410
    },
    {
      "epoch": 8.168,
      "grad_norm": 1.8048275709152222,
      "learning_rate": 9.348979591836734e-06,
      "loss": 0.08,
      "step": 20420
    },
    {
      "epoch": 8.172,
      "grad_norm": 0.8977206349372864,
      "learning_rate": 9.328571428571429e-06,
      "loss": 0.0601,
      "step": 20430
    },
    {
      "epoch": 8.176,
      "grad_norm": 1.5406162738800049,
      "learning_rate": 9.308163265306124e-06,
      "loss": 0.0781,
      "step": 20440
    },
    {
      "epoch": 8.18,
      "grad_norm": 0.8431692719459534,
      "learning_rate": 9.287755102040817e-06,
      "loss": 0.0323,
      "step": 20450
    },
    {
      "epoch": 8.184,
      "grad_norm": 1.252599835395813,
      "learning_rate": 9.26734693877551e-06,
      "loss": 0.0524,
      "step": 20460
    },
    {
      "epoch": 8.188,
      "grad_norm": 1.0034310817718506,
      "learning_rate": 9.246938775510204e-06,
      "loss": 0.1053,
      "step": 20470
    },
    {
      "epoch": 8.192,
      "grad_norm": 0.838312029838562,
      "learning_rate": 9.226530612244899e-06,
      "loss": 0.0604,
      "step": 20480
    },
    {
      "epoch": 8.196,
      "grad_norm": 0.3299233019351959,
      "learning_rate": 9.206122448979594e-06,
      "loss": 0.0242,
      "step": 20490
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.31275275349617004,
      "learning_rate": 9.185714285714287e-06,
      "loss": 0.0569,
      "step": 20500
    },
    {
      "epoch": 8.204,
      "grad_norm": 0.2586154341697693,
      "learning_rate": 9.16530612244898e-06,
      "loss": 0.0582,
      "step": 20510
    },
    {
      "epoch": 8.208,
      "grad_norm": 0.6491708159446716,
      "learning_rate": 9.144897959183673e-06,
      "loss": 0.1063,
      "step": 20520
    },
    {
      "epoch": 8.212,
      "grad_norm": 0.3170880675315857,
      "learning_rate": 9.124489795918367e-06,
      "loss": 0.0833,
      "step": 20530
    },
    {
      "epoch": 8.216,
      "grad_norm": 1.757542610168457,
      "learning_rate": 9.104081632653062e-06,
      "loss": 0.0788,
      "step": 20540
    },
    {
      "epoch": 8.22,
      "grad_norm": 0.44033852219581604,
      "learning_rate": 9.083673469387757e-06,
      "loss": 0.0533,
      "step": 20550
    },
    {
      "epoch": 8.224,
      "grad_norm": 1.1195579767227173,
      "learning_rate": 9.06326530612245e-06,
      "loss": 0.0419,
      "step": 20560
    },
    {
      "epoch": 8.228,
      "grad_norm": 1.222568154335022,
      "learning_rate": 9.042857142857143e-06,
      "loss": 0.0387,
      "step": 20570
    },
    {
      "epoch": 8.232,
      "grad_norm": 0.3786439299583435,
      "learning_rate": 9.022448979591836e-06,
      "loss": 0.0847,
      "step": 20580
    },
    {
      "epoch": 8.236,
      "grad_norm": 0.09011529386043549,
      "learning_rate": 9.00204081632653e-06,
      "loss": 0.0187,
      "step": 20590
    },
    {
      "epoch": 8.24,
      "grad_norm": 0.867326557636261,
      "learning_rate": 8.981632653061225e-06,
      "loss": 0.056,
      "step": 20600
    },
    {
      "epoch": 8.244,
      "grad_norm": 1.2504644393920898,
      "learning_rate": 8.96122448979592e-06,
      "loss": 0.0947,
      "step": 20610
    },
    {
      "epoch": 8.248,
      "grad_norm": 2.4103739261627197,
      "learning_rate": 8.940816326530613e-06,
      "loss": 0.1059,
      "step": 20620
    },
    {
      "epoch": 8.252,
      "grad_norm": 0.6767240166664124,
      "learning_rate": 8.920408163265306e-06,
      "loss": 0.0678,
      "step": 20630
    },
    {
      "epoch": 8.256,
      "grad_norm": 1.8749934434890747,
      "learning_rate": 8.9e-06,
      "loss": 0.0848,
      "step": 20640
    },
    {
      "epoch": 8.26,
      "grad_norm": 0.4494166970252991,
      "learning_rate": 8.879591836734694e-06,
      "loss": 0.0857,
      "step": 20650
    },
    {
      "epoch": 8.264,
      "grad_norm": 0.9794719815254211,
      "learning_rate": 8.85918367346939e-06,
      "loss": 0.0431,
      "step": 20660
    },
    {
      "epoch": 8.268,
      "grad_norm": 0.4588441550731659,
      "learning_rate": 8.838775510204083e-06,
      "loss": 0.0561,
      "step": 20670
    },
    {
      "epoch": 8.272,
      "grad_norm": 1.1525347232818604,
      "learning_rate": 8.818367346938776e-06,
      "loss": 0.0593,
      "step": 20680
    },
    {
      "epoch": 8.276,
      "grad_norm": 1.0109753608703613,
      "learning_rate": 8.79795918367347e-06,
      "loss": 0.0279,
      "step": 20690
    },
    {
      "epoch": 8.28,
      "grad_norm": 0.859478771686554,
      "learning_rate": 8.777551020408163e-06,
      "loss": 0.1427,
      "step": 20700
    },
    {
      "epoch": 8.284,
      "grad_norm": 1.1377710103988647,
      "learning_rate": 8.757142857142858e-06,
      "loss": 0.0681,
      "step": 20710
    },
    {
      "epoch": 8.288,
      "grad_norm": 0.14640100300312042,
      "learning_rate": 8.736734693877552e-06,
      "loss": 0.0612,
      "step": 20720
    },
    {
      "epoch": 8.292,
      "grad_norm": 1.4461277723312378,
      "learning_rate": 8.716326530612246e-06,
      "loss": 0.0936,
      "step": 20730
    },
    {
      "epoch": 8.296,
      "grad_norm": 0.7441148161888123,
      "learning_rate": 8.695918367346939e-06,
      "loss": 0.0627,
      "step": 20740
    },
    {
      "epoch": 8.3,
      "grad_norm": 1.2542574405670166,
      "learning_rate": 8.675510204081632e-06,
      "loss": 0.0512,
      "step": 20750
    },
    {
      "epoch": 8.304,
      "grad_norm": 1.211333990097046,
      "learning_rate": 8.655102040816326e-06,
      "loss": 0.0508,
      "step": 20760
    },
    {
      "epoch": 8.308,
      "grad_norm": 0.5668941140174866,
      "learning_rate": 8.63469387755102e-06,
      "loss": 0.0374,
      "step": 20770
    },
    {
      "epoch": 8.312,
      "grad_norm": 1.060953140258789,
      "learning_rate": 8.614285714285716e-06,
      "loss": 0.0384,
      "step": 20780
    },
    {
      "epoch": 8.316,
      "grad_norm": 0.9366180896759033,
      "learning_rate": 8.593877551020409e-06,
      "loss": 0.0551,
      "step": 20790
    },
    {
      "epoch": 8.32,
      "grad_norm": 1.407869815826416,
      "learning_rate": 8.573469387755102e-06,
      "loss": 0.0931,
      "step": 20800
    },
    {
      "epoch": 8.324,
      "grad_norm": 0.6727648973464966,
      "learning_rate": 8.553061224489795e-06,
      "loss": 0.0748,
      "step": 20810
    },
    {
      "epoch": 8.328,
      "grad_norm": 0.40136685967445374,
      "learning_rate": 8.53265306122449e-06,
      "loss": 0.0438,
      "step": 20820
    },
    {
      "epoch": 8.332,
      "grad_norm": 0.21690486371517181,
      "learning_rate": 8.512244897959185e-06,
      "loss": 0.0496,
      "step": 20830
    },
    {
      "epoch": 8.336,
      "grad_norm": 0.694771409034729,
      "learning_rate": 8.491836734693879e-06,
      "loss": 0.0468,
      "step": 20840
    },
    {
      "epoch": 8.34,
      "grad_norm": 0.3206353187561035,
      "learning_rate": 8.471428571428572e-06,
      "loss": 0.0594,
      "step": 20850
    },
    {
      "epoch": 8.344,
      "grad_norm": 1.1887574195861816,
      "learning_rate": 8.451020408163265e-06,
      "loss": 0.0596,
      "step": 20860
    },
    {
      "epoch": 8.348,
      "grad_norm": 0.6039131879806519,
      "learning_rate": 8.430612244897958e-06,
      "loss": 0.0492,
      "step": 20870
    },
    {
      "epoch": 8.352,
      "grad_norm": 1.138405680656433,
      "learning_rate": 8.410204081632653e-06,
      "loss": 0.0706,
      "step": 20880
    },
    {
      "epoch": 8.356,
      "grad_norm": 0.7422482371330261,
      "learning_rate": 8.389795918367348e-06,
      "loss": 0.0645,
      "step": 20890
    },
    {
      "epoch": 8.36,
      "grad_norm": 1.8049954175949097,
      "learning_rate": 8.369387755102042e-06,
      "loss": 0.0761,
      "step": 20900
    },
    {
      "epoch": 8.364,
      "grad_norm": 0.7925271987915039,
      "learning_rate": 8.348979591836735e-06,
      "loss": 0.0541,
      "step": 20910
    },
    {
      "epoch": 8.368,
      "grad_norm": 1.5445187091827393,
      "learning_rate": 8.328571428571428e-06,
      "loss": 0.0401,
      "step": 20920
    },
    {
      "epoch": 8.372,
      "grad_norm": 0.394790917634964,
      "learning_rate": 8.308163265306121e-06,
      "loss": 0.0578,
      "step": 20930
    },
    {
      "epoch": 8.376,
      "grad_norm": 0.10788440704345703,
      "learning_rate": 8.287755102040816e-06,
      "loss": 0.0396,
      "step": 20940
    },
    {
      "epoch": 8.38,
      "grad_norm": 1.3133890628814697,
      "learning_rate": 8.267346938775511e-06,
      "loss": 0.0583,
      "step": 20950
    },
    {
      "epoch": 8.384,
      "grad_norm": 1.312947392463684,
      "learning_rate": 8.246938775510205e-06,
      "loss": 0.0758,
      "step": 20960
    },
    {
      "epoch": 8.388,
      "grad_norm": 2.4759702682495117,
      "learning_rate": 8.226530612244898e-06,
      "loss": 0.0848,
      "step": 20970
    },
    {
      "epoch": 8.392,
      "grad_norm": 0.22138741612434387,
      "learning_rate": 8.206122448979591e-06,
      "loss": 0.0442,
      "step": 20980
    },
    {
      "epoch": 8.396,
      "grad_norm": 0.44585397839546204,
      "learning_rate": 8.185714285714286e-06,
      "loss": 0.0505,
      "step": 20990
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.05312023311853409,
      "learning_rate": 8.165306122448981e-06,
      "loss": 0.0494,
      "step": 21000
    },
    {
      "epoch": 8.404,
      "grad_norm": 0.15767300128936768,
      "learning_rate": 8.144897959183674e-06,
      "loss": 0.0479,
      "step": 21010
    },
    {
      "epoch": 8.408,
      "grad_norm": 0.35271403193473816,
      "learning_rate": 8.124489795918368e-06,
      "loss": 0.0621,
      "step": 21020
    },
    {
      "epoch": 8.412,
      "grad_norm": 0.2206406593322754,
      "learning_rate": 8.104081632653061e-06,
      "loss": 0.0664,
      "step": 21030
    },
    {
      "epoch": 8.416,
      "grad_norm": 0.07396864145994186,
      "learning_rate": 8.083673469387754e-06,
      "loss": 0.0639,
      "step": 21040
    },
    {
      "epoch": 8.42,
      "grad_norm": 0.06283783912658691,
      "learning_rate": 8.06326530612245e-06,
      "loss": 0.0579,
      "step": 21050
    },
    {
      "epoch": 8.424,
      "grad_norm": 0.8368384838104248,
      "learning_rate": 8.042857142857144e-06,
      "loss": 0.05,
      "step": 21060
    },
    {
      "epoch": 8.428,
      "grad_norm": 1.8844207525253296,
      "learning_rate": 8.022448979591838e-06,
      "loss": 0.0776,
      "step": 21070
    },
    {
      "epoch": 8.432,
      "grad_norm": 0.8850238919258118,
      "learning_rate": 8.00204081632653e-06,
      "loss": 0.0354,
      "step": 21080
    },
    {
      "epoch": 8.436,
      "grad_norm": 1.0677549839019775,
      "learning_rate": 7.981632653061224e-06,
      "loss": 0.073,
      "step": 21090
    },
    {
      "epoch": 8.44,
      "grad_norm": 0.56574547290802,
      "learning_rate": 7.961224489795917e-06,
      "loss": 0.0754,
      "step": 21100
    },
    {
      "epoch": 8.444,
      "grad_norm": 0.7575340270996094,
      "learning_rate": 7.940816326530612e-06,
      "loss": 0.077,
      "step": 21110
    },
    {
      "epoch": 8.448,
      "grad_norm": 0.15808452665805817,
      "learning_rate": 7.920408163265307e-06,
      "loss": 0.0986,
      "step": 21120
    },
    {
      "epoch": 8.452,
      "grad_norm": 0.42306944727897644,
      "learning_rate": 7.9e-06,
      "loss": 0.0666,
      "step": 21130
    },
    {
      "epoch": 8.456,
      "grad_norm": 0.7711167931556702,
      "learning_rate": 7.879591836734694e-06,
      "loss": 0.0632,
      "step": 21140
    },
    {
      "epoch": 8.46,
      "grad_norm": 1.0763881206512451,
      "learning_rate": 7.859183673469387e-06,
      "loss": 0.0742,
      "step": 21150
    },
    {
      "epoch": 8.464,
      "grad_norm": 0.06687500327825546,
      "learning_rate": 7.838775510204082e-06,
      "loss": 0.0734,
      "step": 21160
    },
    {
      "epoch": 8.468,
      "grad_norm": 0.8654347658157349,
      "learning_rate": 7.818367346938777e-06,
      "loss": 0.0994,
      "step": 21170
    },
    {
      "epoch": 8.472,
      "grad_norm": 0.3182615637779236,
      "learning_rate": 7.79795918367347e-06,
      "loss": 0.0307,
      "step": 21180
    },
    {
      "epoch": 8.475999999999999,
      "grad_norm": 1.5370224714279175,
      "learning_rate": 7.777551020408164e-06,
      "loss": 0.0585,
      "step": 21190
    },
    {
      "epoch": 8.48,
      "grad_norm": 2.156935691833496,
      "learning_rate": 7.757142857142857e-06,
      "loss": 0.0613,
      "step": 21200
    },
    {
      "epoch": 8.484,
      "grad_norm": 0.8107689619064331,
      "learning_rate": 7.73673469387755e-06,
      "loss": 0.0508,
      "step": 21210
    },
    {
      "epoch": 8.488,
      "grad_norm": 0.3436775505542755,
      "learning_rate": 7.716326530612245e-06,
      "loss": 0.0797,
      "step": 21220
    },
    {
      "epoch": 8.492,
      "grad_norm": 0.23005066812038422,
      "learning_rate": 7.69591836734694e-06,
      "loss": 0.044,
      "step": 21230
    },
    {
      "epoch": 8.496,
      "grad_norm": 1.1815738677978516,
      "learning_rate": 7.675510204081633e-06,
      "loss": 0.0931,
      "step": 21240
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.1036920547485352,
      "learning_rate": 7.655102040816327e-06,
      "loss": 0.1144,
      "step": 21250
    },
    {
      "epoch": 8.504,
      "grad_norm": 0.6103699803352356,
      "learning_rate": 7.63469387755102e-06,
      "loss": 0.0584,
      "step": 21260
    },
    {
      "epoch": 8.508,
      "grad_norm": 2.064575433731079,
      "learning_rate": 7.614285714285714e-06,
      "loss": 0.1089,
      "step": 21270
    },
    {
      "epoch": 8.512,
      "grad_norm": 0.5055886507034302,
      "learning_rate": 7.593877551020409e-06,
      "loss": 0.0732,
      "step": 21280
    },
    {
      "epoch": 8.516,
      "grad_norm": 0.5388458967208862,
      "learning_rate": 7.573469387755102e-06,
      "loss": 0.0402,
      "step": 21290
    },
    {
      "epoch": 8.52,
      "grad_norm": 1.3494198322296143,
      "learning_rate": 7.5530612244897965e-06,
      "loss": 0.1116,
      "step": 21300
    },
    {
      "epoch": 8.524000000000001,
      "grad_norm": 0.9507012367248535,
      "learning_rate": 7.53265306122449e-06,
      "loss": 0.0673,
      "step": 21310
    },
    {
      "epoch": 8.528,
      "grad_norm": 0.5652436017990112,
      "learning_rate": 7.512244897959184e-06,
      "loss": 0.0382,
      "step": 21320
    },
    {
      "epoch": 8.532,
      "grad_norm": 1.2674509286880493,
      "learning_rate": 7.491836734693877e-06,
      "loss": 0.0683,
      "step": 21330
    },
    {
      "epoch": 8.536,
      "grad_norm": 0.23903660476207733,
      "learning_rate": 7.471428571428572e-06,
      "loss": 0.0574,
      "step": 21340
    },
    {
      "epoch": 8.54,
      "grad_norm": 0.23869392275810242,
      "learning_rate": 7.451020408163266e-06,
      "loss": 0.05,
      "step": 21350
    },
    {
      "epoch": 8.544,
      "grad_norm": 0.9527525901794434,
      "learning_rate": 7.4306122448979595e-06,
      "loss": 0.0512,
      "step": 21360
    },
    {
      "epoch": 8.548,
      "grad_norm": 0.17488066852092743,
      "learning_rate": 7.410204081632653e-06,
      "loss": 0.0203,
      "step": 21370
    },
    {
      "epoch": 8.552,
      "grad_norm": 1.4158660173416138,
      "learning_rate": 7.389795918367347e-06,
      "loss": 0.0703,
      "step": 21380
    },
    {
      "epoch": 8.556000000000001,
      "grad_norm": 1.4444186687469482,
      "learning_rate": 7.369387755102042e-06,
      "loss": 0.0667,
      "step": 21390
    },
    {
      "epoch": 8.56,
      "grad_norm": 0.24977974593639374,
      "learning_rate": 7.348979591836735e-06,
      "loss": 0.0416,
      "step": 21400
    },
    {
      "epoch": 8.564,
      "grad_norm": 0.06401783227920532,
      "learning_rate": 7.328571428571429e-06,
      "loss": 0.0552,
      "step": 21410
    },
    {
      "epoch": 8.568,
      "grad_norm": 0.7481815814971924,
      "learning_rate": 7.308163265306123e-06,
      "loss": 0.0903,
      "step": 21420
    },
    {
      "epoch": 8.572,
      "grad_norm": 1.285627841949463,
      "learning_rate": 7.287755102040817e-06,
      "loss": 0.075,
      "step": 21430
    },
    {
      "epoch": 8.576,
      "grad_norm": 0.6820053458213806,
      "learning_rate": 7.26734693877551e-06,
      "loss": 0.0781,
      "step": 21440
    },
    {
      "epoch": 8.58,
      "grad_norm": 1.0015631914138794,
      "learning_rate": 7.246938775510205e-06,
      "loss": 0.0635,
      "step": 21450
    },
    {
      "epoch": 8.584,
      "grad_norm": 1.8881397247314453,
      "learning_rate": 7.226530612244898e-06,
      "loss": 0.0559,
      "step": 21460
    },
    {
      "epoch": 8.588,
      "grad_norm": 0.1763942390680313,
      "learning_rate": 7.206122448979592e-06,
      "loss": 0.0524,
      "step": 21470
    },
    {
      "epoch": 8.592,
      "grad_norm": 1.6829502582550049,
      "learning_rate": 7.185714285714286e-06,
      "loss": 0.0644,
      "step": 21480
    },
    {
      "epoch": 8.596,
      "grad_norm": 1.7522168159484863,
      "learning_rate": 7.16530612244898e-06,
      "loss": 0.0668,
      "step": 21490
    },
    {
      "epoch": 8.6,
      "grad_norm": 1.3782919645309448,
      "learning_rate": 7.144897959183673e-06,
      "loss": 0.0487,
      "step": 21500
    },
    {
      "epoch": 8.604,
      "grad_norm": 0.943353533744812,
      "learning_rate": 7.124489795918368e-06,
      "loss": 0.0517,
      "step": 21510
    },
    {
      "epoch": 8.608,
      "grad_norm": 0.8413397073745728,
      "learning_rate": 7.104081632653062e-06,
      "loss": 0.0439,
      "step": 21520
    },
    {
      "epoch": 8.612,
      "grad_norm": 0.40012624859809875,
      "learning_rate": 7.083673469387755e-06,
      "loss": 0.0421,
      "step": 21530
    },
    {
      "epoch": 8.616,
      "grad_norm": 0.4449642598628998,
      "learning_rate": 7.063265306122449e-06,
      "loss": 0.0507,
      "step": 21540
    },
    {
      "epoch": 8.62,
      "grad_norm": 1.1888326406478882,
      "learning_rate": 7.042857142857143e-06,
      "loss": 0.0406,
      "step": 21550
    },
    {
      "epoch": 8.624,
      "grad_norm": 1.7374821901321411,
      "learning_rate": 7.022448979591838e-06,
      "loss": 0.1145,
      "step": 21560
    },
    {
      "epoch": 8.628,
      "grad_norm": 1.7164736986160278,
      "learning_rate": 7.002040816326531e-06,
      "loss": 0.0747,
      "step": 21570
    },
    {
      "epoch": 8.632,
      "grad_norm": 0.03876575082540512,
      "learning_rate": 6.981632653061225e-06,
      "loss": 0.0733,
      "step": 21580
    },
    {
      "epoch": 8.636,
      "grad_norm": 0.30938518047332764,
      "learning_rate": 6.9612244897959185e-06,
      "loss": 0.0607,
      "step": 21590
    },
    {
      "epoch": 8.64,
      "grad_norm": 0.9242736101150513,
      "learning_rate": 6.940816326530613e-06,
      "loss": 0.0468,
      "step": 21600
    },
    {
      "epoch": 8.644,
      "grad_norm": 0.7810598611831665,
      "learning_rate": 6.920408163265306e-06,
      "loss": 0.0761,
      "step": 21610
    },
    {
      "epoch": 8.648,
      "grad_norm": 1.8622263669967651,
      "learning_rate": 6.900000000000001e-06,
      "loss": 0.0413,
      "step": 21620
    },
    {
      "epoch": 8.652,
      "grad_norm": 0.7451707124710083,
      "learning_rate": 6.879591836734694e-06,
      "loss": 0.0722,
      "step": 21630
    },
    {
      "epoch": 8.656,
      "grad_norm": 0.367694616317749,
      "learning_rate": 6.859183673469388e-06,
      "loss": 0.0952,
      "step": 21640
    },
    {
      "epoch": 8.66,
      "grad_norm": 0.3176288306713104,
      "learning_rate": 6.8387755102040815e-06,
      "loss": 0.0658,
      "step": 21650
    },
    {
      "epoch": 8.664,
      "grad_norm": 0.2578260898590088,
      "learning_rate": 6.818367346938776e-06,
      "loss": 0.0434,
      "step": 21660
    },
    {
      "epoch": 8.668,
      "grad_norm": 1.0222402811050415,
      "learning_rate": 6.797959183673469e-06,
      "loss": 0.0625,
      "step": 21670
    },
    {
      "epoch": 8.672,
      "grad_norm": 0.33215051889419556,
      "learning_rate": 6.777551020408164e-06,
      "loss": 0.0798,
      "step": 21680
    },
    {
      "epoch": 8.676,
      "grad_norm": 0.8285396695137024,
      "learning_rate": 6.757142857142858e-06,
      "loss": 0.0768,
      "step": 21690
    },
    {
      "epoch": 8.68,
      "grad_norm": 0.290194034576416,
      "learning_rate": 6.736734693877551e-06,
      "loss": 0.0295,
      "step": 21700
    },
    {
      "epoch": 8.684,
      "grad_norm": 0.00516881188377738,
      "learning_rate": 6.716326530612245e-06,
      "loss": 0.0454,
      "step": 21710
    },
    {
      "epoch": 8.688,
      "grad_norm": 0.5860009789466858,
      "learning_rate": 6.695918367346939e-06,
      "loss": 0.0382,
      "step": 21720
    },
    {
      "epoch": 8.692,
      "grad_norm": 0.31042712926864624,
      "learning_rate": 6.675510204081634e-06,
      "loss": 0.0692,
      "step": 21730
    },
    {
      "epoch": 8.696,
      "grad_norm": 1.225111722946167,
      "learning_rate": 6.655102040816327e-06,
      "loss": 0.057,
      "step": 21740
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.6655300855636597,
      "learning_rate": 6.634693877551021e-06,
      "loss": 0.0337,
      "step": 21750
    },
    {
      "epoch": 8.704,
      "grad_norm": 0.8059629797935486,
      "learning_rate": 6.614285714285714e-06,
      "loss": 0.0959,
      "step": 21760
    },
    {
      "epoch": 8.708,
      "grad_norm": 1.132385492324829,
      "learning_rate": 6.5938775510204085e-06,
      "loss": 0.0798,
      "step": 21770
    },
    {
      "epoch": 8.712,
      "grad_norm": 1.33633553981781,
      "learning_rate": 6.573469387755102e-06,
      "loss": 0.0983,
      "step": 21780
    },
    {
      "epoch": 8.716,
      "grad_norm": 0.9159920811653137,
      "learning_rate": 6.553061224489797e-06,
      "loss": 0.0699,
      "step": 21790
    },
    {
      "epoch": 8.72,
      "grad_norm": 1.2040441036224365,
      "learning_rate": 6.532653061224491e-06,
      "loss": 0.0593,
      "step": 21800
    },
    {
      "epoch": 8.724,
      "grad_norm": 0.4662970304489136,
      "learning_rate": 6.512244897959184e-06,
      "loss": 0.0459,
      "step": 21810
    },
    {
      "epoch": 8.728,
      "grad_norm": 0.8042556047439575,
      "learning_rate": 6.491836734693877e-06,
      "loss": 0.0873,
      "step": 21820
    },
    {
      "epoch": 8.732,
      "grad_norm": 1.3311108350753784,
      "learning_rate": 6.4714285714285715e-06,
      "loss": 0.0466,
      "step": 21830
    },
    {
      "epoch": 8.736,
      "grad_norm": 0.5255174040794373,
      "learning_rate": 6.451020408163265e-06,
      "loss": 0.0759,
      "step": 21840
    },
    {
      "epoch": 8.74,
      "grad_norm": 0.9278506636619568,
      "learning_rate": 6.43061224489796e-06,
      "loss": 0.0893,
      "step": 21850
    },
    {
      "epoch": 8.744,
      "grad_norm": 1.4917393922805786,
      "learning_rate": 6.410204081632654e-06,
      "loss": 0.0749,
      "step": 21860
    },
    {
      "epoch": 8.748,
      "grad_norm": 0.11850645393133163,
      "learning_rate": 6.389795918367347e-06,
      "loss": 0.0189,
      "step": 21870
    },
    {
      "epoch": 8.752,
      "grad_norm": 2.5656514167785645,
      "learning_rate": 6.3693877551020405e-06,
      "loss": 0.0441,
      "step": 21880
    },
    {
      "epoch": 8.756,
      "grad_norm": 0.24592143297195435,
      "learning_rate": 6.348979591836735e-06,
      "loss": 0.0269,
      "step": 21890
    },
    {
      "epoch": 8.76,
      "grad_norm": 0.031610894948244095,
      "learning_rate": 6.3285714285714296e-06,
      "loss": 0.0287,
      "step": 21900
    },
    {
      "epoch": 8.764,
      "grad_norm": 0.9815226197242737,
      "learning_rate": 6.308163265306123e-06,
      "loss": 0.0598,
      "step": 21910
    },
    {
      "epoch": 8.768,
      "grad_norm": 0.007431467063724995,
      "learning_rate": 6.287755102040817e-06,
      "loss": 0.0688,
      "step": 21920
    },
    {
      "epoch": 8.772,
      "grad_norm": 0.38517895340919495,
      "learning_rate": 6.26734693877551e-06,
      "loss": 0.0389,
      "step": 21930
    },
    {
      "epoch": 8.776,
      "grad_norm": 1.2187851667404175,
      "learning_rate": 6.246938775510204e-06,
      "loss": 0.0857,
      "step": 21940
    },
    {
      "epoch": 8.78,
      "grad_norm": 1.3534679412841797,
      "learning_rate": 6.2265306122448985e-06,
      "loss": 0.0765,
      "step": 21950
    },
    {
      "epoch": 8.784,
      "grad_norm": 0.18033571541309357,
      "learning_rate": 6.206122448979592e-06,
      "loss": 0.0531,
      "step": 21960
    },
    {
      "epoch": 8.788,
      "grad_norm": 0.8732843399047852,
      "learning_rate": 6.185714285714287e-06,
      "loss": 0.0595,
      "step": 21970
    },
    {
      "epoch": 8.792,
      "grad_norm": 0.10615465044975281,
      "learning_rate": 6.16530612244898e-06,
      "loss": 0.0174,
      "step": 21980
    },
    {
      "epoch": 8.796,
      "grad_norm": 0.522102415561676,
      "learning_rate": 6.144897959183673e-06,
      "loss": 0.0802,
      "step": 21990
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.2243768870830536,
      "learning_rate": 6.124489795918368e-06,
      "loss": 0.0693,
      "step": 22000
    },
    {
      "epoch": 8.804,
      "grad_norm": 0.2647874057292938,
      "learning_rate": 6.1040816326530616e-06,
      "loss": 0.0284,
      "step": 22010
    },
    {
      "epoch": 8.808,
      "grad_norm": 1.1343841552734375,
      "learning_rate": 6.083673469387755e-06,
      "loss": 0.0562,
      "step": 22020
    },
    {
      "epoch": 8.812,
      "grad_norm": 0.19226117432117462,
      "learning_rate": 6.06326530612245e-06,
      "loss": 0.0602,
      "step": 22030
    },
    {
      "epoch": 8.816,
      "grad_norm": 0.8447650671005249,
      "learning_rate": 6.042857142857143e-06,
      "loss": 0.0763,
      "step": 22040
    },
    {
      "epoch": 8.82,
      "grad_norm": 0.104707732796669,
      "learning_rate": 6.022448979591837e-06,
      "loss": 0.0558,
      "step": 22050
    },
    {
      "epoch": 8.824,
      "grad_norm": 2.355064868927002,
      "learning_rate": 6.002040816326531e-06,
      "loss": 0.0591,
      "step": 22060
    },
    {
      "epoch": 8.828,
      "grad_norm": 0.24367991089820862,
      "learning_rate": 5.981632653061225e-06,
      "loss": 0.0605,
      "step": 22070
    },
    {
      "epoch": 8.832,
      "grad_norm": 1.300600290298462,
      "learning_rate": 5.961224489795919e-06,
      "loss": 0.0628,
      "step": 22080
    },
    {
      "epoch": 8.836,
      "grad_norm": 0.43074139952659607,
      "learning_rate": 5.940816326530613e-06,
      "loss": 0.0754,
      "step": 22090
    },
    {
      "epoch": 8.84,
      "grad_norm": 1.1273386478424072,
      "learning_rate": 5.920408163265306e-06,
      "loss": 0.0596,
      "step": 22100
    },
    {
      "epoch": 8.844,
      "grad_norm": 1.3561111688613892,
      "learning_rate": 5.9e-06,
      "loss": 0.0521,
      "step": 22110
    },
    {
      "epoch": 8.848,
      "grad_norm": 0.3117345869541168,
      "learning_rate": 5.879591836734694e-06,
      "loss": 0.0721,
      "step": 22120
    },
    {
      "epoch": 8.852,
      "grad_norm": 0.4680955410003662,
      "learning_rate": 5.859183673469388e-06,
      "loss": 0.0508,
      "step": 22130
    },
    {
      "epoch": 8.856,
      "grad_norm": 0.44777292013168335,
      "learning_rate": 5.838775510204083e-06,
      "loss": 0.0493,
      "step": 22140
    },
    {
      "epoch": 8.86,
      "grad_norm": 0.7360290884971619,
      "learning_rate": 5.818367346938776e-06,
      "loss": 0.048,
      "step": 22150
    },
    {
      "epoch": 8.864,
      "grad_norm": 0.48203641176223755,
      "learning_rate": 5.797959183673469e-06,
      "loss": 0.0502,
      "step": 22160
    },
    {
      "epoch": 8.868,
      "grad_norm": 0.6222926378250122,
      "learning_rate": 5.777551020408164e-06,
      "loss": 0.0528,
      "step": 22170
    },
    {
      "epoch": 8.872,
      "grad_norm": 1.1240178346633911,
      "learning_rate": 5.7571428571428574e-06,
      "loss": 0.0734,
      "step": 22180
    },
    {
      "epoch": 8.876,
      "grad_norm": 1.307289958000183,
      "learning_rate": 5.736734693877551e-06,
      "loss": 0.08,
      "step": 22190
    },
    {
      "epoch": 8.88,
      "grad_norm": 0.38565465807914734,
      "learning_rate": 5.716326530612246e-06,
      "loss": 0.0774,
      "step": 22200
    },
    {
      "epoch": 8.884,
      "grad_norm": 0.2085622102022171,
      "learning_rate": 5.695918367346939e-06,
      "loss": 0.0768,
      "step": 22210
    },
    {
      "epoch": 8.888,
      "grad_norm": 0.13509340584278107,
      "learning_rate": 5.675510204081633e-06,
      "loss": 0.0755,
      "step": 22220
    },
    {
      "epoch": 8.892,
      "grad_norm": 0.7440593242645264,
      "learning_rate": 5.655102040816327e-06,
      "loss": 0.0729,
      "step": 22230
    },
    {
      "epoch": 8.896,
      "grad_norm": 1.723789095878601,
      "learning_rate": 5.6346938775510205e-06,
      "loss": 0.0697,
      "step": 22240
    },
    {
      "epoch": 8.9,
      "grad_norm": 0.6131852269172668,
      "learning_rate": 5.614285714285715e-06,
      "loss": 0.0692,
      "step": 22250
    },
    {
      "epoch": 8.904,
      "grad_norm": 0.5708765387535095,
      "learning_rate": 5.593877551020409e-06,
      "loss": 0.0503,
      "step": 22260
    },
    {
      "epoch": 8.908,
      "grad_norm": 0.11904697865247726,
      "learning_rate": 5.573469387755102e-06,
      "loss": 0.0486,
      "step": 22270
    },
    {
      "epoch": 8.912,
      "grad_norm": 1.3138478994369507,
      "learning_rate": 5.553061224489796e-06,
      "loss": 0.0565,
      "step": 22280
    },
    {
      "epoch": 8.916,
      "grad_norm": 0.031466543674468994,
      "learning_rate": 5.53265306122449e-06,
      "loss": 0.0761,
      "step": 22290
    },
    {
      "epoch": 8.92,
      "grad_norm": 0.1995389610528946,
      "learning_rate": 5.5122448979591836e-06,
      "loss": 0.055,
      "step": 22300
    },
    {
      "epoch": 8.924,
      "grad_norm": 0.1116352453827858,
      "learning_rate": 5.4918367346938785e-06,
      "loss": 0.0717,
      "step": 22310
    },
    {
      "epoch": 8.928,
      "grad_norm": 0.2038067728281021,
      "learning_rate": 5.471428571428572e-06,
      "loss": 0.0334,
      "step": 22320
    },
    {
      "epoch": 8.932,
      "grad_norm": 0.5318784713745117,
      "learning_rate": 5.451020408163265e-06,
      "loss": 0.063,
      "step": 22330
    },
    {
      "epoch": 8.936,
      "grad_norm": 0.7307229042053223,
      "learning_rate": 5.43061224489796e-06,
      "loss": 0.0761,
      "step": 22340
    },
    {
      "epoch": 8.94,
      "grad_norm": 0.20800764858722687,
      "learning_rate": 5.410204081632653e-06,
      "loss": 0.0222,
      "step": 22350
    },
    {
      "epoch": 8.943999999999999,
      "grad_norm": 0.3286333680152893,
      "learning_rate": 5.389795918367347e-06,
      "loss": 0.034,
      "step": 22360
    },
    {
      "epoch": 8.948,
      "grad_norm": 1.8707176446914673,
      "learning_rate": 5.369387755102042e-06,
      "loss": 0.0569,
      "step": 22370
    },
    {
      "epoch": 8.952,
      "grad_norm": 1.4356191158294678,
      "learning_rate": 5.348979591836735e-06,
      "loss": 0.0779,
      "step": 22380
    },
    {
      "epoch": 8.956,
      "grad_norm": 1.3258508443832397,
      "learning_rate": 5.328571428571429e-06,
      "loss": 0.0376,
      "step": 22390
    },
    {
      "epoch": 8.96,
      "grad_norm": 0.6030747890472412,
      "learning_rate": 5.308163265306123e-06,
      "loss": 0.079,
      "step": 22400
    },
    {
      "epoch": 8.964,
      "grad_norm": 0.5337899327278137,
      "learning_rate": 5.287755102040816e-06,
      "loss": 0.0758,
      "step": 22410
    },
    {
      "epoch": 8.968,
      "grad_norm": 0.994440495967865,
      "learning_rate": 5.2673469387755105e-06,
      "loss": 0.0659,
      "step": 22420
    },
    {
      "epoch": 8.972,
      "grad_norm": 0.21991309523582458,
      "learning_rate": 5.246938775510205e-06,
      "loss": 0.0639,
      "step": 22430
    },
    {
      "epoch": 8.975999999999999,
      "grad_norm": 1.891791582107544,
      "learning_rate": 5.226530612244898e-06,
      "loss": 0.0603,
      "step": 22440
    },
    {
      "epoch": 8.98,
      "grad_norm": 0.3317027688026428,
      "learning_rate": 5.206122448979592e-06,
      "loss": 0.0713,
      "step": 22450
    },
    {
      "epoch": 8.984,
      "grad_norm": 2.226853847503662,
      "learning_rate": 5.185714285714286e-06,
      "loss": 0.0551,
      "step": 22460
    },
    {
      "epoch": 8.988,
      "grad_norm": 0.21832242608070374,
      "learning_rate": 5.1653061224489794e-06,
      "loss": 0.086,
      "step": 22470
    },
    {
      "epoch": 8.992,
      "grad_norm": 0.6263203620910645,
      "learning_rate": 5.1448979591836736e-06,
      "loss": 0.0462,
      "step": 22480
    },
    {
      "epoch": 8.996,
      "grad_norm": 0.8663492798805237,
      "learning_rate": 5.124489795918368e-06,
      "loss": 0.0891,
      "step": 22490
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.2783132493495941,
      "learning_rate": 5.104081632653061e-06,
      "loss": 0.0539,
      "step": 22500
    },
    {
      "epoch": 9.004,
      "grad_norm": 0.0773688554763794,
      "learning_rate": 5.083673469387756e-06,
      "loss": 0.1024,
      "step": 22510
    },
    {
      "epoch": 9.008,
      "grad_norm": 1.5149714946746826,
      "learning_rate": 5.063265306122449e-06,
      "loss": 0.0351,
      "step": 22520
    },
    {
      "epoch": 9.012,
      "grad_norm": 1.9762986898422241,
      "learning_rate": 5.042857142857143e-06,
      "loss": 0.0695,
      "step": 22530
    },
    {
      "epoch": 9.016,
      "grad_norm": 1.2888904809951782,
      "learning_rate": 5.0224489795918375e-06,
      "loss": 0.0538,
      "step": 22540
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.8989208936691284,
      "learning_rate": 5.002040816326531e-06,
      "loss": 0.0868,
      "step": 22550
    },
    {
      "epoch": 9.024,
      "grad_norm": 0.5388416051864624,
      "learning_rate": 4.981632653061225e-06,
      "loss": 0.0297,
      "step": 22560
    },
    {
      "epoch": 9.028,
      "grad_norm": 0.5266205668449402,
      "learning_rate": 4.961224489795919e-06,
      "loss": 0.0831,
      "step": 22570
    },
    {
      "epoch": 9.032,
      "grad_norm": 0.9843430519104004,
      "learning_rate": 4.940816326530612e-06,
      "loss": 0.0321,
      "step": 22580
    },
    {
      "epoch": 9.036,
      "grad_norm": 0.46366289258003235,
      "learning_rate": 4.920408163265306e-06,
      "loss": 0.0639,
      "step": 22590
    },
    {
      "epoch": 9.04,
      "grad_norm": 0.9314762353897095,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 0.0256,
      "step": 22600
    },
    {
      "epoch": 9.044,
      "grad_norm": 0.09413178265094757,
      "learning_rate": 4.879591836734694e-06,
      "loss": 0.069,
      "step": 22610
    },
    {
      "epoch": 9.048,
      "grad_norm": 0.5550455451011658,
      "learning_rate": 4.859183673469388e-06,
      "loss": 0.033,
      "step": 22620
    },
    {
      "epoch": 9.052,
      "grad_norm": 0.07211538404226303,
      "learning_rate": 4.838775510204082e-06,
      "loss": 0.0406,
      "step": 22630
    },
    {
      "epoch": 9.056,
      "grad_norm": 0.8711054921150208,
      "learning_rate": 4.818367346938775e-06,
      "loss": 0.038,
      "step": 22640
    },
    {
      "epoch": 9.06,
      "grad_norm": 0.6863800287246704,
      "learning_rate": 4.7979591836734694e-06,
      "loss": 0.0546,
      "step": 22650
    },
    {
      "epoch": 9.064,
      "grad_norm": 1.3086659908294678,
      "learning_rate": 4.7775510204081636e-06,
      "loss": 0.0666,
      "step": 22660
    },
    {
      "epoch": 9.068,
      "grad_norm": 0.02899380959570408,
      "learning_rate": 4.757142857142857e-06,
      "loss": 0.0792,
      "step": 22670
    },
    {
      "epoch": 9.072,
      "grad_norm": 1.237491250038147,
      "learning_rate": 4.736734693877552e-06,
      "loss": 0.0735,
      "step": 22680
    },
    {
      "epoch": 9.076,
      "grad_norm": 0.5602355599403381,
      "learning_rate": 4.716326530612245e-06,
      "loss": 0.1106,
      "step": 22690
    },
    {
      "epoch": 9.08,
      "grad_norm": 1.1353384256362915,
      "learning_rate": 4.695918367346939e-06,
      "loss": 0.0541,
      "step": 22700
    },
    {
      "epoch": 9.084,
      "grad_norm": 0.007268612738698721,
      "learning_rate": 4.675510204081633e-06,
      "loss": 0.0467,
      "step": 22710
    },
    {
      "epoch": 9.088,
      "grad_norm": 2.1169557571411133,
      "learning_rate": 4.655102040816327e-06,
      "loss": 0.066,
      "step": 22720
    },
    {
      "epoch": 9.092,
      "grad_norm": 0.7449683547019958,
      "learning_rate": 4.634693877551021e-06,
      "loss": 0.0468,
      "step": 22730
    },
    {
      "epoch": 9.096,
      "grad_norm": 1.7691949605941772,
      "learning_rate": 4.614285714285715e-06,
      "loss": 0.0576,
      "step": 22740
    },
    {
      "epoch": 9.1,
      "grad_norm": 0.10433332622051239,
      "learning_rate": 4.593877551020408e-06,
      "loss": 0.0508,
      "step": 22750
    },
    {
      "epoch": 9.104,
      "grad_norm": 0.36633965373039246,
      "learning_rate": 4.573469387755102e-06,
      "loss": 0.0526,
      "step": 22760
    },
    {
      "epoch": 9.108,
      "grad_norm": 0.12594878673553467,
      "learning_rate": 4.553061224489796e-06,
      "loss": 0.0207,
      "step": 22770
    },
    {
      "epoch": 9.112,
      "grad_norm": 0.2864735424518585,
      "learning_rate": 4.53265306122449e-06,
      "loss": 0.0532,
      "step": 22780
    },
    {
      "epoch": 9.116,
      "grad_norm": 0.264819860458374,
      "learning_rate": 4.512244897959184e-06,
      "loss": 0.041,
      "step": 22790
    },
    {
      "epoch": 9.12,
      "grad_norm": 0.06312666833400726,
      "learning_rate": 4.491836734693878e-06,
      "loss": 0.0599,
      "step": 22800
    },
    {
      "epoch": 9.124,
      "grad_norm": 0.6263453364372253,
      "learning_rate": 4.471428571428571e-06,
      "loss": 0.0448,
      "step": 22810
    },
    {
      "epoch": 9.128,
      "grad_norm": 0.23097309470176697,
      "learning_rate": 4.451020408163265e-06,
      "loss": 0.0381,
      "step": 22820
    },
    {
      "epoch": 9.132,
      "grad_norm": 0.5426933765411377,
      "learning_rate": 4.4306122448979595e-06,
      "loss": 0.0323,
      "step": 22830
    },
    {
      "epoch": 9.136,
      "grad_norm": 0.25334522128105164,
      "learning_rate": 4.410204081632653e-06,
      "loss": 0.0631,
      "step": 22840
    },
    {
      "epoch": 9.14,
      "grad_norm": 1.506721019744873,
      "learning_rate": 4.389795918367348e-06,
      "loss": 0.0613,
      "step": 22850
    },
    {
      "epoch": 9.144,
      "grad_norm": 1.3723468780517578,
      "learning_rate": 4.369387755102041e-06,
      "loss": 0.0341,
      "step": 22860
    },
    {
      "epoch": 9.148,
      "grad_norm": 0.7693566083908081,
      "learning_rate": 4.348979591836735e-06,
      "loss": 0.0393,
      "step": 22870
    },
    {
      "epoch": 9.152,
      "grad_norm": 1.5127428770065308,
      "learning_rate": 4.328571428571429e-06,
      "loss": 0.0687,
      "step": 22880
    },
    {
      "epoch": 9.156,
      "grad_norm": 0.0457845963537693,
      "learning_rate": 4.3081632653061225e-06,
      "loss": 0.0404,
      "step": 22890
    },
    {
      "epoch": 9.16,
      "grad_norm": 1.1464455127716064,
      "learning_rate": 4.287755102040817e-06,
      "loss": 0.0876,
      "step": 22900
    },
    {
      "epoch": 9.164,
      "grad_norm": 0.8146435022354126,
      "learning_rate": 4.267346938775511e-06,
      "loss": 0.0637,
      "step": 22910
    },
    {
      "epoch": 9.168,
      "grad_norm": 1.2002884149551392,
      "learning_rate": 4.246938775510204e-06,
      "loss": 0.0886,
      "step": 22920
    },
    {
      "epoch": 9.172,
      "grad_norm": 0.7259697914123535,
      "learning_rate": 4.226530612244898e-06,
      "loss": 0.0969,
      "step": 22930
    },
    {
      "epoch": 9.176,
      "grad_norm": 0.19060403108596802,
      "learning_rate": 4.206122448979592e-06,
      "loss": 0.0627,
      "step": 22940
    },
    {
      "epoch": 9.18,
      "grad_norm": 1.1814510822296143,
      "learning_rate": 4.1857142857142856e-06,
      "loss": 0.0551,
      "step": 22950
    },
    {
      "epoch": 9.184,
      "grad_norm": 0.8830876350402832,
      "learning_rate": 4.16530612244898e-06,
      "loss": 0.0774,
      "step": 22960
    },
    {
      "epoch": 9.188,
      "grad_norm": 1.2936816215515137,
      "learning_rate": 4.144897959183674e-06,
      "loss": 0.0394,
      "step": 22970
    },
    {
      "epoch": 9.192,
      "grad_norm": 0.41494718194007874,
      "learning_rate": 4.124489795918367e-06,
      "loss": 0.0527,
      "step": 22980
    },
    {
      "epoch": 9.196,
      "grad_norm": 1.9706743955612183,
      "learning_rate": 4.104081632653061e-06,
      "loss": 0.0516,
      "step": 22990
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.9869312047958374,
      "learning_rate": 4.083673469387755e-06,
      "loss": 0.0492,
      "step": 23000
    },
    {
      "epoch": 9.204,
      "grad_norm": 1.5036590099334717,
      "learning_rate": 4.063265306122449e-06,
      "loss": 0.0488,
      "step": 23010
    },
    {
      "epoch": 9.208,
      "grad_norm": 1.2437723875045776,
      "learning_rate": 4.042857142857144e-06,
      "loss": 0.0545,
      "step": 23020
    },
    {
      "epoch": 9.212,
      "grad_norm": 0.3820272982120514,
      "learning_rate": 4.022448979591837e-06,
      "loss": 0.0576,
      "step": 23030
    },
    {
      "epoch": 9.216,
      "grad_norm": 1.8860433101654053,
      "learning_rate": 4.002040816326531e-06,
      "loss": 0.05,
      "step": 23040
    },
    {
      "epoch": 9.22,
      "grad_norm": 0.03089272603392601,
      "learning_rate": 3.981632653061225e-06,
      "loss": 0.0547,
      "step": 23050
    },
    {
      "epoch": 9.224,
      "grad_norm": 1.1976488828659058,
      "learning_rate": 3.961224489795918e-06,
      "loss": 0.0685,
      "step": 23060
    },
    {
      "epoch": 9.228,
      "grad_norm": 1.7911640405654907,
      "learning_rate": 3.9408163265306125e-06,
      "loss": 0.0699,
      "step": 23070
    },
    {
      "epoch": 9.232,
      "grad_norm": 2.208488941192627,
      "learning_rate": 3.920408163265307e-06,
      "loss": 0.0687,
      "step": 23080
    },
    {
      "epoch": 9.236,
      "grad_norm": 1.8427501916885376,
      "learning_rate": 3.9e-06,
      "loss": 0.082,
      "step": 23090
    },
    {
      "epoch": 9.24,
      "grad_norm": 1.0774446725845337,
      "learning_rate": 3.879591836734694e-06,
      "loss": 0.0418,
      "step": 23100
    },
    {
      "epoch": 9.244,
      "grad_norm": 0.6590688228607178,
      "learning_rate": 3.859183673469388e-06,
      "loss": 0.0761,
      "step": 23110
    },
    {
      "epoch": 9.248,
      "grad_norm": 1.1874476671218872,
      "learning_rate": 3.8387755102040815e-06,
      "loss": 0.037,
      "step": 23120
    },
    {
      "epoch": 9.252,
      "grad_norm": 0.5757917761802673,
      "learning_rate": 3.818367346938776e-06,
      "loss": 0.1226,
      "step": 23130
    },
    {
      "epoch": 9.256,
      "grad_norm": 0.9950971603393555,
      "learning_rate": 3.7979591836734697e-06,
      "loss": 0.0504,
      "step": 23140
    },
    {
      "epoch": 9.26,
      "grad_norm": 0.3082285225391388,
      "learning_rate": 3.7775510204081634e-06,
      "loss": 0.0435,
      "step": 23150
    },
    {
      "epoch": 9.264,
      "grad_norm": 1.3459842205047607,
      "learning_rate": 3.757142857142857e-06,
      "loss": 0.0632,
      "step": 23160
    },
    {
      "epoch": 9.268,
      "grad_norm": 0.9888308644294739,
      "learning_rate": 3.7367346938775512e-06,
      "loss": 0.0472,
      "step": 23170
    },
    {
      "epoch": 9.272,
      "grad_norm": 0.19170323014259338,
      "learning_rate": 3.716326530612245e-06,
      "loss": 0.0516,
      "step": 23180
    },
    {
      "epoch": 9.276,
      "grad_norm": 0.5600842237472534,
      "learning_rate": 3.6959183673469395e-06,
      "loss": 0.0598,
      "step": 23190
    },
    {
      "epoch": 9.28,
      "grad_norm": 1.329727292060852,
      "learning_rate": 3.6755102040816328e-06,
      "loss": 0.05,
      "step": 23200
    },
    {
      "epoch": 9.284,
      "grad_norm": 0.24927794933319092,
      "learning_rate": 3.6551020408163265e-06,
      "loss": 0.0402,
      "step": 23210
    },
    {
      "epoch": 9.288,
      "grad_norm": 0.16460947692394257,
      "learning_rate": 3.634693877551021e-06,
      "loss": 0.0839,
      "step": 23220
    },
    {
      "epoch": 9.292,
      "grad_norm": 0.15275603532791138,
      "learning_rate": 3.6142857142857143e-06,
      "loss": 0.0422,
      "step": 23230
    },
    {
      "epoch": 9.296,
      "grad_norm": 1.2100307941436768,
      "learning_rate": 3.593877551020408e-06,
      "loss": 0.0508,
      "step": 23240
    },
    {
      "epoch": 9.3,
      "grad_norm": 0.015145762823522091,
      "learning_rate": 3.5734693877551025e-06,
      "loss": 0.0444,
      "step": 23250
    },
    {
      "epoch": 9.304,
      "grad_norm": 0.10409747064113617,
      "learning_rate": 3.5530612244897962e-06,
      "loss": 0.0424,
      "step": 23260
    },
    {
      "epoch": 9.308,
      "grad_norm": 0.4290270209312439,
      "learning_rate": 3.5326530612244895e-06,
      "loss": 0.0285,
      "step": 23270
    },
    {
      "epoch": 9.312,
      "grad_norm": 0.2615882158279419,
      "learning_rate": 3.512244897959184e-06,
      "loss": 0.06,
      "step": 23280
    },
    {
      "epoch": 9.316,
      "grad_norm": 1.153244972229004,
      "learning_rate": 3.4918367346938778e-06,
      "loss": 0.0484,
      "step": 23290
    },
    {
      "epoch": 9.32,
      "grad_norm": 1.5420383214950562,
      "learning_rate": 3.4714285714285715e-06,
      "loss": 0.0638,
      "step": 23300
    },
    {
      "epoch": 9.324,
      "grad_norm": 0.20435717701911926,
      "learning_rate": 3.4510204081632656e-06,
      "loss": 0.0421,
      "step": 23310
    },
    {
      "epoch": 9.328,
      "grad_norm": 0.7073861956596375,
      "learning_rate": 3.4306122448979593e-06,
      "loss": 0.0749,
      "step": 23320
    },
    {
      "epoch": 9.332,
      "grad_norm": 0.24490174651145935,
      "learning_rate": 3.410204081632653e-06,
      "loss": 0.065,
      "step": 23330
    },
    {
      "epoch": 9.336,
      "grad_norm": 0.11804884672164917,
      "learning_rate": 3.389795918367347e-06,
      "loss": 0.0673,
      "step": 23340
    },
    {
      "epoch": 9.34,
      "grad_norm": 0.5147419571876526,
      "learning_rate": 3.369387755102041e-06,
      "loss": 0.0926,
      "step": 23350
    },
    {
      "epoch": 9.344,
      "grad_norm": 0.6538210511207581,
      "learning_rate": 3.3489795918367354e-06,
      "loss": 0.0609,
      "step": 23360
    },
    {
      "epoch": 9.348,
      "grad_norm": 1.136881709098816,
      "learning_rate": 3.3285714285714286e-06,
      "loss": 0.0441,
      "step": 23370
    },
    {
      "epoch": 9.352,
      "grad_norm": 1.776400089263916,
      "learning_rate": 3.3081632653061223e-06,
      "loss": 0.0838,
      "step": 23380
    },
    {
      "epoch": 9.356,
      "grad_norm": 0.00878743827342987,
      "learning_rate": 3.287755102040817e-06,
      "loss": 0.0993,
      "step": 23390
    },
    {
      "epoch": 9.36,
      "grad_norm": 0.7191947102546692,
      "learning_rate": 3.2673469387755106e-06,
      "loss": 0.089,
      "step": 23400
    },
    {
      "epoch": 9.364,
      "grad_norm": 0.15932512283325195,
      "learning_rate": 3.246938775510204e-06,
      "loss": 0.0543,
      "step": 23410
    },
    {
      "epoch": 9.368,
      "grad_norm": 0.35714012384414673,
      "learning_rate": 3.2265306122448984e-06,
      "loss": 0.061,
      "step": 23420
    },
    {
      "epoch": 9.372,
      "grad_norm": 1.3585833311080933,
      "learning_rate": 3.206122448979592e-06,
      "loss": 0.0888,
      "step": 23430
    },
    {
      "epoch": 9.376,
      "grad_norm": 1.1207551956176758,
      "learning_rate": 3.185714285714286e-06,
      "loss": 0.0543,
      "step": 23440
    },
    {
      "epoch": 9.38,
      "grad_norm": 1.000974178314209,
      "learning_rate": 3.16530612244898e-06,
      "loss": 0.0968,
      "step": 23450
    },
    {
      "epoch": 9.384,
      "grad_norm": 0.9985191226005554,
      "learning_rate": 3.1448979591836737e-06,
      "loss": 0.0427,
      "step": 23460
    },
    {
      "epoch": 9.388,
      "grad_norm": 0.09603259712457657,
      "learning_rate": 3.1244897959183674e-06,
      "loss": 0.0439,
      "step": 23470
    },
    {
      "epoch": 9.392,
      "grad_norm": 1.7013804912567139,
      "learning_rate": 3.1040816326530615e-06,
      "loss": 0.0805,
      "step": 23480
    },
    {
      "epoch": 9.396,
      "grad_norm": 1.7893339395523071,
      "learning_rate": 3.083673469387755e-06,
      "loss": 0.0859,
      "step": 23490
    },
    {
      "epoch": 9.4,
      "grad_norm": 1.5336650609970093,
      "learning_rate": 3.0632653061224493e-06,
      "loss": 0.0676,
      "step": 23500
    },
    {
      "epoch": 9.404,
      "grad_norm": 1.6376999616622925,
      "learning_rate": 3.042857142857143e-06,
      "loss": 0.0765,
      "step": 23510
    },
    {
      "epoch": 9.408,
      "grad_norm": 1.5201085805892944,
      "learning_rate": 3.0224489795918367e-06,
      "loss": 0.0315,
      "step": 23520
    },
    {
      "epoch": 9.412,
      "grad_norm": 0.2642041742801666,
      "learning_rate": 3.002040816326531e-06,
      "loss": 0.0581,
      "step": 23530
    },
    {
      "epoch": 9.416,
      "grad_norm": 1.0525459051132202,
      "learning_rate": 2.9816326530612245e-06,
      "loss": 0.0501,
      "step": 23540
    },
    {
      "epoch": 9.42,
      "grad_norm": 0.3480600118637085,
      "learning_rate": 2.9612244897959182e-06,
      "loss": 0.065,
      "step": 23550
    },
    {
      "epoch": 9.424,
      "grad_norm": 0.8983901739120483,
      "learning_rate": 2.9408163265306124e-06,
      "loss": 0.0796,
      "step": 23560
    },
    {
      "epoch": 9.428,
      "grad_norm": 0.5719810724258423,
      "learning_rate": 2.9204081632653065e-06,
      "loss": 0.0604,
      "step": 23570
    },
    {
      "epoch": 9.432,
      "grad_norm": 0.46256542205810547,
      "learning_rate": 2.9e-06,
      "loss": 0.0884,
      "step": 23580
    },
    {
      "epoch": 9.436,
      "grad_norm": 1.61806058883667,
      "learning_rate": 2.879591836734694e-06,
      "loss": 0.0966,
      "step": 23590
    },
    {
      "epoch": 9.44,
      "grad_norm": 1.9734387397766113,
      "learning_rate": 2.859183673469388e-06,
      "loss": 0.0789,
      "step": 23600
    },
    {
      "epoch": 9.444,
      "grad_norm": 1.2528342008590698,
      "learning_rate": 2.8387755102040817e-06,
      "loss": 0.0575,
      "step": 23610
    },
    {
      "epoch": 9.448,
      "grad_norm": 0.48392584919929504,
      "learning_rate": 2.8183673469387754e-06,
      "loss": 0.0585,
      "step": 23620
    },
    {
      "epoch": 9.452,
      "grad_norm": 0.5376696586608887,
      "learning_rate": 2.7979591836734695e-06,
      "loss": 0.0638,
      "step": 23630
    },
    {
      "epoch": 9.456,
      "grad_norm": 0.08403825759887695,
      "learning_rate": 2.7775510204081637e-06,
      "loss": 0.0319,
      "step": 23640
    },
    {
      "epoch": 9.46,
      "grad_norm": 0.8536651134490967,
      "learning_rate": 2.7571428571428574e-06,
      "loss": 0.069,
      "step": 23650
    },
    {
      "epoch": 9.464,
      "grad_norm": 0.8011232018470764,
      "learning_rate": 2.736734693877551e-06,
      "loss": 0.1054,
      "step": 23660
    },
    {
      "epoch": 9.468,
      "grad_norm": 1.0206918716430664,
      "learning_rate": 2.716326530612245e-06,
      "loss": 0.0758,
      "step": 23670
    },
    {
      "epoch": 9.472,
      "grad_norm": 0.8860263228416443,
      "learning_rate": 2.695918367346939e-06,
      "loss": 0.0474,
      "step": 23680
    },
    {
      "epoch": 9.475999999999999,
      "grad_norm": 0.945909321308136,
      "learning_rate": 2.6755102040816326e-06,
      "loss": 0.1039,
      "step": 23690
    },
    {
      "epoch": 9.48,
      "grad_norm": 0.009792761877179146,
      "learning_rate": 2.6551020408163267e-06,
      "loss": 0.0572,
      "step": 23700
    },
    {
      "epoch": 9.484,
      "grad_norm": 0.6250784397125244,
      "learning_rate": 2.6346938775510204e-06,
      "loss": 0.0816,
      "step": 23710
    },
    {
      "epoch": 9.488,
      "grad_norm": 0.31091630458831787,
      "learning_rate": 2.614285714285714e-06,
      "loss": 0.0511,
      "step": 23720
    },
    {
      "epoch": 9.492,
      "grad_norm": 1.2755999565124512,
      "learning_rate": 2.5938775510204082e-06,
      "loss": 0.0702,
      "step": 23730
    },
    {
      "epoch": 9.496,
      "grad_norm": 0.6778820753097534,
      "learning_rate": 2.5734693877551024e-06,
      "loss": 0.0702,
      "step": 23740
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.18410912156105042,
      "learning_rate": 2.553061224489796e-06,
      "loss": 0.0742,
      "step": 23750
    },
    {
      "epoch": 9.504,
      "grad_norm": 0.2778388261795044,
      "learning_rate": 2.5326530612244898e-06,
      "loss": 0.0358,
      "step": 23760
    },
    {
      "epoch": 9.508,
      "grad_norm": 0.3581199049949646,
      "learning_rate": 2.512244897959184e-06,
      "loss": 0.0877,
      "step": 23770
    },
    {
      "epoch": 9.512,
      "grad_norm": 1.452761173248291,
      "learning_rate": 2.4918367346938776e-06,
      "loss": 0.0488,
      "step": 23780
    },
    {
      "epoch": 9.516,
      "grad_norm": 0.5884928703308105,
      "learning_rate": 2.4714285714285713e-06,
      "loss": 0.0522,
      "step": 23790
    },
    {
      "epoch": 9.52,
      "grad_norm": 1.6213711500167847,
      "learning_rate": 2.4510204081632654e-06,
      "loss": 0.0997,
      "step": 23800
    },
    {
      "epoch": 9.524000000000001,
      "grad_norm": 0.4050009250640869,
      "learning_rate": 2.4306122448979596e-06,
      "loss": 0.048,
      "step": 23810
    },
    {
      "epoch": 9.528,
      "grad_norm": 0.5812179446220398,
      "learning_rate": 2.4102040816326533e-06,
      "loss": 0.0543,
      "step": 23820
    },
    {
      "epoch": 9.532,
      "grad_norm": 1.4363820552825928,
      "learning_rate": 2.389795918367347e-06,
      "loss": 0.0707,
      "step": 23830
    },
    {
      "epoch": 9.536,
      "grad_norm": 0.40250712633132935,
      "learning_rate": 2.369387755102041e-06,
      "loss": 0.0443,
      "step": 23840
    },
    {
      "epoch": 9.54,
      "grad_norm": 1.5887614488601685,
      "learning_rate": 2.3489795918367348e-06,
      "loss": 0.0421,
      "step": 23850
    },
    {
      "epoch": 9.544,
      "grad_norm": 1.8562002182006836,
      "learning_rate": 2.3285714285714285e-06,
      "loss": 0.0846,
      "step": 23860
    },
    {
      "epoch": 9.548,
      "grad_norm": 1.7172499895095825,
      "learning_rate": 2.3081632653061226e-06,
      "loss": 0.0894,
      "step": 23870
    },
    {
      "epoch": 9.552,
      "grad_norm": 1.1342155933380127,
      "learning_rate": 2.2877551020408167e-06,
      "loss": 0.0614,
      "step": 23880
    },
    {
      "epoch": 9.556000000000001,
      "grad_norm": 1.9659192562103271,
      "learning_rate": 2.26734693877551e-06,
      "loss": 0.0812,
      "step": 23890
    },
    {
      "epoch": 9.56,
      "grad_norm": 0.8756101727485657,
      "learning_rate": 2.246938775510204e-06,
      "loss": 0.0401,
      "step": 23900
    },
    {
      "epoch": 9.564,
      "grad_norm": 1.833457112312317,
      "learning_rate": 2.2265306122448983e-06,
      "loss": 0.069,
      "step": 23910
    },
    {
      "epoch": 9.568,
      "grad_norm": 0.5505481958389282,
      "learning_rate": 2.206122448979592e-06,
      "loss": 0.0578,
      "step": 23920
    },
    {
      "epoch": 9.572,
      "grad_norm": 0.139830082654953,
      "learning_rate": 2.1857142857142857e-06,
      "loss": 0.0354,
      "step": 23930
    },
    {
      "epoch": 9.576,
      "grad_norm": 0.08549951016902924,
      "learning_rate": 2.1653061224489798e-06,
      "loss": 0.0431,
      "step": 23940
    },
    {
      "epoch": 9.58,
      "grad_norm": 1.5295857191085815,
      "learning_rate": 2.1448979591836735e-06,
      "loss": 0.0926,
      "step": 23950
    },
    {
      "epoch": 9.584,
      "grad_norm": 0.09040699899196625,
      "learning_rate": 2.124489795918367e-06,
      "loss": 0.0657,
      "step": 23960
    },
    {
      "epoch": 9.588,
      "grad_norm": 0.6503819227218628,
      "learning_rate": 2.1040816326530613e-06,
      "loss": 0.1033,
      "step": 23970
    },
    {
      "epoch": 9.592,
      "grad_norm": 0.5842853784561157,
      "learning_rate": 2.0836734693877554e-06,
      "loss": 0.0472,
      "step": 23980
    },
    {
      "epoch": 9.596,
      "grad_norm": 1.5906522274017334,
      "learning_rate": 2.0632653061224487e-06,
      "loss": 0.0506,
      "step": 23990
    },
    {
      "epoch": 9.6,
      "grad_norm": 1.3896511793136597,
      "learning_rate": 2.042857142857143e-06,
      "loss": 0.0514,
      "step": 24000
    },
    {
      "epoch": 9.604,
      "grad_norm": 2.0210561752319336,
      "learning_rate": 2.022448979591837e-06,
      "loss": 0.0742,
      "step": 24010
    },
    {
      "epoch": 9.608,
      "grad_norm": 0.48575714230537415,
      "learning_rate": 2.0020408163265307e-06,
      "loss": 0.078,
      "step": 24020
    },
    {
      "epoch": 9.612,
      "grad_norm": 1.167042851448059,
      "learning_rate": 1.9816326530612244e-06,
      "loss": 0.0623,
      "step": 24030
    },
    {
      "epoch": 9.616,
      "grad_norm": 0.05817323923110962,
      "learning_rate": 1.9612244897959185e-06,
      "loss": 0.0662,
      "step": 24040
    },
    {
      "epoch": 9.62,
      "grad_norm": 1.3450417518615723,
      "learning_rate": 1.9408163265306126e-06,
      "loss": 0.0604,
      "step": 24050
    },
    {
      "epoch": 9.624,
      "grad_norm": 1.6727198362350464,
      "learning_rate": 1.920408163265306e-06,
      "loss": 0.053,
      "step": 24060
    },
    {
      "epoch": 9.628,
      "grad_norm": 1.7735207080841064,
      "learning_rate": 1.9e-06,
      "loss": 0.0822,
      "step": 24070
    },
    {
      "epoch": 9.632,
      "grad_norm": 0.3456853926181793,
      "learning_rate": 1.879591836734694e-06,
      "loss": 0.0318,
      "step": 24080
    },
    {
      "epoch": 9.636,
      "grad_norm": 1.0713634490966797,
      "learning_rate": 1.859183673469388e-06,
      "loss": 0.0633,
      "step": 24090
    },
    {
      "epoch": 9.64,
      "grad_norm": 0.2573932409286499,
      "learning_rate": 1.8387755102040815e-06,
      "loss": 0.0773,
      "step": 24100
    },
    {
      "epoch": 9.644,
      "grad_norm": 0.9922465682029724,
      "learning_rate": 1.8183673469387757e-06,
      "loss": 0.0565,
      "step": 24110
    },
    {
      "epoch": 9.648,
      "grad_norm": 1.2874836921691895,
      "learning_rate": 1.7979591836734696e-06,
      "loss": 0.0603,
      "step": 24120
    },
    {
      "epoch": 9.652,
      "grad_norm": 1.2786370515823364,
      "learning_rate": 1.7775510204081633e-06,
      "loss": 0.0709,
      "step": 24130
    },
    {
      "epoch": 9.656,
      "grad_norm": 0.9210026264190674,
      "learning_rate": 1.7571428571428572e-06,
      "loss": 0.0696,
      "step": 24140
    },
    {
      "epoch": 9.66,
      "grad_norm": 0.1473308652639389,
      "learning_rate": 1.7367346938775511e-06,
      "loss": 0.0805,
      "step": 24150
    },
    {
      "epoch": 9.664,
      "grad_norm": 0.6159886121749878,
      "learning_rate": 1.7163265306122448e-06,
      "loss": 0.0499,
      "step": 24160
    },
    {
      "epoch": 9.668,
      "grad_norm": 1.94334077835083,
      "learning_rate": 1.6959183673469387e-06,
      "loss": 0.0891,
      "step": 24170
    },
    {
      "epoch": 9.672,
      "grad_norm": 0.3704563081264496,
      "learning_rate": 1.6755102040816329e-06,
      "loss": 0.0555,
      "step": 24180
    },
    {
      "epoch": 9.676,
      "grad_norm": 0.03399214148521423,
      "learning_rate": 1.6551020408163268e-06,
      "loss": 0.06,
      "step": 24190
    },
    {
      "epoch": 9.68,
      "grad_norm": 0.15800486505031586,
      "learning_rate": 1.6346938775510205e-06,
      "loss": 0.0552,
      "step": 24200
    },
    {
      "epoch": 9.684,
      "grad_norm": 1.234185814857483,
      "learning_rate": 1.6142857142857144e-06,
      "loss": 0.1036,
      "step": 24210
    },
    {
      "epoch": 9.688,
      "grad_norm": 0.8244636654853821,
      "learning_rate": 1.5938775510204083e-06,
      "loss": 0.0434,
      "step": 24220
    },
    {
      "epoch": 9.692,
      "grad_norm": 0.18421119451522827,
      "learning_rate": 1.573469387755102e-06,
      "loss": 0.0593,
      "step": 24230
    },
    {
      "epoch": 9.696,
      "grad_norm": 0.20664124190807343,
      "learning_rate": 1.553061224489796e-06,
      "loss": 0.049,
      "step": 24240
    },
    {
      "epoch": 9.7,
      "grad_norm": 0.48118922114372253,
      "learning_rate": 1.53265306122449e-06,
      "loss": 0.0435,
      "step": 24250
    },
    {
      "epoch": 9.704,
      "grad_norm": 0.14511509239673615,
      "learning_rate": 1.5122448979591837e-06,
      "loss": 0.0668,
      "step": 24260
    },
    {
      "epoch": 9.708,
      "grad_norm": 1.602657675743103,
      "learning_rate": 1.4918367346938774e-06,
      "loss": 0.0712,
      "step": 24270
    },
    {
      "epoch": 9.712,
      "grad_norm": 0.41460123658180237,
      "learning_rate": 1.4714285714285716e-06,
      "loss": 0.0523,
      "step": 24280
    },
    {
      "epoch": 9.716,
      "grad_norm": 1.0387192964553833,
      "learning_rate": 1.4510204081632653e-06,
      "loss": 0.0387,
      "step": 24290
    },
    {
      "epoch": 9.72,
      "grad_norm": 0.35416778922080994,
      "learning_rate": 1.4306122448979594e-06,
      "loss": 0.0466,
      "step": 24300
    },
    {
      "epoch": 9.724,
      "grad_norm": 1.1086888313293457,
      "learning_rate": 1.410204081632653e-06,
      "loss": 0.049,
      "step": 24310
    },
    {
      "epoch": 9.728,
      "grad_norm": 1.3248612880706787,
      "learning_rate": 1.389795918367347e-06,
      "loss": 0.1082,
      "step": 24320
    },
    {
      "epoch": 9.732,
      "grad_norm": 0.2755374014377594,
      "learning_rate": 1.369387755102041e-06,
      "loss": 0.0359,
      "step": 24330
    },
    {
      "epoch": 9.736,
      "grad_norm": 0.9658117890357971,
      "learning_rate": 1.3489795918367346e-06,
      "loss": 0.0362,
      "step": 24340
    },
    {
      "epoch": 9.74,
      "grad_norm": 0.7652403116226196,
      "learning_rate": 1.3285714285714287e-06,
      "loss": 0.0674,
      "step": 24350
    },
    {
      "epoch": 9.744,
      "grad_norm": 0.7681308388710022,
      "learning_rate": 1.3081632653061224e-06,
      "loss": 0.0428,
      "step": 24360
    },
    {
      "epoch": 9.748,
      "grad_norm": 1.229833960533142,
      "learning_rate": 1.2877551020408166e-06,
      "loss": 0.0609,
      "step": 24370
    },
    {
      "epoch": 9.752,
      "grad_norm": 0.3093283474445343,
      "learning_rate": 1.2673469387755103e-06,
      "loss": 0.0914,
      "step": 24380
    },
    {
      "epoch": 9.756,
      "grad_norm": 0.77833092212677,
      "learning_rate": 1.246938775510204e-06,
      "loss": 0.0837,
      "step": 24390
    },
    {
      "epoch": 9.76,
      "grad_norm": 0.19969165325164795,
      "learning_rate": 1.226530612244898e-06,
      "loss": 0.0616,
      "step": 24400
    },
    {
      "epoch": 9.764,
      "grad_norm": 1.8286027908325195,
      "learning_rate": 1.2061224489795918e-06,
      "loss": 0.0599,
      "step": 24410
    },
    {
      "epoch": 9.768,
      "grad_norm": 1.3994321823120117,
      "learning_rate": 1.185714285714286e-06,
      "loss": 0.0451,
      "step": 24420
    },
    {
      "epoch": 9.772,
      "grad_norm": 1.0549415349960327,
      "learning_rate": 1.1653061224489796e-06,
      "loss": 0.0453,
      "step": 24430
    },
    {
      "epoch": 9.776,
      "grad_norm": 1.7360787391662598,
      "learning_rate": 1.1448979591836735e-06,
      "loss": 0.1021,
      "step": 24440
    },
    {
      "epoch": 9.78,
      "grad_norm": 0.6708832383155823,
      "learning_rate": 1.1244897959183674e-06,
      "loss": 0.0873,
      "step": 24450
    },
    {
      "epoch": 9.784,
      "grad_norm": 1.6947740316390991,
      "learning_rate": 1.1040816326530611e-06,
      "loss": 0.0421,
      "step": 24460
    },
    {
      "epoch": 9.788,
      "grad_norm": 0.9256719946861267,
      "learning_rate": 1.0836734693877553e-06,
      "loss": 0.0663,
      "step": 24470
    },
    {
      "epoch": 9.792,
      "grad_norm": 0.7989009618759155,
      "learning_rate": 1.063265306122449e-06,
      "loss": 0.1082,
      "step": 24480
    },
    {
      "epoch": 9.796,
      "grad_norm": 0.28860294818878174,
      "learning_rate": 1.0428571428571429e-06,
      "loss": 0.027,
      "step": 24490
    },
    {
      "epoch": 9.8,
      "grad_norm": 0.5842697620391846,
      "learning_rate": 1.0224489795918368e-06,
      "loss": 0.0577,
      "step": 24500
    },
    {
      "epoch": 9.804,
      "grad_norm": 0.06086952984333038,
      "learning_rate": 1.0020408163265305e-06,
      "loss": 0.0653,
      "step": 24510
    },
    {
      "epoch": 9.808,
      "grad_norm": 0.9159743189811707,
      "learning_rate": 9.816326530612246e-07,
      "loss": 0.0461,
      "step": 24520
    },
    {
      "epoch": 9.812,
      "grad_norm": 0.28542324900627136,
      "learning_rate": 9.612244897959183e-07,
      "loss": 0.0786,
      "step": 24530
    },
    {
      "epoch": 9.816,
      "grad_norm": 0.07198817282915115,
      "learning_rate": 9.408163265306123e-07,
      "loss": 0.0501,
      "step": 24540
    },
    {
      "epoch": 9.82,
      "grad_norm": 0.6244613528251648,
      "learning_rate": 9.204081632653062e-07,
      "loss": 0.0368,
      "step": 24550
    },
    {
      "epoch": 9.824,
      "grad_norm": 1.3034749031066895,
      "learning_rate": 9e-07,
      "loss": 0.1198,
      "step": 24560
    },
    {
      "epoch": 9.828,
      "grad_norm": 0.8334771990776062,
      "learning_rate": 8.79591836734694e-07,
      "loss": 0.0444,
      "step": 24570
    },
    {
      "epoch": 9.832,
      "grad_norm": 0.5064961314201355,
      "learning_rate": 8.591836734693878e-07,
      "loss": 0.0571,
      "step": 24580
    },
    {
      "epoch": 9.836,
      "grad_norm": 0.2888171970844269,
      "learning_rate": 8.387755102040817e-07,
      "loss": 0.0573,
      "step": 24590
    },
    {
      "epoch": 9.84,
      "grad_norm": 0.4068416655063629,
      "learning_rate": 8.183673469387755e-07,
      "loss": 0.0707,
      "step": 24600
    },
    {
      "epoch": 9.844,
      "grad_norm": 1.4303797483444214,
      "learning_rate": 7.979591836734693e-07,
      "loss": 0.0557,
      "step": 24610
    },
    {
      "epoch": 9.848,
      "grad_norm": 0.40786948800086975,
      "learning_rate": 7.775510204081633e-07,
      "loss": 0.0398,
      "step": 24620
    },
    {
      "epoch": 9.852,
      "grad_norm": 1.0800104141235352,
      "learning_rate": 7.571428571428572e-07,
      "loss": 0.0588,
      "step": 24630
    },
    {
      "epoch": 9.856,
      "grad_norm": 1.8228319883346558,
      "learning_rate": 7.36734693877551e-07,
      "loss": 0.0762,
      "step": 24640
    },
    {
      "epoch": 9.86,
      "grad_norm": 0.7076947093009949,
      "learning_rate": 7.16326530612245e-07,
      "loss": 0.0472,
      "step": 24650
    },
    {
      "epoch": 9.864,
      "grad_norm": 0.7933372259140015,
      "learning_rate": 6.959183673469388e-07,
      "loss": 0.0545,
      "step": 24660
    },
    {
      "epoch": 9.868,
      "grad_norm": 1.4608209133148193,
      "learning_rate": 6.755102040816327e-07,
      "loss": 0.0657,
      "step": 24670
    },
    {
      "epoch": 9.872,
      "grad_norm": 0.27958062291145325,
      "learning_rate": 6.551020408163266e-07,
      "loss": 0.0521,
      "step": 24680
    },
    {
      "epoch": 9.876,
      "grad_norm": 1.043463945388794,
      "learning_rate": 6.346938775510204e-07,
      "loss": 0.0448,
      "step": 24690
    },
    {
      "epoch": 9.88,
      "grad_norm": 0.836286723613739,
      "learning_rate": 6.142857142857143e-07,
      "loss": 0.0428,
      "step": 24700
    },
    {
      "epoch": 9.884,
      "grad_norm": 1.4726907014846802,
      "learning_rate": 5.938775510204082e-07,
      "loss": 0.0624,
      "step": 24710
    },
    {
      "epoch": 9.888,
      "grad_norm": 0.15842722356319427,
      "learning_rate": 5.73469387755102e-07,
      "loss": 0.0395,
      "step": 24720
    },
    {
      "epoch": 9.892,
      "grad_norm": 1.39445960521698,
      "learning_rate": 5.53061224489796e-07,
      "loss": 0.0512,
      "step": 24730
    },
    {
      "epoch": 9.896,
      "grad_norm": 0.027696790173649788,
      "learning_rate": 5.326530612244899e-07,
      "loss": 0.0424,
      "step": 24740
    },
    {
      "epoch": 9.9,
      "grad_norm": 1.2277663946151733,
      "learning_rate": 5.122448979591837e-07,
      "loss": 0.0807,
      "step": 24750
    },
    {
      "epoch": 9.904,
      "grad_norm": 0.2168160080909729,
      "learning_rate": 4.918367346938776e-07,
      "loss": 0.0501,
      "step": 24760
    },
    {
      "epoch": 9.908,
      "grad_norm": 1.1550402641296387,
      "learning_rate": 4.7142857142857145e-07,
      "loss": 0.0547,
      "step": 24770
    },
    {
      "epoch": 9.912,
      "grad_norm": 1.6077178716659546,
      "learning_rate": 4.5102040816326536e-07,
      "loss": 0.0933,
      "step": 24780
    },
    {
      "epoch": 9.916,
      "grad_norm": 0.193800151348114,
      "learning_rate": 4.306122448979592e-07,
      "loss": 0.0348,
      "step": 24790
    },
    {
      "epoch": 9.92,
      "grad_norm": 1.2730413675308228,
      "learning_rate": 4.10204081632653e-07,
      "loss": 0.089,
      "step": 24800
    },
    {
      "epoch": 9.924,
      "grad_norm": 1.3874046802520752,
      "learning_rate": 3.89795918367347e-07,
      "loss": 0.0646,
      "step": 24810
    },
    {
      "epoch": 9.928,
      "grad_norm": 0.28288733959198,
      "learning_rate": 3.693877551020408e-07,
      "loss": 0.0583,
      "step": 24820
    },
    {
      "epoch": 9.932,
      "grad_norm": 0.180215522646904,
      "learning_rate": 3.489795918367347e-07,
      "loss": 0.0566,
      "step": 24830
    },
    {
      "epoch": 9.936,
      "grad_norm": 1.4219051599502563,
      "learning_rate": 3.285714285714286e-07,
      "loss": 0.0336,
      "step": 24840
    },
    {
      "epoch": 9.94,
      "grad_norm": 0.6382414102554321,
      "learning_rate": 3.0816326530612243e-07,
      "loss": 0.0538,
      "step": 24850
    },
    {
      "epoch": 9.943999999999999,
      "grad_norm": 0.35861340165138245,
      "learning_rate": 2.8775510204081634e-07,
      "loss": 0.0616,
      "step": 24860
    },
    {
      "epoch": 9.948,
      "grad_norm": 0.045330170542001724,
      "learning_rate": 2.673469387755102e-07,
      "loss": 0.0506,
      "step": 24870
    },
    {
      "epoch": 9.952,
      "grad_norm": 0.2410009205341339,
      "learning_rate": 2.4693877551020407e-07,
      "loss": 0.0521,
      "step": 24880
    },
    {
      "epoch": 9.956,
      "grad_norm": 0.04019743949174881,
      "learning_rate": 2.2653061224489798e-07,
      "loss": 0.0795,
      "step": 24890
    },
    {
      "epoch": 9.96,
      "grad_norm": 1.4330130815505981,
      "learning_rate": 2.0612244897959184e-07,
      "loss": 0.0395,
      "step": 24900
    },
    {
      "epoch": 9.964,
      "grad_norm": 1.4861546754837036,
      "learning_rate": 1.8571428571428572e-07,
      "loss": 0.0491,
      "step": 24910
    },
    {
      "epoch": 9.968,
      "grad_norm": 0.4696558713912964,
      "learning_rate": 1.6530612244897958e-07,
      "loss": 0.0386,
      "step": 24920
    },
    {
      "epoch": 9.972,
      "grad_norm": 0.16586028039455414,
      "learning_rate": 1.4489795918367347e-07,
      "loss": 0.0512,
      "step": 24930
    },
    {
      "epoch": 9.975999999999999,
      "grad_norm": 1.6764792203903198,
      "learning_rate": 1.2448979591836736e-07,
      "loss": 0.0722,
      "step": 24940
    },
    {
      "epoch": 9.98,
      "grad_norm": 0.564096987247467,
      "learning_rate": 1.0408163265306122e-07,
      "loss": 0.0575,
      "step": 24950
    },
    {
      "epoch": 9.984,
      "grad_norm": 0.614526629447937,
      "learning_rate": 8.36734693877551e-08,
      "loss": 0.0404,
      "step": 24960
    },
    {
      "epoch": 9.988,
      "grad_norm": 1.8882954120635986,
      "learning_rate": 6.326530612244899e-08,
      "loss": 0.0486,
      "step": 24970
    },
    {
      "epoch": 9.992,
      "grad_norm": 1.0146781206130981,
      "learning_rate": 4.285714285714286e-08,
      "loss": 0.074,
      "step": 24980
    },
    {
      "epoch": 9.996,
      "grad_norm": 1.0687519311904907,
      "learning_rate": 2.2448979591836735e-08,
      "loss": 0.0762,
      "step": 24990
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.4290846586227417,
      "learning_rate": 2.040816326530612e-09,
      "loss": 0.071,
      "step": 25000
    }
  ],
  "logging_steps": 10,
  "max_steps": 25000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
